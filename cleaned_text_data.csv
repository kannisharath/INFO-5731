paperId,title,abstract,clean_abstract
55ad5e818cfed72317576027fb33a9609210d592,Training and Evaluating a Jupyter Notebook Data Science Assistant,"We study the feasibility of a Data Science assistant powered by a sequence-to-sequence transformer by training a new model JuPyT5 on all publicly available Jupyter Notebook GitHub repositories and developing a new metric: Data Science Problems (DSP). DSP is a collection of 1119 problems curated from 306 pedagogical notebooks with 92 dataset dependencies, natural language and Markdown problem descriptions, and assert-based unit tests. These notebooks were designed to test university students' mastery of various Python implementations of Math and Data Science, and we now leverage them to study the ability of JuPyT5 to understand and pass the tests. We analyze the content of DSP, validate its quality, and we find that given 100 sampling attempts JuPyT5 is able to solve 77.5\% of the DSP problems. We further present various ablation and statistical analyses and compare DSP to other recent natural language to code benchmarks.",studi feasibl data scienc assist power sequencetosequ transform train new model jupyt publicli avail jupyt notebook github repositori develop new metric data scienc problem dsp dsp collect problem curat pedagog notebook dataset depend natur languag markdown problem descript assertbas unit test notebook design test univers student masteri variou python implement math data scienc leverag studi abil jupyt understand pass test analyz content dsp valid qualiti find given sampl attempt jupyt abl solv dsp problem present variou ablat statist analys compar dsp recent natur languag code benchmark
70fe060c12b3f100148d1a2be1e8f4254022543e,The case for data science in experimental chemistry: examples and recommendations,,nan
0934b1ae89f61279ac864327a9f3ea961cf1fd1c,Data Science,,nan
9a727f29f01c5efc66a977332e523b37f73ea372,SMU Data Science Review SMU Data Science,". Before the internet, high-speed laptop computers, and big data became accessible and popular, academia on stock market trading concentrated on Efficient Market Hypothesis (EMH). EMH hinges on the idea that the market is efficient and there is no extra return that could be generated. With the dynamic development of the internet, big-data and computing technology, many researchers started to pay attention to Technical Analysis and its usage. Numerous academic papers claimed that technical analysis can enhance returns by using various technical tools. This paper explores in-depth the simulation model of Moving Average and Moving Average Convergence/Divergence (MACD) to come up with optimized parameters that will allow traders to profit from trading Dow Jones Industrial Index and Hang Seng Index.",internet highspe laptop comput big data becam access popular academia stock market trade concentr effici market hypothesi emh emh hing idea market effici extra return could gener dynam develop internet bigdata comput technolog mani research start pay attent technic analysi usag numer academ paper claim technic analysi enhanc return use variou technic tool paper explor indepth simul model move averag move averag convergencediverg macd come optim paramet allow trader profit trade dow jone industri index hang seng index
88ca84ce36ddc1bf7b6593b7f73fe2663e2365ad,Foundations of Data Science,"Computer science as an academic discipline began in the 1960’s. Emphasis was on programming languages, compilers, operating systems, and the mathematical theory that supported these areas. Courses in theoretical computer science covered finite automata, regular expressions, context-free languages, and computability. In the 1970’s, the study of algorithms was added as an important component of theory. The emphasis was on making computers useful. Today, a fundamental change is taking place and the focus is more on applications. There are many reasons for this change. The merging of computing and communications has played an important role. The enhanced ability to observe, collect, and store data in the natural sciences, in commerce, and in other fields calls for a change in our understanding of data and how to handle it in the modern setting. The emergence of the web and social networks as central aspects of daily life presents both opportunities and challenges for theory.",comput scienc academ disciplin began emphasi program languag compil oper system mathemat theori support area cours theoret comput scienc cover finit automata regular express contextfre languag comput studi algorithm ad import compon theori emphasi make comput use today fundament chang take place focu applic mani reason chang merg comput commun play import role enhanc abil observ collect store data natur scienc commerc field call chang understand data handl modern set emerg web social network central aspect daili life present opportun challeng theori
108acf9a358512a40191d857e2456aeaaac3303b,Diversifying the genomic data science research community,"Over the past 20 years, the explosion of genomic data collection and the cloud computing revolution have made computational and data science research accessible to anyone with a web browser and an internet connection. However, students at institutions with limited resources have received relatively little exposure to curricula or professional development opportunities that lead to careers in genomic data science. To broaden participation in genomics research, the scientific community needs to support these programs in local education and research at underserved institutions (UIs). These include community colleges, historically Black colleges and universities, Hispanic-serving institutions, and tribal colleges and universities that support ethnically, racially, and socioeconomically underrepresented students in the United States. We have formed the Genomic Data Science Community Network to support students, faculty, and their networks to identify opportunities and broaden access to genomic data science. These opportunities include expanding access to infrastructure and data, providing UI faculty development opportunities, strengthening collaborations among faculty, recognizing UI teaching and research excellence, fostering student awareness, developing modular and open-source resources, expanding course-based undergraduate research experiences (CUREs), building curriculum, supporting student professional development and research, and removing financial barriers through funding programs and collaborator support.",past year explos genom data collect cloud comput revolut made comput data scienc research access anyon web browser internet connect howev student institut limit resourc receiv rel littl exposur curricula profession develop opportun lead career genom data scienc broaden particip genom research scientif commun need support program local educ research underserv institut ui includ commun colleg histor black colleg univers hispanicserv institut tribal colleg univers support ethnic racial socioeconom underrepres student unit state form genom data scienc commun network support student faculti network identifi opportun broaden access genom data scienc opportun includ expand access infrastructur data provid ui faculti develop opportun strengthen collabor among faculti recogn ui teach research excel foster student awar develop modular opensourc resourc expand coursebas undergradu research experi cure build curriculum support student profession develop research remov financi barrier fund program collabor support
4c6e31458b0b44c1e8bd6e58f7d7e0767f7fde44,CRISP-DM Twenty Years Later: From Data Mining Processes to Data Science Trajectories,"CRISP-DM(CRoss-Industry Standard Process for Data Mining) has its origins in the second half of the nineties and is thus about two decades old. According to many surveys and user polls it is still the de facto standard for developing data mining and knowledge discovery projects. However, undoubtedly the field has moved on considerably in twenty years, with data science now the leading term being favoured over data mining. In this paper we investigate whether, and in what contexts, CRISP-DM is still fit for purpose for data science projects. We argue that if the project is goal-directed and process-driven the process model view still largely holds. On the other hand, when data science projects become more exploratory the paths that the project can take become more varied, and a more flexible model is called for. We suggest what the outlines of such a trajectory-based model might look like and how it can be used to categorise data science projects (goal-directed, exploratory or data management). We examine seven real-life exemplars where exploratory activities play an important role and compare them against 51 use cases extracted from the NIST Big Data Public Working Group. We anticipate this categorisation can help project planning in terms of time and cost characteristics.",crispdmcrossindustri standard process data mine origin second half nineti thu two decad old accord mani survey user poll still de facto standard develop data mine knowledg discoveri project howev undoubtedli field move consider twenti year data scienc lead term favour data mine paper investig whether context crispdm still fit purpos data scienc project argu project goaldirect processdriven process model view still larg hold hand data scienc project becom exploratori path project take becom vari flexibl model call suggest outlin trajectorybas model might look like use categoris data scienc project goaldirect exploratori data manag examin seven reallif exemplar exploratori activ play import role compar use case extract nist big data public work group anticip categoris help project plan term time cost characterist
646b226e4fb7b81512e8bec11c3a9d4107f36c70,Data Science,"Data Science refers to an arising district of work regard the accumulation, arrangement, reasoning, imagination, administration, and protection of abundant groups of facts. Although the name Data Science appears to combine most powerfully accompanying extents to a degree databases and information technology, many various types of abilities containing nonmathematical abilities are still wanted attending. Data Science is much in addition to plainly analysing data. The main aim of Data Science search out turn big sets of two together unorganized and organized data into valuable news that can help organisations to create strong data-compelled resolutions. At a extreme level, data erudition maybe defined as a set of fundamental law unavoidable for profitable ancestry of news from data. Since we accumulate data continually and about everything, its use is various. The most average request is in healthcare, travel, e - trade, sports, management, public publishing, etc. The aim concerning this paper search out present data erudition and to present allure benefits and request in differing fields.",data scienc refer aris district work regard accumul arrang reason imagin administr protect abund group fact although name data scienc appear combin power accompani extent degre databas inform technolog mani variou type abil contain nonmathemat abil still want attend data scienc much addit plainli analys data main aim data scienc search turn big set two togeth unorgan organ data valuabl news help organis creat strong datacompel resolut extrem level data erudit mayb defin set fundament law unavoid profit ancestri news data sinc accumul data continu everyth use variou averag request healthcar travel e trade sport manag public publish etc aim concern paper search present data erudit present allur benefit request differ field
370d248f97b75c4040e5828a658bbe4c3b80bf1e,Eleven grand challenges in single-cell data science,,nan
72d3ddf1f7210d7e70144bbc09f770ec411fe909,"Machine Learning in Python: Main developments and technology trends in data science, machine learning, and artificial intelligence","Smarter applications are making better use of the insights gleaned from data, having an impact on every industry and research discipline. At the core of this revolution lies the tools and the methods that are driving it, from processing the massive piles of data generated each day to learning from and taking useful action. Deep neural networks, along with advancements in classical machine learning and scalable general-purpose graphics processing unit (GPU) computing, have become critical components of artificial intelligence, enabling many of these astounding breakthroughs and lowering the barrier to adoption. Python continues to be the most preferred language for scientific computing, data science, and machine learning, boosting both performance and productivity by enabling the use of low-level libraries and clean high-level APIs. This survey offers insight into the field of machine learning with Python, taking a tour through important topics to identify some of the core hardware and software paradigms that have enabled it. We cover widely-used libraries and concepts, collected together for holistic comparison, with the goal of educating the reader and driving the field of Python machine learning forward.",smarter applic make better use insight glean data impact everi industri research disciplin core revolut lie tool method drive process massiv pile data gener day learn take use action deep neural network along advanc classic machin learn scalabl generalpurpos graphic process unit gpu comput becom critic compon artifici intellig enabl mani astound breakthrough lower barrier adopt python continu prefer languag scientif comput data scienc machin learn boost perform product enabl use lowlevel librari clean highlevel api survey offer insight field machin learn python take tour import topic identifi core hardwar softwar paradigm enabl cover widelyus librari concept collect togeth holist comparison goal educ reader drive field python machin learn forward
b79ca6fd3df135a9bcf778844be625b764fbcfb3,Nucleus segmentation across imaging experiments: the 2018 Data Science Bowl,,nan
9bcf291c6245a3c2ee101babf4c1f0bbfa166f92,Data science approach to stock prices forecasting in Indonesia during Covid-19 using Long Short-Term Memory (LSTM),,nan
7282f5c9d84cd47c516a6a66c5a6b8f1e2cf44b6,AutoDS: Towards Human-Centered Automation of Data Science,"Data science (DS) projects often follow a lifecycle that consists of laborious tasks for data scientists and domain experts (e.g., data exploration, model training, etc.). Only till recently, machine learning(ML) researchers have developed promising automation techniques to aid data workers in these tasks. This paper introduces AutoDS, an automated machine learning (AutoML) system that aims to leverage the latest ML automation techniques to support data science projects. Data workers only need to upload their dataset, then the system can automatically suggest ML configurations, preprocess data, select algorithm, and train the model. These suggestions are presented to the user via a web-based graphical user interface and a notebook-based programming user interface. Our goal is to offer a systematic investigation of user interaction and perceptions of using an AutoDS system in solving a data science task. We studied AutoDS with 30 professional data scientists, where one group used AutoDS, and the other did not, to complete a data science project. As expected, AutoDS improves productivity; Yet surprisingly, we find that the models produced by the AutoDS group have higher quality and less errors, but lower human confidence scores. We reflect on the findings by presenting design implications for incorporating automation techniques into human work in the data science lifecycle.",data scienc ds project often follow lifecycl consist labori task data scientist domain expert eg data explor model train etc till recent machin learningml research develop promis autom techniqu aid data worker task paper introduc autod autom machin learn automl system aim leverag latest ml autom techniqu support data scienc project data worker need upload dataset system automat suggest ml configur preprocess data select algorithm train model suggest present user via webbas graphic user interfac notebookbas program user interfac goal offer systemat investig user interact percept use autod system solv data scienc task studi autod profession data scientist one group use autod complet data scienc project expect autod improv product yet surprisingli find model produc autod group higher qualiti less error lower human confid score reflect find present design implic incorpor autom techniqu human work data scienc lifecycl
44321686d59d889af1760357940f04fbb6629597,"The role of data science in healthcare advancements: applications, benefits, and future prospects",,nan
ede0a8039a561905f40777ec2ae66c2010e3f2bc,Cybersecurity data science: an overview from machine learning perspective,,nan
0405bfdc3f0ecb8e9d31ae68911731e61a65c01d,Surgical data science and artificial intelligence for surgical education,"Surgical data science (SDS) aims to improve the quality of interventional healthcare and its value through the capture, organization, analysis, and modeling of procedural data. As data capture has increased and artificial intelligence (AI) has advanced, SDS can help to unlock augmented and automated coaching, feedback, assessment, and decision support in surgery. We review major concepts in SDS and AI as applied to surgical education and surgical oncology.",surgic data scienc sd aim improv qualiti intervent healthcar valu captur organ analysi model procedur data data captur increas artifici intellig ai advanc sd help unlock augment autom coach feedback assess decis support surgeri review major concept sd ai appli surgic educ surgic oncolog
f9d403c58db99e2214f43e5b1740694b9c79002f,"The Art and Practice of Data Science Pipelines: A Comprehensive Study of Data Science Pipelines In Theory, In-The-Small, and In-The-Large","Increasingly larger number of software systems today are including data science components for descriptive, predictive, and prescriptive analytics. The collection of data science stages from acquisition, to cleaning/curation, to modeling, and so on are referred to as data science pipelines. To facilitate research and practice on data science pipelines, it is essential to understand their nature. What are the typical stages of a data science pipeline? How are they connected? Do the pipelines differ in the theoretical representations and that in the practice? Today we do not fully understand these architectural characteristics of data science pipelines. In this work, we present a three-pronged comprehensive study to answer this for the state-of-the-art, data science in-the-small, and data science in-the-large, Our study analyzes three datasets: a collection of 71 proposals for data science pipelines and related concepts in theory, a collection of over 105 implementations of curated data science pipelines from Kaggle competitions to understand data science in-the-small, and a collection of 21 mature data science projects from GitHub to understand data science in-the-large. Our study has led to three representations of data science pipelines that capture the essence of our subjects in theory, in-the-small, and in-the-large.",increasingli larger number softwar system today includ data scienc compon descript predict prescript analyt collect data scienc stage acquisit cleaningcur model refer data scienc pipelin facilit research practic data scienc pipelin essenti understand natur typic stage data scienc pipelin connect pipelin differ theoret represent practic today fulli understand architectur characterist data scienc pipelin work present threeprong comprehens studi answer stateoftheart data scienc inthesmal data scienc inthelarg studi analyz three dataset collect propos data scienc pipelin relat concept theori collect implement curat data scienc pipelin kaggl competit understand data scienc inthesmal collect matur data scienc project github understand data scienc inthelarg studi led three represent data scienc pipelin captur essenc subject theori inthesmal inthelarg
3df3bacc84593e9efb86d2c4d3ce30463048159f,Data Science,,nan
2d6adb9636df5a8a5dbcbfaecd0c4d34d7c85034,Spectral Methods for Data Science: A Statistical Perspective,"Spectral methods have emerged as a simple yet surprisingly effective approach for extracting information from massive, noisy and incomplete data. In a nutshell, spectral methods refer to a collection of algorithms built upon the eigenvalues (resp. singular values) and eigenvectors (resp. singular vectors) of some properly designed matrices constructed from data. A diverse array of applications have been found in machine learning, data science, and signal processing. Due to their simplicity and effectiveness, spectral methods are not only used as a stand-alone estimator, but also frequently employed to initialize other more sophisticated algorithms to improve performance. 
While the studies of spectral methods can be traced back to classical matrix perturbation theory and methods of moments, the past decade has witnessed tremendous theoretical advances in demystifying their efficacy through the lens of statistical modeling, with the aid of non-asymptotic random matrix theory. This monograph aims to present a systematic, comprehensive, yet accessible introduction to spectral methods from a modern statistical perspective, highlighting their algorithmic implications in diverse large-scale applications. In particular, our exposition gravitates around several central questions that span various applications: how to characterize the sample efficiency of spectral methods in reaching a target level of statistical accuracy, and how to assess their stability in the face of random noise, missing data, and adversarial corruptions? In addition to conventional $\ell_2$ perturbation analysis, we present a systematic $\ell_{\infty}$ and $\ell_{2,\infty}$ perturbation theory for eigenspace and singular subspaces, which has only recently become available owing to a powerful ""leave-one-out"" analysis framework.",spectral method emerg simpl yet surprisingli effect approach extract inform massiv noisi incomplet data nutshel spectral method refer collect algorithm built upon eigenvalu resp singular valu eigenvector resp singular vector properli design matric construct data divers array applic found machin learn data scienc signal process due simplic effect spectral method use standalon estim also frequent employ initi sophist algorithm improv perform studi spectral method trace back classic matrix perturb theori method moment past decad wit tremend theoret advanc demystifi efficaci len statist model aid nonasymptot random matrix theori monograph aim present systemat comprehens yet access introduct spectral method modern statist perspect highlight algorithm implic divers largescal applic particular exposit gravit around sever central question span variou applic character sampl effici spectral method reach target level statist accuraci assess stabil face random nois miss data adversari corrupt addit convent ell_ perturb analysi present systemat ell_infti ell_infti perturb theori eigenspac singular subspac recent becom avail owe power leaveoneout analysi framework
8bba999de25bfb288b3f7f88e1d907aab02638b6,Big-Data Science in Porous Materials: Materials Genomics and Machine Learning,"By combining metal nodes with organic linkers we can potentially synthesize millions of possible metal–organic frameworks (MOFs). The fact that we have so many materials opens many exciting avenues but also create new challenges. We simply have too many materials to be processed using conventional, brute force, methods. In this review, we show that having so many materials allows us to use big-data methods as a powerful technique to study these materials and to discover complex correlations. The first part of the review gives an introduction to the principles of big-data science. We show how to select appropriate training sets, survey approaches that are used to represent these materials in feature space, and review different learning architectures, as well as evaluation and interpretation strategies. In the second part, we review how the different approaches of machine learning have been applied to porous materials. In particular, we discuss applications in the field of gas storage and separation, the stability of these materials, their electronic properties, and their synthesis. Given the increasing interest of the scientific community in machine learning, we expect this list to rapidly expand in the coming years.",combin metal node organ linker potenti synthes million possibl metalorgan framework mof fact mani materi open mani excit avenu also creat new challeng simpli mani materi process use convent brute forc method review show mani materi allow us use bigdata method power techniqu studi materi discov complex correl first part review give introduct principl bigdata scienc show select appropri train set survey approach use repres materi featur space review differ learn architectur well evalu interpret strategi second part review differ approach machin learn appli porou materi particular discuss applic field ga storag separ stabil materi electron properti synthesi given increas interest scientif commun machin learn expect list rapidli expand come year
f9b0b10713044c146caa84704b66804aa1e82d5e,Automating data science,"Given the complexity of data science projects and related demand for human expertise, automation has the potential to transform the data science process.",given complex data scienc project relat demand human expertis autom potenti transform data scienc process
c13147ef0b86d5ec833c272840f8f3bdacf96e7f,Data science: a game changer for science and innovation,,nan
ab8ba0f2d290a8e56eb61e10027d0b2e57d2d544,"How do Data Science Workers Collaborate? Roles, Workflows, and Tools","Today, the prominence of data science within organizations has given rise to teams of data science workers collaborating on extracting insights from data, as opposed to individual data scientists working alone. However, we still lack a deep understanding of how data science workers collaborate in practice. In this work, we conducted an online survey with 183 participants who work in various aspects of data science. We focused on their reported interactions with each other (e.g., managers with engineers) and with different tools (e.g., Jupyter Notebook). We found that data science teams are extremely collaborative and work with a variety of stakeholders and tools during the six common steps of a data science workflow (e.g., clean data and train model). We also found that the collaborative practices workers employ, such as documentation, vary according to the kinds of tools they use. Based on these findings, we discuss design implications for supporting data science team collaborations and future research directions.",today promin data scienc within organ given rise team data scienc worker collabor extract insight data oppos individu data scientist work alon howev still lack deep understand data scienc worker collabor practic work conduct onlin survey particip work variou aspect data scienc focus report interact eg manag engin differ tool eg jupyt notebook found data scienc team extrem collabor work varieti stakehold tool six common step data scienc workflow eg clean data train model also found collabor practic worker employ document vari accord kind tool use base find discuss design implic support data scienc team collabor futur research direct
0751d2fa3a54cbbb4d594f2ee47c3aa7e4003a24,Leveraging Data Science to Combat COVID-19: A Comprehensive Review,"COVID-19, an infectious disease caused by the SARS-CoV-2 virus, was declared a pandemic by the World Health Organisation (WHO) in March 2020. By mid-August 2020, more than 21 million people have tested positive worldwide. Infections have been growing rapidly and tremendous efforts are being made to fight the disease. In this paper, we attempt to systematise the various COVID-19 research activities leveraging data science, where we define data science broadly to encompass the various methods and tools—including those from artificial intelligence (AI), machine learning (ML), statistics, modeling, simulation, and data visualization—that can be used to store, process, and extract insights from data. In addition to reviewing the rapidly growing body of recent research, we survey public datasets and repositories that can be used for further work to track COVID-19 spread and mitigation strategies. As part of this, we present a bibliometric analysis of the papers produced in this short span of time. Finally, building on these insights, we highlight common challenges and pitfalls observed across the surveyed works. We also created a live resource repository at https://github.com/Data-Science-and-COVID-19/Leveraging-Data-Science-To-Combat-COVID-19-A-Comprehensive-Review that we intend to keep updated with the latest resources including new papers and datasets.",covid infecti diseas caus sarscov viru declar pandem world health organis march midaugust million peopl test posit worldwid infect grow rapidli tremend effort made fight diseas paper attempt systematis variou covid research activ leverag data scienc defin data scienc broadli encompass variou method toolsinclud artifici intellig ai machin learn ml statist model simul data visualizationthat use store process extract insight data addit review rapidli grow bodi recent research survey public dataset repositori use work track covid spread mitig strategi part present bibliometr analysi paper produc short span time final build insight highlight common challeng pitfal observ across survey work also creat live resourc repositori httpsgithubcomdatascienceandcovidleveragingdatasciencetocombatcovidacomprehensivereview intend keep updat latest resourc includ new paper dataset
1ba044d3d501dddd94b479aa9dbe55a93bfa9d5f,"QIIME 2: Reproducible, interactive, scalable, and extensible microbiome data science","We present QIIME 2, an open-source microbiome data science platform accessible to users spanning the microbiome research ecosystem, from scientists and engineers to clinicians and policy makers. QIIME 2 provides new features that will drive the next generation of microbiome research. These include interactive spatial and temporal analysis and visualization tools, support for metabolomics and shotgun metagenomics analysis, and automated data provenance tracking to ensure reproducible, transparent microbiome data science.",present qiim opensourc microbiom data scienc platform access user span microbiom research ecosystem scientist engin clinician polici maker qiim provid new featur drive next gener microbiom research includ interact spatial tempor analysi visual tool support metabolom shotgun metagenom analysi autom data proven track ensur reproduc transpar microbiom data scienc
f42c69dbd792155fee6f4d2c525971f8d43f138b,Finding Related Tables in Data Lakes for Interactive Data Science,"Many modern data science applications build on data lakes, schema-agnostic repositories of data files and data products that offer limited organization and management capabilities. There is a need to build data lake search capabilities into data science environments, so scientists and analysts can find tables, schemas, workflows, and datasets useful to their task at hand. We develop search and management solutions for the Jupyter Notebook data science platform, to enable scientists to augment training data, find potential features to extract, clean data, and find joinable or linkable tables. Our core methods also generalize to other settings where computational tasks involve execution of programs or scripts.",mani modern data scienc applic build data lake schemaagnost repositori data file data product offer limit organ manag capabl need build data lake search capabl data scienc environ scientist analyst find tabl schema workflow dataset use task hand develop search manag solut jupyt notebook data scienc platform enabl scientist augment train data find potenti featur extract clean data find joinabl linkabl tabl core method also gener set comput task involv execut program script
5b9ea2abf1c5a04b3024367409284edceb741ef2,A new paradigm for accelerating clinical data science at Stanford Medicine,"Stanford Medicine is building a new data platform for our academic research community to do better clinical data science. Hospitals have a large amount of patient data and researchers have demonstrated the ability to reuse that data and AI approaches to derive novel insights, support patient care, and improve care quality. However, the traditional data warehouse and Honest Broker approaches that are in current use, are not scalable. We are establishing a new secure Big Data platform that aims to reduce time to access and analyze data. In this platform, data is anonymized to preserve patient data privacy and made available preparatory to Institutional Review Board (IRB) submission. Furthermore, the data is standardized such that analysis done at Stanford can be replicated elsewhere using the same analytical code and clinical concepts. Finally, the analytics data warehouse integrates with a secure data science computational facility to support large scale data analytics. The ecosystem is designed to bring the modern data science community to highly sensitive clinical data in a secure and collaborative big data analytics environment with a goal to enable bigger, better and faster science.",stanford medicin build new data platform academ research commun better clinic data scienc hospit larg amount patient data research demonstr abil reus data ai approach deriv novel insight support patient care improv care qualiti howev tradit data warehous honest broker approach current use scalabl establish new secur big data platform aim reduc time access analyz data platform data anonym preserv patient data privaci made avail preparatori institut review board irb submiss furthermor data standard analysi done stanford replic elsewher use analyt code clinic concept final analyt data warehous integr secur data scienc comput facil support larg scale data analyt ecosystem design bring modern data scienc commun highli sensit clinic data secur collabor big data analyt environ goal enabl bigger better faster scienc
a4b6f802b3f416fb1af6d723e0549c5e6d34faae,Data science in economics: comprehensive review of advanced machine learning and deep learning methods,"This paper provides a state-of-the-art investigation of advances in data science in emerging economic applications. The analysis was performed on novel data science methods in four individual classes of deep learning models, hybrid deep learning models, hybrid machine learning, and ensemble models. Application domains include a wide and diverse range of economics research from the stock market, marketing, and e-commerce to corporate banking and cryptocurrency. Prisma method, a systematic literature review methodology, was used to ensure the quality of the survey. The findings reveal that the trends follow the advancement of hybrid models, which, based on the accuracy metric, outperform other learning algorithms. It is further expected that the trends will converge toward the advancements of sophisticated hybrid deep learning models.",paper provid stateoftheart investig advanc data scienc emerg econom applic analysi perform novel data scienc method four individu class deep learn model hybrid deep learn model hybrid machin learn ensembl model applic domain includ wide divers rang econom research stock market market ecommerc corpor bank cryptocurr prisma method systemat literatur review methodolog use ensur qualiti survey find reveal trend follow advanc hybrid model base accuraci metric outperform learn algorithm expect trend converg toward advanc sophist hybrid deep learn model
7dcd9585d08eb40f043ae2ffccb86897a6a031e6,Supervised and Unsupervised Learning for Data Science,,nan
648ba966b63975c6859e1948ae3ddc30053884e4,Making data science systems work,"How are data science systems made to work? It may seem that whether a system works is a function of its technical design, but it is also accomplished through ongoing forms of discretionary work by many actors. Based on six months of ethnographic fieldwork with a corporate data science team, we describe how actors involved in a corporate project negotiated what work the system should do, how it should work, and how to assess whether it works. These negotiations laid the foundation for how, why, and to what extent the system ultimately worked. We describe three main findings. First, how already-existing technologies are essential reference points to determine how and whether systems work. Second, how the situated resolution of development challenges continually reshapes the understanding of how and whether systems work. Third, how business goals, and especially their negotiated balance with data science imperatives, affect a system’s working. We conclude with takeaways for critical data studies, orienting researchers to focus on the organizational and cultural aspects of data science, the third-party platforms underlying data science systems, and ways to engage with practitioners’ imagination of how systems can and should work.",data scienc system made work may seem whether system work function technic design also accomplish ongo form discretionari work mani actor base six month ethnograph fieldwork corpor data scienc team describ actor involv corpor project negoti work system work assess whether work negoti laid foundat extent system ultim work describ three main find first alreadyexist technolog essenti refer point determin whether system work second situat resolut develop challeng continu reshap understand whether system work third busi goal especi negoti balanc data scienc imper affect system work conclud takeaway critic data studi orient research focu organiz cultur aspect data scienc thirdparti platform underli data scienc system way engag practition imagin system work
12f62537251cf8eb76fa11c59df68d2211008898,Big Earth Data science: an information framework for a sustainable planet,"ABSTRACT The digital transformation of our society coupled with the increasing exploitation of natural resources makes sustainability challenges more complex and dynamic than ever before. These changes will unlikely stop or even decelerate in the near future. There is an urgent need for a new scientific approach and an advanced form of evidence-based decision-making towards the benefit of society, the economy, and the environment. To understand the impacts and interrelationships between humans as a society and natural Earth system processes, we propose a new engineering discipline, Big Earth Data science. This science is called to provide the methodologies and tools to generate knowledge from diverse, numerous, and complex data sources necessary to ensure a sustainable human society essential for the preservation of planet Earth. Big Earth Data science aims at utilizing data from Earth observation and social sensing and develop theories for understanding the mechanisms of how such a social-physical system operates and evolves. The manuscript introduces the universe of discourse characterizing this new science, its foundational paradigms and methodologies, and a possible technological framework to be implemented by applying an ecosystem approach. CASEarth and GEOSS are presented as examples of international implementation attempts. Conclusions discuss important challenges and collaboration opportunities.",abstract digit transform societi coupl increas exploit natur resourc make sustain challeng complex dynam ever chang unlik stop even deceler near futur urgent need new scientif approach advanc form evidencebas decisionmak toward benefit societi economi environ understand impact interrelationship human societi natur earth system process propos new engin disciplin big earth data scienc scienc call provid methodolog tool gener knowledg divers numer complex data sourc necessari ensur sustain human societi essenti preserv planet earth big earth data scienc aim util data earth observ social sens develop theori understand mechan socialphys system oper evolv manuscript introduc univers discours character new scienc foundat paradigm methodolog possibl technolog framework implement appli ecosystem approach casearth geoss present exampl intern implement attempt conclus discuss import challeng collabor opportun
82620503cacf8ff6f8f3490e7bdf7508f1ab2021,Opening practice: supporting reproducibility and critical spatial data science,,nan
deb4e0c46f2e389ec5e4528f9dcee643bb6a15fa,Fixed Point Strategies in Data Science,"The goal of this article is to promote the use of fixed point strategies in data science by showing that they provide a simplifying and unifying framework to model, analyze, and solve a great variety of problems. They are seen to constitute a natural environment to explain the behavior of advanced convex optimization methods as well as of recent nonlinear methods in data science which are formulated in terms of paradigms that go beyond minimization concepts and involve constructs such as Nash equilibria or monotone inclusions. We review the pertinent tools of fixed point theory and describe the main state-of-the-art algorithms for provenly convergent fixed point construction. We also incorporate additional ingredients such as stochasticity, block-implementations, and non-Euclidean metrics, which provide further enhancements. Applications to signal and image processing, machine learning, statistics, neural networks, and inverse problems are discussed.",goal articl promot use fix point strategi data scienc show provid simplifi unifi framework model analyz solv great varieti problem seen constitut natur environ explain behavior advanc convex optim method well recent nonlinear method data scienc formul term paradigm go beyond minim concept involv construct nash equilibria monoton inclus review pertin tool fix point theori describ main stateoftheart algorithm provenli converg fix point construct also incorpor addit ingredi stochast blockimplement noneuclidean metric provid enhanc applic signal imag process machin learn statist neural network invers problem discuss
398b154013db9d8025bf60f910bc156dedd9b40e,"How Data Science Workers Work with Data: Discovery, Capture, Curation, Design, Creation","With the rise of big data, there has been an increasing need for practitioners in this space and an increasing opportunity for researchers to understand their workflows and design new tools to improve it. Data science is often described as data-driven, comprising unambiguous data and proceeding through regularized steps of analysis. However, this view focuses more on abstract processes, pipelines, and workflows, and less on how data science workers engage with the data. In this paper, we build on the work of other CSCW and HCI researchers in describing the ways that scientists, scholars, engineers, and others work with their data, through analyses of interviews with 21 data science professionals. We set five approaches to data along a dimension of interventions: Data as given; as captured; as curated; as designed; and as created. Data science workers develop an intuitive sense of their data and processes, and actively shape their data. We propose new ways to apply these interventions analytically, to make sense of the complex activities around data practices.",rise big data increas need practition space increas opportun research understand workflow design new tool improv data scienc often describ datadriven compris unambigu data proceed regular step analysi howev view focus abstract process pipelin workflow less data scienc worker engag data paper build work cscw hci research describ way scientist scholar engin other work data analys interview data scienc profession set five approach data along dimens intervent data given captur curat design creat data scienc worker develop intuit sens data process activ shape data propos new way appli intervent analyt make sens complex activ around data practic
8ece479b5dfed4727d2d9b9763f777bb9a94096e,Human-AI Collaboration in Data Science,"The rapid advancement of artificial intelligence (AI) is changing our lives in many ways. One application domain is data science. New techniques in automating the creation of AI, known as AutoAI or AutoML, aim to automate the work practices of data scientists. AutoAI systems are capable of autonomously ingesting and pre-processing data, engineering new features, and creating and scoring models based on a target objectives (e.g. accuracy or run-time efficiency). Though not yet widely adopted, we are interested in understanding how AutoAI will impact the practice of data science. We conducted interviews with 20 data scientists who work at a large, multinational technology company and practice data science in various business settings. Our goal is to understand their current work practices and how these practices might change with AutoAI. Reactions were mixed: while informants expressed concerns about the trend of automating their jobs, they also strongly felt it was inevitable. Despite these concerns, they remained optimistic about their future job security due to a view that the future of data science work will be a collaboration between humans and AI systems, in which both automation and human expertise are indispensable.",rapid advanc artifici intellig ai chang live mani way one applic domain data scienc new techniqu autom creation ai known autoai automl aim autom work practic data scientist autoai system capabl autonom ingest preprocess data engin new featur creat score model base target object eg accuraci runtim effici though yet wide adopt interest understand autoai impact practic data scienc conduct interview data scientist work larg multin technolog compani practic data scienc variou busi set goal understand current work practic practic might chang autoai reaction mix inform express concern trend autom job also strongli felt inevit despit concern remain optimist futur job secur due view futur data scienc work collabor human ai system autom human expertis indispens
a11e157cb828b800426223f0a3d79e8fb122c8cc,Process Mining for Python (PM4Py): Bridging the Gap Between Process- and Data Science,"Process mining, i.e., a sub-field of data science focusing on the analysis of event data generated during the execution of (business) processes, has seen a tremendous change over the past two decades. Starting off in the early 2000's, with limited to no tool support, nowadays, several software tools, i.e., both open-source, e.g., ProM and Apromore, and commercial, e.g., Disco, Celonis, ProcessGold, etc., exist. The commercial process mining tools provide limited support for implementing custom algorithms. Moreover, both commercial and open-source process mining tools are often only accessible through a graphical user interface, which hampers their usage in large-scale experimental settings. Initiatives such as RapidProM provide process mining support in the scientific workflow-based data science suite RapidMiner. However, these offer limited to no support for algorithmic customization. In the light of the aforementioned, in this paper, we present a novel process mining library, i.e. Process Mining for Python (PM4Py) that aims to bridge this gap, providing integration with state-of-the-art data science libraries, e.g., pandas, numpy, scipy and scikit-learn. We provide a global overview of the architecture and functionality of PM4Py, accompanied by some representative examples of its usage.",process mine ie subfield data scienc focus analysi event data gener execut busi process seen tremend chang past two decad start earli limit tool support nowaday sever softwar tool ie opensourc eg prom apromor commerci eg disco celoni processgold etc exist commerci process mine tool provid limit support implement custom algorithm moreov commerci opensourc process mine tool often access graphic user interfac hamper usag largescal experiment set initi rapidprom provid process mine support scientif workflowbas data scienc suit rapidmin howev offer limit support algorithm custom light aforement paper present novel process mine librari ie process mine python pmpi aim bridg gap provid integr stateoftheart data scienc librari eg panda numpi scipi scikitlearn provid global overview architectur function pmpi accompani repres exampl usag
0669286d8d4ca8ec2fdf16b7813157c21eb690be,Heidelberg colorectal data set for surgical data science in the sensor operating room,,nan
3b16bcb226bb1c87a6e63e0658be30067ed03f57,A Systematic Review on Supervised and Unsupervised Machine Learning Algorithms for Data Science,,nan
e57f360d4ffd1d3aa1dfbcc92d35b506f46f3afd,Data science and AI in FinTech: an overview,,nan
840b60da93c2776230d3e6123d708e1c7e66ebc0,Teaching Creative and Practical Data Science at Scale,"Abstract–Nolan and Temple Lang’s Computing in the Statistics Curricula (2010) advocated for a shift in statistical education to broadly include computing. In the time since, individuals with training in both computing and statistics have become increasingly employable in the burgeoning data science field. In response, universities have developed new courses and programs to meet the growing demand for data science education. To address this demand, we created Data Science in Practice, a large-enrollment undergraduate course. Here, we present our goals for teaching this course, including: (1) conceptualizing data science as creative problem solving, with a focus on project-based learning, (2) prioritizing practical application, teaching and using standardized tools and best practices, and (3) scaling education through coursework that enables hands-on and classroom learning in a large-enrollment course. Throughout this course we also emphasize social context and data ethics to best prepare students for the interdisciplinary and impactful nature of their work. We highlight creative problem solving and strategies for teaching automation-resilient skills, while providing students the opportunity to create a unique data science project that demonstrates their technical and creative capacities.",abstractnolan templ lang comput statist curricula advoc shift statist educ broadli includ comput time sinc individu train comput statist becom increasingli employ burgeon data scienc field respons univers develop new cours program meet grow demand data scienc educ address demand creat data scienc practic largeenrol undergradu cours present goal teach cours includ conceptu data scienc creativ problem solv focu projectbas learn priorit practic applic teach use standard tool best practic scale educ coursework enabl handson classroom learn largeenrol cours throughout cours also emphas social context data ethic best prepar student interdisciplinari impact natur work highlight creativ problem solv strategi teach automationresili skill provid student opportun creat uniqu data scienc project demonstr technic creativ capac
d88d39dd9c910105e7503aa43698c806d42d5198,Statistical Foundations of Data Science,,nan
c016852106ac787678105fd9dd22e57ba620517c,Human Data Science,,nan
579b64d2179a58a8bc586c30850ea238d3c14164,A Survey on Data Pricing: From Economics to Data Science,"Data are invaluable. How can we assess the value of data objectively, systematically and quantitatively? Pricing data, or information goods in general, has been studied and practiced in dispersed areas and principles, such as economics, marketing, electronic commerce, data management, data mining and machine learning. In this article, we present a unified, interdisciplinary and comprehensive overview of this important direction. We examine various motivations behind data pricing, understand the economics of data pricing and review the development and evolution of pricing models according to a series of fundamental principles. We discuss both digital products and data products. We also consider a series of challenges and directions for future work.",data invalu assess valu data object systemat quantit price data inform good gener studi practic dispers area principl econom market electron commerc data manag data mine machin learn articl present unifi interdisciplinari comprehens overview import direct examin variou motiv behind data price understand econom data price review develop evolut price model accord seri fundament principl discuss digit product data product also consid seri challeng direct futur work
d9a984e15b1a86a66ecbac9e66d458dae4cb616c,What Is Data Science,,nan
27b9d1182e913decc7ef6a3509245fa6b6fd509d,Veridical data science,"Significance Predictability, computability, and stability (PCS) are three core principles of data science. They embed the scientific principles of prediction and replication in data-driven decision making while recognizing the central role of computation. Based on these principles, we propose the PCS framework, including workflow and documentation (in R Markdown or Jupyter Notebook). The PCS framework aims at responsible, reliable, reproducible, and transparent analysis across fields of science, social science, engineering, business, and government. It can be used as a recommendation system for scientific hypothesis generation and experimental design. In particular, we propose (basic) PCS inference for reliability measures on data results, extending statistical inference to a much broader scope as current data science practice entails. Building and expanding on principles of statistics, machine learning, and scientific inquiry, we propose the predictability, computability, and stability (PCS) framework for veridical data science. Our framework, composed of both a workflow and documentation, aims to provide responsible, reliable, reproducible, and transparent results across the data science life cycle. The PCS workflow uses predictability as a reality check and considers the importance of computation in data collection/storage and algorithm design. It augments predictability and computability with an overarching stability principle. Stability expands on statistical uncertainty considerations to assess how human judgment calls impact data results through data and model/algorithm perturbations. As part of the PCS workflow, we develop PCS inference procedures, namely PCS perturbation intervals and PCS hypothesis testing, to investigate the stability of data results relative to problem formulation, data cleaning, modeling decisions, and interpretations. We illustrate PCS inference through neuroscience and genomics projects of our own and others. Moreover, we demonstrate its favorable performance over existing methods in terms of receiver operating characteristic (ROC) curves in high-dimensional, sparse linear model simulations, including a wide range of misspecified models. Finally, we propose PCS documentation based on R Markdown or Jupyter Notebook, with publicly available, reproducible codes and narratives to back up human choices made throughout an analysis. The PCS workflow and documentation are demonstrated in a genomics case study available on Zenodo.",signific predict comput stabil pc three core principl data scienc emb scientif principl predict replic datadriven decis make recogn central role comput base principl propos pc framework includ workflow document r markdown jupyt notebook pc framework aim respons reliabl reproduc transpar analysi across field scienc social scienc engin busi govern use recommend system scientif hypothesi gener experiment design particular propos basic pc infer reliabl measur data result extend statist infer much broader scope current data scienc practic entail build expand principl statist machin learn scientif inquiri propos predict comput stabil pc framework verid data scienc framework compos workflow document aim provid respons reliabl reproduc transpar result across data scienc life cycl pc workflow use predict realiti check consid import comput data collectionstorag algorithm design augment predict comput overarch stabil principl stabil expand statist uncertainti consider assess human judgment call impact data result data modelalgorithm perturb part pc workflow develop pc infer procedur name pc perturb interv pc hypothesi test investig stabil data result rel problem formul data clean model decis interpret illustr pc infer neurosci genom project other moreov demonstr favor perform exist method term receiv oper characterist roc curv highdimension spars linear model simul includ wide rang misspecifi model final propos pc document base r markdown jupyt notebook publicli avail reproduc code narr back human choic made throughout analysi pc workflow document demonstr genom case studi avail zenodo
62a9d4f1763c5071cb2476c100614ba9741f036b,Data science applications to string theory,,nan
e2055b85dab66c922ccf25a28046e8e559074824,Algorithmic Government: Automating Public Services and Supporting Civil Servants in using Data Science Technologies,"The data science technologies of artificial intelligence (AI), Internet of Things (IoT), big data and behavioral/predictive analytics, and blockchain are poised to revolutionize government and create a new generation of GovTech start-ups. The impact from the ‘smartification’ of public services and the national infrastructure will be much more significant in comparison to any other sector given government's function and importance to every institution and individual. Potential GovTech systems include Chatbots and intelligent assistants for public engagement, Robo-advisors to support civil servants, real-time management of the national infrastructure using IoT and blockchain, automated compliance/regulation, public records securely stored in blockchain distributed ledgers, online judicial and dispute resolution systems, and laws/statutes encoded as blockchain smart contracts. Government is potentially the major ‘client’ and also ‘public champion’ for these new data technologies. This review paper uses our simple taxonomy of government services to provide an overview of data science automation being deployed by governments world-wide. The goal of this review paper is to encourage the Computer Science community to engage with government to develop these new systems to transform public services and support the work of civil servants.",data scienc technolog artifici intellig ai internet thing iot big data behavioralpredict analyt blockchain pois revolution govern creat new gener govtech startup impact smartif public servic nation infrastructur much signific comparison sector given govern function import everi institut individu potenti govtech system includ chatbot intellig assist public engag roboadvisor support civil servant realtim manag nation infrastructur use iot blockchain autom complianceregul public record secur store blockchain distribut ledger onlin judici disput resolut system lawsstatut encod blockchain smart contract govern potenti major client also public champion new data technolog review paper use simpl taxonomi govern servic provid overview data scienc autom deploy govern worldwid goal review paper encourag comput scienc commun engag govern develop new system transform public servic support work civil servant
41cf91ee13a1d15983ede066ddf6b67cc94a41f4,The Role of Academia in Data Science Education,"As the demand for data scientists continues to grow, universities are trying to figure out how to best contribute to the training of a workforce. However, there does not appear to be a consensus on the fundamental principles, expertise, skills, or knowledge-base needed to define an academic discipline. We argue that data science is not a discipline but rather an umbrella term used to describe a complex process involving not one data scientist possessing all the necessary expertise, but a team of data scientists with nonoverlapping complementary skills. We provide some recommendations for how to take this into account when designing data science academic programs.Keywords: applied statistics, data science, data science curriculum, data wrangling, machine learning, software engineering",demand data scientist continu grow univers tri figur best contribut train workforc howev appear consensu fundament principl expertis skill knowledgebas need defin academ disciplin argu data scienc disciplin rather umbrella term use describ complex process involv one data scientist possess necessari expertis team data scientist nonoverlap complementari skill provid recommend take account design data scienc academ programskeyword appli statist data scienc data scienc curriculum data wrangl machin learn softwar engin
4b5505a54799d796ae94115409b01ee33a7e2b20,Glossary for public health surveillance in the age of data science,"Public health surveillance is the ongoing systematic collection, analysis and interpretation of data, closely integrated with the timely dissemination of the resulting information to those responsible for preventing and controlling disease and injury. With the rapid development of data science, encompassing big data and artificial intelligence, and with the exponential growth of accessible and highly heterogeneous health-related data, from healthcare providers to user-generated online content, the field of surveillance and health monitoring is changing rapidly. It is, therefore, the right time for a short glossary of key terms in public health surveillance, with an emphasis on new data-science developments in the field.",public health surveil ongo systemat collect analysi interpret data close integr time dissemin result inform respons prevent control diseas injuri rapid develop data scienc encompass big data artifici intellig exponenti growth access highli heterogen healthrel data healthcar provid usergener onlin content field surveil health monitor chang rapidli therefor right time short glossari key term public health surveil emphasi new datasci develop field
b017bf6879e57077b4b4e180a02747b89878d7a1,A Fresh Look at Introductory Data Science,"ABSTRACT The proliferation of vast quantities of available datasets that are large and complex in nature has challenged universities to keep up with the demand for graduates trained in both the statistical and the computational set of skills required to effectively plan, acquire, manage, analyze, and communicate the findings of such data. To keep up with this demand, attracting students early on to data science as well as providing them a solid foray into the field becomes increasingly important. We present a case study of an introductory undergraduate course in data science that is designed to address these needs. Offered at Duke University, this course has no prerequisites and serves a wide audience of aspiring statistics and data science majors as well as humanities, social sciences, and natural sciences students. We discuss the unique set of challenges posed by offering such a course, and in light of these challenges, we present a detailed discussion into the pedagogical design elements, content, structure, computational infrastructure, and the assessment methodology of the course. We also offer a repository containing all teaching materials that are open-source, along with supplementary materials and the R code for reproducing the figures found in the article.",abstract prolifer vast quantiti avail dataset larg complex natur challeng univers keep demand graduat train statist comput set skill requir effect plan acquir manag analyz commun find data keep demand attract student earli data scienc well provid solid foray field becom increasingli import present case studi introductori undergradu cours data scienc design address need offer duke univers cours prerequisit serv wide audienc aspir statist data scienc major well human social scienc natur scienc student discuss uniqu set challeng pose offer cours light challeng present detail discuss pedagog design element content structur comput infrastructur assess methodolog cours also offer repositori contain teach materi opensourc along supplementari materi r code reproduc figur found articl
28cc044d5ba938472bc53d87240583982ad21663,Data Management for Data Science - Towards Embedded Analytics,"textabstractThe rise of Data Science has caused an influx of new usersin need of data management solutions. However, insteadof utilizing existing RDBMS solutions they are opting touse a stack of independent solutions for data storage andprocessing glued together by scripting languages. This is notbecause they do not need the functionality that an integratedRDBMS provides, but rather because existing RDBMS im-plementations do not cater to their use case. To solve theseissues, we propose a new class of data management systems:embedded analytical systems. These systems are tightlyintegrated with analytical tools, and provide fast and effi-cient access to the data stored within them. In this work,we describe the unique challenges and opportunities w.r.tworkloads, resilience and cooperation that are faced by thisnew class of systems and the steps we have taken towardsaddressing them in the DuckDB system.",textabstractth rise data scienc caus influx new usersin need data manag solut howev insteadof util exist rdbm solut opt tous stack independ solut data storag andprocess glu togeth script languag notbecaus need function integratedrdbm provid rather exist rdbm implement cater use case solv theseissu propos new class data manag systemsembed analyt system system tightlyintegr analyt tool provid fast effici access data store within workw describ uniqu challeng opportun wrtworkload resili cooper face thisnew class system step taken towardsaddress duckdb system
b16ef64a90e9e300931d6a92fd2b9277f6cfd584,Passing the Data Baton : A Retrospective Analysis on Data Science Work and Workers,"Data science is a rapidly growing discipline and organizations increasingly depend on data science work. Yet the ambiguity around data science, what it is, and who data scientists are can make it difficult for visualization researchers to identify impactful research trajectories. We have conducted a retrospective analysis of data science work and workers as described within the data visualization, human computer interaction, and data science literature. From this analysis we synthesis a comprehensive model that describes data science work and breakdown to data scientists into nine distinct roles. We summarise and reflect on the role that visualization has throughout data science work and the varied needs of data scientists themselves for tooling support. Our findings are intended to arm visualization researchers with a more concrete framing of data science with the hope that it will help them surface innovative opportunities for impacting data science work. Data availability: https://osf.io/z2xpd/?view_only=87fa24be486a473884adb9ffbe8db4ec",data scienc rapidli grow disciplin organ increasingli depend data scienc work yet ambigu around data scienc data scientist make difficult visual research identifi impact research trajectori conduct retrospect analysi data scienc work worker describ within data visual human comput interact data scienc literatur analysi synthesi comprehens model describ data scienc work breakdown data scientist nine distinct role summaris reflect role visual throughout data scienc work vari need data scientist tool support find intend arm visual research concret frame data scienc hope help surfac innov opportun impact data scienc work data avail httpsosfiozxpdview_onlyfabeaadbffbedbec
b85ac20631159ca3e370afa9c1f81a4618242b4f,The Democratization of Data Science Education,"Abstract Over the last three decades, data have become ubiquitous and cheap. This transition has accelerated over the last five years and training in statistics, machine learning, and data analysis has struggled to keep up. In April 2014, we launched a program of nine courses, the Johns Hopkins Data Science Specialization, which has now had more than 4 million enrollments over the past five years. Here, the program is described and compared to standard data science curricula as they were organized in 2014 and 2015. We show that novel pedagogical and administrative decisions introduced in our program are now standard in online data science programs. The impact of the Data Science Specialization on data science education in the U.S. is also discussed. Finally, we conclude with some thoughts about the future of data science education in a data democratized world.",abstract last three decad data becom ubiquit cheap transit acceler last five year train statist machin learn data analysi struggl keep april launch program nine cours john hopkin data scienc special million enrol past five year program describ compar standard data scienc curricula organ show novel pedagog administr decis introduc program standard onlin data scienc program impact data scienc special data scienc educ us also discuss final conclud thought futur data scienc educ data democrat world
38f0c0f2567e074c775017e0e8dd1a43b1f6fcdd,"Data Science in 2020: Computing, Curricula, and Challenges for the Next 10 Years","Abstract In the past 10 years, new data science courses and programs have proliferated at the collegiate level. As faculty and administrators enter the race to provide data science training and attract new students, the road map for teaching data science remains elusive. In 2019, 69 college and university faculty teaching data science courses and developing data science curricula were surveyed to learn about their curricula, computing tools, and challenges they face in their classrooms. Faculty reported teaching a variety of computing skills in introductory data science (albeit fewer computing topics than statistics topics), and that one of the biggest challenges they face is teaching computing to a diverse audience with varying preparation. The ever-evolving nature of data science is a major hurdle for faculty teaching data science courses, and a call for more data science teaching resources was echoed in many responses.",abstract past year new data scienc cours program prolifer collegi level faculti administr enter race provid data scienc train attract new student road map teach data scienc remain elus colleg univers faculti teach data scienc cours develop data scienc curricula survey learn curricula comput tool challeng face classroom faculti report teach varieti comput skill introductori data scienc albeit fewer comput topic statist topic one biggest challeng face teach comput divers audienc vari prepar everevolv natur data scienc major hurdl faculti teach data scienc cours call data scienc teach resourc echo mani respons
3746152e023e79b7d03cf12a560e473de2945d67,Interrogating Data Science,"Data science provides powerful tools and methods. CSCW researchers have contributed insightfulstudies of conventional work-practices in data science - and particularly machine learning. However,recent research has shown that human skills and collaborative decision-making, play important rolesin defining data, acquiring data, curating data, designing data, and creating data. This workshopgathers researchers and practitioners together to take a collective and critical look at data sciencework-practices, and at how those work-practices make crucial and often invisible impacts on theformal work of data science. When we understand the human and social contributions to data sciencepipelines, we can constructively redesign both work and technologies for new insights, theories, andchallenges.",data scienc provid power tool method cscw research contribut insightfulstudi convent workpractic data scienc particularli machin learn howeverrec research shown human skill collabor decisionmak play import rolesin defin data acquir data curat data design data creat data workshopgath research practition togeth take collect critic look data scienceworkpractic workpractic make crucial often invis impact theform work data scienc understand human social contribut data sciencepipelin construct redesign work technolog new insight theori andchalleng
f56425ec56586dcfd2694ab83643e9e76f314e91,50 Years of Data Science,"ABSTRACT More than 50 years ago, John Tukey called for a reformation of academic statistics. In “The Future of Data Analysis,” he pointed to the existence of an as-yet unrecognized science, whose subject of interest was learning from data, or “data analysis.” Ten to 20 years ago, John Chambers, Jeff Wu, Bill Cleveland, and Leo Breiman independently once again urged academic statistics to expand its boundaries beyond the classical domain of theoretical statistics; Chambers called for more emphasis on data preparation and presentation rather than statistical modeling; and Breiman called for emphasis on prediction rather than inference. Cleveland and Wu even suggested the catchy name “data science” for this envisioned field. A recent and growing phenomenon has been the emergence of “data science” programs at major universities, including UC Berkeley, NYU, MIT, and most prominently, the University of Michigan, which in September 2015 announced a $100M “Data Science Initiative” that aims to hire 35 new faculty. Teaching in these new programs has significant overlap in curricular subject matter with traditional statistics courses; yet many academic statisticians perceive the new programs as “cultural appropriation.” This article reviews some ingredients of the current “data science moment,” including recent commentary about data science in the popular media, and about how/whether data science is really different from statistics. The now-contemplated field of data science amounts to a superset of the fields of statistics and machine learning, which adds some technology for “scaling up” to “big data.” This chosen superset is motivated by commercial rather than intellectual developments. Choosing in this way is likely to miss out on the really important intellectual event of the next 50 years. Because all of science itself will soon become data that can be mined, the imminent revolution in data science is not about mere “scaling up,” but instead the emergence of scientific studies of data analysis science-wide. In the future, we will be able to predict how a proposal to change data analysis workflows would impact the validity of data analysis across all of science, even predicting the impacts field-by-field. Drawing on work by Tukey, Cleveland, Chambers, and Breiman, I present a vision of data science based on the activities of people who are “learning from data,” and I describe an academic field dedicated to improving that activity in an evidence-based manner. This new field is a better academic enlargement of statistics and machine learning than today’s data science initiatives, while being able to accommodate the same short-term goals. Based on a presentation at the Tukey Centennial Workshop, Princeton, NJ, September 18, 2015.",abstract year ago john tukey call reform academ statist futur data analysi point exist asyet unrecogn scienc whose subject interest learn data data analysi ten year ago john chamber jeff wu bill cleveland leo breiman independ urg academ statist expand boundari beyond classic domain theoret statist chamber call emphasi data prepar present rather statist model breiman call emphasi predict rather infer cleveland wu even suggest catchi name data scienc envis field recent grow phenomenon emerg data scienc program major univers includ uc berkeley nyu mit promin univers michigan septemb announc data scienc initi aim hire new faculti teach new program signific overlap curricular subject matter tradit statist cours yet mani academ statistician perceiv new program cultur appropri articl review ingredi current data scienc moment includ recent commentari data scienc popular media howwheth data scienc realli differ statist nowcontempl field data scienc amount superset field statist machin learn add technolog scale big data chosen superset motiv commerci rather intellectu develop choos way like miss realli import intellectu event next year scienc soon becom data mine immin revolut data scienc mere scale instead emerg scientif studi data analysi sciencewid futur abl predict propos chang data analysi workflow would impact valid data analysi across scienc even predict impact fieldbyfield draw work tukey cleveland chamber breiman present vision data scienc base activ peopl learn data describ academ field dedic improv activ evidencebas manner new field better academ enlarg statist machin learn today data scienc initi abl accommod shortterm goal base present tukey centenni workshop princeton nj septemb
4271faaa82eb722d079222211c30ab642bc734be,The data science life cycle,A cycle that traces ways to define the landscape of data science.,cycl trace way defin landscap data scienc
89f41c87c8849ce37e609c1010087291a4679a37,Outbreak analytics: a developing data science for informing the response to emerging pathogens,"Despite continued efforts to improve health systems worldwide, emerging pathogen epidemics remain a major public health concern. Effective response to such outbreaks relies on timely intervention, ideally informed by all available sources of data. The collection, visualization and analysis of outbreak data are becoming increasingly complex, owing to the diversity in types of data, questions and available methods to address them. Recent advances have led to the rise of outbreak analytics, an emerging data science focused on the technological and methodological aspects of the outbreak data pipeline, from collection to analysis, modelling and reporting to inform outbreak response. In this article, we assess the current state of the field. After laying out the context of outbreak response, we critically review the most common analytics components, their inter-dependencies, data requirements and the type of information they can provide to inform operations in real time. We discuss some challenges and opportunities and conclude on the potential role of outbreak analytics for improving our understanding of, and response to outbreaks of emerging pathogens. This article is part of the theme issue ‘Modelling infectious disease outbreaks in humans, animals and plants: epidemic forecasting and control‘. This theme issue is linked with the earlier issue ‘Modelling infectious disease outbreaks in humans, animals and plants: approaches and important themes’.",despit continu effort improv health system worldwid emerg pathogen epidem remain major public health concern effect respons outbreak reli time intervent ideal inform avail sourc data collect visual analysi outbreak data becom increasingli complex owe divers type data question avail method address recent advanc led rise outbreak analyt emerg data scienc focus technolog methodolog aspect outbreak data pipelin collect analysi model report inform outbreak respons articl assess current state field lay context outbreak respons critic review common analyt compon interdepend data requir type inform provid inform oper real time discuss challeng opportun conclud potenti role outbreak analyt improv understand respons outbreak emerg pathogen articl part theme issu model infecti diseas outbreak human anim plant epidem forecast control theme issu link earlier issu model infecti diseas outbreak human anim plant approach import theme
1ec4d0e29455e47245edaa17368257df3efb6562,"Practitioners Teaching Data Science in Industry and Academia: Expectations, Workflows, and Challenges","Data science has been growing in prominence across both academia and industry, but there is still little formal consensus about how to teach it. Many people who currently teach data science are practitioners such as computational researchers in academia or data scientists in industry. To understand how these practitioner-instructors pass their knowledge onto novices and how that contrasts with teaching more traditional forms of programming, we interviewed 20 data scientists who teach in settings ranging from small-group workshops to large online courses. We found that: 1) they must empathize with a diverse array of student backgrounds and expectations, 2) they teach technical workflows that integrate authentic practices surrounding code, data, and communication, 3) they face challenges involving authenticity versus abstraction in software setup, finding and curating pedagogically-relevant datasets, and acclimating students to live with uncertainty in data analysis. These findings can point the way toward better tools for data science education and help bring data literacy to more people around the world.",data scienc grow promin across academia industri still littl formal consensu teach mani peopl current teach data scienc practition comput research academia data scientist industri understand practitionerinstructor pass knowledg onto novic contrast teach tradit form program interview data scientist teach set rang smallgroup workshop larg onlin cours found must empath divers array student background expect teach technic workflow integr authent practic surround code data commun face challeng involv authent versu abstract softwar setup find curat pedagogicallyrelev dataset acclim student live uncertainti data analysi find point way toward better tool data scienc educ help bring data literaci peopl around world
9f2b2111cd65cc33c0c440f4f8e548b58d8dd851,The State of the Art of Data Science and Engineering in Structural Health Monitoring,,nan
2ad13329d44c74041626a60898ccf921b0bdacd3,SystemDS: A Declarative Machine Learning System for the End-to-End Data Science Lifecycle,"Machine learning (ML) applications become increasingly common in many domains. ML systems to execute these workloads include numerical computing frameworks and libraries, ML algorithm libraries, and specialized systems for deep neural networks and distributed ML. These systems focus primarily on efficient model training and scoring. However, the data science process is exploratory, and deals with underspecified objectives and a wide variety of heterogeneous data sources. Therefore, additional tools are employed for data engineering and debugging, which requires boundary crossing, unnecessary manual effort, and lacks optimization across the lifecycle. In this paper, we introduce SystemDS, an open source ML system for the end-to-end data science lifecycle from data integration, cleaning, and preparation, over local, distributed, and federated ML model training, to debugging and serving. To this end, we aim to provide a stack of declarative languages with R-like syntax for the different lifecycle tasks, and users with different expertise. We describe the overall system architecture, explain major design decisions (motivated by lessons learned from Apache SystemML), and discuss key features and research directions. Finally, we provide preliminary results that show the potential of end-to-end lifecycle optimization.",machin learn ml applic becom increasingli common mani domain ml system execut workload includ numer comput framework librari ml algorithm librari special system deep neural network distribut ml system focu primarili effici model train score howev data scienc process exploratori deal underspecifi object wide varieti heterogen data sourc therefor addit tool employ data engin debug requir boundari cross unnecessari manual effort lack optim across lifecycl paper introduc systemd open sourc ml system endtoend data scienc lifecycl data integr clean prepar local distribut feder ml model train debug serv end aim provid stack declar languag rlike syntax differ lifecycl task user differ expertis describ overal system architectur explain major design decis motiv lesson learn apach systemml discuss key featur research direct final provid preliminari result show potenti endtoend lifecycl optim
1ac524c713423bc50822b34e0aa1bbfab42d2b00,Data science for entrepreneurship research: studying demand dynamics for entrepreneurial skills in the Netherlands,,nan
678da221aa156807bc2c191ed5f4bcbb0b25d421,Data science ethical considerations: a systematic literature review and proposed project framework,,nan
0c86e8d19d0fc62a5f829ea625ffd3e7fa9551b9,Toward collaborative open data science in metabolomics using Jupyter Notebooks and cloud computing,,nan
5c8b7127ad0b5257f81ce1aa70b89faa97bbc211,Data Science of the Natural Environment: A Research Roadmap,"Data science is the science of extracting meaning from potentially complex data. This is a fast moving field, drawing principles and techniques from a number of different disciplinary areas including computer science, statistics and complexity science. Data science is having a profound impact on a number of areas including commerce, health and smart cities. This paper argues that data science can have an equal if not greater impact in the area of earth and environmental sciences, offering a rich tapestry of new techniques to support both a deeper understanding of the natural environment in all its complexities, as well as the development of well-founded mitigation and adaptation strategies in the face of climate change. The paper argues that data science for the natural environment brings about new challenges for data science, particularly around complexity, spatial and temporal reasoning, and managing uncertainty. The paper also describes a case study in environmental data science which offers up insights into the promise of the area. The paper concludes with a research roadmap highlighting ten top challenges of environmental data science and also an invitation to become part of an international community working collaboratively on these problems.",data scienc scienc extract mean potenti complex data fast move field draw principl techniqu number differ disciplinari area includ comput scienc statist complex scienc data scienc profound impact number area includ commerc health smart citi paper argu data scienc equal greater impact area earth environment scienc offer rich tapestri new techniqu support deeper understand natur environ complex well develop wellfound mitig adapt strategi face climat chang paper argu data scienc natur environ bring new challeng data scienc particularli around complex spatial tempor reason manag uncertainti paper also describ case studi environment data scienc offer insight promis area paper conclud research roadmap highlight ten top challeng environment data scienc also invit becom part intern commun work collabor problem
2081ed6854290a479f796f2432c7951ff24232fe,Human-Centered Study of Data Science Work Practices,"With the rise of big data, there has been an increasing need to understand who is working in data science and how they are doing their work. HCI and CSCW researchers have begun to examine these questions. In this workshop, we invite researchers to share their observations, experiences, hypotheses, and insights, in the hopes of developing a taxonomy of work practices and open issues in the behavioral and social study of data science and data science workers.",rise big data increas need understand work data scienc work hci cscw research begun examin question workshop invit research share observ experi hypothes insight hope develop taxonomi work practic open issu behavior social studi data scienc data scienc worker
e564e3656395782d0ab9f801bfbe9f9f1a5d34a7,Data science in data librarianship: Core competencies of a data librarian,"Currently, data are stored in an always-on condition, and can be globally accessed at any point, by any user. Data librarianship has its origins in the social sciences. In particular, the creation of data services and data archives, in the United Kingdom (Data Archives Services) and in the United States and Canada (Data Library Services), is a key factor for the emergence of data librarianship. The focus of data librarianship nowadays is on the creation of new library services. Data librarians are concerned with the proposition of services for data management and curation in academic libraries and other research organizations. The purpose of this paper is to understand how the complexity of the data can serve as the basis for identifying the technical skills required by data librarians. This essay is systematically divided, first introducing the concepts of data and research data in data librarianship, followed by an overview of data science as a theory, method, and technology to assess data. Next, the identification of the competencies and skills required by data scientists and data librarians are discussed. Our final remarks highlight that data librarians should understand that the complexity and novelty associated with data science praxis. Data science provides new methods and practices for data librarianship. A data librarian need not become a programmer, statistician, or database manager, but should be interested in learning about the languages and programming logic of computers, databases, and information retrieval tools. We believe that numerous kinds of scientific data research provide opportunities for a data librarian to engage with data science.",current data store alwayson condit global access point user data librarianship origin social scienc particular creation data servic data archiv unit kingdom data archiv servic unit state canada data librari servic key factor emerg data librarianship focu data librarianship nowaday creation new librari servic data librarian concern proposit servic data manag curat academ librari research organ purpos paper understand complex data serv basi identifi technic skill requir data librarian essay systemat divid first introduc concept data research data data librarianship follow overview data scienc theori method technolog assess data next identif compet skill requir data scientist data librarian discuss final remark highlight data librarian understand complex novelti associ data scienc praxi data scienc provid new method practic data librarianship data librarian need becom programm statistician databas manag interest learn languag program logic comput databas inform retriev tool believ numer kind scientif data research provid opportun data librarian engag data scienc
0e23ff1f915b6af32bf1a1107ee7e15ebe10efe8,The Challenge of Big Data and Data Science,"Big data and data science are transforming the world in ways that spawn new concerns for social scientists, such as the impacts of the internet on citizens and the media, the repercussions of smart cities, the possibilities of cyber-warfare and cyber-terrorism, the implications of precision medicine, and the consequences of artificial intelligence and automation. Along with these changes in society, powerful new data science methods support research using administrative, internet, textual, and sensor-audio-video data. Burgeoning data and innovative methods facilitate answering previously hard-to-tackle questions about society by offering new ways to form concepts from data, to do descriptive inference, to make causal inferences, and to generate predictions. They also pose challenges as social scientists must grasp the meaning of concepts and predictions generated by convoluted algorithms, weigh the relative value of prediction versus causal inference, and cope with ethical challenges as their methods, such as algorithms for mobilizing voters or determining bail, are adopted by policy makers.",big data data scienc transform world way spawn new concern social scientist impact internet citizen media repercuss smart citi possibl cyberwarfar cyberterror implic precis medicin consequ artifici intellig autom along chang societi power new data scienc method support research use administr internet textual sensoraudiovideo data burgeon data innov method facilit answer previous hardtotackl question societi offer new way form concept data descript infer make causal infer gener predict also pose challeng social scientist must grasp mean concept predict gener convolut algorithm weigh rel valu predict versu causal infer cope ethic challeng method algorithm mobil voter determin bail adopt polici maker
2ab2796390ac12df283e218907ed0ffef232dbc7,Situating Data Science: Exploring How Relationships to Data Shape Learning,"The emerging field of Data Science has had a large impact on science and society. This has led to over a decade of calls to establish a corresponding field of Data Science Education. There is still a need, however, to more deeply conceptualize what a field of Data Science Education might entail in terms of scope, responsibility, and execution. This special issue explores how one distinguishing feature of Data Science—its focus on data collected from social and environmental contexts within which learners often find themselves deeply embedded—suggests serious implications for learning and education. The learning sciences is uniquely positioned to investigate how such contextual embeddings impact learners’ engagement with data including conceptual, experiential, communal, racialized, spatial, and political dimensions. This special issue demonstrates the richly layered relationships learners build with data and reveals them to be not merely utilitarian mechanisms for learning about data, but a critical part of navigating data as social text and understanding Data Science as a discipline. Together, the contributions offer a vision of how the learning sciences can contribute to a more expansive, agentive and socially aware Data Science Education.",emerg field data scienc larg impact scienc societi led decad call establish correspond field data scienc educ still need howev deepli conceptu field data scienc educ might entail term scope respons execut special issu explor one distinguish featur data scienceit focu data collect social environment context within learner often find deepli embeddedsuggest seriou implic learn educ learn scienc uniqu posit investig contextu embed impact learner engag data includ conceptu experienti commun racial spatial polit dimens special issu demonstr richli layer relationship learner build data reveal mere utilitarian mechan learn data critic part navig data social text understand data scienc disciplin togeth contribut offer vision learn scienc contribut expans agent social awar data scienc educ
b00f836c62d0ea7678d0f20aeec3397138633060,Health Care and Precision Medicine Research: Analysis of a Scalable Data Science Platform,"Background Health care data are increasing in volume and complexity. Storing and analyzing these data to implement precision medicine initiatives and data-driven research has exceeded the capabilities of traditional computer systems. Modern big data platforms must be adapted to the specific demands of health care and designed for scalability and growth. Objective The objectives of our study were to (1) demonstrate the implementation of a data science platform built on open source technology within a large, academic health care system and (2) describe 2 computational health care applications built on such a platform. Methods We deployed a data science platform based on several open source technologies to support real-time, big data workloads. We developed data-acquisition workflows for Apache Storm and NiFi in Java and Python to capture patient monitoring and laboratory data for downstream analytics. Results Emerging data management approaches, along with open source technologies such as Hadoop, can be used to create integrated data lakes to store large, real-time datasets. This infrastructure also provides a robust analytics platform where health care and biomedical research data can be analyzed in near real time for precision medicine and computational health care use cases. Conclusions The implementation and use of integrated data science platforms offer organizations the opportunity to combine traditional datasets, including data from the electronic health record, with emerging big data sources, such as continuous patient monitoring and real-time laboratory results. These platforms can enable cost-effective and scalable analytics for the information that will be key to the delivery of precision medicine initiatives. Organizations that can take advantage of the technical advances found in data science platforms will have the opportunity to provide comprehensive access to health care data for computational health care and precision medicine research.",background health care data increas volum complex store analyz data implement precis medicin initi datadriven research exceed capabl tradit comput system modern big data platform must adapt specif demand health care design scalabl growth object object studi demonstr implement data scienc platform built open sourc technolog within larg academ health care system describ comput health care applic built platform method deploy data scienc platform base sever open sourc technolog support realtim big data workload develop dataacquisit workflow apach storm nifi java python captur patient monitor laboratori data downstream analyt result emerg data manag approach along open sourc technolog hadoop use creat integr data lake store larg realtim dataset infrastructur also provid robust analyt platform health care biomed research data analyz near real time precis medicin comput health care use case conclus implement use integr data scienc platform offer organ opportun combin tradit dataset includ data electron health record emerg big data sourc continu patient monitor realtim laboratori result platform enabl costeffect scalabl analyt inform key deliveri precis medicin initi organ take advantag technic advanc found data scienc platform opportun provid comprehens access health care data comput health care precis medicin research
b134d892f4e76081f5fa36b0b7c2e7118be53907,Genomics and data science: an application within an umbrella,,nan
e799d31e1c2d80a971c1f956d62b98c0a9f27031,Big Data and data science: A critical review of issues for educational research,"Big Data refers to large and disparate volumes of data generated by people, applications and machines. It is gaining increasing attention from a variety of domains, including education. What are the challenges of engaging with Big Data research in education? This paper identifies a wide range of critical issues that researchers need to consider when working with Big Data in education. The issues identified include diversity in the conception and meaning of Big Data in education, ontological, epistemological disparity, technical challenges, ethics and privacy, digital divide and digital dividend, lack of expertise and academic development opportunities to prepare educational researchers to leverage opportunities afforded by Big Data. The goal of this paper is to raise awareness on these issues and initiate a dialogue. The paper was inspired partly by insights drawn from the literature but mostly informed by experience researching into Big Data in education. [ABSTRACT FROM AUTHOR]",big data refer larg dispar volum data gener peopl applic machin gain increas attent varieti domain includ educ challeng engag big data research educ paper identifi wide rang critic issu research need consid work big data educ issu identifi includ divers concept mean big data educ ontolog epistemolog dispar technic challeng ethic privaci digit divid digit dividend lack expertis academ develop opportun prepar educ research leverag opportun afford big data goal paper rais awar issu initi dialogu paper inspir partli insight drawn literatur mostli inform experi research big data educ abstract author
eaa3bbe9e3c52781fd84149d8ee6e2670c90e5ec,Bayesian Optimization and Data Science,,nan
747359803e9a734fa4f1338a83121a942f3da60e,Geographic Data Science,"It is widely acknowledged that the emergence of “Big Data” is having a profound and often controversial impact on the production of knowledge. In this context, Data Science has developed as an interdisciplinary approach that turns such “Big Data” into information. This article argues for the positive role that Geography can have on Data Science when being applied to spatially explicit problems; and inversely, makes the case that there is much that Geography and Geographical Analysis could learn from Data Science. We propose a deeper integration through an ambitious research agenda, including systems engineering, new methodological development, and work toward addressing some acute challenges around epistemology. We argue that such issues must be resolved in order to realize a Geographic Data Science, and that such goal would be a desirable one.",wide acknowledg emerg big data profound often controversi impact product knowledg context data scienc develop interdisciplinari approach turn big data inform articl argu posit role geographi data scienc appli spatial explicit problem invers make case much geographi geograph analysi could learn data scienc propos deeper integr ambiti research agenda includ system engin new methodolog develop work toward address acut challeng around epistemolog argu issu must resolv order realiz geograph data scienc goal would desir one
863a35bdd1ae803491801e283c2ae79fe973cf68,Microbiome data science,,nan
702cd9a7a128706b8a6ec88e7424e06c326021e5,Upscaling urban data science for global climate solutions,"Non-technical summary Manhattan, Berlin and New Delhi all need to take action to adapt to climate change and to reduce greenhouse gas emissions. While case studies on these cities provide valuable insights, comparability and scalability remain sidelined. It is therefore timely to review the state-of-the-art in data infrastructures, including earth observations, social media data, and how they could be better integrated to advance climate change science in cities and urban areas. We present three routes for expanding knowledge on global urban areas: mainstreaming data collections, amplifying the use of big data and taking further advantage of computational methods to analyse qualitative data to gain new insights. These data-based approaches have the potential to upscale urban climate solutions and effect change at the global scale. Technical summary Cities have an increasingly integral role in addressing climate change. To gain a common understanding of solutions, we require adequate and representative data of urban areas, including data on related greenhouse gas emissions, climate threats and of socio-economic contexts. Here, we review the current state of urban data science in the context of climate change, investigating the contribution of urban metabolism studies, remote sensing, big data approaches, urban economics, urban climate and weather studies. We outline three routes for upscaling urban data science for global climate solutions: 1) Mainstreaming and harmonizing data collection in cities worldwide; 2) Exploiting big data and machine learning to scale solutions while maintaining privacy; 3) Applying computational techniques and data science methods to analyse published qualitative information for the systematization and understanding of first-order climate effects and solutions. Collaborative efforts towards a joint data platform and integrated urban services would provide the quantitative foundations of the emerging global urban sustainability science.",nontechn summari manhattan berlin new delhi need take action adapt climat chang reduc greenhous ga emiss case studi citi provid valuabl insight compar scalabl remain sidelin therefor time review stateoftheart data infrastructur includ earth observ social media data could better integr advanc climat chang scienc citi urban area present three rout expand knowledg global urban area mainstream data collect amplifi use big data take advantag comput method analys qualit data gain new insight databas approach potenti upscal urban climat solut effect chang global scale technic summari citi increasingli integr role address climat chang gain common understand solut requir adequ repres data urban area includ data relat greenhous ga emiss climat threat socioeconom context review current state urban data scienc context climat chang investig contribut urban metabol studi remot sens big data approach urban econom urban climat weather studi outlin three rout upscal urban data scienc global climat solut mainstream harmon data collect citi worldwid exploit big data machin learn scale solut maintain privaci appli comput techniqu data scienc method analys publish qualit inform systemat understand firstord climat effect solut collabor effort toward joint data platform integr urban servic would provid quantit foundat emerg global urban sustain scienc
f9e0e85732f0736c0d5a6f0c63df5c7f1f245dcd,From hype to reality: data science enabling personalized medicine,,nan
590ead4aeddbf8fea8414998b2dc3b74576a71cb,A Second Chance to Get Causal Inference Right: A Classification of Data Science Tasks,"Causal inference from observational data is the goal of many data analyses in the health and social sciences. However, academic statistics has often frowned upon data analyses with a causal objective. The introduction of the term ""data science"" provides a historic opportunity to redefine data analysis in such a way that it naturally accommodates causal inference from observational data. Like others before, we organize the scientific contributions of data science into three classes of tasks: Description, prediction, and counterfactual prediction (which includes causal inference). An explicit classification of data science tasks is necessary to discuss the data, assumptions, and analytics required to successfully accomplish each task. We argue that a failure to adequately describe the role of subject-matter expert knowledge in data analysis is a source of widespread misunderstandings about data science. Specifically, causal analyses typically require not only good data and algorithms, but also domain expert knowledge. We discuss the implications for the use of data science to guide decision-making in the real world and to train data scientists.",causal infer observ data goal mani data analys health social scienc howev academ statist often frown upon data analys causal object introduct term data scienc provid histor opportun redefin data analysi way natur accommod causal infer observ data like other organ scientif contribut data scienc three class task descript predict counterfactu predict includ causal infer explicit classif data scienc task necessari discuss data assumpt analyt requir success accomplish task argu failur adequ describ role subjectmatt expert knowledg data analysi sourc widespread misunderstand data scienc specif causal analys typic requir good data algorithm also domain expert knowledg discuss implic use data scienc guid decisionmak real world train data scientist
bb44d1472bb281c699ef556f6eb6ccc66889f2d3,Data Science and Machine Learning,"The purpose of Data Science and Machine Learning: Mathematical and Statistical Methods is to provide an accessible, yet comprehensive textbook intended for students interested in gaining a better understanding of the mathematics and statistics that underpin the rich variety of ideas and machine learning algorithms in data science.",purpos data scienc machin learn mathemat statist method provid access yet comprehens textbook intend student interest gain better understand mathemat statist underpin rich varieti idea machin learn algorithm data scienc
bb6adeeb3a21479cc45490a5c2ff6d8dd5e77603,Knowledge-based Biomedical Data Science 2019,"Knowledge-based biomedical data science involves the design and implementation of computer systems that act as if they knew about biomedicine. Such systems depend on formally represented knowledge in computer systems, often in the form of knowledge graphs. Here we survey recent progress in systems that use formally represented knowledge to address data science problems in both clinical and biological domains, as well as progress on approaches for creating knowledge graphs. Major themes include the relationships between knowledge graphs and machine learning, the use of natural language processing to construct knowledge graphs, and the expansion of novel knowledge-based approaches to clinical and biological domains.",knowledgebas biomed data scienc involv design implement comput system act knew biomedicin system depend formal repres knowledg comput system often form knowledg graph survey recent progress system use formal repres knowledg address data scienc problem clinic biolog domain well progress approach creat knowledg graph major theme includ relationship knowledg graph machin learn use natur languag process construct knowledg graph expans novel knowledgebas approach clinic biolog domain
8d446e7af03d7c7f9fe5828b2d9939e23a3ed7b0,A Data Science Framework for Movement,"Author(s): Dodge, S | Abstract: © 2019 The Ohio State University Movement is the driving force behind the form and function of many ecological and human systems. Identification and analysis of movement patterns that may relate to the behavior of individuals and their interactions is a fundamental first step in understanding these systems. With advances in IoT and the ubiquity of smart connected sensors to collect movement and contextual data, we now have access to a wealth of geo-enriched high-resolution tracking data. These data promise new forms of knowledge and insight into movement of humans, animals, and goods, and hence can increase our understanding of complex spatiotemporal processes such as disease outbreak, urban mobility, migration, and human-species interaction. To take advantage of the evolution in our data, we need a revolution in how we visualize, model, and analyze movement as a multidimensional process that involves space, time, and context. This paper introduces a data science paradigm with the aim of advancing research on movement.",author dodg abstract ohio state univers movement drive forc behind form function mani ecolog human system identif analysi movement pattern may relat behavior individu interact fundament first step understand system advanc iot ubiqu smart connect sensor collect movement contextu data access wealth geoenrich highresolut track data data promis new form knowledg insight movement human anim good henc increas understand complex spatiotempor process diseas outbreak urban mobil migrat humanspeci interact take advantag evolut data need revolut visual model analyz movement multidimension process involv space time context paper introduc data scienc paradigm aim advanc research movement
daec8baf1740a09725b375729d95caebc42f61c8,ACM Task Force on Data Science Education: Draft Report and Opportunity for Feedback,"The ACM Data Science Task Force was established by the ACM Education Council and tasked with articulating the role of computing discipline-specific contributions to this emerging field. This special session seeks to introduce the work of the ACM Data Science Task Force as well as to engage the SIGCSE community in this effort. Members of the task force will introduce key components of a draft report, including a summary of data science curricular efforts to date, results of ACM academic and industry surveys on data science, as well as the initial articulation of computing competencies for undergraduate programs in data science. This session should be of interest to all SIGCSE attendees, but especially faculty developing college-level curricula in Data Science.",acm data scienc task forc establish acm educ council task articul role comput disciplinespecif contribut emerg field special session seek introduc work acm data scienc task forc well engag sigcs commun effort member task forc introduc key compon draft report includ summari data scienc curricular effort date result acm academ industri survey data scienc well initi articul comput compet undergradu program data scienc session interest sigcs attende especi faculti develop collegelevel curricula data scienc
36708c11c2fde2efb50e75d81f174b2c205082c8,What is responsible and sustainable data science?,"In the expansion of health ecosystems, issues of responsibility and sustainability of the data science involved are central. The idea that these values should be central to the practice of data science is increasingly gaining traction, yet there is no agreement on what exactly makes data science responsible or sustainable because these concepts prove slippery when applied to a global field involving commercial, academic and governmental actors. This lack of clarity is causing problems in setting goals and boundaries for data scientific practice, and risks fundamental disagreement on governance principles for this emerging field. We will argue in this commentary for a commons analytical framework as one approach to this problem, since it offers useful signposts for how to establish governance principles for shared resources.",expans health ecosystem issu respons sustain data scienc involv central idea valu central practic data scienc increasingli gain traction yet agreement exactli make data scienc respons sustain concept prove slipperi appli global field involv commerci academ government actor lack clariti caus problem set goal boundari data scientif practic risk fundament disagr govern principl emerg field argu commentari common analyt framework one approach problem sinc offer use signpost establish govern principl share resourc
4f0218eb9ed62d5acc03f02bfa24b388a66067e8,Distance geometry and data science,,nan
46f1c45c62b7dbf77af405f5ddcf137b5e1ddde9,Data science from a library and information science perspective,"
Purpose
Data science is a relatively new field which has gained considerable attention in recent years. This new field requires a wide range of knowledge and skills from different disciplines including mathematics and statistics, computer science and information science. The purpose of this paper is to present the results of the study that explored the field of data science from the library and information science (LIS) perspective.


Design/methodology/approach
Analysis of research publications on data science was made on the basis of papers published in the Web of Science database. The following research questions were proposed: What are the main tendencies in publication years, document types, countries of origin, source titles, authors of publications, affiliations of the article authors and the most cited articles related to data science in the field of LIS? What are the main themes discussed in the publications from the LIS perspective?


Findings
The highest contribution to data science comes from the computer science research community. The contribution of information science and library science community is quite small. However, there has been continuous increase in articles from the year 2015. The main document types are journal articles, followed by conference proceedings and editorial material. The top three journals that publish data science papers from the LIS perspective are the Journal of the American Medical Informatics Association, the International Journal of Information Management and the Journal of the Association for Information Science and Technology. The top five countries publishing are USA, China, England, Australia and India. The most cited article has got 112 citations. The analysis revealed that the data science field is quite interdisciplinary by nature. In addition to the field of LIS the papers belonged to several other research areas. The reviewed articles belonged to the six broad categories: data science education and training; knowledge and skills of the data professional; the role of libraries and librarians in the data science movement; tools, techniques and applications of data science; data science from the knowledge management perspective; and data science from the perspective of health sciences.


Research limitations/implications
The limitations of this research are that this study only analyzed research papers in the Web of Science database and therefore only covers a certain amount of scientific papers published in the field of LIS. In addition, only publications with the term “data science” in the topic area of the Web of Science database were analyzed. Therefore, several relevant studies are not discussed in this paper that are not reflected in the Web of Science database or were related to other keywords such as “e-science,” “e-research,” “data service,” “data curation” or “research data management.”


Originality/value
The field of data science has not been explored using bibliographic analysis of publications from the perspective of the LIS. This paper helps to better understand the field of data science and the perspectives for information professionals.
",purpos data scienc rel new field gain consider attent recent year new field requir wide rang knowledg skill differ disciplin includ mathemat statist comput scienc inform scienc purpos paper present result studi explor field data scienc librari inform scienc li perspect designmethodologyapproach analysi research public data scienc made basi paper publish web scienc databas follow research question propos main tendenc public year document type countri origin sourc titl author public affili articl author cite articl relat data scienc field li main theme discuss public li perspect find highest contribut data scienc come comput scienc research commun contribut inform scienc librari scienc commun quit small howev continu increas articl year main document type journal articl follow confer proceed editori materi top three journal publish data scienc paper li perspect journal american medic informat associ intern journal inform manag journal associ inform scienc technolog top five countri publish usa china england australia india cite articl got citat analysi reveal data scienc field quit interdisciplinari natur addit field li paper belong sever research area review articl belong six broad categori data scienc educ train knowledg skill data profession role librari librarian data scienc movement tool techniqu applic data scienc data scienc knowledg manag perspect data scienc perspect health scienc research limitationsimpl limit research studi analyz research paper web scienc databas therefor cover certain amount scientif paper publish field li addit public term data scienc topic area web scienc databas analyz therefor sever relev studi discuss paper reflect web scienc databas relat keyword escienc eresearch data servic data curat research data manag originalityvalu field data scienc explor use bibliograph analysi public perspect li paper help better understand field data scienc perspect inform profession
4aeda303fa0b9beae3f6d65e052dace9d4540116,Data Science Support at the Academic Library,"Abstract Data science is a rapidly growing field with applications across all scientific domains. The demand for support in data science literacy is outpacing available resources at college campuses. The academic library is uniquely positioned to provide training and guidance in a number of areas relevant to data science. The University of Arizona Libraries has built a successful data science support program, focusing on computational literacy, geographic information systems, and reproducible science. Success of the program has largely been due to the strength of library personnel and strategic partnerships with units outside of the library. Academic libraries can support campus data science needs through professional development of current staff and recruitment of new personnel with expertise in data-intensive domains.",abstract data scienc rapidli grow field applic across scientif domain demand support data scienc literaci outpac avail resourc colleg campus academ librari uniqu posit provid train guidanc number area relev data scienc univers arizona librari built success data scienc support program focus comput literaci geograph inform system reproduc scienc success program larg due strength librari personnel strateg partnership unit outsid librari academ librari support campu data scienc need profession develop current staff recruit new personnel expertis dataintens domain
fb566f2001e44a65433fb7cc2eb7bcf6513a7db8,The 9 Pitfalls of Data Science,"Scientific rigor and critical thinking skills are indispensable in this age of big data because machine learning and artificial intelligence are often led astray by meaningless patterns. The 9 Pitfalls of Data Science is loaded with entertaining real-world examples of both successful and misguided approaches to interpreting data, both grand successes and epic failures. Anyone can learn to distinguish between good data science and nonsense. We are confident that readers will learn how to avoid being duped by data, and make better, more informed decisions. Whether they want to be effective creators, interpreters, or users of data, they need to know the nine pitfalls of data science.",scientif rigor critic think skill indispens age big data machin learn artifici intellig often led astray meaningless pattern pitfal data scienc load entertain realworld exampl success misguid approach interpret data grand success epic failur anyon learn distinguish good data scienc nonsens confid reader learn avoid dupe data make better inform decis whether want effect creator interpret user data need know nine pitfal data scienc
08468bac470e5c2cbbd2b66e8e7cf2ab65f38e02,Data Science for Local Government,"The Data Science for Local Government project was about understanding how the growth of ‘data science’ is changing the way that local government works in the UK. We define data science as a dual shift which involves both bringing in new decision making and analytical techniques to local government work (e.g. machine learning and predictive analytics, artificial intelligence and A/B testing) and also expanding the types of data local government makes use of (for example, by repurposing administrative data, harvesting social media data, or working with mobile phone companies). The emergence of data science is facilitated by the growing availability of free, open-source tools for both collecting data and performing analysis. Based on extensive documentary review, a nationwide survey of local authorities, and in-depth interviews with over 30 practitioners, we have sought to produce a comprehensive guide to the different types of data science being undertaken in the UK, the types of opportunities and benefits created, and also some of the challenges and difficulties being encountered. Our aim was to provide a basis for people working in local government to start on their own data science projects, both by providing a library of dozens of ideas which have been tried elsewhere and also by providing hints and tips for overcoming key problems and challenges.",data scienc local govern project understand growth data scienc chang way local govern work uk defin data scienc dual shift involv bring new decis make analyt techniqu local govern work eg machin learn predict analyt artifici intellig ab test also expand type data local govern make use exampl repurpos administr data harvest social media data work mobil phone compani emerg data scienc facilit grow avail free opensourc tool collect data perform analysi base extens documentari review nationwid survey local author indepth interview practition sought produc comprehens guid differ type data scienc undertaken uk type opportun benefit creat also challeng difficulti encount aim provid basi peopl work local govern start data scienc project provid librari dozen idea tri elsewher also provid hint tip overcom key problem challeng
0a4b3c33e830d8cde364443a52e673c2c07dcfe8,Open Data Science,,nan
e1c8f86668d3e37e430f187b7fd91d1643a0a0ff,Theory-Guided Data Science: A New Paradigm for Scientific Discovery from Data,"Data science models, although successful in a number of commercial domains, have had limited applicability in scientific problems involving complex physical phenomena. Theory-guided data science (TGDS) is an emerging paradigm that aims to leverage the wealth of scientific knowledge for improving the effectiveness of data science models in enabling scientific discovery. The overarching vision of TGDS is to introduce scientific consistency as an essential component for learning generalizable models. Further, by producing scientifically interpretable models, TGDS aims to advance our scientific understanding by discovering novel domain insights. Indeed, the paradigm of TGDS has started to gain prominence in a number of scientific disciplines such as turbulence modeling, material discovery, quantum chemistry, bio-medical science, bio-marker discovery, climate science, and hydrology. In this paper, we formally conceptualize the paradigm of TGDS and present a taxonomy of research themes in TGDS. We describe several approaches for integrating domain knowledge in different research themes using illustrative examples from different disciplines. We also highlight some of the promising avenues of novel research for realizing the full potential of theory-guided data science.",data scienc model although success number commerci domain limit applic scientif problem involv complex physic phenomena theoryguid data scienc tgd emerg paradigm aim leverag wealth scientif knowledg improv effect data scienc model enabl scientif discoveri overarch vision tgd introduc scientif consist essenti compon learn generaliz model produc scientif interpret model tgd aim advanc scientif understand discov novel domain insight inde paradigm tgd start gain promin number scientif disciplin turbul model materi discoveri quantum chemistri biomed scienc biomark discoveri climat scienc hydrolog paper formal conceptu paradigm tgd present taxonomi research theme tgd describ sever approach integr domain knowledg differ research theme use illustr exampl differ disciplin also highlight promis avenu novel research realiz full potenti theoryguid data scienc
bf12943b1862cbdf556ba1ddcdbc685d4f38a6c3,Realizing the potential of data science,"Data science promises new insights, helping transform information into knowledge that can drive science and industry.",data scienc promis new insight help transform inform knowledg drive scienc industri
6bec0106bebc93fc30ec47af9779d7e327639034,Machine learning and data science in soft materials engineering,"In many branches of materials science it is now routine to generate data sets of such large size and dimensionality that conventional methods of analysis fail. Paradigms and tools from data science and machine learning can provide scalable approaches to identify and extract trends and patterns within voluminous data sets, perform guided traversals of high-dimensional phase spaces, and furnish data-driven strategies for inverse materials design. This topical review provides an accessible introduction to machine learning tools in the context of soft and biological materials by ‘de-jargonizing’ data science terminology, presenting a taxonomy of machine learning techniques, and surveying the mathematical underpinnings and software implementations of popular tools, including principal component analysis, independent component analysis, diffusion maps, support vector machines, and relative entropy. We present illustrative examples of machine learning applications in soft matter, including inverse design of self-assembling materials, nonlinear learning of protein folding landscapes, high-throughput antimicrobial peptide design, and data-driven materials design engines. We close with an outlook on the challenges and opportunities for the field.",mani branch materi scienc routin gener data set larg size dimension convent method analysi fail paradigm tool data scienc machin learn provid scalabl approach identifi extract trend pattern within volumin data set perform guid travers highdimension phase space furnish datadriven strategi invers materi design topic review provid access introduct machin learn tool context soft biolog materi dejargon data scienc terminolog present taxonomi machin learn techniqu survey mathemat underpin softwar implement popular tool includ princip compon analysi independ compon analysi diffus map support vector machin rel entropi present illustr exampl machin learn applic soft matter includ invers design selfassembl materi nonlinear learn protein fold landscap highthroughput antimicrobi peptid design datadriven materi design engin close outlook challeng opportun field
c0b1eedfa2031a69fbdf02a4abc8a741faf6a912,Introduction to Data Science,,nan
ffdb6039a5d82f8edd70b2d177074c2f2c89e97f,Data Science as Political Action: Grounding Data Science in a Politics of Justice,"In response to recent controversies, the field of data science has rushed to adopt codes of ethics. Such professional codes, however, are ill-equipped to address broad matters of social justice. Instead of ethics codes, I argue, the field must embrace politics. Data scientists must recognize themselves as political actors engaged in normative constructions of society and, as befits political work, evaluate their work according to its downstream material impacts on people's lives. I justify this notion in two parts: first, by articulating why data scientists must recognize themselves as political actors, and second, by describing how the field can evolve toward a deliberative and rigorous grounding in a politics of social justice. Part 1 responds to three arguments that are commonly invoked by data scientists when they are challenged to take political positions regarding their work. In confronting these arguments, I will demonstrate why attempting to remain apolitical is itself a political stance--a fundamentally conservative one--and why the field's current attempts to promote ""social good"" dangerously rely on vague and unarticulated political assumptions. Part 2 proposes a framework for what a politically-engaged data science could look like and how to achieve it, recognizing the challenge of reforming the field in this manner. I conceptualize the process of incorporating politics into data science in four stages: becoming interested in directly addressing social issues, recognizing the politics underlying these issues, redirecting existing methods toward new applications, and, finally, developing new practices and methods that orient data science around a mission of social justice. The path ahead does not require data scientists to abandon their technical expertise, but it does entail expanding their notions of what problems to work on and how to engage with society.",respons recent controversi field data scienc rush adopt code ethic profession code howev illequip address broad matter social justic instead ethic code argu field must embrac polit data scientist must recogn polit actor engag norm construct societi befit polit work evalu work accord downstream materi impact peopl live justifi notion two part first articul data scientist must recogn polit actor second describ field evolv toward delib rigor ground polit social justic part respond three argument commonli invok data scientist challeng take polit posit regard work confront argument demonstr attempt remain apolit polit stancea fundament conserv oneand field current attempt promot social good danger reli vagu unarticul polit assumpt part propos framework politicallyengag data scienc could look like achiev recogn challeng reform field manner conceptu process incorpor polit data scienc four stage becom interest directli address social issu recogn polit underli issu redirect exist method toward new applic final develop new practic method orient data scienc around mission social justic path ahead requir data scientist abandon technic expertis entail expand notion problem work engag societi
3335c340c20609b4e6de481c9eaf67ecd6c960dc,Evaluation of a Tree-based Pipeline Optimization Tool for Automating Data Science,"As the field of data science continues to grow, there will be an ever-increasing demand for tools that make machine learning accessible to non-experts. In this paper, we introduce the concept of tree-based pipeline optimization for automating one of the most tedious parts of machine learning--pipeline design. We implement an open source Tree-based Pipeline Optimization Tool (TPOT) in Python and demonstrate its effectiveness on a series of simulated and real-world benchmark data sets. In particular, we show that TPOT can design machine learning pipelines that provide a significant improvement over a basic machine learning analysis while requiring little to no input nor prior knowledge from the user. We also address the tendency for TPOT to design overly complex pipelines by integrating Pareto optimization, which produces compact pipelines without sacrificing classification accuracy. As such, this work represents an important step toward fully automating machine learning pipeline design.",field data scienc continu grow everincreas demand tool make machin learn access nonexpert paper introduc concept treebas pipelin optim autom one tediou part machin learningpipelin design implement open sourc treebas pipelin optim tool tpot python demonstr effect seri simul realworld benchmark data set particular show tpot design machin learn pipelin provid signific improv basic machin learn analysi requir littl input prior knowledg user also address tendenc tpot design overli complex pipelin integr pareto optim produc compact pipelin without sacrif classif accuraci work repres import step toward fulli autom machin learn pipelin design
c0b1eedfa2031a69fbdf02a4abc8a741faf6a912,Introduction to Data Science,,nan
ffdb6039a5d82f8edd70b2d177074c2f2c89e97f,Data Science as Political Action: Grounding Data Science in a Politics of Justice,"In response to recent controversies, the field of data science has rushed to adopt codes of ethics. Such professional codes, however, are ill-equipped to address broad matters of social justice. Instead of ethics codes, I argue, the field must embrace politics. Data scientists must recognize themselves as political actors engaged in normative constructions of society and, as befits political work, evaluate their work according to its downstream material impacts on people's lives. I justify this notion in two parts: first, by articulating why data scientists must recognize themselves as political actors, and second, by describing how the field can evolve toward a deliberative and rigorous grounding in a politics of social justice. Part 1 responds to three arguments that are commonly invoked by data scientists when they are challenged to take political positions regarding their work. In confronting these arguments, I will demonstrate why attempting to remain apolitical is itself a political stance--a fundamentally conservative one--and why the field's current attempts to promote ""social good"" dangerously rely on vague and unarticulated political assumptions. Part 2 proposes a framework for what a politically-engaged data science could look like and how to achieve it, recognizing the challenge of reforming the field in this manner. I conceptualize the process of incorporating politics into data science in four stages: becoming interested in directly addressing social issues, recognizing the politics underlying these issues, redirecting existing methods toward new applications, and, finally, developing new practices and methods that orient data science around a mission of social justice. The path ahead does not require data scientists to abandon their technical expertise, but it does entail expanding their notions of what problems to work on and how to engage with society.",respons recent controversi field data scienc rush adopt code ethic profession code howev illequip address broad matter social justic instead ethic code argu field must embrac polit data scientist must recogn polit actor engag norm construct societi befit polit work evalu work accord downstream materi impact peopl live justifi notion two part first articul data scientist must recogn polit actor second describ field evolv toward delib rigor ground polit social justic part respond three argument commonli invok data scientist challeng take polit posit regard work confront argument demonstr attempt remain apolit polit stancea fundament conserv oneand field current attempt promot social good danger reli vagu unarticul polit assumpt part propos framework politicallyengag data scienc could look like achiev recogn challeng reform field manner conceptu process incorpor polit data scienc four stage becom interest directli address social issu recogn polit underli issu redirect exist method toward new applic final develop new practic method orient data scienc around mission social justic path ahead requir data scientist abandon technic expertis entail expand notion problem work engag societi
3335c340c20609b4e6de481c9eaf67ecd6c960dc,Evaluation of a Tree-based Pipeline Optimization Tool for Automating Data Science,"As the field of data science continues to grow, there will be an ever-increasing demand for tools that make machine learning accessible to non-experts. In this paper, we introduce the concept of tree-based pipeline optimization for automating one of the most tedious parts of machine learning--pipeline design. We implement an open source Tree-based Pipeline Optimization Tool (TPOT) in Python and demonstrate its effectiveness on a series of simulated and real-world benchmark data sets. In particular, we show that TPOT can design machine learning pipelines that provide a significant improvement over a basic machine learning analysis while requiring little to no input nor prior knowledge from the user. We also address the tendency for TPOT to design overly complex pipelines by integrating Pareto optimization, which produces compact pipelines without sacrificing classification accuracy. As such, this work represents an important step toward fully automating machine learning pipeline design.",field data scienc continu grow everincreas demand tool make machin learn access nonexpert paper introduc concept treebas pipelin optim autom one tediou part machin learningpipelin design implement open sourc treebas pipelin optim tool tpot python demonstr effect seri simul realworld benchmark data set particular show tpot design machin learn pipelin provid signific improv basic machin learn analysi requir littl input prior knowledg user also address tendenc tpot design overli complex pipelin integr pareto optim produc compact pipelin without sacrif classif accuraci work repres import step toward fulli autom machin learn pipelin design
140a6476f7b8dde9e7bbcd199d248fc629721faa,Trust in Data Science,"The trustworthiness of data science systems in applied and real-world settings emerges from the resolution of specific tensions through situated, pragmatic, and ongoing forms of work. Drawing on research in CSCW, critical data studies, and history and sociology of science, and six months of immersive ethnographic fieldwork with a corporate data science team, we describe four common tensions in applied data science work: (un)equivocal numbers, (counter)intuitive knowledge, (in)credible data, and (in)scrutable models. We show how organizational actors establish and re-negotiate trust under messy and uncertain analytic conditions through practices of skepticism, assessment, and credibility. Highlighting the collaborative and heterogeneous nature of real-world data science, we show how the management of trust in applied corporate data science settings depends not only on pre-processing and quantification, but also on negotiation and translation. We conclude by discussing the implications of our findings for data science research and practice, both within and beyond CSCW.",trustworthi data scienc system appli realworld set emerg resolut specif tension situat pragmat ongo form work draw research cscw critic data studi histori sociolog scienc six month immers ethnograph fieldwork corpor data scienc team describ four common tension appli data scienc work unequivoc number counterintuit knowledg incred data inscrut model show organiz actor establish renegoti trust messi uncertain analyt condit practic skeptic assess credibl highlight collabor heterogen natur realworld data scienc show manag trust appli corpor data scienc set depend preprocess quantif also negoti translat conclud discuss implic find data scienc research practic within beyond cscw
305600f3cba8a63bad1bedeab34a299bf748754b,Northstar: An Interactive Data Science System,"In order to democratize data science, we need to fundamentally rethink the current analytics stack, from the user interface to the ""guts."" Most importantly, enabling a broader range of users to unfold the potential of (their) data requires a change in the interface and the ""protection"" we offer them. On the one hand, visual interfaces for data science have to be intuitive, easy, and interactive to reach users without a strong background in computer science or statistics. On the other hand, we need to protect users from making false discoveries. Furthermore, it requires that technically involved (and often boring) tasks have to be automatically done by the system so that the user can focus on contributing their domain expertise to the problem. In this paper, we present Northstar, the Interactive Data Science System, which we have developed over the last 4 years to explore designs that make advanced analytics and model building more accessible.",order democrat data scienc need fundament rethink current analyt stack user interfac gut importantli enabl broader rang user unfold potenti data requir chang interfac protect offer one hand visual interfac data scienc intuit easi interact reach user without strong background comput scienc statist hand need protect user make fals discoveri furthermor requir technic involv often bore task automat done system user focu contribut domain expertis problem paper present northstar interact data scienc system develop last year explor design make advanc analyt model build access
577564ac25a12b37972d77a35b589f6b2270a45f,Big Data and Data Science in Critical Care.,,nan
6e8d94181832771bc5dca8d288c52b6ad5914029,Data Science as Machinic Neoplatonism,,nan
f968cdd4637e7b26ca6c057a2f7f593b8cea2d18,Fundamentals of Clinical Data Science,,nan
ff6586ab32e9ed45d20a486ec7c5be02da5d3f1f,Data Science: the impact of statistics,,nan
6bf9d589f80823735084956f056728ae1a7bcfa8,"Situating Ecology as a Big-Data Science: Current Advances, Challenges, and Solutions","Ecology has joined a world of big data. Two complementary frameworks define big data: data that exceed the analytical capacities of individuals or disciplines or the “Four Vs” axes of volume, variety, veracity, and velocity. Variety predominates in ecoinformatics and limits the scalability of ecological science. Volume varies widely. Ecological velocity is low but growing as data throughput and societal needs increase. Ecological big-data systems include in situ and remote sensors, community data resources, biodiversity databases, citizen science, and permanent stations. Technological solutions include the development of open code- and data-sharing platforms, flexible statistical models that can handle heterogeneous data and sources of uncertainty, and cloud-computing delivery of high-velocity computing to large-volume analytics. Cultural solutions include training targeted to early and current scientific workforce and strengthening collaborations among ecologists and data scientists. The broader goal is to maximize the power, scalability, and timeliness of ecological insights and forecasting.",ecolog join world big data two complementari framework defin big data data exceed analyt capac individu disciplin four vs axe volum varieti verac veloc varieti predomin ecoinformat limit scalabl ecolog scienc volum vari wide ecolog veloc low grow data throughput societ need increas ecolog bigdata system includ situ remot sensor commun data resourc biodivers databas citizen scienc perman station technolog solut includ develop open code datashar platform flexibl statist model handl heterogen data sourc uncertainti cloudcomput deliveri highveloc comput largevolum analyt cultur solut includ train target earli current scientif workforc strengthen collabor among ecologist data scientist broader goal maxim power scalabl timeli ecolog insight forecast
2146edb37621d80f53c1261c8a53c94d3dda84c8,Smart Blockchain Badges for Data Science Education,"Blockchain technology has the potential to revolutionise education in a number of ways. In this paper, we explore the applications of Smart Blockchain Badges on data science education. In particular, we investigate how Smart Blockchain Badges can support learners that want to advance their careers in data science, by offering them personalised recommendations based on their learning achievements. This work aims at enhancing data science accreditation by introducing a robust system based on the Blockchain technology. Learners will benefit from a sophisticated, open and transparent accreditation system, as well as from receiving job recommendations that match their skills and can potentially progress their careers. As a result, this work contributes towards closing the data science skills gap by linking data science education to the industry.",blockchain technolog potenti revolutionis educ number way paper explor applic smart blockchain badg data scienc educ particular investig smart blockchain badg support learner want advanc career data scienc offer personalis recommend base learn achiev work aim enhanc data scienc accredit introduc robust system base blockchain technolog learner benefit sophist open transpar accredit system well receiv job recommend match skill potenti progress career result work contribut toward close data scienc skill gap link data scienc educ industri
2a85f034ae7a6119ae6b718c8f73a58dc1fbd7b4,Curriculum Guidelines for Undergraduate Programs in Data Science,"The Park City Math Institute (PCMI) 2016 Summer Undergraduate Faculty Program met for the purpose of composing guidelines for undergraduate programs in Data Science. The group consisted of 25 undergraduate faculty from a variety of institutions in the U.S., primarily from the disciplines of mathematics, statistics and computer science. These guidelines are meant to provide some structure for institutions planning for or revising a major in Data Science.",park citi math institut pcmi summer undergradu faculti program met purpos compos guidelin undergradu program data scienc group consist undergradu faculti varieti institut us primarili disciplin mathemat statist comput scienc guidelin meant provid structur institut plan revis major data scienc
0ec2d4c804dd2b4446e1808dc85b4fe4a27b1766,Surgical data science for next-generation interventions,,nan
c0225f99c9b1619c3be74b63241faffe02d275d7,Science and data science,"Data science has attracted a lot of attention, promising to turn vast amounts of data into useful predictions and insights. In this article, we ask why scientists should care about data science. To answer, we discuss data science from three perspectives: statistical, computational, and human. Although each of the three is a critical component of data science, we argue that the effective combination of all three components is the essence of what data science is about.",data scienc attract lot attent promis turn vast amount data use predict insight articl ask scientist care data scienc answer discuss data scienc three perspect statist comput human although three critic compon data scienc argu effect combin three compon essenc data scienc
79be83a308a9a75ef4e64f63a938b201531c0bbf,Data Science,"The 21st century has ushered in the age of big data and data economy, in which data DNA, which carries important knowledge, insights, and potential, has become an intrinsic constituent of all data-based organisms. An appropriate understanding of data DNA and its organisms relies on the new field of data science and its keystone, analytics. Although it is widely debated whether big data is only hype and buzz, and data science is still in a very early phase, significant challenges and opportunities are emerging or have been inspired by the research, innovation, business, profession, and education of data science. This article provides a comprehensive survey and tutorial of the fundamental aspects of data science: the evolution from data analysis to data science, the data science concepts, a big picture of the era of data science, the major challenges and directions in data innovation, the nature of data analytics, new industrialization and service opportunities in the data economy, the profession and competency of data education, and the future of data science. This article is the first in the field to draw a comprehensive big picture, in addition to offering rich observations, lessons, and thinking about data science and analytics.",st centuri usher age big data data economi data dna carri import knowledg insight potenti becom intrins constitu databas organ appropri understand data dna organ reli new field data scienc keyston analyt although wide debat whether big data hype buzz data scienc still earli phase signific challeng opportun emerg inspir research innov busi profess educ data scienc articl provid comprehens survey tutori fundament aspect data scienc evolut data analysi data scienc data scienc concept big pictur era data scienc major challeng direct data innov natur data analyt new industri servic opportun data economi profess compet data educ futur data scienc articl first field draw comprehens big pictur addit offer rich observ lesson think data scienc analyt
e4c66275e46a66586365c851f0974a3c88baf3d7,Network embedding in biomedical data science,"Owning to the rapid development of computer technologies, an increasing number of relational data have been emerging in modern biomedical research. Many network-based learning methods have been proposed to perform analysis on such data, which provide people a deep understanding of topology and knowledge behind the biomedical networks and benefit a lot of applications for human healthcare. However, most network-based methods suffer from high computational and space cost. There remain challenges on handling high dimensionality and sparsity of the biomedical networks. The latest advances in network embedding technologies provide new effective paradigms to solve the network analysis problem. It converts network into a low-dimensional space while maximally preserves structural properties. In this way, downstream tasks such as link prediction and node classification can be done by traditional machine learning methods. In this survey, we conduct a comprehensive review of the literature on applying network embedding to advance the biomedical domain. We first briefly introduce the widely used network embedding models. After that, we carefully discuss how the network embedding approaches were performed on biomedical networks as well as how they accelerated the downstream tasks in biomedical science. Finally, we discuss challenges the existing network embedding applications in biomedical domains are faced with and suggest several promising future directions for a better improvement in human healthcare.",own rapid develop comput technolog increas number relat data emerg modern biomed research mani networkbas learn method propos perform analysi data provid peopl deep understand topolog knowledg behind biomed network benefit lot applic human healthcar howev networkbas method suffer high comput space cost remain challeng handl high dimension sparsiti biomed network latest advanc network embed technolog provid new effect paradigm solv network analysi problem convert network lowdimension space maxim preserv structur properti way downstream task link predict node classif done tradit machin learn method survey conduct comprehens review literatur appli network embed advanc biomed domain first briefli introduc wide use network embed model care discuss network embed approach perform biomed network well acceler downstream task biomed scienc final discuss challeng exist network embed applic biomed domain face suggest sever promis futur direct better improv human healthcar
89535aa63bc5dac6f3beb60b813abb77aa4309d1,Critique and Contribute: A Practice-Based Framework for Improving Critical Data Studies and Data Science,"Abstract What would data science look like if its key critics were engaged to help improve it, and how might critiques of data science improve with an approach that considers the day-to-day practices of data science? This article argues for scholars to bridge the conversations that seek to critique data science and those that seek to advance data science practice to identify and create the social and organizational arrangements necessary for a more ethical data science. We summarize four critiques that are commonly made in critical data studies: data are inherently interpretive, data are inextricable from context, data are mediated through the sociomaterial arrangements that produce them, and data serve as a medium for the negotiation and communication of values. We present qualitative research with academic data scientists, “data for good” projects, and specialized cross-disciplinary engineering teams to show evidence of these critiques in the day-to-day experience of data scientists as they acknowledge and grapple with the complexities of their work. Using ethnographic vignettes from two large multiresearcher field sites, we develop a set of concepts for analyzing and advancing the practice of data science and improving critical data studies, including (1) communication is central to the data science endeavor; (2) making sense of data is a collective process; (3) data are starting, not end points, and (4) data are sets of stories. We conclude with two calls to action for researchers and practitioners in data science and critical data studies alike. First, creating opportunities for bringing social scientific and humanistic expertise into data science practice simultaneously will advance both data science and critical data studies. Second, practitioners should leverage the insights from critical data studies to build new kinds of organizational arrangements, which we argue will help advance a more ethical data science. Engaging the insights of critical data studies will improve data science. Careful attention to the practices of data science will improve scholarly critiques. Genuine collaborative conversations between these different communities will help push for more ethical, and better, ways of knowing in increasingly datum-saturated societies.",abstract would data scienc look like key critic engag help improv might critiqu data scienc improv approach consid daytoday practic data scienc articl argu scholar bridg convers seek critiqu data scienc seek advanc data scienc practic identifi creat social organiz arrang necessari ethic data scienc summar four critiqu commonli made critic data studi data inher interpret data inextric context data mediat sociomateri arrang produc data serv medium negoti commun valu present qualit research academ data scientist data good project special crossdisciplinari engin team show evid critiqu daytoday experi data scientist acknowledg grappl complex work use ethnograph vignett two larg multiresearch field site develop set concept analyz advanc practic data scienc improv critic data studi includ commun central data scienc endeavor make sens data collect process data start end point data set stori conclud two call action research practition data scienc critic data studi alik first creat opportun bring social scientif humanist expertis data scienc practic simultan advanc data scienc critic data studi second practition leverag insight critic data studi build new kind organiz arrang argu help advanc ethic data scienc engag insight critic data studi improv data scienc care attent practic data scienc improv scholarli critiqu genuin collabor convers differ commun help push ethic better way know increasingli datumsatur societi
5a44f70130875b212452ad777ab02a4eb5cd35d9,A Position Statement on Population Data Science: The Science of Data about People,"Information is increasingly digital, creating opportunities to respond to pressing issues about human populations using linked datasets that are large, complex, and diverse. The potential social and individual benefits that can come from data-intensive science are large, but raise challenges of balancing individual privacy and the public good, building appropriate socio-technical systems to support data-intensive science, and determining whether defining a new field of inquiry might help move those collective interests and activities forward. A combination of expert engagement, literature review, and iterative conversations led to our conclusion that defining the field of Population Data Science (challenge 3) will help address the other two challenges as well. We define Population Data Science succinctly as the science of data about people and note that it is related to but distinct from the fields of data science and informatics. A broader definition names four characteristics of: data use for positive impact on citizens and society; bringing together and analyzing data from multiple sources; finding population-level insights; and developing safe, privacy-sensitive and ethical infrastructure to support research. One implication of these characteristics is that few people possess all of the requisite knowledge and skills of Population Data Science, so this is by nature a multi-disciplinary field. Other implications include the need to advance various aspects of science, such as data linkage technology, various forms of analytics, and methods of public engagement. These implications are the beginnings of a research agenda for Population Data Science, which if approached as a collective field, can catalyze significant advances in our understanding of trends in society, health, and human behavior.",inform increasingli digit creat opportun respond press issu human popul use link dataset larg complex divers potenti social individu benefit come dataintens scienc larg rais challeng balanc individu privaci public good build appropri sociotechn system support dataintens scienc determin whether defin new field inquiri might help move collect interest activ forward combin expert engag literatur review iter convers led conclus defin field popul data scienc challeng help address two challeng well defin popul data scienc succinctli scienc data peopl note relat distinct field data scienc informat broader definit name four characterist data use posit impact citizen societi bring togeth analyz data multipl sourc find populationlevel insight develop safe privacysensit ethic infrastructur support research one implic characterist peopl possess requisit knowledg skill popul data scienc natur multidisciplinari field implic includ need advanc variou aspect scienc data linkag technolog variou form analyt method public engag implic begin research agenda popul data scienc approach collect field catalyz signific advanc understand trend societi health human behavior
afe79672aa99b7f606cbff234ec2454cf2295554,Big Data Science: Opportunities and Challenges to Address Minority Health and Health Disparities in the 21st Century.,"Addressing minority health and health disparities has been a missing piece of the puzzle in Big Data science. This article focuses on three priority opportunities that Big Data science may offer to the reduction of health and health care disparities. One opportunity is to incorporate standardized information on demographic and social determinants in electronic health records in order to target ways to improve quality of care for the most disadvantaged populations over time. A second opportunity is to enhance public health surveillance by linking geographical variables and social determinants of health for geographically defined populations to clinical data and health outcomes. Third and most importantly, Big Data science may lead to a better understanding of the etiology of health disparities and understanding of minority health in order to guide intervention development. However, the promise of Big Data needs to be considered in light of significant challenges that threaten to widen health disparities. Care must be taken to incorporate diverse populations to realize the potential benefits. Specific recommendations include investing in data collection on small sample populations, building a diverse workforce pipeline for data science, actively seeking to reduce digital divides, developing novel ways to assure digital data privacy for small populations, and promoting widespread data sharing to benefit under-resourced minority-serving institutions and minority researchers. With deliberate efforts, Big Data presents a dramatic opportunity for reducing health disparities but without active engagement, it risks further widening them.",address minor health health dispar miss piec puzzl big data scienc articl focus three prioriti opportun big data scienc may offer reduct health health care dispar one opportun incorpor standard inform demograph social determin electron health record order target way improv qualiti care disadvantag popul time second opportun enhanc public health surveil link geograph variabl social determin health geograph defin popul clinic data health outcom third importantli big data scienc may lead better understand etiolog health dispar understand minor health order guid intervent develop howev promis big data need consid light signific challeng threaten widen health dispar care must taken incorpor divers popul realiz potenti benefit specif recommend includ invest data collect small sampl popul build divers workforc pipelin data scienc activ seek reduc digit divid develop novel way assur digit data privaci small popul promot widespread data share benefit underresourc minorityserv institut minor research deliber effort big data present dramat opportun reduc health dispar without activ engag risk widen
b154d9ce0a551be90557d7a24a49b1988add2a81,"Three principles of data science: predictability, computability, and stability (PCS)","In this talk, I'd like to discuss the intertwining importance and connections of three principles of data science in the title and the PCS workflow that is built on the three principles. The principles will be demonstrated in the context of two collaborative projects in neuroscience and genomics for interpretable data results and testable hypothesis generation.",talk id like discuss intertwin import connect three principl data scienc titl pc workflow built three principl principl demonstr context two collabor project neurosci genom interpret data result testabl hypothesi gener
cdd5d0a3e2ba0e1f4b5bcd3115e5f5b6536e24f9,The Data Science Design Manual,,nan
3c51a892ce5a8fc78d57ea290c6e5144ee9db579,Key Concepts for a Data Science Ethics Curriculum,"Data science is a new field that integrates aspects of computer science, statistics and information management. As a new field, ethical issues a data scientist may encounter have received little attention to date, and ethics training within a data science curriculum has received even less attention. To address this gap, this article explores the different codes of conduct and ethics frameworks related to data science. We compare this analysis with the results of a systematic literature review focusing on ethics in data science. Our analysis identified twelve key ethics areas that should be included within a data science ethics curriculum. Our research notes that none of the existing codes or frameworks covers all of the identified themes. Data science educators and program coordinators can use our results as a way to identify key ethical concepts that can be introduced within a data science program.",data scienc new field integr aspect comput scienc statist inform manag new field ethic issu data scientist may encount receiv littl attent date ethic train within data scienc curriculum receiv even less attent address gap articl explor differ code conduct ethic framework relat data scienc compar analysi result systemat literatur review focus ethic data scienc analysi identifi twelv key ethic area includ within data scienc ethic curriculum research note none exist code framework cover identifi theme data scienc educ program coordin use result way identifi key ethic concept introduc within data scienc program
fde0b586e3bc9e5139a14493044bce9ff61706d4,Inverse statistical problems: from the inverse Ising problem to data science,"Inverse problems in statistical physics are motivated by the challenges of ‘big data’ in different fields, in particular high-throughput experiments in biology. In inverse problems, the usual procedure of statistical physics needs to be reversed: Instead of calculating observables on the basis of model parameters, we seek to infer parameters of a model based on observations. In this review, we focus on the inverse Ising problem and closely related problems, namely how to infer the coupling strengths between spins given observed spin correlations, magnetizations, or other data. We review applications of the inverse Ising problem, including the reconstruction of neural connections, protein structure determination, and the inference of gene regulatory networks. For the inverse Ising problem in equilibrium, a number of controlled and uncontrolled approximate solutions have been developed in the statistical mechanics community. A particularly strong method, pseudolikelihood, stems from statistics. We also review the inverse Ising problem in the non-equilibrium case, where the model parameters must be reconstructed based on non-equilibrium statistics.",invers problem statist physic motiv challeng big data differ field particular highthroughput experi biolog invers problem usual procedur statist physic need revers instead calcul observ basi model paramet seek infer paramet model base observ review focu invers ise problem close relat problem name infer coupl strength spin given observ spin correl magnet data review applic invers ise problem includ reconstruct neural connect protein structur determin infer gene regulatori network invers ise problem equilibrium number control uncontrol approxim solut develop statist mechan commun particularli strong method pseudolikelihood stem statist also review invers ise problem nonequilibrium case model paramet must reconstruct base nonequilibrium statist
a1dbdc2ce338d694a720163f591e4eb5c4070140,Deep Learning in Biomedical Data Science,"Since the 1980s, deep learning and biomedical data have been coevolving and feeding each other. The breadth, complexity, and rapidly expanding size of biomedical data have stimulated the development of novel deep learning methods, and application of these methods to biomedical data have led to scientific discoveries and practical solutions. This overview provides technical and historical pointers to the field, and surveys current applications of deep learning to biomedical data organized around five subareas, roughly of increasing spatial scale: chemoinformatics, proteomics, genomics and transcriptomics, biomedical imaging, and health care. The black box problem of deep learning methods is also briefly discussed.",sinc deep learn biomed data coevolv feed breadth complex rapidli expand size biomed data stimul develop novel deep learn method applic method biomed data led scientif discoveri practic solut overview provid technic histor pointer field survey current applic deep learn biomed data organ around five subarea roughli increas spatial scale chemoinformat proteom genom transcriptom biomed imag health care black box problem deep learn method also briefli discuss
b0fbdffb9733e7857afbb21ccbcd9cd74803ca1d,"Data Science and symbolic AI: Synergies, challenges and opportunities","Symbolic approaches to Artificial Intelligence (AI) represent things within a domain of knowledge through physical symbols, combine symbols into symbol expressions, and manipulate symbols and symbol expressions through inference processes. While a large part of Data Science relies on statistics and applies statistical approaches to AI, there is an increasing potential for successfully applying symbolic approaches as well. Symbolic representations and symbolic inference are close to human cognitive representations and therefore comprehensible and interpretable; they are widely used to represent data and metadata, and their specific semantic content must be taken into account for analysis of such information; and human communication largely relies on symbols, making symbolic representations a crucial part in the analysis of natural language. Here we discuss the role symbolic representations and inference can play in Data Science, highlight the research challenges from the perspective of the data scientist, and argue that symbolic methods should become a crucial component of the data scientists’ toolbox.",symbol approach artifici intellig ai repres thing within domain knowledg physic symbol combin symbol symbol express manipul symbol symbol express infer process larg part data scienc reli statist appli statist approach ai increas potenti success appli symbol approach well symbol represent symbol infer close human cognit represent therefor comprehens interpret wide use repres data metadata specif semant content must taken account analysi inform human commun larg reli symbol make symbol represent crucial part analysi natur languag discuss role symbol represent infer play data scienc highlight research challeng perspect data scientist argu symbol method becom crucial compon data scientist toolbox
f4e66bd035e195f539f1b65a5aaec0e873cdee29,Data science in education: Big data and learning analytics,This paper considers the data science and the summaries significance of Big Data and Learning Analytics in education. The widespread platform of making high‐quality benefits that could be achieved by exhausting big data techniques in the field of education is considered. One principal architecture framework to support education research is proposed.,paper consid data scienc summari signific big data learn analyt educ widespread platform make highqual benefit could achiev exhaust big data techniqu field educ consid one princip architectur framework support educ research propos
d2f83aa22def149095f1dd89b4cf36d09a748a87,Data science is science's second chance to get causal inference right: A classification of data science tasks,"Causal inference from observational data is the goal of many data analyses in the health and social sciences. However, academic statistics has often frowned upon data analyses with a causal objective. The introduction of the term""data science""provides a historic opportunity to redefine data analysis in such a way that it naturally accommodates causal inference from observational data. Like others before, we organize the scientific contributions of data science into three classes of tasks: Description, prediction, and counterfactual prediction (which includes causal inference). An explicit classification of data science tasks is necessary to discuss the data, assumptions, and analytics required to successfully accomplish each task. We argue that a failure to adequately describe the role of subject-matter expert knowledge in data analysis is a source of widespread misunderstandings about data science. Specifically, causal analyses typically require not only good data and algorithms, but also domain expert knowledge. We discuss the implications for the use of data science to guide decision-making in the real world and to train data scientists.",causal infer observ data goal mani data analys health social scienc howev academ statist often frown upon data analys causal object introduct termdata scienceprovid histor opportun redefin data analysi way natur accommod causal infer observ data like other organ scientif contribut data scienc three class task descript predict counterfactu predict includ causal infer explicit classif data scienc task necessari discuss data assumpt analyt requir success accomplish task argu failur adequ describ role subjectmatt expert knowledg data analysi sourc widespread misunderstand data scienc specif causal analys typic requir good data algorithm also domain expert knowledg discuss implic use data scienc guid decisionmak real world train data scientist
843793928e308b5414d2883ac869e813ec16f65d,Progressive Data Science: Potential and Challenges,"Data science requires time-consuming iterative manual activities. In particular, activities such as data selection, preprocessing, transformation, and mining, highly depend on iterative trial-and-error processes that could be sped up significantly by providing quick feedback on the impact of changes. The idea of progressive data science is to compute the results of changes in a progressive manner, returning a first approximation of results quickly and allow iterative refinements until converging to a final result. Enabling the user to interact with the intermediate results allows an early detection of erroneous or suboptimal choices, the guided definition of modifications to the pipeline and their quick assessment. In this paper, we discuss the progressiveness challenges arising in different steps of the data science pipeline. We describe how changes in each step of the pipeline impact the subsequent steps and outline why progressive data science will help to make the process more effective. Computing progressive approximations of outcomes resulting from changes creates numerous research challenges, especially if the changes are made in the early steps of the pipeline. We discuss these challenges and outline first steps towards progressiveness, which, we argue, will ultimately help to significantly speed-up the overall data science process.",data scienc requir timeconsum iter manual activ particular activ data select preprocess transform mine highli depend iter trialanderror process could sped significantli provid quick feedback impact chang idea progress data scienc comput result chang progress manner return first approxim result quickli allow iter refin converg final result enabl user interact intermedi result allow earli detect erron suboptim choic guid definit modif pipelin quick assess paper discuss progress challeng aris differ step data scienc pipelin describ chang step pipelin impact subsequ step outlin progress data scienc help make process effect comput progress approxim outcom result chang creat numer research challeng especi chang made earli step pipelin discuss challeng outlin first step toward progress argu ultim help significantli speedup overal data scienc process
dd1f93c3faae464d50d2e97c2bf4ac8d43681cb1,Twinning data science with information science in schools of library and information science,"As an emerging discipline, data science represents a vital new current of school of library and information science (LIS) education. However, it remains unclear how it relates to information science within LIS schools. The purpose of this paper is to clarify this issue.,Mission statement and nature of both data science and information science are analyzed by reviewing existing work in the two disciplines and drawing DIKW hierarchy. It looks at the ways in which information science theories bring new insights and shed new light on fundamentals of data science.,Data science and information science are twin disciplines by nature. The mission, task and nature of data science are consistent with those of information science. They greatly overlap and share similar concerns. Furthermore, they can complement each other. LIS school should integrate both sciences and develop organizational ambidexterity. Information science can make unique contributions to data science research, including conception of data, data quality control, data librarianship and theory dualism. Document theory, as a promising direction of unified information science, should be introduced to data science to solve the disciplinary divide.,The results of this paper may contribute to the integration of data science and information science within LIS schools and iSchools. It has particular value for LIS school development and reform in the age of big data.",emerg disciplin data scienc repres vital new current school librari inform scienc li educ howev remain unclear relat inform scienc within li school purpos paper clarifi issuemiss statement natur data scienc inform scienc analyz review exist work two disciplin draw dikw hierarchi look way inform scienc theori bring new insight shed new light fundament data sciencedata scienc inform scienc twin disciplin natur mission task natur data scienc consist inform scienc greatli overlap share similar concern furthermor complement li school integr scienc develop organiz ambidexter inform scienc make uniqu contribut data scienc research includ concept data data qualiti control data librarianship theori dualism document theori promis direct unifi inform scienc introduc data scienc solv disciplinari divideth result paper may contribut integr data scienc inform scienc within li school ischool particular valu li school develop reform age big data
5de20ffb7852ae0665c382084c8a56918f23dc0b,Drafting a Data Science Curriculum for Secondary Schools,"Data science as the art of generating information and knowledge from data is increasingly becoming an important part of most operational processes. But up to now, data science is hardly an issue in German computer science education at secondary schools. For this reason, we are developing a data science curriculum for German secondary schools, which first guidelines and ideas we present in this paper. The curriculum is designed as interdisciplinary approach between maths and computer science education, with also a strong focus on societal aspects. After a brief discussion of important concepts and challenges in data science, a first draft of the curriculum and an outline of a data science course for upper secondary schools accompanying the development are presented.",data scienc art gener inform knowledg data increasingli becom import part oper process data scienc hardli issu german comput scienc educ secondari school reason develop data scienc curriculum german secondari school first guidelin idea present paper curriculum design interdisciplinari approach math comput scienc educ also strong focu societ aspect brief discuss import concept challeng data scienc first draft curriculum outlin data scienc cours upper secondari school accompani develop present
b34b9758b36c92c023c3c10f3a39aeb8f5c83927,Exploring Project Management Methodologies Used Within Data Science Teams,"There are many reasons data science teams should use a well-defined process to manage and coordinate their efforts, such as improved collaboration, efficiency and stakeholder communication. This paper explores the current methodology data science teams use to manage and coordinate their efforts. Unfortunately, based on our survey results, most data science teams currently use an ad hoc project management approach. In fact, 82% of the data scientists surveyed did not follow an explicit process. However, it is encouraging to note that 85% of the respondents thought that adopting an improved process methodology would improve the teams’ outcomes. Based on these results, we described six possible process methodologies teams could use. To conclude, we outlined plans to describe best practices for data science team processes and to develop a process evaluation framework.",mani reason data scienc team use welldefin process manag coordin effort improv collabor effici stakehold commun paper explor current methodolog data scienc team use manag coordin effort unfortun base survey result data scienc team current use ad hoc project manag approach fact data scientist survey follow explicit process howev encourag note respond thought adopt improv process methodolog would improv team outcom base result describ six possibl process methodolog team could use conclud outlin plan describ best practic data scienc team process develop process evalu framework
c9ed1ad1a3a08bf5ebebe8105805dd102546b8f3,Process-Structure Linkages Using a Data Science Approach: Application to Simulated Additive Manufacturing Data,,nan
94c52a7516ef8955f76c3ee1319ff4fd8bf071fd,"Computer Age Statistical Inference: Algorithms, Evidence, and Data Science","The twenty-first century has seen a breathtaking expansion of statistical methodology, both in scope and in influence. 'Big data', 'data science', and 'machine learning' have become familiar terms in the news, as statistical methods are brought to bear upon the enormous data sets of modern science and commerce. How did we get here? And where are we going? This book takes us on an exhilarating journey through the revolution in data analysis following the introduction of electronic computation in the 1950s. Beginning with classical inferential theories - Bayesian, frequentist, Fisherian - individual chapters take up a series of influential topics: survival analysis, logistic regression, empirical Bayes, the jackknife and bootstrap, random forests, neural networks, Markov chain Monte Carlo, inference after model selection, and dozens more. The distinctly modern approach integrates methodology and algorithms with statistical inference. The book ends with speculation on the future direction of statistics and data science.",twentyfirst centuri seen breathtak expans statist methodolog scope influenc big data data scienc machin learn becom familiar term news statist method brought bear upon enorm data set modern scienc commerc get go book take us exhilar journey revolut data analysi follow introduct electron comput begin classic inferenti theori bayesian frequentist fisherian individu chapter take seri influenti topic surviv analysi logist regress empir bay jackknif bootstrap random forest neural network markov chain mont carlo infer model select dozen distinctli modern approach integr methodolog algorithm statist infer book end specul futur direct statist data scienc
88761dffd173cd0e75e88c02d68f866f8cc43c14,Knowledge-based biomedical Data Science,"Computational manipulation of knowledge is an important, and often under-appreciated, aspect of biomedical Data Science. The first Data Science initiative from the US National Institutes of Health was entitled “Big Data to Knowledge (BD2K).” The main emphasis of the more than $200M allocated to that program has been on “Big Data;” the “Knowledge” component has largely been the implicit assumption that the work will lead to new biomedical knowledge. However, there is long-standing and highly productive work in computational knowledge representation and reasoning, and computational processing of knowledge has a role in the world of Data Science. Knowledge-based biomedical Data Science involves the design and implementation of computer systems that act as if they knew about biomedicine. There are many ways in which a computational approach might act as if it knew something: for example, it might be able to answer a natural language question about a biomedical topic, or pass an exam; it might be able to use existing biomedical knowledge to rank or evaluate hypotheses; it might explain or interpret data in light of prior knowledge, either in a Bayesian or other sort of framework. These are all examples of automated reasoning that act on computational representations of knowledge. After a brief survey of existing approaches to knowledge-based data science, this position paper argues that such research is ripe for expansion, and expanded application.",comput manipul knowledg import often underappreci aspect biomed data scienc first data scienc initi us nation institut health entitl big data knowledg bdk main emphasi alloc program big data knowledg compon larg implicit assumpt work lead new biomed knowledg howev longstand highli product work comput knowledg represent reason comput process knowledg role world data scienc knowledgebas biomed data scienc involv design implement comput system act knew biomedicin mani way comput approach might act knew someth exampl might abl answer natur languag question biomed topic pass exam might abl use exist biomed knowledg rank evalu hypothes might explain interpret data light prior knowledg either bayesian sort framework exampl autom reason act comput represent knowledg brief survey exist approach knowledgebas data scienc posit paper argu research ripe expans expand applic
1901a26945ecb5445a9d58b4c32a0dc6dbd12f1a,"STS, Meet Data Science, Once Again","Science and technology studies (STS) and the emerging field of data science share surprising elective affinities. At the growing intersections of these fields, there will be many opportunities and not a few thorny difficulties for STS scholars. First, I discuss how both fields frame the rollout of data science as a simultaneously social and technical endeavor, even if in distinct ways and for diverging purposes. Second, I discuss the logic of domains in contemporary computer, information, and data science circles. While STS is often agnostic about the borders between the sciences or with industry and state—occasionally taking those boundaries as an object of study—data science takes those boundaries as its target to overcome. These two elective affinities present analytic and practical challenges for STS but also opportunities for engagement. Overall, in addition to these typifications, I urge STS scholars to strategically position themselves to investigate and contribute to the breadth of transformations that seek to touch virtually every science and newly bind spheres of academy, industry, and state.",scienc technolog studi st emerg field data scienc share surpris elect affin grow intersect field mani opportun thorni difficulti st scholar first discuss field frame rollout data scienc simultan social technic endeavor even distinct way diverg purpos second discuss logic domain contemporari comput inform data scienc circl st often agnost border scienc industri stateoccasion take boundari object studydata scienc take boundari target overcom two elect affin present analyt practic challeng st also opportun engag overal addit typif urg st scholar strateg posit investig contribut breadth transform seek touch virtual everi scienc newli bind sphere academi industri state
04d7b3457dc78b2d2282e6af2c787308f75c9b26,Care and the Practice of Data Science for Social Good,"Data science is an interdisciplinary field that extracts insights from data through a multi-stage process of data collection, analysis and use. When data science is applied for social good, a variety of stakeholders are introduced to the process with an intention to inform policies or programs to improve well-being. Our goal in this paper is to propose an orientation to care in the practice of data science for social good. When applied to data science, a logic of care can improve the data science process and reveal outcomes of ""good"" throughout. Consideration of care in practice has its origins in Science and Technology Studies (STS) and has recently been applied by Human Computer Interaction (HCI) researchers to understand technology repair and use in under-served environments as well as care in remote health monitoring. We bring care to the practice of data science through a detailed examination of our engaged research with a community group that uses data as a strategy to advocate for permanently affordable housing. We identify opportunities and experiences of care throughout the stages of the data science process. We bring greater detail to the notion of human-centered systems for data science and begin to describe what these look like.",data scienc interdisciplinari field extract insight data multistag process data collect analysi use data scienc appli social good varieti stakehold introduc process intent inform polici program improv wellb goal paper propos orient care practic data scienc social good appli data scienc logic care improv data scienc process reveal outcom good throughout consider care practic origin scienc technolog studi st recent appli human comput interact hci research understand technolog repair use underserv environ well care remot health monitor bring care practic data scienc detail examin engag research commun group use data strategi advoc perman afford hous identifi opportun experi care throughout stage data scienc process bring greater detail notion humancent system data scienc begin describ look like
b4332aaabec46e386fff31d066f278fc27cfa1cb,How data science can advance mental health research,,nan
798e5e09c20b0270701b194a3198427fec6a4fcd,What makes Data Science different? A discussion involving Statistics2.0 and Computational Sciences,,nan
ea07f64ad84542e04acc41db6b171007f344efd7,Milo: A visual programming environment for Data Science Education,"Most courses on Data Science offered at universities or online require students to have familiarity with at least one programming language. In this paper, we present, “Milo”, a web-based visual programming environment for Data Science Education, designed as a pedagogical tool that can be used by students without prior-programming experience. To that end, Milo uses graphical blocks as abstractions of language specific implementations of Data Science and Machine Learning(ML) concepts along with creation of interactive visualizations. Using block definitions created by a user, Milo generates equivalent source code in JavaScript to run entirely in the browser. Based on a preliminary user study with a focus group of undergraduate computer science students, Milo succeeds as an effective tool for novice learners in the field of Data Science.",cours data scienc offer univers onlin requir student familiar least one program languag paper present milo webbas visual program environ data scienc educ design pedagog tool use student without priorprogram experi end milo use graphic block abstract languag specif implement data scienc machin learningml concept along creation interact visual use block definit creat user milo gener equival sourc code javascript run entir browser base preliminari user studi focu group undergradu comput scienc student milo succe effect tool novic learner field data scienc
dcecbf916b9e2c61042f0dc992bdfd8ac1c99b8d,Materials Knowledge Systems in Python—a Data Science Framework for Accelerated Development of Hierarchical Materials,,nan
e36022198f21f46d066007ee5cf901ea55080e21,"Introduction to Data Science: A Python Approach to Concepts, Techniques and Applications","This accessible and classroom-tested textbook/reference presents an introduction to the fundamentals of the emerging and interdisciplinary field of data science. The coverage spans key concepts adopted from statistics and machine learning, useful techniques for graph analysis and parallel programming, and the practical application of data science for such tasks as building recommender systems or performing sentiment analysis. Topics and features: provides numerous practical case studies using real-world data throughout the book; supports understanding through hands-on experience of solving data science problems using Python; describes techniques and tools for statistical analysis, machine learning, graph analysis, and parallel programming; reviews a range of applications of data science, including recommender systems and sentiment analysis of text data; provides supplementary code resources and data at an associated website.",access classroomtest textbookrefer present introduct fundament emerg interdisciplinari field data scienc coverag span key concept adopt statist machin learn use techniqu graph analysi parallel program practic applic data scienc task build recommend system perform sentiment analysi topic featur provid numer practic case studi use realworld data throughout book support understand handson experi solv data scienc problem use python describ techniqu tool statist analysi machin learn graph analysi parallel program review rang applic data scienc includ recommend system sentiment analysi text data provid supplementari code resourc data associ websit
1d045f4f347409f0635c9d15d538dbfabb6b38fa,Environmental Data Science,,nan
9b54c9a7d2060f800961c2f9195fcf5408288f17,Data Science for Undergraduates,,nan
a0ef3467c09acc3106b915258b7b8db7bb663b77,Data Science Methodology for Cybersecurity Projects,"Cyber-security solutions are traditionally static and signature-based. The traditional solutions along with the use of analytic models, machine learning and big data could be improved by automatically trigger mitigation or provide relevant awareness to control or limit consequences of threats. This kind of intelligent solutions is covered in the context of Data Science for Cyber-security. Data Science provides a significant role in cyber-security by utilising the power of data (and big data), high-performance computing and data mining (and machine learning) to protect users against cyber-crimes. For this purpose, a successful data science project requires an effective methodology to cover all issues and provide adequate resources. In this paper, we are introducing popular data science methodologies and will compare them in accordance with cyber-security challenges. A comparison discussion has also delivered to explain methodologies strengths and weaknesses in case of cyber-security projects.",cybersecur solut tradit static signaturebas tradit solut along use analyt model machin learn big data could improv automat trigger mitig provid relev awar control limit consequ threat kind intellig solut cover context data scienc cybersecur data scienc provid signific role cybersecur utilis power data big data highperform comput data mine machin learn protect user cybercrim purpos success data scienc project requir effect methodolog cover issu provid adequ resourc paper introduc popular data scienc methodolog compar accord cybersecur challeng comparison discuss also deliv explain methodolog strength weak case cybersecur project
e420259fd53d15c2b6cb8906027d5a100ca356d7,Data science for building energy management: A review,,nan
010f65dd2fa979892a8229db825954871652fb8f,Defining Data Science by a Data-Driven Quantification of the Community,"Data science is a new academic field that has received much attention in recent years. One reason for this is that our increasingly digitalized society generates more and more data in all areas of our lives and science and we are desperately seeking for solutions to deal with this problem. In this paper, we investigate the academic roots of data science. We are using data of scientists and their citations from Google Scholar, who have an interest in data science, to perform a quantitative analysis of the data science community. Furthermore, for decomposing the data science community into its major defining factors corresponding to the most important research fields, we introduce a statistical regression model that is fully automatic and robust with respect to a subsampling of the data. This statistical model allows us to define the ‘importance’ of a field as its predictive abilities. Overall, our method provides an objective answer to the question ‘What is data science?’.",data scienc new academ field receiv much attent recent year one reason increasingli digit societi gener data area live scienc desper seek solut deal problem paper investig academ root data scienc use data scientist citat googl scholar interest data scienc perform quantit analysi data scienc commun furthermor decompos data scienc commun major defin factor correspond import research field introduc statist regress model fulli automat robust respect subsampl data statist model allow us defin import field predict abil overal method provid object answer question data scienc
e78be911203960b3b2a417465d726734367f8e30,Counter‐mapping data science,"Counter-mapping is a combination of critical ideas and practices for social change that offers a productive and promising approach for grassroots data science initiatives. Current information technologies collect, store, and analyze data with new degrees of size, speed, heterogeneity, and detail. While much work utilizing data science technologies is dedicated to generating profit or to national security, some data science projects explicitly attempt to facilitate new social relations, though with inconsistent results and consequences. This paper reviews counter-mapping's particular combination of theory and practice as a potential point of reference for such initiatives. Counter-mapping takes the tools of institutional map-making at government agencies and corporations and applies them in situated, bottom-up ways. Moreover, counter-mapping's multiple theoretical approaches and polyglot practices offer a variety of inspirations and avenues for future work in identifying and realizing alternative, ideally better, possibilities. This paper defines counter-mapping; outlines its multiple theorizations; briefly describes three relevant case studies, The Detroit Geographical Expedition and Institute, Mapping Police Violence, and the Counter-Cartographies Collective; and concludes with a few hard-learned considerations from counter-mapping that are directly pertinent for data-oriented projects focused on change.",countermap combin critic idea practic social chang offer product promis approach grassroot data scienc initi current inform technolog collect store analyz data new degre size speed heterogen detail much work util data scienc technolog dedic gener profit nation secur data scienc project explicitli attempt facilit new social relat though inconsist result consequ paper review countermap particular combin theori practic potenti point refer initi countermap take tool institut mapmak govern agenc corpor appli situat bottomup way moreov countermap multipl theoret approach polyglot practic offer varieti inspir avenu futur work identifi realiz altern ideal better possibl paper defin countermap outlin multipl theoriz briefli describ three relev case studi detroit geograph expedit institut map polic violenc countercartographi collect conclud hardlearn consider countermap directli pertin dataori project focus chang
00b1fa3c7170563567fb22a9bb6ff4c7b2e8853e,Comparing Data Science Project Management Methodologies via a Controlled Experiment,"Data Science is an emerging field with a significant research focus on improving the techniques available to analyze data. However, there has been much less focus on how people should work together on a data science project. In this paper, we report on the results of an experiment comparing four different methodologies to manage and coordinate a data science project. We first introduce a model to compare different project management methodologies and then report on the results of our experiment. The results from our experiment demonstrate that there are significant differences based on the methodology used, with an Agile Kanban methodology being the most effective and surprisingly, an Agile Scrum methodology being the least effective.",data scienc emerg field signific research focu improv techniqu avail analyz data howev much less focu peopl work togeth data scienc project paper report result experi compar four differ methodolog manag coordin data scienc project first introduc model compar differ project manag methodolog report result experi result experi demonstr signific differ base methodolog use agil kanban methodolog effect surprisingli agil scrum methodolog least effect
972edbd8bd19486a37c0a9f34508634fc8733529,Our path to better science in less time using open data science tools,,nan
818c9fd2df1229f962af3c50ef493e8633433fb9,Data Science Thinking,,nan
8d89159249e0faf5deae508cc8533010898bbda5,Data Science in Action,,nan
82feed9f0f8d077046b9b8be36e664483a66e33b,Teaching Stats for Data Science,"ABSTRACT “Data science” is a useful catchword for methods and concepts original to the field of statistics, but typically being applied to large, multivariate, observational records. Such datasets call for techniques not often part of an introduction to statistics: modeling, consideration of covariates, sophisticated visualization, and causal reasoning. This article re-imagines introductory statistics as an introduction to data science and proposes a sequence of 10 blocks that together compose a suitable course for extracting information from contemporary data. Recent extensions to the mosaic packages for R together with tools from the “tidyverse” provide a concise and readable notation for wrangling, visualization, model-building, and model interpretation: the fundamental computational tasks of data science.",abstract data scienc use catchword method concept origin field statist typic appli larg multivari observ record dataset call techniqu often part introduct statist model consider covari sophist visual causal reason articl reimagin introductori statist introduct data scienc propos sequenc block togeth compos suitabl cours extract inform contemporari data recent extens mosaic packag r togeth tool tidyvers provid concis readabl notat wrangl visual modelbuild model interpret fundament comput task data scienc
a1dc9a3df54ac24712fc47ac5f0b116f1043b95e,R – Data Science,,nan
38fadf7c21c32b183fa3dcf32da1044e8441b813,The Data Science Handbook,"Data frameworks, modules, and toolkits are for doing data but they’re also a good way to dive into the without actually understanding data In this you’ll how many of the most fundamental data science tools and algorithms work by implementing them from scratch. If you an aptitude for mathematics and some programming you get with the math and at the core of data and with hacking skills you need to get started as a data scientist. Today’s messy glut of data holds answers to questions no one’s even thought to ask. This book provides you with the know-how to dig those answers out. Get a crash course in Python Learn the basics of linear algebra, statistics, and probability—and understand how and when they're used in data science Collect, explore, clean, munge, and manipulate data Dive into the fundamentals of machine learning Implement models such as k-nearest Neighbors, Naive Bayes, linear and logistic regression, decision trees, neural networks, and clustering Explore recommender systems, natural language processing, network analysis, MapReduce, and databases of microbial community dynamics, Support Vector Machines, a robust prediction method with applications in bioinformatics, Bayesian Model Selection for Data with High Dimension, High dimensional statistical inference: theoretical development to data analytics, Big data challenges in genomics, Analysis of microarray gene expression data using information theory and stochastic algorithm, Hybrid Models, Markov Chain Monte Carlo Methods: Theory and Practice, and more. Provides the authority and expertise of leading contributors from an international board of authors Presents the latest release in the Handbook of Statistics series Updated release includes the latest information on Principles and Methods for Data Science file organization with UNIX/Linux shell, version control with Git and GitHub, and reproducible document preparation. This book is a textbook for a first course in data science. No previous knowledge of R is necessary, although some experience with programming may be helpful. The book is divided into six parts: R, data visualization, statistics with R, data wrangling, machine learning, and productivity tools. Each part has several chapters meant to be presented as one lecture. The author uses motivating case studies that realistically mimic a data scientist’s experience. He starts by asking specific questions and answers these through data analysis so concepts are learned as a means to answering the questions. Examples of the case studies included are: US murder rates by state, self-reported student heights, trends in world health and economics, the impact of vaccines on infectious disease rates, the financial crisis of 2007-2008, election forecasting, building a baseball team, image processing of hand-written digits, and movie recommendation systems. The statistical concepts used to answer the case study questions are only briefly introduced, so complementing with a probability and statistics textbook is highly recommended for in-depth understanding of these concepts. If you read and understand the chapters and complete the exercises, you will be prepared to learn the more advanced concepts and skills needed to become an expert. The statistics profession is at a unique point in history. The need for valid statistical tools is greater than ever; data sets are massive, often measuring hundreds of thousands of measurements for a single subject. The field is ready to move towards clear objective benchmarks under which tools can be evaluated. Targeted learning allows (1) the full generalization and utilization of cross-validation as an estimator selection tool so that the subjective choices made by humans are now made by the machine, and (2) targeting the fitting of the probability distribution of the data toward the target parameter representing the scientific question of interest. This book is aimed at both statisticians and applied researchers interested in causal inference and general effect estimation for observational and experimental data. Part I is an accessible introduction to super learning and the targeted maximum likelihood estimator, including related concepts necessary to understand and apply these methods. Parts II-IX handle complex data structures and topics applied researchers will immediately recognize from their own research, including time-to-event outcomes, direct and indirect effects, positivity violations, case-control studies, and algorithmic foundations of data science, including machine learning, high-dimensional geometry, and analysis of large networks. Topics include the counterintuitive nature of data in high dimensions, important linear algebraic techniques such as singular value decomposition, the theory of random walks and Markov chains, the fundamentals of and important algorithms for machine learning, algorithms and analysis for clustering, probabilistic models for large networks, representation learning including topic modelling and non-negative matrix factorization, wavelets and compressed sensing. Important probabilistic techniques are developed including the law of large numbers, tail inequalities, analysis of random projections, generalization guarantees in machine learning, and moment methods for analysis of phase transitions in large random graphs. Additionally, important structural and complexity measures are discussed such as matrix norms and VC-dimension. This book is suitable for both undergraduate and graduate courses in the design and analysis of algorithms for data. As telescopes, detectors, and computers grow ever more powerful, the volume of data at the disposal of astronomers and astrophysicists will enter the petabyte domain, providing accurate measurements for billions of celestial objects. This book provides a comprehensive and accessible introduction to the cutting-edge statistical methods needed to efficiently analyze complex data sets from astronomical surveys such as the Panoramic Survey Telescope and Rapid Response System, the Dark Energy Survey, and the upcoming Large Synoptic Survey Telescope. It serves as a practical handbook for graduate students and advanced undergraduates in physics and astronomy, and as an indispensable reference for researchers. Statistics, Data Mining, and Machine Learning in Astronomy presents a wealth of practical analysis problems, evaluates techniques for solving them, and explains how to use various approaches for different types and sizes of data sets. For all applications described in the book, Python code and example data sets are provided. The supporting data sets have been carefully selected from contemporary astronomical surveys (for example, the Sloan Digital Sky Survey) and are easy to download and use. The accompanying Python code is publicly available, well documented, and follows uniform coding standards. Together, the data sets and code enable readers to reproduce all the figures and examples, evaluate the methods, and adapt them to their own fields of interest. Describes the most useful statistical and data-mining methods for extracting knowledge from huge and complex astronomical data sets Features real-world data sets from contemporary astronomical surveys Uses a freely available Python codebase throughout Ideal for students and working astronomers competitive by analyzing the data their support their decision-making an of the concepts, tools, and techniques behind the fields of data and artificial intelligence (AI) applied to business and industries. of Applied Data and Artificial in and all stages of data to AI their application real across industries—from and and together practice and science to successful from both and offline",data framework modul toolkit data theyr also good way dive without actual understand data youll mani fundament data scienc tool algorithm work implement scratch aptitud mathemat program get math core data hack skill need get start data scientist today messi glut data hold answer question one even thought ask book provid knowhow dig answer get crash cours python learn basic linear algebra statist probabilityand understand theyr use data scienc collect explor clean mung manipul data dive fundament machin learn implement model knearest neighbor naiv bay linear logist regress decis tree neural network cluster explor recommend system natur languag process network analysi mapreduc databas microbi commun dynam support vector machin robust predict method applic bioinformat bayesian model select data high dimens high dimension statist infer theoret develop data analyt big data challeng genom analysi microarray gene express data use inform theori stochast algorithm hybrid model markov chain mont carlo method theori practic provid author expertis lead contributor intern board author present latest releas handbook statist seri updat releas includ latest inform principl method data scienc file organ unixlinux shell version control git github reproduc document prepar book textbook first cours data scienc previou knowledg r necessari although experi program may help book divid six part r data visual statist r data wrangl machin learn product tool part sever chapter meant present one lectur author use motiv case studi realist mimic data scientist experi start ask specif question answer data analysi concept learn mean answer question exampl case studi includ us murder rate state selfreport student height trend world health econom impact vaccin infecti diseas rate financi crisi elect forecast build basebal team imag process handwritten digit movi recommend system statist concept use answer case studi question briefli introduc complement probabl statist textbook highli recommend indepth understand concept read understand chapter complet exercis prepar learn advanc concept skill need becom expert statist profess uniqu point histori need valid statist tool greater ever data set massiv often measur hundr thousand measur singl subject field readi move toward clear object benchmark tool evalu target learn allow full gener util crossvalid estim select tool subject choic made human made machin target fit probabl distribut data toward target paramet repres scientif question interest book aim statistician appli research interest causal infer gener effect estim observ experiment data part access introduct super learn target maximum likelihood estim includ relat concept necessari understand appli method part iiix handl complex data structur topic appli research immedi recogn research includ timetoev outcom direct indirect effect posit violat casecontrol studi algorithm foundat data scienc includ machin learn highdimension geometri analysi larg network topic includ counterintuit natur data high dimens import linear algebra techniqu singular valu decomposit theori random walk markov chain fundament import algorithm machin learn algorithm analysi cluster probabilist model larg network represent learn includ topic model nonneg matrix factor wavelet compress sens import probabilist techniqu develop includ law larg number tail inequ analysi random project gener guarante machin learn moment method analysi phase transit larg random graph addit import structur complex measur discuss matrix norm vcdimens book suitabl undergradu graduat cours design analysi algorithm data telescop detector comput grow ever power volum data dispos astronom astrophysicist enter petabyt domain provid accur measur billion celesti object book provid comprehens access introduct cuttingedg statist method need effici analyz complex data set astronom survey panoram survey telescop rapid respons system dark energi survey upcom larg synopt survey telescop serv practic handbook graduat student advanc undergradu physic astronomi indispens refer research statist data mine machin learn astronomi present wealth practic analysi problem evalu techniqu solv explain use variou approach differ type size data set applic describ book python code exampl data set provid support data set care select contemporari astronom survey exampl sloan digit sky survey easi download use accompani python code publicli avail well document follow uniform code standard togeth data set code enabl reader reproduc figur exampl evalu method adapt field interest describ use statist datamin method extract knowledg huge complex astronom data set featur realworld data set contemporari astronom survey use freeli avail python codebas throughout ideal student work astronom competit analyz data support decisionmak concept tool techniqu behind field data artifici intellig ai appli busi industri appli data artifici stage data ai applic real across industriesfrom togeth practic scienc success offlin
bfd6caddec8a98d531ee9f1f7ebf5833797cd5e3,Introducing Data Science to School Kids,"Data-driven decision making is fast becoming a necessary skill in jobs across the board. The industry today uses analytics and machine learning to get useful insights from a wealth of digital information in order to make decisions. With data science becoming an important skill needed in varying degrees of complexity by the workforce of the near future, we felt the need to expose school-goers to its power through a hands-on exercise. We organized a half-day long data science tutorial for kids in grades 5 through 9 (10-15 years old). Our aim was to expose them to the full cycle of a typical supervised learning approach - data collection, data entry, data visualization, feature engineering, model building, model testing and data permissions. We discuss herein the design choices made while developing the dataset, the method and the pedagogy for the tutorial. These choices aimed to maximize student engagement while ensuring minimal pre-requisite knowledge. This was a challenging task given that we limited the pre-requisites for the kids to the knowledge of counting, addition, percentages, comparisons and a basic exposure to operating computers. By designing an exercise with the stated principles, we were able to provide to kids an exciting, hands-on introduction to data science, as confirmed by their experiences. To the best of the authors' knowledge, the tutorial was the first of its kind. Considering the positive reception of such a tutorial, we hope that educators across the world are encouraged to introduce data science in their respective curricula for high-schoolers and are able to use the principles laid out in this work to build full-fledged courses.",datadriven decis make fast becom necessari skill job across board industri today use analyt machin learn get use insight wealth digit inform order make decis data scienc becom import skill need vari degre complex workforc near futur felt need expos schoolgoer power handson exercis organ halfday long data scienc tutori kid grade year old aim expos full cycl typic supervis learn approach data collect data entri data visual featur engin model build model test data permiss discuss herein design choic made develop dataset method pedagogi tutori choic aim maxim student engag ensur minim prerequisit knowledg challeng task given limit prerequisit kid knowledg count addit percentag comparison basic exposur oper comput design exercis state principl abl provid kid excit handson introduct data scienc confirm experi best author knowledg tutori first kind consid posit recept tutori hope educ across world encourag introduc data scienc respect curricula highschool abl use principl laid work build fullfledg cours
61b3ce156347a7f107df75924a45f81f12a0ef14,Surgical data science: the new knowledge domain,"Abstract Healthcare in general, and surgery/interventional care in particular, is evolving through rapid advances in technology and increasing complexity of care, with the goal of maximizing the quality and value of care. Whereas innovations in diagnostic and therapeutic technologies have driven past improvements in the quality of surgical care, future transformation in care will be enabled by data. Conventional methodologies, such as registry studies, are limited in their scope for discovery and research, extent and complexity of data, breadth of analytical techniques, and translation or integration of research findings into patient care. We foresee the emergence of surgical/interventional data science (SDS) as a key element to addressing these limitations and creating a sustainable path toward evidence-based improvement of interventional healthcare pathways. SDS will create tools to measure, model, and quantify the pathways or processes within the context of patient health states or outcomes and use information gained to inform healthcare decisions, guidelines, best practices, policy, and training, thereby improving the safety and quality of healthcare and its value. Data are pervasive throughout the surgical care pathway; thus, SDS can impact various aspects of care, including prevention, diagnosis, intervention, or postoperative recovery. The existing literature already provides preliminary results, suggesting how a data science approach to surgical decision-making could more accurately predict severe complications using complex data from preoperative, intraoperative, and postoperative contexts, how it could support intraoperative decision-making using both existing knowledge and continuous data streams throughout the surgical care pathway, and how it could enable effective collaboration between human care providers and intelligent technologies. In addition, SDS is poised to play a central role in surgical education, for example, through objective assessments, automated virtual coaching, and robot-assisted active learning of surgical skill. However, the potential for transforming surgical care and training through SDS may only be realized through a cultural shift that not only institutionalizes technology to seamlessly capture data but also assimilates individuals with expertise in data science into clinical research teams. Furthermore, collaboration with industry partners from the inception of the discovery process promotes optimal design of data products as well as their efficient translation and commercialization. As surgery continues to evolve through advances in technology that enhance delivery of care, SDS represents a new knowledge domain to engineer surgical care of the future.",abstract healthcar gener surgeryintervent care particular evolv rapid advanc technolog increas complex care goal maxim qualiti valu care wherea innov diagnost therapeut technolog driven past improv qualiti surgic care futur transform care enabl data convent methodolog registri studi limit scope discoveri research extent complex data breadth analyt techniqu translat integr research find patient care forese emerg surgicalintervent data scienc sd key element address limit creat sustain path toward evidencebas improv intervent healthcar pathway sd creat tool measur model quantifi pathway process within context patient health state outcom use inform gain inform healthcar decis guidelin best practic polici train therebi improv safeti qualiti healthcar valu data pervas throughout surgic care pathway thu sd impact variou aspect care includ prevent diagnosi intervent postop recoveri exist literatur alreadi provid preliminari result suggest data scienc approach surgic decisionmak could accur predict sever complic use complex data preoper intraop postop context could support intraop decisionmak use exist knowledg continu data stream throughout surgic care pathway could enabl effect collabor human care provid intellig technolog addit sd pois play central role surgic educ exampl object assess autom virtual coach robotassist activ learn surgic skill howev potenti transform surgic care train sd may realiz cultur shift institution technolog seamlessli captur data also assimil individu expertis data scienc clinic research team furthermor collabor industri partner incept discoveri process promot optim design data product well effici translat commerci surgeri continu evolv advanc technolog enhanc deliveri care sd repres new knowledg domain engin surgic care futur
796d70a6eb0428ae19f1187ae1c81185d4ae6701,Automating Biomedical Data Science Through Tree-Based Pipeline Optimization,,nan
843149b649b888fdb3649b8d4852263b62356799,Democratizing data science through data science training,"The biomedical sciences have experienced an explosion of data which promises to overwhelm many current practitioners. Without easy access to data science training resources, biomedical researchers may find themselves unable to wrangle their own datasets. In 2014, to address the challenges posed such a data onslaught, the National Institutes of Health (NIH) launched the Big Data to Knowledge (BD2K) initiative. To this end, the BD2K Training Coordinating Center (TCC; bigdatau.org) was funded to facilitate both in-person and online learning, and open up the concepts of data science to the widest possible audience. Here, we describe the activities of the BD2K TCC and its focus on the construction of the Educational Resource Discovery Index (ERuDIte), which identifies, collects, describes, and organizes online data science materials from BD2K awardees, open online courses, and videos from scientific lectures and tutorials. ERuDIte now indexes over 9,500 resources. Given the richness of online training materials and the constant evolution of biomedical data science, computational methods applying information retrieval, natural language processing, and machine learning techniques are required - in effect, using data science to inform training in data science. In so doing, the TCC seeks to democratize novel insights and discoveries brought forth via large-scale data science training.",biomed scienc experienc explos data promis overwhelm mani current practition without easi access data scienc train resourc biomed research may find unabl wrangl dataset address challeng pose data onslaught nation institut health nih launch big data knowledg bdk initi end bdk train coordin center tcc bigdatauorg fund facilit inperson onlin learn open concept data scienc widest possibl audienc describ activ bdk tcc focu construct educ resourc discoveri index erudit identifi collect describ organ onlin data scienc materi bdk awarde open onlin cours video scientif lectur tutori erudit index resourc given rich onlin train materi constant evolut biomed data scienc comput method appli inform retriev natur languag process machin learn techniqu requir effect use data scienc inform train data scienc tcc seek democrat novel insight discoveri brought forth via largescal data scienc train
589ebdd0d7b4a58f7fdfb07f116f62681bb9a915,Hack weeks as a model for data science education and collaboration,"Significance As scientific disciplines grapple with more datasets of rapidly increasing complexity and size, new approaches are urgently required to introduce new statistical and computational tools into research communities and improve the cross-disciplinary exchange of ideas. In this paper, we introduce a type of scientific workshop, called a hack week, which allows for fast dissemination of new methodologies into scientific communities and fosters exchange and collaboration within and between disciplines. We present implementations of this concept in astronomy, neuroscience, and geoscience and show that hack weeks produce positive learning outcomes, foster lasting collaborations, yield scientific results, and promote positive attitudes toward open science. Across many scientific disciplines, methods for recording, storing, and analyzing data are rapidly increasing in complexity. Skillfully using data science tools that manage this complexity requires training in new programming languages and frameworks as well as immersion in new modes of interaction that foster data sharing, collaborative software development, and exchange across disciplines. Learning these skills from traditional university curricula can be challenging because most courses are not designed to evolve on time scales that can keep pace with rapidly shifting data science methods. Here, we present the concept of a hack week as an effective model offering opportunities for networking and community building, education in state-of-the-art data science methods, and immersion in collaborative project work. We find that hack weeks are successful at cultivating collaboration and facilitating the exchange of knowledge. Participants self-report that these events help them in both their day-to-day research as well as their careers. Based on our results, we conclude that hack weeks present an effective, easy-to-implement, fairly low-cost tool to positively impact data analysis literacy in academic disciplines, foster collaboration, and cultivate best practices.",signific scientif disciplin grappl dataset rapidli increas complex size new approach urgent requir introduc new statist comput tool research commun improv crossdisciplinari exchang idea paper introduc type scientif workshop call hack week allow fast dissemin new methodolog scientif commun foster exchang collabor within disciplin present implement concept astronomi neurosci geoscienc show hack week produc posit learn outcom foster last collabor yield scientif result promot posit attitud toward open scienc across mani scientif disciplin method record store analyz data rapidli increas complex skill use data scienc tool manag complex requir train new program languag framework well immers new mode interact foster data share collabor softwar develop exchang across disciplin learn skill tradit univers curricula challeng cours design evolv time scale keep pace rapidli shift data scienc method present concept hack week effect model offer opportun network commun build educ stateoftheart data scienc method immers collabor project work find hack week success cultiv collabor facilit exchang knowledg particip selfreport event help daytoday research well career base result conclud hack week present effect easytoimpl fairli lowcost tool posit impact data analysi literaci academ disciplin foster collabor cultiv best practic
b2114228411d367cfa6ca091008291f250a2c490,Deep learning and process understanding for data-driven Earth system science,,nan
d83a99bfb6f81565a186e0eb86858864568c1327,Data science,"While it may not be possible to build a data brain identical to a human, data science can still aspire to imaginative machine thinking.",may possibl build data brain ident human data scienc still aspir imagin machin think
021865bb9fcc59814d2ce84d086554e5e0259779,"Big Metadata, Smart Metadata, and Metadata Capital: Toward Greater Synergy Between Data Science and Metadata","Abstract Purpose The purpose of the paper is to provide a framework for addressing the disconnect between metadata and data science. Data science cannot progress without metadata research. This paper takes steps toward advancing the synergy between metadata and data science, and identifies pathways for developing a more cohesive metadata research agenda in data science. Design/methodology/approach This paper identifies factors that challenge metadata research in the digital ecosystem, defines metadata and data science, and presents the concepts big metadata, smart metadata, and metadata capital as part of a metadata lingua franca connecting to data science. Findings The “utilitarian nature” and “historical and traditional views” of metadata are identified as two intersecting factors that have inhibited metadata research. Big metadata, smart metadata, and metadata capital are presented as part of a metadata lingua franca to help frame research in the data science research space. Research limitations There are additional, intersecting factors to consider that likely inhibit metadata research, and other significant metadata concepts to explore. Practical implications The immediate contribution of this work is that it may elicit response, critique, revision, or, more significantly, motivate research. The work presented can encourage more researchers to consider the significance of metadata as a research worthy topic within data science and the larger digital ecosystem. Originality/value Although metadata research has not kept pace with other data science topics, there is little attention directed to this problem. This is surprising, given that metadata is essential for data science endeavors. This examination synthesizes original and prior scholarship to provide new grounding for metadata research in data science.",abstract purpos purpos paper provid framework address disconnect metadata data scienc data scienc cannot progress without metadata research paper take step toward advanc synergi metadata data scienc identifi pathway develop cohes metadata research agenda data scienc designmethodologyapproach paper identifi factor challeng metadata research digit ecosystem defin metadata data scienc present concept big metadata smart metadata metadata capit part metadata lingua franca connect data scienc find utilitarian natur histor tradit view metadata identifi two intersect factor inhibit metadata research big metadata smart metadata metadata capit present part metadata lingua franca help frame research data scienc research space research limit addit intersect factor consid like inhibit metadata research signific metadata concept explor practic implic immedi contribut work may elicit respons critiqu revis significantli motiv research work present encourag research consid signific metadata research worthi topic within data scienc larger digit ecosystem originalityvalu although metadata research kept pace data scienc topic littl attent direct problem surpris given metadata essenti data scienc endeavor examin synthes origin prior scholarship provid new ground metadata research data scienc
f447afeccbdb9ed5df15c44011aec9c018d4b2c4,Big Data and Data Science: Opportunities and Challenges of iSchools,"Abstract Due to the recent explosion of big data, our society has been rapidly going through digital transformation and entering a new world with numerous eye-opening developments. These new trends impact the society and future jobs, and thus student careers. At the heart of this digital transformation is data science, the discipline that makes sense of big data. With many rapidly emerging digital challenges ahead of us, this article discusses perspectives on iSchools’ opportunities and suggestions in data science education. We argue that iSchools should empower their students with “information computing” disciplines, which we define as the ability to solve problems and create values, information, and knowledge using tools in application domains. As specific approaches to enforcing information computing disciplines in data science education, we suggest the three foci of user-based, tool-based, and application-based. These three foci will serve to differentiate the data science education of iSchools from that of computer science or business schools. We present a layered Data Science Education Framework (DSEF) with building blocks that include the three pillars of data science (people, technology, and data), computational thinking, data-driven paradigms, and data science lifecycles. Data science courses built on the top of this framework should thus be executed with user-based, tool-based, and application-based approaches. This framework will help our students think about data science problems from the big picture perspective and foster appropriate problem-solving skills in conjunction with broad perspectives of data science lifecycles. We hope the DSEF discussed in this article will help fellow iSchools in their design of new data science curricula.",abstract due recent explos big data societi rapidli go digit transform enter new world numer eyeopen develop new trend impact societi futur job thu student career heart digit transform data scienc disciplin make sens big data mani rapidli emerg digit challeng ahead us articl discuss perspect ischool opportun suggest data scienc educ argu ischool empow student inform comput disciplin defin abil solv problem creat valu inform knowledg use tool applic domain specif approach enforc inform comput disciplin data scienc educ suggest three foci userbas toolbas applicationbas three foci serv differenti data scienc educ ischool comput scienc busi school present layer data scienc educ framework dsef build block includ three pillar data scienc peopl technolog data comput think datadriven paradigm data scienc lifecycl data scienc cours built top framework thu execut userbas toolbas applicationbas approach framework help student think data scienc problem big pictur perspect foster appropri problemsolv skill conjunct broad perspect data scienc lifecycl hope dsef discuss articl help fellow ischool design new data scienc curricula
da63f30bd5b3a1b16c261f75ca1b1daddfc5b44d,Big Data and Data Science Methods for Management Research,"The recent advent of remote sensing, mobile technologies, novel transaction systems, and highperformance computing offers opportunities to understand trends, behaviors, and actions in a manner that has not been previously possible. Researchers can thus leverage “big data” that are generated from a plurality of sources including mobile transactions, wearable technologies, social media, ambient networks, andbusiness transactions.An earlierAcademy of Management Journal (AMJ) editorial explored the potential implications for data science inmanagement research and highlighted questions for management scholarship as well as the attendant challenges of data sharing and privacy (George, Haas, & Pentland, 2014). This nascent field is evolving rapidly and at a speed that leaves scholars and practitioners alike attempting to make sense of the emergent opportunities that big datahold.With thepromiseof bigdata comequestions about the analytical value and thus relevance of these data for theory development—including concerns over the context-specific relevance, its reliability and its validity. To address this challenge, data science is emerging as an interdisciplinary field that combines statistics, data mining, machine learning, and analytics to understand and explainhowwecan generate analytical insights and prediction models from structured and unstructured big data. Data science emphasizes the systematic study of the organization, properties, and analysis of data and their role in inference, including our confidence in the inference (Dhar, 2013).Whereas both big data and data science terms are often used interchangeably, “big data” refer to large and varied data that can be collected and managed, whereas “data science” develops models that capture, visualize, andanalyze theunderlyingpatterns in thedata. In this editorial, we address both the collection and handling of big data and the analytical tools provided by data science for management scholars. At the current time, practitioners suggest that data science applications tackle the three core elements of big data: volume, velocity, and variety (McAfee & Brynjolfsson, 2012; Zikopoulos & Eaton, 2011). “Volume” represents the sheer size of the dataset due to the aggregation of a large number of variables and an even larger set of observations for each variable. “Velocity” reflects the speed atwhich these data are collected and analyzed, whether in real time or near real time from sensors, sales transactions, social media posts, and sentiment data for breaking news and social trends. “Variety” in big data comes from the plurality of structured and unstructured data sources such as text, videos, networks, and graphics among others. The combinations of volume, velocity, and variety reveal the complex task of generating knowledge from big data, which often runs into millions of observations, and deriving theoretical contributions from such data. In this editorial, we provide a primer or a “starter kit” for potential data science applications inmanagement research. We do so with a caveat that emerging fields outdate and improve uponmethodologies while often supplanting them with new applications. Nevertheless, this primer can guide management scholars who wish to use data science techniques to reach better answers to existing questions or explore completely new research questions.",recent advent remot sens mobil technolog novel transact system highperform comput offer opportun understand trend behavior action manner previous possibl research thu leverag big data gener plural sourc includ mobil transact wearabl technolog social media ambient network andbusi transactionsan earlieracademi manag journal amj editori explor potenti implic data scienc inmanag research highlight question manag scholarship well attend challeng data share privaci georg haa pentland nascent field evolv rapidli speed leav scholar practition alik attempt make sens emerg opportun big dataholdwith thepromiseof bigdata comequest analyt valu thu relev data theori developmentinclud concern contextspecif relev reliabl valid address challeng data scienc emerg interdisciplinari field combin statist data mine machin learn analyt understand explainhowwecan gener analyt insight predict model structur unstructur big data data scienc emphas systemat studi organ properti analysi data role infer includ confid infer dhar wherea big data data scienc term often use interchang big data refer larg vari data collect manag wherea data scienc develop model captur visual andanalyz theunderlyingpattern thedata editori address collect handl big data analyt tool provid data scienc manag scholar current time practition suggest data scienc applic tackl three core element big data volum veloc varieti mcafe brynjolfsson zikopoulo eaton volum repres sheer size dataset due aggreg larg number variabl even larger set observ variabl veloc reflect speed atwhich data collect analyz whether real time near real time sensor sale transact social media post sentiment data break news social trend varieti big data come plural structur unstructur data sourc text video network graphic among other combin volum veloc varieti reveal complex task gener knowledg big data often run million observ deriv theoret contribut data editori provid primer starter kit potenti data scienc applic inmanag research caveat emerg field outdat improv uponmethodolog often supplant new applic nevertheless primer guid manag scholar wish use data scienc techniqu reach better answer exist question explor complet new research question
97a3726b3f9395c8919c6271540d87d1c44e10ac,Deep feature synthesis: Towards automating data science endeavors,"In this paper, we develop the Data Science Machine, which is able to derive predictive models from raw data automatically. To achieve this automation, we first propose and develop the Deep Feature Synthesis algorithm for automatically generating features for relational datasets. The algorithm follows relationships in the data to a base field, and then sequentially applies mathematical functions along that path to create the final feature. Second, we implement a generalizable machine learning pipeline and tune it using a novel Gaussian Copula process based approach. We entered the Data Science Machine in 3 data science competitions that featured 906 other data science teams. Our approach beats 615 teams in these data science competitions. In 2 of the 3 competitions we beat a majority of competitors, and in the third, we achieved 94% of the best competitor's score. In the best case, with an ongoing competition, we beat 85.6% of the teams and achieved 95.7% of the top submissions score.",paper develop data scienc machin abl deriv predict model raw data automat achiev autom first propos develop deep featur synthesi algorithm automat gener featur relat dataset algorithm follow relationship data base field sequenti appli mathemat function along path creat final featur second implement generaliz machin learn pipelin tune use novel gaussian copula process base approach enter data scienc machin data scienc competit featur data scienc team approach beat team data scienc competit competit beat major competitor third achiev best competitor score best case ongo competit beat team achiev top submiss score
19bb52bec8b5ced3175f4c3ef1b8fb7027cc5ff1,Applications of Python to evaluate environmental data science problems,"There is a significant convergence of interests in the research community efforts to advance the development and application of software resources (capable of handling the relevant mathematical algorithms to provide scalable information) for solving data science problems. Anaconda is one of the many open source platforms that facilitate the use of open source programming languages (R, Python) for large‐scale data processing, predictive analytics, and scientific computing. The environmental research community may choose to adapt the use of either of the R or the Python programming languages for analyzing the data science problems on the Anaconda platform. This study demonstrated the applications of using Scikit‐learn (a Python machine learning library package) on Anaconda platform for analyzing the in‐bus carbon dioxide concentrations by (i) importing the data into Spyder (Python 3.6) in Anaconda, (ii) performing an exploratory data analysis, (iii) performing dimensionality reduction through RandomForestRegressor feature selection, (iv) developing statistical regression models, and (v) generating regression decision tree models with DecisionTreeRegressor feature. The readers may adopt the methods (inclusive of the Python coding) discussed in this article to successfully address their own data science problems. © 2017 American Institute of Chemical Engineers Environ Prog, 36: 1580–1586, 2017",signific converg interest research commun effort advanc develop applic softwar resourc capabl handl relev mathemat algorithm provid scalabl inform solv data scienc problem anaconda one mani open sourc platform facilit use open sourc program languag r python largescal data process predict analyt scientif comput environment research commun may choos adapt use either r python program languag analyz data scienc problem anaconda platform studi demonstr applic use scikitlearn python machin learn librari packag anaconda platform analyz inbu carbon dioxid concentr import data spyder python anaconda ii perform exploratori data analysi iii perform dimension reduct randomforestregressor featur select iv develop statist regress model v gener regress decis tree model decisiontreeregressor featur reader may adopt method inclus python code discuss articl success address data scienc problem american institut chemic engin environ prog
dc86a7295d737fc2f195b67a273e90b549bd6272,Business Analytics and Data Science: Once Again?,,nan
96f5a9360ccfd1c5c4210dc62948baac234c372d,Predicting data science sociotechnical execution challenges by categorizing data science projects,"The challenge in executing a data science project is more than just identifying the best algorithm and tool set to use. Additional sociotechnical challenges include items such as how to define the project goals and how to ensure the project is effectively managed. This paper reports on a set of case studies where researchers were embedded within data science teams and where the researcher observations and analysis was focused on the attributes that can help describe data science projects and the challenges faced by the teams executing these projects, as opposed to the algorithms and technologies that were used to perform the analytics. Based on our case studies, we identified 14 characteristics that can help describe a data science project. We then used these characteristics to create a model that defines two key dimensions of the project. Finally, by clustering the projects within these two dimensions, we identified four types of data science projects, and based on the type of project, we identified some of the sociotechnical challenges that project teams should expect to encounter when executing data science projects.",challeng execut data scienc project identifi best algorithm tool set use addit sociotechn challeng includ item defin project goal ensur project effect manag paper report set case studi research embed within data scienc team research observ analysi focus attribut help describ data scienc project challeng face team execut project oppos algorithm technolog use perform analyt base case studi identifi characterist help describ data scienc project use characterist creat model defin two key dimens project final cluster project within two dimens identifi four type data scienc project base type project identifi sociotechn challeng project team expect encount execut data scienc project
3a8da09a87f06273c19fb61573b299388f8d1673,Data science vs. statistics: two cultures?,,nan
427a613d349d305726e1c4c7935b33c79de5850a,Python Data Science Handbook: Essential Tools for Working with Data,"For many researchers, Python is a first-class tool mainly because of its libraries for storing, manipulating, and gaining insight from data. Several resources exist for individual pieces of this data science stack, but only with the Python Data Science Handbook do you get them all IPython, NumPy, Pandas, Matplotlib, Scikit-Learn, and other related tools. Working scientists and data crunchers familiar with reading and writing Python code will find this comprehensive desk reference ideal for tackling day-to-day issues: manipulating, transforming, and cleaning data; visualizing different types of data; and using data to build statistical or machine learning models. Quite simply, this is the must-have reference for scientific computing in Python. With this handbook, youll learn how to use:IPython and Jupyter: provide computational environments for data scientists using PythonNumPy: includes the ndarray for efficient storage and manipulation of dense data arrays in PythonPandas: features the DataFrame for efficient storage and manipulation of labeled/columnar data in PythonMatplotlib: includes capabilities for a flexible range of data visualizations in PythonScikit-Learn: for efficient and clean Python implementations of the most important and established machine learning algorithms",mani research python firstclass tool mainli librari store manipul gain insight data sever resourc exist individu piec data scienc stack python data scienc handbook get ipython numpi panda matplotlib scikitlearn relat tool work scientist data cruncher familiar read write python code find comprehens desk refer ideal tackl daytoday issu manipul transform clean data visual differ type data use data build statist machin learn model quit simpli musthav refer scientif comput python handbook youll learn useipython jupyt provid comput environ data scientist use pythonnumpi includ ndarray effici storag manipul dens data array pythonpanda featur datafram effici storag manipul labeledcolumnar data pythonmatplotlib includ capabl flexibl rang data visual pythonscikitlearn effici clean python implement import establish machin learn algorithm
9141efc0d91ab0bda9b264ff6d1df5f20fd1dbb0,Transdisciplinary Foundations of Geospatial Data Science,"Recent developments in data mining and machine learning approaches have brought lots of excitement in providing solutions for challenging tasks (e.g., computer vision). However, many approaches have limited interpretability, so their success and failure modes are difficult to understand and their scientific robustness is difficult to evaluate. Thus, there is an urgent need for better understanding of the scientific reasoning behind data mining and machine learning approaches. This requires taking a transdisciplinary view of data science and recognizing its foundations in mathematics, statistics, and computer science. Focusing on the geospatial domain, we apply this crucial transdisciplinary perspective to five common geospatial techniques (hotspot detection, colocation detection, prediction, outlier detection and teleconnection detection). We also describe challenges and opportunities for future advancement.",recent develop data mine machin learn approach brought lot excit provid solut challeng task eg comput vision howev mani approach limit interpret success failur mode difficult understand scientif robust difficult evalu thu urgent need better understand scientif reason behind data mine machin learn approach requir take transdisciplinari view data scienc recogn foundat mathemat statist comput scienc focus geospati domain appli crucial transdisciplinari perspect five common geospati techniqu hotspot detect coloc detect predict outlier detect teleconnect detect also describ challeng opportun futur advanc
12e17fa5dd5715c563aadf705427da84817f100f,Data science: Data science tutorials,,nan
bc0fff42a78b116e9338593a9149406715d7a531,Data science,"Design, development, evaluation 3D user interfaces. Interaction techniques metaphors, immersive. Selection manipulation. Travel and navigation. Symbolic, menu, gestural, and multimodal interaction. Dialogue design. 3D software support. 3D interaction devices and displays. Virtual and augmented reality. Tangible user interfaces. Review of relevant 3D math.",design develop evalu user interfac interact techniqu metaphor immers select manipul travel navig symbol menu gestur multimod interact dialogu design softwar support interact devic display virtual augment realiti tangibl user interfac review relev math
cd247b7830fb58c6f019a79ae9679251176e8342,Game Theory for Data Science: Eliciting Truthful Information,,nan
4a6d46962d3f58d278cfb46d3ddebbb30bf275f5,Geographic Data Science,"Data science methods and approaches address all stages of transition from data to knowledge and action. Visualization of this data is essential for human understanding of the subject under study, analytical reasoning about it, and generating new knowledge. Geographic data science deals with data that incorporates spatial and, often, temporal elements. The articles selected for this special issue represent a mix of theoretical approaches and novel applications of geographic data science.",data scienc method approach address stage transit data knowledg action visual data essenti human understand subject studi analyt reason gener new knowledg geograph data scienc deal data incorpor spatial often tempor element articl select special issu repres mix theoret approach novel applic geograph data scienc
4676cf6b5e97bfcdb7654487ed76ebf2ef6a4035,An Introduction to Data Science,"An Introduction to Data Scienceby Jeffrey S. Saltz and Jeffrey M. Stanton is an easy-to-read, gentle introduction for people with a wide range of backgrounds into the world of data science. Needing no prior coding experience or a deep understanding of statistics, this book uses the R programming language and RStudio platform to make data science welcoming and accessible for all learners. After introducing the basics of data science, the book builds on each previous concept to explain R programming from the ground up. Readers will learn essential skills in data science through demonstrations of how to use data to construct models, predict outcomes, and visualize data.",introduct data sciencebi jeffrey saltz jeffrey stanton easytoread gentl introduct peopl wide rang background world data scienc need prior code experi deep understand statist book use r program languag rstudio platform make data scienc welcom access learner introduc basic data scienc book build previou concept explain r program ground reader learn essenti skill data scienc demonstr use data construct model predict outcom visual data
f6705e68c71bc0b51ddb8d1e4f986c894ba8f34f,"Data Science, Predictive Analytics, and Big Data in Supply Chain Management: Current State and Future Potential","While data science, predictive analytics, and big data have been frequently used buzzwords, rigorous academic investigations into these areas are just emerging. In this forward thinking article, we discuss the results of a recent large-scale survey on these topics among supply chain management (SCM) professionals, complemented with our experiences in developing, implementing, and administering one of the first master's degree programs in predictive analytics. As such, we effectively provide an assessment of the current state of the field via a large-scale survey, and offer insight into its future potential via the discussion of how a research university is training next-generation data scientists. Specifically, we report on the current use of predictive analytics in SCM and the underlying motivations, as well as perceived benefits and barriers. In addition, we highlight skills desired for successful data scientists, and provide illustrations of how predictive analytics can be implemented in the curriculum. Relying on one of the largest data sets of predictive analytics users in SCM collected to date and our experiences with one of the first master's degree programs in predictive analytics, it is our intent to provide a timely assessment of the field, illustrate its future potential, and motivate additional research and pedagogical advancements in this domain.",data scienc predict analyt big data frequent use buzzword rigor academ investig area emerg forward think articl discuss result recent largescal survey topic among suppli chain manag scm profession complement experi develop implement administ one first master degre program predict analyt effect provid assess current state field via largescal survey offer insight futur potenti via discuss research univers train nextgener data scientist specif report current use predict analyt scm underli motiv well perceiv benefit barrier addit highlight skill desir success data scientist provid illustr predict analyt implement curriculum reli one largest data set predict analyt user scm collect date experi one first master degre program predict analyt intent provid time assess field illustr futur potenti motiv addit research pedagog advanc domain
0a9b30386408595ff0b3155d4de4a56dad80a97b,The ambiguity of data science team roles and the need for a data science workforce framework,"This paper first reviews the benefits of well-defined roles and then discusses the current lack of standardized roles within the data science community, perhaps due to the newness of the field. Specifically, the paper reports on five case studies exploring five different attempts to define a standard set of roles. These case studies explore the usage of roles from an industry perspective as well as from national standard big data committee efforts. The paper then leverages the results of these case studies to explore the use of data science roles within online job postings. While some roles appeared frequently, such as data scientist and data engineer, no role was consistently used across all five case studies. Hence, the paper concludes by noting the need to create a data science workforce framework that could be used by students, employers, and academic institutions. This framework would enable organizations to staff their data science teams more accurately with the desired skillsets.",paper first review benefit welldefin role discuss current lack standard role within data scienc commun perhap due new field specif paper report five case studi explor five differ attempt defin standard set role case studi explor usag role industri perspect well nation standard big data committe effort paper leverag result case studi explor use data scienc role within onlin job post role appear frequent data scientist data engin role consist use across five case studi henc paper conclud note need creat data scienc workforc framework could use student employ academ institut framework would enabl organ staff data scienc team accur desir skillset
5b42e8ab6542fbbc11d84b07b34443a6853f96f1,Responsible Data Science,,nan
9a552de12d0b5a1561cf741f3170a0864f2b15d2,Ushering in a New Frontier in Geospace Through Data Science,"Our understanding and specification of solar‐terrestrial interactions benefit from taking advantage of comprehensive data‐intensive approaches. These data‐driven methods are taking on new importance in light of the shifting data landscape of the geospace system, which extends from the near Earth space environment, through the magnetosphere and interplanetary space, to the Sun. The space physics community faces both an exciting opportunity and an important imperative to create a new frontier built at the intersection of traditional approaches and state‐of‐the‐art data‐driven sciences and technologies. This brief commentary addresses the current paradigm of geospace science and the emerging need for data science innovation, discusses the meaning of data science in the context of geospace, and highlights community efforts to respond to the changing landscape.",understand specif solarterrestri interact benefit take advantag comprehens dataintens approach datadriven method take new import light shift data landscap geospac system extend near earth space environ magnetospher interplanetari space sun space physic commun face excit opportun import imper creat new frontier built intersect tradit approach stateoftheart datadriven scienc technolog brief commentari address current paradigm geospac scienc emerg need data scienc innov discuss mean data scienc context geospac highlight commun effort respond chang landscap
dd340315c44a9c68391d8d2f600a0adc76b70c09,Fides: Towards a Platform for Responsible Data Science,"Issues of responsible data analysis and use are coming to the forefront of the discourse in data science research and practice, with most significant efforts to date on the part of the data mining, machine learning, and security and privacy communities. In these fields, the research has been focused on analyzing the fairness, accountability and transparency (FAT) properties of specific algorithms and their outputs. Although these issues are most apparent in the social sciences where fairness is interpreted in terms of the distribution of resources across protected groups, management of bias in source data affects a variety of fields. Consider climate change studies that require representative data from geographically diverse regions, or supply chain analyses that require data that represents the diversity of products and customers. Any domain that involves sparse or sampled data has exposure to potential bias. In this vision paper, we argue that FAT properties must be considered as database system issues, further upstream in the data science lifecycle: bias in source data goes unnoticed, and bias may be introduced during pre-processing (fairness), spurious correlations lead to reproducibility problems (accountability), and assumptions made during pre-processing have invisible but significant effects on decisions (transparency). As machine learning methods continue to be applied broadly by non-experts, the potential for misuse increases. We see a need for a data sharing and collaborative analytics platform with features to encourage (and in some cases, enforce) best practices at all stages of the data science lifecycle. We describe features of such a platform, which we term Fides, in the context of urban analytics, outlining a systems research agenda in responsible data science.",issu respons data analysi use come forefront discours data scienc research practic signific effort date part data mine machin learn secur privaci commun field research focus analyz fair account transpar fat properti specif algorithm output although issu appar social scienc fair interpret term distribut resourc across protect group manag bia sourc data affect varieti field consid climat chang studi requir repres data geograph divers region suppli chain analys requir data repres divers product custom domain involv spars sampl data exposur potenti bia vision paper argu fat properti must consid databas system issu upstream data scienc lifecycl bia sourc data goe unnot bia may introduc preprocess fair spuriou correl lead reproduc problem account assumpt made preprocess invis signific effect decis transpar machin learn method continu appli broadli nonexpert potenti misus increas see need data share collabor analyt platform featur encourag case enforc best practic stage data scienc lifecycl describ featur platform term fide context urban analyt outlin system research agenda respons data scienc
ce0b7ee60920f9b37f88cab785cb8b4dc337e89f,Educational data science in massive open online courses,"The current massive open online course (MOOC) euphoria is revolutionizing online education. Despite its expediency, there is considerable skepticism over various concerns. In order to resolve some of these problems, educational data science (EDS) has been used with success. MOOCs provide a wealth of information about the way in which a large number of learners interact with educational platforms and engage with the courses offered. This extensive amount of data provided by MOOCs concerning students' usage information is a gold mine for EDS. This paper aims to provide the reader with a complete and comprehensive review of the existing literature that helps us understand the application of EDS in MOOCs. The main works in this area are described and grouped by task or issue to be solved, along with the techniques used. WIREs Data Mining Knowl Discov 2017, 7:e1187. doi: 10.1002/widm.1187",current massiv open onlin cours mooc euphoria revolution onlin educ despit expedi consider skeptic variou concern order resolv problem educ data scienc ed use success mooc provid wealth inform way larg number learner interact educ platform engag cours offer extens amount data provid mooc concern student usag inform gold mine ed paper aim provid reader complet comprehens review exist literatur help us understand applic ed mooc main work area describ group task issu solv along techniqu use wire data mine knowl discov e doi widm
224eb3407b50533668b6c1caa55a720688b8b532,"A review and future direction of agile, business intelligence, analytics and data science",,nan
3af056b2aed8724dcddea074eb68aff6dd11c926,Building the biomedical data science workforce,"This article describes efforts at the National Institutes of Health (NIH) from 2013 to 2016 to train a national workforce in biomedical data science. We provide an analysis of the Big Data to Knowledge (BD2K) training program strengths and weaknesses with an eye toward future directions aimed at any funder and potential funding recipient worldwide. The focus is on extramurally funded programs that have a national or international impact rather than the training of NIH staff, which was addressed by the NIH’s internal Data Science Workforce Development Center. From its inception, the major goal of BD2K was to narrow the gap between needed and existing biomedical data science skills. As biomedical research increasingly relies on computational, mathematical, and statistical thinking, supporting the training and education of the workforce of tomorrow requires new emphases on analytical skills. From 2013 to 2016, BD2K jump-started training in this area for all levels, from graduate students to senior researchers.",articl describ effort nation institut health nih train nation workforc biomed data scienc provid analysi big data knowledg bdk train program strength weak eye toward futur direct aim funder potenti fund recipi worldwid focu extramur fund program nation intern impact rather train nih staff address nih intern data scienc workforc develop center incept major goal bdk narrow gap need exist biomed data scienc skill biomed research increasingli reli comput mathemat statist think support train educ workforc tomorrow requir new emphas analyt skill bdk jumpstart train area level graduat student senior research
31485e1213dd886fa2b668eefcd9b13533d8a9fe,Big data and data science: what should we teach?,"The era of big data has arrived. Big data bring us the data‐driven paradigm and enlighten us to challenge new classes of problems we were not able to solve in the past. We are beginning to see the impacts of big data in every aspect of our lives and society. We need a science that can address these big data problems. Data science is a new emerging discipline that was termed to address challenges that we are facing and going to face in the big data era. Thus, education in data science is the key to success, and we need concrete strategies and approaches to better educate future data scientists. In this paper, we discuss general concepts on big data, data science, and data scientists and show the results of an extensive survey on current data science education in United States. Finally, we propose various approaches that data science education should aim to accomplish.",era big data arriv big data bring us datadriven paradigm enlighten us challeng new class problem abl solv past begin see impact big data everi aspect live societi need scienc address big data problem data scienc new emerg disciplin term address challeng face go face big data era thu educ data scienc key success need concret strategi approach better educ futur data scientist paper discuss gener concept big data data scienc data scientist show result extens survey current data scienc educ unit state final propos variou approach data scienc educ aim accomplish
0ec1992151e28c5678832c0923e56aeb58caad53,From Data Science to Value Creation,,nan
47134cbdfa7c44a55de5697a35b6652d0fcfee30,Data Science in Libraries,"EDITOR'S SUMMARY 
 
The new field of data science involves advanced knowledge in statistics and computer science, combined with copious amounts of data. A report from the Big Data and Research Initiative under the Obama Administration, The Federal Big Data Research and Development Strategic Plan, calls attention to the roles that librarians will play in the future of data science. However, there are skills and management gaps librarians face that inhibit their ability to move forward in data science. A number of educational programs are now offered to remedy this problem, such as the Data and Visualization Institute for Librarians from North Carolina State University, the volunteer-led Library Carpentry program, and most recently, the Data Sciences in Libraries Project, funded by the IMLS. This project aims to get librarians and library managers together to discuss the world of data science and create a roadmap for strategic planning.",editor summari new field data scienc involv advanc knowledg statist comput scienc combin copiou amount data report big data research initi obama administr feder big data research develop strateg plan call attent role librarian play futur data scienc howev skill manag gap librarian face inhibit abil move forward data scienc number educ program offer remedi problem data visual institut librarian north carolina state univers volunteerl librari carpentri program recent data scienc librari project fund iml project aim get librarian librari manag togeth discuss world data scienc creat roadmap strateg plan
3b963487cbf944d51f33c2a0b41eb2aed7c68b89,Locating ethics in data science: responsibility and accountability in global and distributed knowledge production systems,"The distributed and global nature of data science creates challenges for evaluating the quality, import and potential impact of the data and knowledge claims being produced. This has significant consequences for the management and oversight of responsibilities and accountabilities in data science. In particular, it makes it difficult to determine who is responsible for what output, and how such responsibilities relate to each other; what ‘participation’ means and which accountabilities it involves, with regard to data ownership, donation and sharing as well as data analysis, re-use and authorship; and whether the trust placed on automated tools for data mining and interpretation is warranted (especially as data processing strategies and tools are often developed separately from the situations of data use where ethical concerns typically emerge). To address these challenges, this paper advocates a participative, reflexive management of data practices. Regulatory structures should encourage data scientists to examine the historical lineages and ethical implications of their work at regular intervals. They should also foster awareness of the multitude of skills and perspectives involved in data science, highlighting how each perspective is partial and in need of confrontation with others. This approach has the potential to improve not only the ethical oversight for data science initiatives, but also the quality and reliability of research outputs. This article is part of the themed issue ‘The ethical impact of data science’.",distribut global natur data scienc creat challeng evalu qualiti import potenti impact data knowledg claim produc signific consequ manag oversight respons account data scienc particular make difficult determin respons output respons relat particip mean account involv regard data ownership donat share well data analysi reus authorship whether trust place autom tool data mine interpret warrant especi data process strategi tool often develop separ situat data use ethic concern typic emerg address challeng paper advoc particip reflex manag data practic regulatori structur encourag data scientist examin histor lineag ethic implic work regular interv also foster awar multitud skill perspect involv data scienc highlight perspect partial need confront other approach potenti improv ethic oversight data scienc initi also qualiti reliabl research output articl part theme issu ethic impact data scienc
ae118a88ada51dfdb2296cbaa948eb4a467942b6,"Computer Age Statistical Inference: Algorithms, Evidence, and Data Science","The twenty-first century has seen a breathtaking expansion of statistical methodology, both in scope and in influence. 'Big data', 'data science', and 'machine learning' have become familiar terms in the news, as statistical methods are brought to bear upon the enormous data sets of modern science and commerce. How did we get here? And where are we going? This book takes us on an exhilarating journey through the revolution in data analysis following the introduction of electronic computation in the 1950s. Beginning with classical inferential theories - Bayesian, frequentist, Fisherian - individual chapters take up a series of influential topics: survival analysis, logistic regression, empirical Bayes, the jackknife and bootstrap, random forests, neural networks, Markov chain Monte Carlo, inference after model selection, and dozens more. The distinctly modern approach integrates methodology and algorithms with statistical inference. The book ends with speculation on the future direction of statistics and data science.",twentyfirst centuri seen breathtak expans statist methodolog scope influenc big data data scienc machin learn becom familiar term news statist method brought bear upon enorm data set modern scienc commerc get go book take us exhilar journey revolut data analysi follow introduct electron comput begin classic inferenti theori bayesian frequentist fisherian individu chapter take seri influenti topic surviv analysi logist regress empir bay jackknif bootstrap random forest neural network markov chain mont carlo infer model select dozen distinctli modern approach integr methodolog algorithm statist infer book end specul futur direct statist data scienc
b26c93eba9e1d99a5c99b07d2476714b386c4d54,Agile big data analytics: AnalyticsOps for data science,"Big data analytic (BDA) systems leverage data distribution and parallel processing across a cluster of resources. This introduces a number of new challenges specifically for analytics. The analytics portion of the complete lifecycle has typically followed a waterfall process — completing one step before beginning the next. While efforts have been made to map different types of analytics to an agile methodology, the steps are often described as breaking activities into smaller tasks while the overall process is still consistent with step-by-step waterfall. BDA changes a number of the activities in the analytics lifecycle, as well as their ordering. The goal of agile analytics — to reach a point of optimality between generating value from data and the time spent getting there. This paper discusses the implications of an agile process for BDA in cleansing, transformation, and analytics.",big data analyt bda system leverag data distribut parallel process across cluster resourc introduc number new challeng specif analyt analyt portion complet lifecycl typic follow waterfal process complet one step begin next effort made map differ type analyt agil methodolog step often describ break activ smaller task overal process still consist stepbystep waterfal bda chang number activ analyt lifecycl well order goal agil analyt reach point optim gener valu data time spent get paper discuss implic agil process bda cleans transform analyt
e1a1ad4025e2c7a82882c7389d937cbdfd10b799,Towards Data Science,"Currently, a huge amount of data is being rapidly generated in cyberspace. Datanature (all data in cyberspace) is forming due to a data explosion. Exploring the patterns and rules in datanature is necessary but difficult. A new discipline called Data Science is coming. It provides a type of novel research method (a data-intensive method) for natural and social sciences and goes beyond computer science in researching data. This paper presents the challenges presented by data and discusses what differentiates data science from the established sciences, data technologies, and big data. Our goal is to encourage data related researchers to transfer their focus towards this new science.",current huge amount data rapidli gener cyberspac datanatur data cyberspac form due data explos explor pattern rule datanatur necessari difficult new disciplin call data scienc come provid type novel research method dataintens method natur social scienc goe beyond comput scienc research data paper present challeng present data discuss differenti data scienc establish scienc data technolog big data goal encourag data relat research transfer focu toward new scienc
52ff64f7f26b28447af255fedeb2216a70b48d66,Large Scale Distributed Data Science using Apache Spark,"Apache Spark is an open-source cluster computing framework for big data processing. It has emerged as the next generation big data processing engine, overtaking Hadoop MapReduce which helped ignite the big data revolution. Spark maintains MapReduce's linear scalability and fault tolerance, but extends it in a few important ways: it is much faster (100 times faster for certain applications), much easier to program in due to its rich APIs in Python, Java, Scala (and shortly R), and its core data abstraction, the distributed data frame, and it goes far beyond batch applications to support a variety of compute-intensive tasks, including interactive queries, streaming, machine learning, and graph processing. This tutorial will provide an accessible introduction to Spark and its potential to revolutionize academic and commercial data science practices.",apach spark opensourc cluster comput framework big data process emerg next gener big data process engin overtak hadoop mapreduc help ignit big data revolut spark maintain mapreduc linear scalabl fault toler extend import way much faster time faster certain applic much easier program due rich api python java scala shortli r core data abstract distribut data frame goe far beyond batch applic support varieti computeintens task includ interact queri stream machin learn graph process tutori provid access introduct spark potenti revolution academ commerci data scienc practic
62806c60226d54ba1a4455bb1d7d2f034ef7c29a,"Introducing Data Science: Big Data, Machine Learning, and more, using Python tools","Summary Introducing Data Science teaches you how to accomplish the fundamental tasks that occupy data scientists. Using the Python language and common Python libraries, you'll experience firsthand the challenges of dealing with data at scale and gain a solid foundation in data science. Purchase of the print book includes a free eBook in PDF, Kindle, and ePub formats from Manning Publications. About the Technology Many companies need developers with data science skills to work on projects ranging from social media marketing to machine learning. Discovering what you need to learn to begin a career as a data scientist can seem bewildering. This book is designed to help you get started. About the BookIntroducing Data Science Introducing Data Science explains vital data science concepts and teaches you how to accomplish the fundamental tasks that occupy data scientists. Youll explore data visualization, graph databases, the use of NoSQL, and the data science process. Youll use the Python language and common Python libraries as you experience firsthand the challenges of dealing with data at scale. Discover how Python allows you to gain insights from data sets so big that they need to be stored on multiple machines, or from data moving so quickly that no single machine can handle it. This book gives you hands-on experience with the most popular Python data science libraries, Scikit-learn and Stats Models. After reading this book, youll have the solid foundation you need to start a career in data science. Whats Inside Handling large data Introduction to machine learning Using Python to work with data Writing data science algorithms About the ReaderThis book assumes you're comfortable reading code in Python or a similar language, such as C, Ruby, or JavaScript. No prior experience with data science is required. About the Authors Davy Cielen, Arno D. B. Meysman, and Mohamed Ali are the founders and managing partners of Optimately and Maiton, where they focus on developing data science projects and solutions in various sectors.",summari introduc data scienc teach accomplish fundament task occupi data scientist use python languag common python librari youll experi firsthand challeng deal data scale gain solid foundat data scienc purchas print book includ free ebook pdf kindl epub format man public technolog mani compani need develop data scienc skill work project rang social media market machin learn discov need learn begin career data scientist seem bewild book design help get start bookintroduc data scienc introduc data scienc explain vital data scienc concept teach accomplish fundament task occupi data scientist youll explor data visual graph databas use nosql data scienc process youll use python languag common python librari experi firsthand challeng deal data scale discov python allow gain insight data set big need store multipl machin data move quickli singl machin handl book give handson experi popular python data scienc librari scikitlearn stat model read book youll solid foundat need start career data scienc what insid handl larg data introduct machin learn use python work data write data scienc algorithm readerthi book assum your comfort read code python similar languag c rubi javascript prior experi data scienc requir author davi cielen arno b meysman moham ali founder manag partner optim maiton focu develop data scienc project solut variou sector
217905fe7b549d5f3d45896072518b06adb8dd98,Data Science from Scratch: First Principles with Python,"Data science libraries, frameworks, modules, and toolkits are great for doing data science, but they're also a good way to dive into the discipline without actually understanding data science. In this book, you'll learn how many of the most fundamental data science tools and algorithms work by implementing them from scratch. If you have an aptitude for mathematics and some programming skills, author Joel Grus will help you get comfortable with the math and statistics at the core of data science, and with hacking skills you need to get started as a data scientist. Today's messy glut of data holds answers to questions no one's even thought to ask. This book provides you with the know-how to dig those answers out.",data scienc librari framework modul toolkit great data scienc theyr also good way dive disciplin without actual understand data scienc book youll learn mani fundament data scienc tool algorithm work implement scratch aptitud mathemat program skill author joel gru help get comfort math statist core data scienc hack skill need get start data scientist today messi glut data hold answer question one even thought ask book provid knowhow dig answer
aeede2d75d7cb3e10bc3b732a897ca1a7bfc12c5,"Data Science and Big Data Analytics: Discovering, Analyzing, Visualizing and Presenting Data","Data Science and Big Data Analytics: Discovering, Analyzing, Visualizing and Presenting Data By EMC Education Services Data Science and Big Data Analytics is about harnessing the power of data for new insights. The book covers the breadth of activities and methods and tools that Data Scientists use. The content focuses on concepts, principles and practical applications that are applicable to any industry and technology environment, and the learning is supported and explained with examples that you can replicate using open-source software. This book will help you: Become a contributor on a data science team ●",data scienc big data analyt discov analyz visual present data emc educ servic data scienc big data analyt har power data new insight book cover breadth activ method tool data scientist use content focus concept principl practic applic applic industri technolog environ learn support explain exampl replic use opensourc softwar book help becom contributor data scienc team
4729ff2eadf9c4b0f5374db6bba41ded944e218e,A Guide to Teaching Data Science,"ABSTRACT Demand for data science education is surging and traditional courses offered by statistics departments are not meeting the needs of those seeking training. This has led to a number of opinion pieces advocating for an update to the Statistics curriculum. The unifying recommendation is that computing should play a more prominent role. We strongly agree with this recommendation, but advocate the main priority is to bring applications to the forefront as proposed by Nolan and Speed in 1999. We also argue that the individuals tasked with developing data science courses should not only have statistical training, but also have experience analyzing data with the main objective of solving real-world problems. Here, we share a set of general principles and offer a detailed guide derived from our successful experience developing and teaching a graduate-level, introductory data science course centered entirely on case studies. We argue for the importance of statistical thinking, as defined by Wild and Pfannkuch in 1999 and describe how our approach teaches students three key skills needed to succeed in data science, which we refer to as creating, connecting, and computing. This guide can also be used for statisticians wanting to gain more practical knowledge about data science before embarking on teaching an introductory course. Supplementary materials for this article are available online.",abstract demand data scienc educ surg tradit cours offer statist depart meet need seek train led number opinion piec advoc updat statist curriculum unifi recommend comput play promin role strongli agre recommend advoc main prioriti bring applic forefront propos nolan speed also argu individu task develop data scienc cours statist train also experi analyz data main object solv realworld problem share set gener principl offer detail guid deriv success experi develop teach graduatelevel introductori data scienc cours center entir case studi argu import statist think defin wild pfannkuch describ approach teach student three key skill need succeed data scienc refer creat connect comput guid also use statistician want gain practic knowledg data scienc embark teach introductori cours supplementari materi articl avail onlin
4c05d4410c0023e14f2bb0cbcf7613468855430b,A Data Science Course for Undergraduates: Thinking With Data,"Data science is an emerging interdisciplinary field that combines elements of mathematics, statistics, computer science, and knowledge in a particular application domain for the purpose of extracting meaningful information from the increasingly sophisticated array of data available in many settings. These data tend to be nontraditional, in the sense that they are often live, large, complex, and/or messy. A first course in statistics at the undergraduate level typically introduces students to a variety of techniques to analyze small, neat, and clean datasets. However, whether they pursue more formal training in statistics or not, many of these students will end up working with data that are considerably more complex, and will need facility with statistical computing techniques. More importantly, these students require a framework for thinking structurally about data. We describe an undergraduate course in a liberal arts environment that provides students with the tools necessary to apply data science. The course emphasizes modern, practical, and useful skills that cover the full data analysis spectrum, from asking an interesting question to acquiring, managing, manipulating, processing, querying, analyzing, and visualizing data, as well communicating findings in written, graphical, and oral forms. Supplementary materials for this article are available online. [Received June 2014. Revised July 2015.]",data scienc emerg interdisciplinari field combin element mathemat statist comput scienc knowledg particular applic domain purpos extract meaning inform increasingli sophist array data avail mani set data tend nontradit sens often live larg complex andor messi first cours statist undergradu level typic introduc student varieti techniqu analyz small neat clean dataset howev whether pursu formal train statist mani student end work data consider complex need facil statist comput techniqu importantli student requir framework think structur data describ undergradu cours liber art environ provid student tool necessari appli data scienc cours emphas modern practic use skill cover full data analysi spectrum ask interest question acquir manag manipul process queri analyz visual data well commun find written graphic oral form supplementari materi articl avail onlin receiv june revis juli
c740a6816155fd123081d2f78926a0d3819926e7,LibGuides: *Data Science: Data Science Resources,"Data science resources, from finding ebooks and blogs, to finding raw datasets and analysis. Learn about data science resources, analysis, communities and data management. Also learn about hte datasets openly available and dataset purchase program.",data scienc resourc find ebook blog find raw dataset analysi learn data scienc resourc analysi commun data manag also learn hte dataset openli avail dataset purchas program
37095b714dad5895d946b1f8435a3a38dee1be8b,"Data quality for data science, predictive analytics, and big data in supply chain management: An introduction to the problem and suggestions for research and applications",,nan
0442b04b4e8741900b65de0721f0c3e152e044ef,Materials Data Science: Current Status and Future Outlook,"The field of materials science and engineering is on the cusp of a digital data revolution. After reviewing the nature of data science and Big Data, we discuss the features of materials data that distinguish them from data in other fields. We introduce the concept of process-structure-property (PSP) linkages and illustrate how the determination of PSPs is one of the main objectives of materials data science. Then we review a selection of materials databases, as well as important aspects of materials data management, such as storage hardware, archiving strategies, and data access strategies. We introduce the emerging field of materials data analytics, which focuses on data-driven approaches to extract and curate materials knowledge from available data sets. The critical need for materials e-collaboration platforms is highlighted, and we conclude the article with a number of suggestions regarding the near-term future of the materials data science field.",field materi scienc engin cusp digit data revolut review natur data scienc big data discuss featur materi data distinguish data field introduc concept processstructureproperti psp linkag illustr determin psp one main object materi data scienc review select materi databas well import aspect materi data manag storag hardwar archiv strategi data access strategi introduc emerg field materi data analyt focus datadriven approach extract curat materi knowledg avail data set critic need materi ecollabor platform highlight conclud articl number suggest regard nearterm futur materi data scienc field
87a7e55b4c3116751edb4b0f74e0484eaf7a853d,"Editorial - Big Data, Data Science, and Analytics: The Opportunity and Challenge for IS Research","We address key questions related to the explosion of interest in the emerging fields of big data, analytics, and data science. We discuss the novelty of the fields and whether the underlying questions are fundamentally different, the strengths that the information systems IS community brings to this discourse, interesting research questions for IS scholars, the role of predictive and explanatory modeling, and how research in this emerging area should be evaluated for contribution and significance.",address key question relat explos interest emerg field big data analyt data scienc discuss novelti field whether underli question fundament differ strength inform system commun bring discours interest research question scholar role predict explanatori model research emerg area evalu contribut signific
8ffe80d758a78810c7d5a33a088cd4529b8a6a4b,Data science: supporting decision-making,"Abstract Data science is a new academic trans-discipline that builds on 60 years of research about supporting decision-making in organisations. It is an important and potentially significant concept and practice. Contemplating the need for data scientists encourages academics and managers to examine issues of decision-maker rationality, data and data analysis needs, analytical tools, job skills and academic preparation. This article explores data science and the data professionals who will use new data streams and analytics to support decision-making. It also examines the dimensions that are changing in the data stream and the skills needed by data scientists to analyse the new data streams. Organisations need data scientists, but academics need to understand the new data science jobs to prepare more people to support decision-making.",abstract data scienc new academ transdisciplin build year research support decisionmak organis import potenti signific concept practic contempl need data scientist encourag academ manag examin issu decisionmak ration data data analysi need analyt tool job skill academ prepar articl explor data scienc data profession use new data stream analyt support decisionmak also examin dimens chang data stream skill need data scientist analys new data stream organis need data scientist academ need understand new data scienc job prepar peopl support decisionmak
071036abe55e7247d7e6ec28a4afc8ef2670f479,A Comparison of Open Source Tools for Data Science,"The next decade of competitive advantage revolves around the ability to make predictions and discover patterns in data. Data science is at the center of this revolution. Data science has been termed the sexiest job of the 21st century. Data science combines data mining, machine learning, and statistical methodologies to extract knowledge and leverage predictions from data. Given the need for data science in organizations, many small or medium organizations are not adequately funded to acquire expensive data science tools. Open source tools may provide the solution to this issue. While studies comparing open source tools for data mining or business intelligence exist, an update on the current state of the art is necessary. This work explores and compares common open source data science tools. Implications include an overview of the state of the art and knowledge for practitioners and academics to select an open source data science tool that suits the requirements of specific data science projects.",next decad competit advantag revolv around abil make predict discov pattern data data scienc center revolut data scienc term sexiest job st centuri data scienc combin data mine machin learn statist methodolog extract knowledg leverag predict data given need data scienc organ mani small medium organ adequ fund acquir expens data scienc tool open sourc tool may provid solut issu studi compar open sourc tool data mine busi intellig exist updat current state art necessari work explor compar common open sourc data scienc tool implic includ overview state art knowledg practition academ select open sourc data scienc tool suit requir specif data scienc project
6b705d7ef453d42d87a9099b31344adad2367f40,EDISON Data Science Framework: A Foundation for Building Data Science Profession for Research and Industry,"Data Science is an emerging field of science, which requires a multi-disciplinary approach and should be built with a strong link to emerging Big Data and data driven technologies, and consequently needs re-thinking and re-design of both traditional educational models and existing courses. The education and training of Data Scientists currently lacks a commonly accepted, harmonized instructional model that reflects by design the whole lifecycle of data handling in modern, data driven research and the digital economy. This paper presents the EDISON Data Science Framework (EDSF) that is intended to create a foundation for the Data Science profession definition. The EDSF includes the following core components: Data Science Competence Framework (CF-DS), Data Science Body of Knowledge (DS-BoK), Data Science Model Curriculum (MC-DS), and Data Science Professional profiles (DSP profiles). The MC-DS is built based on CF-DS and DS-BoK, where Learning Outcomes are defined based on CF-DS competences and Learning Units are mapped to Knowledge Units in DS-BoK. In its own turn, Learning Units are defined based on the ACM Classification of Computer Science (CCS2012) and reflect typical courses naming used by universities in their current programmes. The paper provides example how the proposed EDSF can be used for designing effective Data Science curricula and reports the experience of implementing EDSF by the Champion Universities that cooperate with the EDISON project.",data scienc emerg field scienc requir multidisciplinari approach built strong link emerg big data data driven technolog consequ need rethink redesign tradit educ model exist cours educ train data scientist current lack commonli accept harmon instruct model reflect design whole lifecycl data handl modern data driven research digit economi paper present edison data scienc framework edsf intend creat foundat data scienc profess definit edsf includ follow core compon data scienc compet framework cfd data scienc bodi knowledg dsbok data scienc model curriculum mcd data scienc profession profil dsp profil mcd built base cfd dsbok learn outcom defin base cfd compet learn unit map knowledg unit dsbok turn learn unit defin base acm classif comput scienc cc reflect typic cours name use univers current programm paper provid exampl propos edsf use design effect data scienc curricula report experi implement edsf champion univers cooper edison project
b9888bb70d6f246c7ffb53dcb9498bfafe113d8f,Thinking by classes in data science: the symbolic data analysis paradigm,"Data Science, considered as a science by itself, is in general terms, the extraction of knowledge from data. Symbolic data analysis (SDA) gives a new way of thinking in Data Science by extending the standard input to a set of classes of individual entities. Hence, classes of a given population are considered to be units of a higher level population to be studied. Such classes often represent the real units of interest. In order to take variability between the members of each class into account, classes are described by intervals, distributions, set of categories or numbers sometimes weighted and the like. In that way, we obtain new kinds of data, called ‘symbolic’ as they cannot be reduced to numbers without losing much information. The first step in SDA is to build the symbolic data table where the rows are classes and the variables can take symbolic values. The second step is to study and extract new knowledge from these new kinds of data by at least an extension of Computer Statistics and Data Mining to symbolic data. SDA is a new paradigm which opens up a vast domain of research and applications by giving complementary results to classical methods applied to standard data. SDA also gives answers to big data and complex data challenges as big data can be reduced and summarized by classes and as complex data with multiple unstructured data tables and unpaired variables can be transformed into a structured data table with paired symbolic‐valued variables. WIREs Comput Stat 2016, 8:172–205. doi: 10.1002/wics.1384",data scienc consid scienc gener term extract knowledg data symbol data analysi sda give new way think data scienc extend standard input set class individu entiti henc class given popul consid unit higher level popul studi class often repres real unit interest order take variabl member class account class describ interv distribut set categori number sometim weight like way obtain new kind data call symbol cannot reduc number without lose much inform first step sda build symbol data tabl row class variabl take symbol valu second step studi extract new knowledg new kind data least extens comput statist data mine symbol data sda new paradigm open vast domain research applic give complementari result classic method appli standard data sda also give answer big data complex data challeng big data reduc summar class complex data multipl unstructur data tabl unpair variabl transform structur data tabl pair symbolicvalu variabl wire comput stat doi wic
ca9f74a1a7b69214c670202bb4f66eb16194f836,Datathons: An Experience Report of Data Hackathons for Data Science Education,Large amounts of data are becoming increasingly available through open data repositories as well as companies and governments collecting data to improve decision making and efficiencies. Consequently there is a need to increase the data literacy of computer science students. Data science is a relatively new area within computer science and the curriculum is rapidly evolving along with the tools required to perform analytics which students need to learn how to effectively use. To address the needs of students learning key data science and analytics skills we propose augmenting existing data science curriculums with hackathon events that focus on data also known as datathons. In this paper we present our experience at hosting and running four datathons that involved students and members from the community coming together to solve challenging problems with data from not-for-profit social good organizations and publicly open data. Our reported experience from our datathons will help inform other academics and community groups who also wish to host datathons to help facilitate their students and members to learn key data science and analytics skills.,larg amount data becom increasingli avail open data repositori well compani govern collect data improv decis make effici consequ need increas data literaci comput scienc student data scienc rel new area within comput scienc curriculum rapidli evolv along tool requir perform analyt student need learn effect use address need student learn key data scienc analyt skill propos augment exist data scienc curriculum hackathon event focu data also known datathon paper present experi host run four datathon involv student member commun come togeth solv challeng problem data notforprofit social good organ publicli open data report experi datathon help inform academ commun group also wish host datathon help facilit student member learn key data scienc analyt skill
12f3b97d76e2e07c3bf2914606d26bbfbbe85bd1,Role of materials data science and informatics in accelerated materials innovation,"The goal of the Materials Genome Initiative is to substantially reduce the time and cost of materials design and deployment. Achieving this goal requires taking advantage of the recent advances in data and information sciences. This critical need has impelled the emergence of a new discipline, called materials data science and informatics. This emerging new discipline not only has to address the core scientific/technological challenges related to datafication of materials science and engineering, but also, a number of equally important challenges around data-driven transformation of the current culture, practices, and workflows employed for materials innovation. A comprehensive effort that addresses both of these aspects in a synergistic manner is likely to succeed in realizing the vision of scaled-up materials innovation. Key toolsets needed for the successful adoption of materials data science and informatics in materials innovation are identified and discussed in this article. Prototypical examples of emerging novel toolsets and their functionality are described along with select case studies.",goal materi genom initi substanti reduc time cost materi design deploy achiev goal requir take advantag recent advanc data inform scienc critic need impel emerg new disciplin call materi data scienc informat emerg new disciplin address core scientifictechnolog challeng relat dataf materi scienc engin also number equal import challeng around datadriven transform current cultur practic workflow employ materi innov comprehens effort address aspect synergist manner like succeed realiz vision scaledup materi innov key toolset need success adopt materi data scienc informat materi innov identifi discuss articl prototyp exampl emerg novel toolset function describ along select case studi
3e209c705350761fe676ac330503e8662279fbf2,Processes Meet Big Data: Connecting Data Science with Process Science,"As more and more companies are embracing Big data, it has become apparent that the ultimate challenge is to relate massive amounts of event data to processes that are highly dynamic. To unleash the value of event data, events need to be tightly connected to the control and management of operational processes. However, the primary focus of Big data technologies is currently on storage, processing, and rather simple analytical tasks. Big data initiatives rarely focus on the improvement of end-to-end processes. To address this mismatch, we advocate a better integration of data science, data technology and process science. Data science approaches tend to be process agonistic whereas process science approaches tend to be model-driven without considering the “evidence” hidden in the data. Process mining aims to bridge this gap. This editorial discusses the interplay between data science and process science and relates process mining to Big data technologies, service orientation, and cloud computing.",compani embrac big data becom appar ultim challeng relat massiv amount event data process highli dynam unleash valu event data event need tightli connect control manag oper process howev primari focu big data technolog current storag process rather simpl analyt task big data initi rare focu improv endtoend process address mismatch advoc better integr data scienc data technolog process scienc data scienc approach tend process agonist wherea process scienc approach tend modeldriven without consid evid hidden data process mine aim bridg gap editori discuss interplay data scienc process scienc relat process mine big data technolog servic orient cloud comput
44a840a63fc0c3edda389bbaf9c10c94e91fbd5a,Data Science,,nan
659890e52fe234cde0e02a2305e213d3e8cb14b2,Data science and cyberinfrastructure: critical enablers for accelerated development of hierarchical materials,"The slow pace of new/improved materials development and deployment has been identified as the main bottleneck in the innovation cycles of most emerging technologies. Much of the continuing discussion in the materials development community is therefore focused on the creation of novel materials innovation ecosystems designed to dramatically accelerate materials development efforts, while lowering the overall cost involved. In this paper, it is argued that the recent advances in data science can be leveraged suitably to address this challenge by effectively mediating between the seemingly disparate, inherently uncertain, multiscale and multimodal measurements and computations involved in the current materials’ development efforts. Proper utilisation of modern data science in the materials’ development efforts can lead to a new generation of data-driven decision support tools for guiding effort investment (for both measurements and computations) at various stages of the materials development. It should also be recognised that the success of such ecosystems is predicated on the creation and utilisation of integration platforms for promoting intimate, synchronous collaborations between cross-disciplinary and distributed team members (i.e. cyberinfrastructure). Indeed, data sciences and cyberinfrastructure form the two main pillars of the emerging new discipline broadly referred to as materials informatics (MI). This paper provides a summary of current capabilities in this emerging new field as they relate to the accelerated development of advanced hierarchical materials (the internal structure plays a dominant role in controlling overall properties/performance in these materials) and identifies specific directions of research that offer the most promising avenues.",slow pace newimprov materi develop deploy identifi main bottleneck innov cycl emerg technolog much continu discuss materi develop commun therefor focus creation novel materi innov ecosystem design dramat acceler materi develop effort lower overal cost involv paper argu recent advanc data scienc leverag suitabl address challeng effect mediat seemingli dispar inher uncertain multiscal multimod measur comput involv current materi develop effort proper utilis modern data scienc materi develop effort lead new gener datadriven decis support tool guid effort invest measur comput variou stage materi develop also recognis success ecosystem predic creation utilis integr platform promot intim synchron collabor crossdisciplinari distribut team member ie cyberinfrastructur inde data scienc cyberinfrastructur form two main pillar emerg new disciplin broadli refer materi informat mi paper provid summari current capabl emerg new field relat acceler develop advanc hierarch materi intern structur play domin role control overal propertiesperform materi identifi specif direct research offer promis avenu
2ce0b954b5180fdc0834c3e4f0d14b5a0e668d53,Mining the Quantified Self: Personal Knowledge Discovery as a Challenge for Data Science,"The last several years have seen an explosion of interest in wearable computing, personal tracking devices, and the so-called quantified self (QS) movement. Quantified self involves ordinary people recording and analyzing numerous aspects of their lives to understand and improve themselves. This is now a mainstream phenomenon, attracting a great deal of attention, participation, and funding. As more people are attracted to the movement, companies are offering various new platforms (hardware and software) that allow ever more aspects of daily life to be tracked. Nearly every aspect of the QS ecosystem is advancing rapidly, except for analytic capabilities, which remain surprisingly primitive. With increasing numbers of qualified self participants collecting ever greater amounts and types of data, many people literally have more data than they know what to do with. This article reviews the opportunities and challenges posed by the QS movement. Data science provides well-tested techniques for knowledge discovery. But making these useful for the QS domain poses unique challenges that derive from the characteristics of the data collected as well as the specific types of actionable insights that people want from the data. Using a small sample of QS time series data containing information about personal health we provide a formulation of the QS problem that connects data to the decisions of interest to the user.",last sever year seen explos interest wearabl comput person track devic socal quantifi self qs movement quantifi self involv ordinari peopl record analyz numer aspect live understand improv mainstream phenomenon attract great deal attent particip fund peopl attract movement compani offer variou new platform hardwar softwar allow ever aspect daili life track nearli everi aspect qs ecosystem advanc rapidli except analyt capabl remain surprisingli primit increas number qualifi self particip collect ever greater amount type data mani peopl liter data know articl review opportun challeng pose qs movement data scienc provid welltest techniqu knowledg discoveri make use qs domain pose uniqu challeng deriv characterist data collect well specif type action insight peopl want data use small sampl qs time seri data contain inform person health provid formul qs problem connect data decis interest user
e12b5363078a6d435bfba80e9d5cbab6b2cac897,Data Science and Digital Art History,"I present a number of core concepts from data science that are relevant to digital art history and the use of quantitative methods to study any cultural artifacts or processes in general. These concepts are objects, features, data, feature space, and dimension reduction. These concepts enable computational exploration of both large and small visual cultural data. We can analyze relations between works on a single artist, many artists, all digitized production from a whole historical period, holdings in museum collections, collection metadata, or writings about art. The same concepts allow us to study contemporary vernacular visual media using massive social media content. (In our lab, we analyzed works by van Gogh, Mondrian, and Rothko, 6000 paintings by French Impressionists, 20,000 photographs from MoMA photo­graphy collection, one million manga pages from manga books, one million artworks of contemporary non-professional artists, and over 13 million Instagram images from 16 global cities.) While data science techniques do not replace other art historical methods, they allow us to see familiar art historical material in new ways, and also to study contemporary digital visual culture.",present number core concept data scienc relev digit art histori use quantit method studi cultur artifact process gener concept object featur data featur space dimens reduct concept enabl comput explor larg small visual cultur data analyz relat work singl artist mani artist digit product whole histor period hold museum collect collect metadata write art concept allow us studi contemporari vernacular visual media use massiv social media content lab analyz work van gogh mondrian rothko paint french impressionist photograph moma photographi collect one million manga page manga book one million artwork contemporari nonprofession artist million instagram imag global citi data scienc techniqu replac art histor method allow us see familiar art histor materi new way also studi contemporari digit visual cultur
f152a4008f114ac19076ee6b98d431268f4aea9e,A Practical and Sustainable Model for Learning and Teaching Data Science,"This paper details our experiences with design and implementation of data science curriculum at University at Buffalo (UB). We discuss (i) briefly the history of project, (ii) a certificate program that we created, (iii) a data-intensive computing course that forms the core of the curriculum and (iv) some of the challenges we faced and how we addressed them. Major goal of the project was to improve the preparedness of our workforce for the emerging data-intensive computing area. We measured this through assessment of student learning on various concepts and topics related to data-intensive computing. We also discuss the best practices in building a data science program. We highlight the importance of external funding support and multi-disciplinary collaborations in the success of the project. The pedagogical resources created for the project are freely available to help educators and other learners navigate the path to learning data science. We expect this paper about our experience will provide a road map for educators who desire to introduce data science in their curriculum.",paper detail experi design implement data scienc curriculum univers buffalo ub discuss briefli histori project ii certif program creat iii dataintens comput cours form core curriculum iv challeng face address major goal project improv prepared workforc emerg dataintens comput area measur assess student learn variou concept topic relat dataintens comput also discuss best practic build data scienc program highlight import extern fund support multidisciplinari collabor success project pedagog resourc creat project freeli avail help educ learner navig path learn data scienc expect paper experi provid road map educ desir introduc data scienc curriculum
5a56bbd762e9dd70dd20afe8740a6d09ec85ffed,Data science from scratch,"This is a first-principles-based, practical introduction to the fundamentals of data science aimed at the mathematically-comfortable reader with some programming skills. The book covers: The important parts of Python to know The important parts of Math / Probability / Statistics to know The basics of data science How commonly-used data science techniques work (learning by implementing them) What is Map-Reduce and how to do it in Python Other applications such as NLP, Network Analysis, and more",firstprinciplesbas practic introduct fundament data scienc aim mathematicallycomfort reader program skill book cover import part python know import part math probabl statist know basic data scienc commonlyus data scienc techniqu work learn implement mapreduc python applic nlp network analysi
8ea48934b6f6a0717efb4e5355be3b008fc5b1bd,Coding the biodigital child: the biopolitics and pedagogic strategies of educational data science,"Abstract Educational data science is an emerging transdisciplinary field formed from an amalgamation of data science and elements of biological, psychological and neuroscientific knowledge about learning, or learning science. This article conceptualises educational data science as a biopolitical strategy focused on the evaluation and management of the corporeal, emotional and embrained lives of children. Such strategies are enacted through the development of new kinds of digitally-mediated ‘biopedagogies’ of body optimisation, ‘psychopedagogies’ of emotional maximisation, and ‘neuropedagogies’ of brain empowerment. The data practices, scientific knowledges, digital devices and pedagogies that constitute educational data science produce new systems of knowledge about the child that are consequential to their formation as ‘biodigital’ subjects, whose assumed qualities and capacities are defined through expert practices of biosensing, emotion analytics, and neurocomputation, combined with associated scientific knowledges. The article develops the concept of transcoding to account for the processes involved in the formation of the biodigital child.",abstract educ data scienc emerg transdisciplinari field form amalgam data scienc element biolog psycholog neuroscientif knowledg learn learn scienc articl conceptualis educ data scienc biopolit strategi focus evalu manag corpor emot embrain live children strategi enact develop new kind digitallymedi biopedagogi bodi optimis psychopedagogi emot maximis neuropedagogi brain empower data practic scientif knowledg digit devic pedagogi constitut educ data scienc produc new system knowledg child consequenti format biodigit subject whose assum qualiti capac defin expert practic biosens emot analyt neurocomput combin associ scientif knowledg articl develop concept transcod account process involv format biodigit child
49522df4fab1ebbeb831fc265196c2c129bf6087,Survey on data science with population-based algorithms,,nan
2081508c05ebe4fc0b7b2a1fd6a356a0e933186b,Teaching Data Science,,nan
b0150dd118ebedbc3ece68726e065f9afaaf3b18,Big data analytics and big data science: a survey,"Big data has attracted much attention from academia and industry. But the discussion of big data is disparate, fragmented and distributed among different outlets. This paper conducts a systematic and extensive review on 186 journal publications about big data from 2011 to 2015 in the Science Citation Index (SCI) and the Social Science Citation Index (SSCI) database aiming to provide scholars and practitioners with a comprehensive overview and big picture about research on big data. The selected papers are grouped into 20 research categories. The contents of the paper(s) in each research category are summarized. Research directions for each category are outlined as well. The results in this study indicate that the selected papers were mainly published between 2013 and 2015 and focus on technological issues regarding big data. Diverse new approaches, methods, frameworks and systems are proposed for data collection, storage, transport, processing and analysis in the selected papers. Possible directions for f...",big data attract much attent academia industri discuss big data dispar fragment distribut among differ outlet paper conduct systemat extens review journal public big data scienc citat index sci social scienc citat index ssci databas aim provid scholar practition comprehens overview big pictur research big data select paper group research categori content paper research categori summar research direct categori outlin well result studi indic select paper mainli publish focu technolog issu regard big data divers new approach method framework system propos data collect storag transport process analysi select paper possibl direct f
bd1c1d5540f246090e740c0d5a0fa7f2c64059d1,Data Science and its Relationship to Big Data and Data-Driven Decision Making,"Companies have realized they need to hire data scientists, academic institutions are scrambling to put together data-science programs, and publications are touting data science as a hot-even ""sexy""-career choice. However, there is confusion about what exactly data science is, and this confusion could lead to disillusionment as the concept diffuses into meaningless buzz. In this article, we argue that there are good reasons why it has been hard to pin down exactly what is data science. One reason is that data science is intricately intertwined with other important concepts also of growing importance, such as big data and data-driven decision making. Another reason is the natural tendency to associate what a practitioner does with the definition of the practitioner's field; this can result in overlooking the fundamentals of the field. We believe that trying to define the boundaries of data science precisely is not of the utmost importance. We can debate the boundaries of the field in an academic setting, but in order for data science to serve business effectively, it is important (i) to understand its relationships to other important related concepts, and (ii) to begin to identify the fundamental principles underlying data science. Once we embrace (ii), we can much better understand and explain exactly what data science has to offer. Furthermore, only once we embrace (ii) should we be comfortable calling it data science. In this article, we present a perspective that addresses all these concepts. We close by offering, as examples, a partial list of fundamental principles underlying data science.",compani realiz need hire data scientist academ institut scrambl put togeth datasci program public tout data scienc hoteven sexycar choic howev confus exactli data scienc confus could lead disillusion concept diffus meaningless buzz articl argu good reason hard pin exactli data scienc one reason data scienc intric intertwin import concept also grow import big data datadriven decis make anoth reason natur tendenc associ practition definit practition field result overlook fundament field believ tri defin boundari data scienc precis utmost import debat boundari field academ set order data scienc serv busi effect import understand relationship import relat concept ii begin identifi fundament principl underli data scienc embrac ii much better understand explain exactli data scienc offer furthermor embrac ii comfort call data scienc articl present perspect address concept close offer exampl partial list fundament principl underli data scienc
9c1b9598f82f9ed7d75ef1a9e627496759aa2387,"Data Science, Predictive Analytics, and Big Data: A Revolution that Will Transform Supply Chain Design and Management","We illuminate the myriad of opportunities for research where supply chain management intersects with data science, predictive analytics, and big data, collectively referred to as DPB. We show that these terms are not only becoming popular but are also relevant to supply chain research and education. Data science requires both domain knowledge and a broad set of quantitative skills, but there is a dearth of literature on the topic and many questions. We call for research on skills that are needed by SCM data scientists and discuss how such skills and domain knowledge affect the effectiveness of a SCM data scientist. Such knowledge is crucial to developing future supply chain leaders. We propose definitions of data science and predictive analytics as applied to supply chain management. We examine possible applications of DPB in practice and provide examples of research questions from these applications, as well as examples of research questions employing DPB that stem from management theories. Finally, we propose specific steps interested researchers can take to respond to our call for research on the intersection of supply chain management and DPB.",illumin myriad opportun research suppli chain manag intersect data scienc predict analyt big data collect refer dpb show term becom popular also relev suppli chain research educ data scienc requir domain knowledg broad set quantit skill dearth literatur topic mani question call research skill need scm data scientist discuss skill domain knowledg affect effect scm data scientist knowledg crucial develop futur suppli chain leader propos definit data scienc predict analyt appli suppli chain manag examin possibl applic dpb practic provid exampl research question applic well exampl research question employ dpb stem manag theori final propos specif step interest research take respond call research intersect suppli chain manag dpb
3eb5f2d152ead21ce528f9781c66197010eea3c8,A Case for Data Commons: Toward Data Science as a Service,"Data commons collocate data, storage, and computing infrastructure with core services and commonly used tools and applications for managing, analyzing, and sharing data to create an interoperable resource for the research community. An architecture for data commons is described, as well as some lessons learned from operating several large-scale data commons.",data common colloc data storag comput infrastructur core servic commonli use tool applic manag analyz share data creat interoper resourc research commun architectur data common describ well lesson learn oper sever largescal data common
8f6a4609531ca9ff35915c32dae5cd146fc57c40,HEALTH BANK - A Workbench for Data Science Applications in Healthcare,"The enormous amounts of data that are generated in the healthcare process and stored in electronic health record (EHR) systems are an underutilized resource that, with the use of data science applica- tions, can be exploited to improve healthcare. To foster the development and use of data science applications in healthcare, there is a fundamen- tal need for access to EHR data, which is typically not readily available to researchers and developers. A relatively rare exception is the large EHR database, the Stockholm EPR Corpus, comprising data from more than two million patients, that has been been made available to a lim- ited group of researchers at Stockholm University. Here, we describe a number of data science applications that have been developed using this database, demonstrating the potential reuse of EHR data to support healthcare and public health activities, as well as facilitate medical re- search. However, in order to realize the full potential of this resource, it needs to be made available to a larger community of researchers, as well as to industry actors. To that end, we envision the provision of an in- frastructure around this database called HEALTH BANK – the Swedish Health Record Research Bank. It will function both as a workbench for the development of data science applications and as a data explo- ration tool, allowing epidemiologists, pharmacologists and other medical researchers to generate and evaluate hypotheses. Aggregated data will be fed into a pipeline for open e-access, while non-aggregated data will be provided to researchers within an ethical permission framework. We believe that HEALTH BANK has the potential to promote a growing industry around the development of data science applications that will ultimately increase the efficiency and effectiveness of healthcare.",enorm amount data gener healthcar process store electron health record ehr system underutil resourc use data scienc applica tion exploit improv healthcar foster develop use data scienc applic healthcar fundamen tal need access ehr data typic readili avail research develop rel rare except larg ehr databas stockholm epr corpu compris data two million patient made avail lim ite group research stockholm univers describ number data scienc applic develop use databas demonstr potenti reus ehr data support healthcar public health activ well facilit medic search howev order realiz full potenti resourc need made avail larger commun research well industri actor end envis provis frastructur around databas call health bank swedish health record research bank function workbench develop data scienc applic data explo ration tool allow epidemiologist pharmacologist medic research gener evalu hypothes aggreg data fed pipelin open eaccess nonaggreg data provid research within ethic permiss framework believ health bank potenti promot grow industri around develop data scienc applic ultim increas effici effect healthcar
469fb7c7178c8370a93fb27dadc9c5c839a9b8ec,Information Science Roles in the Emerging Field of Data Science,"There has long been discussion about the distinctions of library science, information science, and informatics, and how these areas differ and overlap with computer science. Today the term data science is emerging that generates excitement and questions about how it relates to and differs from these other areas of study. For our purposes here, I consider information science to be the general term that subsumes library science and informatics and focuses on distinctions and similarities among these disciplines that each informs data science. At the most general levels, information science deals with the genesis, flow, use, and preservation of information; computer science deals with algorithms and techniques for computational processes. Data science as a concept emerges from the applications of existing studies of measurement, representation, interpretation, and management to problems in Citation: Gary Marchionini (2016). Information Science Roles in the Emerging Field of Data Science. Received: Mar. 10, 2016 Accepted: Mar. 22, 2016",long discuss distinct librari scienc inform scienc informat area differ overlap comput scienc today term data scienc emerg gener excit question relat differ area studi purpos consid inform scienc gener term subsum librari scienc informat focus distinct similar among disciplin inform data scienc gener level inform scienc deal genesi flow use preserv inform comput scienc deal algorithm techniqu comput process data scienc concept emerg applic exist studi measur represent interpret manag problem citat gari marchionini inform scienc role emerg field data scienc receiv mar accept mar
de84e808462b8240c75987364a6d518eff7d8813,Statistics: a data science for the 21st century,"The rise of data science could be seen as a potental threat to the long‐term status of the statistics discipline. I first argue that, although there is a threat, there is also a much greater opportunity to re‐emphasize the universal relevance of statistical method to the interpretation of data, and I give a short historical outline of the increasingly important links between statistics and information technology. The core of the paper is a summary of several recent research projects, through which I hope to demonstrate that statistics makes an essential, but incomplete, contribution to the emerging field of ‘electronic health’ research. Finally, I offer personal thoughts on how statistics might best be organized in a research‐led university, on what we should teach our students and on some issues broadly related to data science where the Royal Statistical Society can take a lead.",rise data scienc could seen potent threat longterm statu statist disciplin first argu although threat also much greater opportun reemphas univers relev statist method interpret data give short histor outlin increasingli import link statist inform technolog core paper summari sever recent research project hope demonstr statist make essenti incomplet contribut emerg field electron health research final offer person thought statist might best organ researchl univers teach student issu broadli relat data scienc royal statist societi take lead
e926ef463fa96b3d06a321fcbcccdab9ff5f3da0,Statistics and computing: the genesis of data science,,nan
b885916e9af51010ca7ebafbc9270f0e5e207b38,Nursing Knowledge: Big Data Science—Implications for Nurse Leaders,"The integration of Big Data from electronic health records and other information systems within and across health care enterprises provides an opportunity to develop actionable predictive models that can increase the confidence of nursing leaders' decisions to improve patient outcomes and safety and control costs. As health care shifts to the community, mobile health applications add to the Big Data available. There is an evolving national action plan that includes nursing data in Big Data science, spearheaded by the University of Minnesota School of Nursing. For the past 3 years, diverse stakeholders from practice, industry, education, research, and professional organizations have collaborated through the “Nursing Knowledge: Big Data Science” conferences to create and act on recommendations for inclusion of nursing data, integrated with patient-generated, interprofessional, and contextual data. It is critical for nursing leaders to understand the value of Big Data science and the ways to standardize data and workflow processes to take advantage of newer cutting edge analytics to support analytic methods to control costs and improve patient quality and safety.",integr big data electron health record inform system within across health care enterpris provid opportun develop action predict model increas confid nurs leader decis improv patient outcom safeti control cost health care shift commun mobil health applic add big data avail evolv nation action plan includ nurs data big data scienc spearhead univers minnesota school nurs past year divers stakehold practic industri educ research profession organ collabor nurs knowledg big data scienc confer creat act recommend inclus nurs data integr patientgener interprofession contextu data critic nurs leader understand valu big data scienc way standard data workflow process take advantag newer cut edg analyt support analyt method control cost improv patient qualiti safeti
e78d7fa72a5dbe5f3bc93f6e200826004f23530b,Data Science: Nature and Pitfalls,Data science is creating exciting trends as well as significant controversy. A critical matter for the healthy development of data science in its early stages is to deeply understand the nature of data and data science and discuss the various pitfalls. These important issues motivate the discussions in this article.,data scienc creat excit trend well signific controversi critic matter healthi develop data scienc earli stage deepli understand natur data data scienc discuss variou pitfal import issu motiv discuss articl
fa15d626d8905d08953abe646a75a31417ad61fa,"Data science on the ground: Hype, criticism, and everyday work","Modern organizations often employ data scientists to improve business processes using diverse sets of data. Researchers and practitioners have both touted the benefits and warned of the drawbacks associated with data science and big data approaches, but few studies investigate how data science is carried out “on the ground.” In this paper, we first review the hype and criticisms surrounding data science and big data approaches. We then present the findings of semistructured interviews with 18 data analysts from various industries and organizational roles. Using qualitative coding techniques, we evaluated these interviews in light of the hype and criticisms surrounding data science in the popular discourse. We found that although the data analysts we interviewed were sensitive to both the allure and the potential pitfalls of data science, their motivations and evaluations of their work were more nuanced. We conclude by reflecting on the relationship between data analysts' work and the discourses around data science and big data, suggesting how future research can better account for the everyday practices of this profession.",modern organ often employ data scientist improv busi process use divers set data research practition tout benefit warn drawback associ data scienc big data approach studi investig data scienc carri ground paper first review hype critic surround data scienc big data approach present find semistructur interview data analyst variou industri organiz role use qualit code techniqu evalu interview light hype critic surround data scienc popular discours found although data analyst interview sensit allur potenti pitfal data scienc motiv evalu work nuanc conclud reflect relationship data analyst work discours around data scienc big data suggest futur research better account everyday practic profess
abe269076b072e14918921a25f10757747fa3493,"Responsible Data Science: Using Event Data in a ""People Friendly"" Manner",,nan
bff0d1d3a3251cb7bcbeb424ae0580c3085649f7,Integrating Systems Modelling and Data Science: The Joint Future of Simulation and 'Big Data' Science,"Although System Dynamics modelling is sometimes referred to as data-poor modelling, it often is -or could be-applied in a data-rich manner. However, more can be done in the era of 'big data'. Big data refers here to situations with much more available data than was until recently manageable. The field of data science makes bigger data manageable. This paper provides a perspective on the future of System Dynamics with a prominent place for bigger data and data science. It discusses different approaches for dealing with bigger data. It reviews methods, techniques and tools for dealing with bigger data in System Dynamics, and sheds light on the modelling phases for which data science is most useful. Finally, it provides several examples of current applications in which big data, data science, and System Dynamics modelling and simulation are being merged.",although system dynam model sometim refer datapoor model often could beappli datarich manner howev done era big data big data refer situat much avail data recent manag field data scienc make bigger data manag paper provid perspect futur system dynam promin place bigger data data scienc discuss differ approach deal bigger data review method techniqu tool deal bigger data system dynam shed light model phase data scienc use final provid sever exampl current applic big data data scienc system dynam model simul merg
def43235dba7eb98659fb8879fa9d27695029df2,Recent Activities in Earth Data Science [Technical Committees],"Recent trends on big Earth-observing (EO) data lead to some questions that the Earth science community needs to address. Are we experiencing a paradigm shift in Earth science research now? How can we better utilize the explosion of technology maturation to create new forms of EO data processing? Can we summarize the existing methodologies and technologies scaling to big EO data as a new field named earth data science? Big data technologies are being widely practiced in Earth sciences and remote sensing communities to support EO data access, processing, and knowledge discovery. The data-intensive scientific discovery, named the fourth paradigm, leads to data science in the big data era [1]. According to the definition by the U.S. National Institute of Standards and Technology, the data science paradigm is the ""extraction of actionable knowledge directly from data through a process of discovery, hypothesis, and hypothesis testing"" [2]. Earth data science is the art and science of applying the data science paradigm to EO data.",recent trend big earthobserv eo data lead question earth scienc commun need address experienc paradigm shift earth scienc research better util explos technolog matur creat new form eo data process summar exist methodolog technolog scale big eo data new field name earth data scienc big data technolog wide practic earth scienc remot sens commun support eo data access process knowledg discoveri dataintens scientif discoveri name fourth paradigm lead data scienc big data era accord definit us nation institut standard technolog data scienc paradigm extract action knowledg directli data process discoveri hypothesi hypothesi test earth data scienc art scienc appli data scienc paradigm eo data
d343c9823bcacf31ea4aca105d0366f3f18a75e5,The Role of Data Science in Web Science,"Web science relies on an interdisciplinary approach that seeks to go beyond what any one subject can say about the World Wide Web. By incorporating numerous disciplinary perspectives and relying heavily on domain knowledge and expertise, data science has emerged as an important new area that integrates statistics with computational knowledge, data collection, cleaning and processing, analysis methods, and visualization to produce actionable insights from big data. As a discipline to use within Web science research, data science offers significant opportunities for uncovering trends in large Web-based datasets. A Web science observatory exemplifies this relationship by offering an online platform of tools for carrying out Web science research, allowing users to carry out data science techniques to produce insights into Web science issues such as community development, online behavior, and information propagation. The authors outline the similarities and differences of these two growing subject areas to demonstrate the important relationship developing between them.",web scienc reli interdisciplinari approach seek go beyond one subject say world wide web incorpor numer disciplinari perspect reli heavili domain knowledg expertis data scienc emerg import new area integr statist comput knowledg data collect clean process analysi method visual produc action insight big data disciplin use within web scienc research data scienc offer signific opportun uncov trend larg webbas dataset web scienc observatori exemplifi relationship offer onlin platform tool carri web scienc research allow user carri data scienc techniqu produc insight web scienc issu commun develop onlin behavior inform propag author outlin similar differ two grow subject area demonstr import relationship develop
b70cfcc6bbb764728f8aa55aa173cc692eb77bdf,The Process of Analyzing Data is the Emergent Feature of Data Science,"In recent years the term “data science” gained considerable attention worldwide. In a A Very Short History Of Data Science by Press (2013), the first appearance of the term is ascribed to Peter Naur in 1974 (Concise Survey of Computer Methods). Regardless who used the term first and in what context it has been used, we think that data science is a good term to indicate that data are the focus of scientific research. This is in analogy to computer science, where the first department of computer science in the USA had been established in 1962 at Purdue University, at a time when the first electronic computers became available and it was still not clear enough what computers can do, one created therefore a new field where the computer was the focus of the study. In this paper, we want to address a couple of questions in order to demystify the meaning and the goals of data science in general.",recent year term data scienc gain consider attent worldwid short histori data scienc press first appear term ascrib peter naur concis survey comput method regardless use term first context use think data scienc good term indic data focu scientif research analog comput scienc first depart comput scienc usa establish purdu univers time first electron comput becam avail still clear enough comput one creat therefor new field comput focu studi paper want address coupl question order demystifi mean goal data scienc gener
23a57b1e2beb4235d2020ed57f484c947e3d0816,The Quantified Self: Fundamental Disruption in Big Data Science and Biological Discovery,"A key contemporary trend emerging in big data science is the quantified self (QS)-individuals engaged in the self-tracking of any kind of biological, physical, behavioral, or environmental information as n=1 individuals or in groups. There are opportunities for big data scientists to develop new models to support QS data collection, integration, and analysis, and also to lead in defining open-access database resources and privacy standards for how personal data is used. Next-generation QS applications could include tools for rendering QS data meaningful in behavior change, establishing baselines and variability in objective metrics, applying new kinds of pattern recognition techniques, and aggregating multiple self-tracking data streams from wearable electronics, biosensors, mobile phones, genomic data, and cloud-based services. The long-term vision of QS activity is that of a systemic monitoring approach where an individual's continuous personal information climate provides real-time performance optimization suggestions. There are some potential limitations related to QS activity-barriers to widespread adoption and a critique regarding scientific soundness-but these may be overcome. One interesting aspect of QS activity is that it is fundamentally a quantitative and qualitative phenomenon since it includes both the collection of objective metrics data and the subjective experience of the impact of these data. Some of this dynamic is being explored as the quantified self is becoming the qualified self in two new ways: by applying QS methods to the tracking of qualitative phenomena such as mood, and by understanding that QS data collection is just the first step in creating qualitative feedback loops for behavior change. In the long-term future, the quantified self may become additionally transformed into the extended exoself as data quantification and self-tracking enable the development of new sense capabilities that are not possible with ordinary senses. The individual body becomes a more knowable, calculable, and administrable object through QS activity, and individuals have an increasingly intimate relationship with data as it mediates the experience of reality.",key contemporari trend emerg big data scienc quantifi self qsindividu engag selftrack kind biolog physic behavior environment inform n individu group opportun big data scientist develop new model support qs data collect integr analysi also lead defin openaccess databas resourc privaci standard person data use nextgener qs applic could includ tool render qs data meaning behavior chang establish baselin variabl object metric appli new kind pattern recognit techniqu aggreg multipl selftrack data stream wearabl electron biosensor mobil phone genom data cloudbas servic longterm vision qs activ system monitor approach individu continu person inform climat provid realtim perform optim suggest potenti limit relat qs activitybarri widespread adopt critiqu regard scientif soundnessbut may overcom one interest aspect qs activ fundament quantit qualit phenomenon sinc includ collect object metric data subject experi impact data dynam explor quantifi self becom qualifi self two new way appli qs method track qualit phenomena mood understand qs data collect first step creat qualit feedback loop behavior chang longterm futur quantifi self may becom addit transform extend exoself data quantif selftrack enabl develop new sens capabl possibl ordinari sens individu bodi becom knowabl calcul administr object qs activ individu increasingli intim relationship data mediat experi realiti
682b105746238d3c39bd4f6cd0baa375dc0c2534,Perspectives on Data Science for Software Engineering,,nan
520515cfffcd2f439469398d7c959f8baa9ccc8b,Philosophy of Big Data: Expanding the Human-Data Relation with Big Data Science Services,"Big data is growing as an area of information technology, service, and science, and so too is the need for its intellectual understanding and interpretation from a theoretical, philosophical, and societal perspective. The Philosophy of Big Data is the branch of philosophy concerned with the foundations, methods, and implications of big data, the definitions, meaning, conceptualization, knowledge possibilities, truth standards, and practices in situations involving very-large data sets that are big in volume, velocity, variety, veracity, and variability. The Philosophy of Big Data is evolving into a discipline at two levels, one internal to the field as a generalized articulation of the concepts, theory, and systems that comprise the overall conduct of big data science. The other is external to the field, as a consideration of the impact of big data science more broadly on individuals, society, and the world. Methods, tools, and concepts are evaluated at both the level of industry practice theory and social impact. Three aspects are considered: what might constitute a Philosophy of Big Data, how the disciplines of the Philosophy of Information and the Philosophy of Big Data are developing, and an example of the Philosophy of Big Data in application in the data-intensive science field of Synthetic Biology. Overall a Philosophy of Big Data might helpful in conceptualizing and realizing big data science as a service practice, and also in transitioning to data-rich futures with human and data entities more productively co-existing in mutual growth and collaboration.",big data grow area inform technolog servic scienc need intellectu understand interpret theoret philosoph societ perspect philosophi big data branch philosophi concern foundat method implic big data definit mean conceptu knowledg possibl truth standard practic situat involv verylarg data set big volum veloc varieti verac variabl philosophi big data evolv disciplin two level one intern field gener articul concept theori system compris overal conduct big data scienc extern field consider impact big data scienc broadli individu societi world method tool concept evalu level industri practic theori social impact three aspect consid might constitut philosophi big data disciplin philosophi inform philosophi big data develop exampl philosophi big data applic dataintens scienc field synthet biolog overal philosophi big data might help conceptu realiz big data scienc servic practic also transit datarich futur human data entiti product coexist mutual growth collabor
5ea0821f37481dafab363a47bf9b904e986f5a20,Data science and analytics: a new era,,nan
57039a11d9fb423595a4e16129f7cc7f3ff2cac7,Data science ethics in government,"Data science can offer huge opportunities for government. With the ability to process larger and more complex datasets than ever before, it can provide better insights for policymakers and make services more tailored and efficient. As with all new technologies, there is a risk that we do not take up its opportunities and miss out on its enormous potential. We want people to feel confident to innovate with data. So, over the past 18 months, the Government Data Science Partnership has taken an open, evidence-based and user-centred approach to creating an ethical framework. It is a practical document that brings all the legal guidance together in one place, and is written in the context of new data science capabilities. As part of its development, we ran a public dialogue on data science ethics, including deliberative workshops, an experimental conjoint survey and an online engagement tool. The research supported the principles set out in the framework as well as provided useful insight into how we need to communicate about data science. It found that people had a low awareness of the term ‘data science’, but that showing data science examples can increase broad support for government exploring innovative uses of data. But people's support is highly context driven. People consider acceptability on a case-by-case basis, first thinking about the overall policy goals and likely intended outcome, and then weighing up privacy and unintended consequences. The ethical framework is a crucial start, but it does not solve all the challenges it highlights, particularly as technology is creating new challenges and opportunities every day. Continued research is needed into data minimization and anonymization, robust data models, algorithmic accountability, and transparency and data security. It also has revealed the need to set out a renewed deal between the citizen and state on data, to maintain and solidify trust in how we use people's data for social good. This article is part of the themed issue ‘The ethical impact of data science’.",data scienc offer huge opportun govern abil process larger complex dataset ever provid better insight policymak make servic tailor effici new technolog risk take opportun miss enorm potenti want peopl feel confid innov data past month govern data scienc partnership taken open evidencebas usercentr approach creat ethic framework practic document bring legal guidanc togeth one place written context new data scienc capabl part develop ran public dialogu data scienc ethic includ delib workshop experiment conjoint survey onlin engag tool research support principl set framework well provid use insight need commun data scienc found peopl low awar term data scienc show data scienc exampl increas broad support govern explor innov use data peopl support highli context driven peopl consid accept casebycas basi first think overal polici goal like intend outcom weigh privaci unintend consequ ethic framework crucial start solv challeng highlight particularli technolog creat new challeng opportun everi day continu research need data minim anonym robust data model algorithm account transpar data secur also reveal need set renew deal citizen state data maintain solidifi trust use peopl data social good articl part theme issu ethic impact data scienc
04831fedd16110da4cbd0798d16e21fbbc34ad06,A survey of open source data science tools,"Purpose – Data science is the study of the generalizable extraction of knowledge from data. It includes a variety of components and develops on methods and concepts from many domains, containing mathematics, probability models, machine learning, statistical learning, computer programming, data engineering, pattern recognition and learning, visualization and data warehousing aiming to extract value from data. The purpose of this paper is to provide an overview of open source (OS) data science tools, proposing a classification scheme that can be used to study OS data science software. Design/methodology/approach – The proposed classification scheme is based on general characteristics, project activity, operational characteristics and data mining characteristics. The authors then use the proposed scheme to examine 70 identified Open Source Software. From this the authors provide insight about the current status of OS data science tools and reveal the state-of-the-art tools. Findings – The features of 70 OS t...",purpos data scienc studi generaliz extract knowledg data includ varieti compon develop method concept mani domain contain mathemat probabl model machin learn statist learn comput program data engin pattern recognit learn visual data wareh aim extract valu data purpos paper provid overview open sourc os data scienc tool propos classif scheme use studi os data scienc softwar designmethodologyapproach propos classif scheme base gener characterist project activ oper characterist data mine characterist author use propos scheme examin identifi open sourc softwar author provid insight current statu os data scienc tool reveal stateoftheart tool find featur os
57c82a005ae353f4683938b15a52e1b0561f6e43,"R for Data Science: Import, Tidy, Transform, Visualize, and Model Data","Learn how to use R to turn raw data into insight, knowledge, and understanding. This book introduces you to R, RStudio, and the tidyverse, a collection of R packages designed to work together to make data science fast, fluent, and fun. Suitable for readers with no previous programming experience, R for Data Science is designed to get you doing data science as quickly as possible. Authors Hadley Wickham and Garrett Grolemund guide you through the steps of importing, wrangling, exploring, and modeling your data and communicating the results. Youll get a complete, big-picture understanding of the data science cycle, along with basic tools you need to manage the details. Each section of the book is paired with exercises to help you practice what youve learned along the way. Youll learn how to: Wrangletransform your datasets into a form convenient for analysisProgramlearn powerful R tools for solving data problems with greater clarity and easeExploreexamine your data, generate hypotheses, and quickly test themModelprovide a low-dimensional summary that captures true ""signals"" in your datasetCommunicatelearn R Markdown for integrating prose, code, and results",learn use r turn raw data insight knowledg understand book introduc r rstudio tidyvers collect r packag design work togeth make data scienc fast fluent fun suitabl reader previou program experi r data scienc design get data scienc quickli possibl author hadley wickham garrett grolemund guid step import wrangl explor model data commun result youll get complet bigpictur understand data scienc cycl along basic tool need manag detail section book pair exercis help practic youv learn along way youll learn wrangletransform dataset form conveni analysisprogramlearn power r tool solv data problem greater clariti easeexploreexamin data gener hypothes quickli test themmodelprovid lowdimension summari captur true signal datasetcommunicatelearn r markdown integr prose code result
dd153ebd44a07dde2259c22d43bb9cd18db44d2a,Modelling and Simulation in Materials Science and Engineering Visualization and analysis of atomistic simulation data with OVITO – the Open Visualization Tool,"The Open Visualization Tool (OVITO) is a new 3D visualization software designed for post-processing atomistic data obtained from molecular dynamics or Monte Carlo simulations. Unique analysis, editing and animations functions are integrated into its easy-to-use graphical user interface. The software is written in object-oriented C++, controllable via Python scripts and easily extendable through a plug-in interface. It is distributed as open-source software and can be downloaded from the website http://ovito.sourceforge.net/. (Some figures in this article are in colour only in the electronic version)",open visual tool ovito new visual softwar design postprocess atomist data obtain molecular dynam mont carlo simul uniqu analysi edit anim function integr easytous graphic user interfac softwar written objectori c control via python script easili extend plugin interfac distribut opensourc softwar download websit httpovitosourceforgenet figur articl colour electron version
1a95f1e8ff32488f228a25764af64531cb758ff0,Exploration of data science techniques to predict fatigue strength of steel from composition and processing parameters,,nan
6f989651c4f592613e92c9e37a8c4ac205998cfe,Data Science in Statistics Curricula: Preparing Students to “Think with Data”,"A growing number of students are completing undergraduate degrees in statistics and entering the workforce as data analysts. In these positions, they are expected to understand how to use databases and other data warehouses, scrape data from Internet sources, program solutions to complex problems in multiple languages, and think algorithmically as well as statistically. These data science topics have not traditionally been a major component of undergraduate programs in statistics. Consequently, a curricular shift is needed to address additional learning outcomes. The goal of this article is to motivate the importance of data science proficiency and to provide examples and resources for instructors to implement data science in their own statistics curricula. We provide case studies from seven institutions. These varied approaches to teaching data science demonstrate curricular innovations to address new needs. Also included here are examples of assignments designed for courses that foster engagement of undergraduates with data and data science. [Received November 2014. Revised July 2015.]",grow number student complet undergradu degre statist enter workforc data analyst posit expect understand use databas data warehous scrape data internet sourc program solut complex problem multipl languag think algorithm well statist data scienc topic tradit major compon undergradu program statist consequ curricular shift need address addit learn outcom goal articl motiv import data scienc profici provid exampl resourc instructor implement data scienc statist curricula provid case studi seven institut vari approach teach data scienc demonstr curricular innov address new need also includ exampl assign design cours foster engag undergradu data data scienc receiv novemb revis juli
9ba08d45d60130c7e5880f63a980b185a86e177c,A Big Data Guide to Understanding Climate Change: The Case for Theory-Guided Data Science,"Global climate change and its impact on human life has become one of our era's greatest challenges. Despite the urgency, data science has had little impact on furthering our understanding of our planet in spite of the abundance of climate data. This is a stark contrast from other fields such as advertising or electronic commerce where big data has been a great success story. This discrepancy stems from the complex nature of climate data as well as the scientific questions climate science brings forth. This article introduces a data science audience to the challenges and opportunities to mine large climate datasets, with an emphasis on the nuanced difference between mining climate data and traditional big data approaches. We focus on data, methods, and application challenges that must be addressed in order for big data to fulfill their promise with regard to climate science applications. More importantly, we highlight research showing that solely relying on traditional big data techniques results in dubious findings, and we instead propose a theory-guided data science paradigm that uses scientific theory to constrain both the big data techniques as well as the results-interpretation process to extract accurate insight from large climate data.",global climat chang impact human life becom one era greatest challeng despit urgenc data scienc littl impact further understand planet spite abund climat data stark contrast field advertis electron commerc big data great success stori discrep stem complex natur climat data well scientif question climat scienc bring forth articl introduc data scienc audienc challeng opportun mine larg climat dataset emphasi nuanc differ mine climat data tradit big data approach focu data method applic challeng must address order big data fulfil promis regard climat scienc applic importantli highlight research show sole reli tradit big data techniqu result dubiou find instead propos theoryguid data scienc paradigm use scientif theori constrain big data techniqu well resultsinterpret process extract accur insight larg climat data
9d653160d048eecf1a8138407994bfc69952324b,Practical Data Science with R,"Summary Practical Data Science with R lives up to its name. It explains basic principles without the theoretical mumbo-jumbo and jumps right to the real use cases you'll face as you collect, curate, and analyze the data crucial to the success of your business. You'll apply the R programming language and statistical analysis techniques to carefully explained examples based in marketing, business intelligence, and decision support. Purchase of the print book includes a free eBook in PDF, Kindle, and ePub formats from Manning Publications. About the Book Business analysts and developers are increasingly collecting, curating, analyzing, and reporting on crucial business data. The R language and its associated tools provide a straightforward way to tackle day-to-day data science tasks without a lot of academic theory or advanced mathematics. Practical Data Science with R shows you how to apply the R programming language and useful statistical techniques to everyday business situations. Using examples from marketing, business intelligence, and decision support, it shows you how to design experiments (such as A/B tests), build predictive models, and present results to audiences of all levels. This book is accessible to readers without a background in data science. Some familiarity with basic statistics, R, or another scripting language is assumed. What's Inside Data science for the business professional Statistical analysis using the R language Project lifecycle, from planning to delivery Numerous instantly familiar use cases Keys to effective data presentations About the Authors Nina Zumel and John Mount are cofounders of a San Francisco-based data science consulting firm. Both hold PhDs from Carnegie Mellon and blog on statistics, probability, and computer science at win-vector.com.",summari practic data scienc r live name explain basic principl without theoret mumbojumbo jump right real use case youll face collect curat analyz data crucial success busi youll appli r program languag statist analysi techniqu care explain exampl base market busi intellig decis support purchas print book includ free ebook pdf kindl epub format man public book busi analyst develop increasingli collect curat analyz report crucial busi data r languag associ tool provid straightforward way tackl daytoday data scienc task without lot academ theori advanc mathemat practic data scienc r show appli r program languag use statist techniqu everyday busi situat use exampl market busi intellig decis support show design experi ab test build predict model present result audienc level book access reader without background data scienc familiar basic statist r anoth script languag assum what insid data scienc busi profession statist analysi use r languag project lifecycl plan deliveri numer instantli familiar use case key effect data present author nina zumel john mount cofound san franciscobas data scienc consult firm hold phd carnegi mellon blog statist probabl comput scienc winvectorcom
c7d7d579d94b7fc67c75b68361e01ba8f59b1d40,Intelligent services for Big Data science,,nan
92efba7c622f54b8cd7b0d70d7cc09063e17b4f3,An undergraduate degree in data science: curriculum and a decade of implementation experience,"We describe Data Science, a four-year undergraduate program in predictive analytics, machine learning, and data mining implemented at the College of Charleston, Charleston, South Carolina, USA. We present a ten-year status report detailing the program's origins, successes, and challenges. Our experience demonstrates that education and training for big data concepts are possible and practical at the undergraduate level. The development of this program parallels the growing demand for finding utility in data sets and streaming data. The curriculum is a seventy-seven credit-hour program that has been successfully implemented in a liberal arts and sciences institution by the faculties of computer science and mathematics.",describ data scienc fouryear undergradu program predict analyt machin learn data mine implement colleg charleston charleston south carolina usa present tenyear statu report detail program origin success challeng experi demonstr educ train big data concept possibl practic undergradu level develop program parallel grow demand find util data set stream data curriculum seventyseven credithour program success implement liber art scienc institut faculti comput scienc mathemat
516a53c59a53b0a471cd8a277b229925e0582114,DataHub: Collaborative Data Science & Dataset Version Management at Scale,"Relational databases have limited support for data collaboration, where teams collaboratively curate and analyze large datasets. Inspired by software version control systems like git, we propose (a) a dataset version control system, giving users the ability to create, branch, merge, difference and search large, divergent collections of datasets, and (b) a platform, DATAHUB, that gives users the ability to perform collaborative data analysis building on this version control system. We outline the challenges in providing dataset version control at scale.",relat databas limit support data collabor team collabor curat analyz larg dataset inspir softwar version control system like git propos dataset version control system give user abil creat branch merg differ search larg diverg collect dataset b platform datahub give user abil perform collabor data analysi build version control system outlin challeng provid dataset version control scale
0040c830969302a8c88c0c083aee5051e405bfe5,"Big Data, Big Problems: Emerging Issues in the Ethics of Data Science and Journalism","As big data techniques become widespread in journalism, both as the subject of reporting and as newsgathering tools, the ethics of data science must inform and be informed by media ethics. This article explores emerging problems in ethical research using big data techniques. It does so using the duty-based framework advanced by W.D. Ross, who has significantly influenced both research science and media ethics. A successful framework must provide stability and flexibility. Without stability, ethical precommitments will vanish as technology rapidly shifts costs. Without flexibility, traditional approaches will rapidly become obsolete in the face of technological change. The article concludes that Ross's duty-based approach both provides stability in the face of rapid technological change and flexibility to innovate to achieve the original purpose of basic ethical principles.",big data techniqu becom widespread journal subject report newsgath tool ethic data scienc must inform inform media ethic articl explor emerg problem ethic research use big data techniqu use dutybas framework advanc wd ross significantli influenc research scienc media ethic success framework must provid stabil flexibl without stabil ethic precommit vanish technolog rapidli shift cost without flexibl tradit approach rapidli becom obsolet face technolog chang articl conclud rosss dutybas approach provid stabil face rapid technolog chang flexibl innov achiev origin purpos basic ethic principl
f707f6d7c3f874cb1a8aa961a50e50706731cd2d,Mechanism design for data science,"The promise of data science is that if data from a system can be recorded and understood then this understanding can potentially be utilized to improve the system. Behavioral and economic data, however, is different from scientific data in that it is subjective to the system. Behavior changes when the system changes, and to predict behavior for any given system change or to optimize over system changes, the behavioral model that generates the data must be inferred from the data. The ease with which this inference can be performed generally also depends on the system. Trivially, a system that ignores behavior does not admit any inference of a behavior generating model that can be used to predict behavior in a system that is responsive to behavior. To realize the promise of data science in economic systems, a theory for the design of such systems must also incorporate the desired inference properties. Consider as an example the revenue-maximizing auctioneer. If the auctioneer has knowledge of the distribution of bidder values then she can run the first-price auction with a reserve price that is tuned to the distribution. Under some mild distributional assumptions, with the appropriate reserve price the first-price auction is revenue optimal [Myerson 1981]. Notice that the historical bid data for the first-price auction with a reserve price will in most cases not have bids for bidders whose values are below the reserve. Therefore, there is no data analysis that the auctioneer can perform that will enable properties of the distribution of bidder values below the reserve price to be inferred. It could be, nonetheless, that over time the population of potential bidders evolves and the optimal reserve price lowers. This change could go completely unnoticed in the auctioneer's data. The two main tools for optimizing revenue in an auction are reserve prices (as above) and ironing. Both of these tools cause pooling behavior (i.e., bidders with distinct values take the same action) and economic inference cannot thereafter differentiate these pooled bidders. In order to maintain the distributional knowledge necessary to be able to run a good auction in the long term, the auctioneer must sacrifice the short-term revenue by running a non-revenue-optimal auction.",promis data scienc data system record understood understand potenti util improv system behavior econom data howev differ scientif data subject system behavior chang system chang predict behavior given system chang optim system chang behavior model gener data must infer data eas infer perform gener also depend system trivial system ignor behavior admit infer behavior gener model use predict behavior system respons behavior realiz promis data scienc econom system theori design system must also incorpor desir infer properti consid exampl revenuemaxim auction auction knowledg distribut bidder valu run firstpric auction reserv price tune distribut mild distribut assumpt appropri reserv price firstpric auction revenu optim myerson notic histor bid data firstpric auction reserv price case bid bidder whose valu reserv therefor data analysi auction perform enabl properti distribut bidder valu reserv price infer could nonetheless time popul potenti bidder evolv optim reserv price lower chang could go complet unnot auction data two main tool optim revenu auction reserv price iron tool caus pool behavior ie bidder distinct valu take action econom infer cannot thereaft differenti pool bidder order maintain distribut knowledg necessari abl run good auction long term auction must sacrific shortterm revenu run nonrevenueoptim auction
0e341b2a181f71dea088dbba800e70262f91a79e,"Color Science: Concepts and Methods, Quantitative Data and Formulae, 2nd Edition",Physical Data. The Eye. Colorimetry. Photometry. Visual Equivalence and Visual Matching. Uniform Color Scales. Visual Thresholds. Theories and Models of Color Vision. Appendix. References. Author and Subject Indexes.,physic data eye colorimetri photometri visual equival visual match uniform color scale visual threshold theori model color vision appendix refer author subject index
5a92ccd20e551c191ff19bdd8e75bf1b64faa54b,Dealing with Data: Science Librarians' Participation in Data Management at Association of Research Libraries Institutions,"As long as empirical research has existed, researchers have been doing “data management” in one form or another. However, funding agency mandates for doing formal data management are relatively recent, and academic libraries’ involvement has been concentrated mainly in the last few years. The National Science Foundation implemented a new mandate in January 2011, requiring researchers to include a data management plan with their proposals for funding. This has prompted many academic libraries to work more actively than before in data management, and science librarians in particular are uniquely poised to step into new roles to meet researchers’ data management needs. This study, a survey of science librarians at institutions affiliated with the Association of Research Libraries, investigates science librarians’ awareness of and involvement in institutional repositories, data repositories, and data management support services at their institutions. The study also explores the roles and responsibilities, both new and traditional, that science librarians have assumed related to data management, and the skills that science librarians believe are necessary to meet the demands of data management work. The results reveal themes of both uncertainty and optimism—uncertainty about the roles of librarians, libraries, and other campus entities; uncertainty about the skills that will be required; but also optimism about applying “traditional” librarian skills to this emerging field of academic librarianship.",long empir research exist research data manag one form anoth howev fund agenc mandat formal data manag rel recent academ librari involv concentr mainli last year nation scienc foundat implement new mandat januari requir research includ data manag plan propos fund prompt mani academ librari work activ data manag scienc librarian particular uniqu pois step new role meet research data manag need studi survey scienc librarian institut affili associ research librari investig scienc librarian awar involv institut repositori data repositori data manag support servic institut studi also explor role respons new tradit scienc librarian assum relat data manag skill scienc librarian believ necessari meet demand data manag work result reveal theme uncertainti optimismuncertainti role librarian librari campu entiti uncertainti skill requir also optim appli tradit librarian skill emerg field academ librarianship
b9111489ec08b50bc573982ede11f5bc2d7a4e88,Sjplot - Data Visualization For Statistics In Social Science.,"New functions


 tab_model() as replacement for sjt.lm() , sjt.glm() , sjt.lmer() and sjt.glmer() . Furthermore, tab_model() is designed to work with the same model-objects as plot_model() .
 New colour scales for ggplot-objects: scale_fill_sjplot() and scale_color_sjplot() . These provide predifined colour palettes from this package.
 show_sjplot_pals() to show all predefined colour palettes provided by this package.
 sjplot_pal() to return colour values of a specific palette.


Deprecated

Following functions are now deprecated:


 sjp.lm() , sjp.glm() , sjp.lmer() , sjp.glmer() and sjp.int() . Please use plot_model() instead.
 sjt.frq() . Please use sjmisc::frq(out = ""v"") instead.


Removed / Defunct

Following functions are now defunct:


 sjt.grpmean() , sjt.mwu() and sjt.df() . The replacements are sjstats::grpmean() , sjstats::mwu() and tab_df() resp. tab_dfs() .


Changes to functions


 plot_model() and plot_models() get a prefix.labels -argument, to prefix automatically retrieved term labels with either the related variable name or label.
 plot_model() gets a show.zeroinf -argument to show or hide the zero-inflation-part of models in the plot.
 plot_model() gets a jitter -argument to add some random variation to data points for those plot types that accept show.data = TRUE .
 plot_model() gets a legend.title -argument to define the legend title for plots that display a legend.
 plot_model() now passes more arguments in ... down to ggeffects::plot() for marginal effects plots.
 plot_model() now plots the zero-inflated part of the model for brmsfit -objects.
 plot_model() now plots multivariate response models, i.e. models with multiple outcomes.
 Diagnostic plots in plot_model() ( type = ""diag"" ) can now also be used with brmsfit -objects.
 Axis limits of diagnostic plots in plot_model() ( type = ""diag"" ) for Stan-models ( brmsfit or stanreg resp. stanfit ) can now be set with the axis.lim -argument.
 The grid.breaks -argument for plot_model() and plot_models() now also takes a vector of values to directly define the grid breaks for the plot.
 Better default calculation for grid breaks in plot_model() and plot_models() when the grid.breaks -argument is of length one.
 The terms -argument for plot_model() now also allows the specification of a range of numeric values in square brackets for marginal effects plots, e.g. terms = ""age [30:50]"" or terms = ""age [pretty]"" .
 For coefficient-plots, the terms - and rm.terms -arguments for plot_model() now also allows specification of factor levels for categorical terms. Coefficients for the indicted factor levels are kept resp. removed (see ?plot_model for details).
 plot_model() now supports clmm -objects (package ordinal).
 plot_model(type = ""diag"") now also shows random-effects QQ-plots for glmmTMB -models, and also plots random-effects QQ-plots for all random effects (if model has more than one random effect term).


Bug fixes


 plot_model(type = ""re"") now supports standard errors and confidence intervals for glmmTMB -objects.
 Fixed typo for glmmTMB -tidier, which may have returned wrong data for zero-inflation part of model.
 Multiple random intercepts for multilevel models fitted with brms area now shown in each own facet per intercept.
 Remove unnecessary warning in sjp.likert() for uneven category count when neutral category is specified.
 plot_model(type = ""int"") could not automatically select mdrt.values properly for non-integer variables.
 sjp.grpfrq() now correctly uses the complete space in facets when facet.grid = TRUE .
 sjp.grpfrq(type = ""boxplot"") did not correctly label the x-axis when one category had no elements in a vector.
 Problems with German umlauts when printing HTML tables were fixed.",new function tab_model replac sjtlm sjtglm sjtlmer sjtglmer furthermor tab_model design work modelobject plot_model new colour scale ggplotobject scale_fill_sjplot scale_color_sjplot provid predifin colour palett packag show_sjplot_p show predefin colour palett provid packag sjplot_pal return colour valu specif palett deprec follow function deprec sjplm sjpglm sjplmer sjpglmer sjpint pleas use plot_model instead sjtfrq pleas use sjmiscfrqout v instead remov defunct follow function defunct sjtgrpmean sjtmwu sjtdf replac sjstatsgrpmean sjstatsmwu tab_df resp tab_df chang function plot_model plot_model get prefixlabel argument prefix automat retriev term label either relat variabl name label plot_model get showzeroinf argument show hide zeroinflationpart model plot plot_model get jitter argument add random variat data point plot type accept showdata true plot_model get legendtitl argument defin legend titl plot display legend plot_model pass argument ggeffectsplot margin effect plot plot_model plot zeroinfl part model brmsfit object plot_model plot multivari respons model ie model multipl outcom diagnost plot plot_model type diag also use brmsfit object axi limit diagnost plot plot_model type diag stanmodel brmsfit stanreg resp stanfit set axislim argument gridbreak argument plot_model plot_model also take vector valu directli defin grid break plot better default calcul grid break plot_model plot_model gridbreak argument length one term argument plot_model also allow specif rang numer valu squar bracket margin effect plot eg term age term age pretti coefficientplot term rmterm argument plot_model also allow specif factor level categor term coeffici indict factor level kept resp remov see plot_model detail plot_model support clmm object packag ordin plot_modeltyp diag also show randomeffect qqplot glmmtmb model also plot randomeffect qqplot random effect model one random effect term bug fix plot_modeltyp support standard error confid interv glmmtmb object fix typo glmmtmb tidier may return wrong data zeroinfl part model multipl random intercept multilevel model fit brm area shown facet per intercept remov unnecessari warn sjplikert uneven categori count neutral categori specifi plot_modeltyp int could automat select mdrtvalu properli noninteg variabl sjpgrpfrq correctli use complet space facet facetgrid true sjpgrpfrqtype boxplot correctli label xaxi one categori element vector problem german umlaut print html tabl fix
0a7dd279ee312c9ef9c6fe04cd6f4f5e974abae3,A Data Science Solution for Mining Interesting Patterns from Uncertain Big Data,"Nowadays, high volumes of valuable uncertain data can be easily collected or generated at high velocity in many real-life applications. Mining these uncertain Big data is computationally intensive due to the presence of existential probability values associated with items in every transaction in the uncertain data. Each existential probability value expresses the likelihood of that item to be present in a particular transaction in the Big data. In some situations, users may be interested in mining all frequent patterns from these uncertain Big data, in other situations, users may be interested in only a tiny portion of these mined patterns. To reduce the computation and to focus the mining for the latter situations, we propose a tree-based algorithm that (i) allows users to express the patterns to be mined according to their intention via the use of constraints and (ii) uses MapReduce to mine uncertain Big data for only those frequent patterns that satisfy user-specified constraints. Experimental results show the effectiveness of our algorithm in mining interesting patterns from uncertain Big data.",nowaday high volum valuabl uncertain data easili collect gener high veloc mani reallif applic mine uncertain big data comput intens due presenc existenti probabl valu associ item everi transact uncertain data existenti probabl valu express likelihood item present particular transact big data situat user may interest mine frequent pattern uncertain big data situat user may interest tini portion mine pattern reduc comput focu mine latter situat propos treebas algorithm allow user express pattern mine accord intent via use constraint ii use mapreduc mine uncertain big data frequent pattern satisfi userspecifi constraint experiment result show effect algorithm mine interest pattern uncertain big data
5bbb90ae23803b8bb115d5d7f60c8defc5376e2a,"Intrinsic Relations between Data Science, Big Data, Business Analytics and Datafication","Data recording and storage have evolved over the past decades from manual gathering of data by using simple writing materials to the automation of data collection. Data storage has evolved significantly in the past decades and today databases no longer suffice as the only medium for the storage and management of data. This is due to the emergence of the Big Data and Data Science concepts. Previous studies have indicated that the multiplication of processing power of computers and the availability of larger data storage at reduced cost are part of the catalysts for the volume and rate at which data is now made available and captured.
 In this paper, the concepts of Big Data, Data Science and Business Analytics are reviewed. This paper discusses datafication of different aspects of life as the fundamental concept behind the growth of Big Data and Data Science. A review of the characteristics and value of Big Data and Data Science suggests that these emerging concepts will bring a paradigm change to a number of areas. Big Data was described as the basis for Data Science and Business Analytics which are tools employed in Data Science. Because these fields are still developing, there are diverse opinions, especially on the definition of Data Science. This paper provides a revised definition of Data Science, based on the review of available literature and proposes a schematic representation of the concepts.",data record storag evolv past decad manual gather data use simpl write materi autom data collect data storag evolv significantli past decad today databas longer suffic medium storag manag data due emerg big data data scienc concept previou studi indic multipl process power comput avail larger data storag reduc cost part catalyst volum rate data made avail captur paper concept big data data scienc busi analyt review paper discuss dataf differ aspect life fundament concept behind growth big data data scienc review characterist valu big data data scienc suggest emerg concept bring paradigm chang number area big data describ basi data scienc busi analyt tool employ data scienc field still develop divers opinion especi definit data scienc paper provid revis definit data scienc base review avail literatur propos schemat represent concept
3d7fcd1399573fb5cb455de6f85f149e0ab53828,The Science of Data Science,,nan
f3eda875e14bf933759f3b777131a4a9973537b4,"Data-driven science and engineering: machine learning, dynamical systems, and control",,nan
c2fb0ded7b21a23cd0931558b52ddbc98fc4f934,Doing Data Science: Straight Talk from the Frontline,"Now that people are aware that data can make the difference in an election or a business model, data science as an occupation is gaining ground. But how can you get started working in a wide-ranging, interdisciplinary field thats so clouded in hype? This insightful book, based on Columbia Universitys Introduction to Data Science class, tells you what you need to know. In many of these chapter-long lectures, data scientists from companies such as Google, Microsoft, and eBay share new algorithms, methods, and models by presenting case studies and the code they use. If youre familiar with linear algebra, probability, and statistics, and have programming experience, this book is an ideal introduction to data science. Topics include:Statistical inference, exploratory data analysis, and the data science process Algorithms Spam filters, Naive Bayes, and data wrangling Logistic regression Financial modeling Recommendation engines and causality Data visualization Social networks and data journalism Data engineering, MapReduce, Pregel, and Hadoop Doing Data Science is collaboration between course instructor Rachel Schutt, Senior VP of Data Science at News Corp, and data science consultant Cathy ONeil, a senior data scientist at Johnson Research Labs, who attended and blogged about the course.",peopl awar data make differ elect busi model data scienc occup gain ground get start work widerang interdisciplinari field that cloud hype insight book base columbia univers introduct data scienc class tell need know mani chapterlong lectur data scientist compani googl microsoft ebay share new algorithm method model present case studi code use your familiar linear algebra probabl statist program experi book ideal introduct data scienc topic includestatist infer exploratori data analysi data scienc process algorithm spam filter naiv bay data wrangl logist regress financi model recommend engin causal data visual social network data journal data engin mapreduc pregel hadoop data scienc collabor cours instructor rachel schutt senior vp data scienc news corp data scienc consult cathi oneil senior data scientist johnson research lab attend blog cours
3858f600d0187c28f381b034a70226213e82a54e,Network analysis of multivariate data in psychological science,,nan
1163c2996dfd0a46639b094e34ad783e969a0692,Data science and prediction,Big data promises automated actionable knowledge creation and predictive models for use by both humans and computers.,big data promis autom action knowledg creation predict model use human comput
3402835f33e3e1342eb86b4d13907e3c9121c82b,Data science for business,"Written by renowned data science experts Foster Provost and Tom Fawcett, Data Science for Business introduces the fundamental principles of data science, and walks you through the ""data-analytic thinking"" necessary for extracting useful knowledge and business value from the data you collect. This guide also helps you understand the many data-mining techniques in use today. Based on an MBA course Provost has taught at New York University over the past ten years, Data Science for Business provides examples of real-world business problems to illustrate these principles. You'll not only learn how to improve communication between business stakeholders and data scientists, but also how participate intelligently in your company's data science projects. You'll also discover how to think data-analytically, and fully appreciate how data science methods can support business decision-making. Understand how data science fits in your organization - and how you can use it for competitive advantage Treat data as a business asset that requires careful investment if you're to gain real value Approach business problems data-analytically, using the data-mining process to gather good data in the most appropriate way Learn general concepts for actually extracting knowledge from data Apply data science principles when interviewing data science job candidates",written renown data scienc expert foster provost tom fawcett data scienc busi introduc fundament principl data scienc walk dataanalyt think necessari extract use knowledg busi valu data collect guid also help understand mani datamin techniqu use today base mba cours provost taught new york univers past ten year data scienc busi provid exampl realworld busi problem illustr principl youll learn improv commun busi stakehold data scientist also particip intellig compani data scienc project youll also discov think dataanalyt fulli appreci data scienc method support busi decisionmak understand data scienc fit organ use competit advantag treat data busi asset requir care invest your gain real valu approach busi problem dataanalyt use datamin process gather good data appropri way learn gener concept actual extract knowledg data appli data scienc principl interview data scienc job candid
0636653b82e152ba99b1d921b0aa2798aa845d1e,"Scopus as a curated, high-quality bibliometric data source for academic research in quantitative science studies","Abstract Scopus is among the largest curated abstract and citation databases, with a wide global and regional coverage of scientific journals, conference proceedings, and books, while ensuring only the highest quality data are indexed through rigorous content selection and re-evaluation by an independent Content Selection and Advisory Board. Additionally, extensive quality assurance processes continuously monitor and improve all data elements in Scopus. Besides enriched metadata records of scientific articles, Scopus offers comprehensive author and institution profiles, obtained from advanced profiling algorithms and manual curation, ensuring high precision and recall. The trustworthiness of Scopus has led to its use as bibliometric data source for large-scale analyses in research assessments, research landscape studies, science policy evaluations, and university rankings. Scopus data have been offered for free for selected studies by the academic research community, such as through application programming interfaces, which have led to many publications employing Scopus data to investigate topics such as researcher mobility, network visualizations, and spatial bibliometrics. In June 2019, the International Center for the Study of Research was launched, with an advisory board consisting of bibliometricians, aiming to work with the scientometric research community and offering a virtual laboratory where researchers will be able to utilize Scopus data.",abstract scopu among largest curat abstract citat databas wide global region coverag scientif journal confer proceed book ensur highest qualiti data index rigor content select reevalu independ content select advisori board addit extens qualiti assur process continu monitor improv data element scopu besid enrich metadata record scientif articl scopu offer comprehens author institut profil obtain advanc profil algorithm manual curat ensur high precis recal trustworthi scopu led use bibliometr data sourc largescal analys research assess research landscap studi scienc polici evalu univers rank scopu data offer free select studi academ research commun applic program interfac led mani public employ scopu data investig topic research mobil network visual spatial bibliometr june intern center studi research launch advisori board consist bibliometrician aim work scientometr research commun offer virtual laboratori research abl util scopu data
cbf6a6d8fff87b74f36c5e4ede09f55e7a71506c,Numerical data and functional relationships in science and technology,,nan
8f63eed1c6aef4e96a08281563c2305ff55e7ab9,ImageJ2: ImageJ for the next generation of scientific image data,,nan
e9931ea8ae9b8db38b519ef9ae32ec41a06d8445,Doing Data Science,"Now that people are aware that data can make the difference in an election or a business model, data science as an occupation is gaining ground. But how can you get started working in a wide-ranging, interdisciplinary field that's so clouded in hype? This insightful book, based on Columbia University's Introduction to Data Science class, tells you what you need to know. In many of these chapter-long lectures, data scientists from companies such as Google, Microsoft, and eBay share new algorithms, methods, and models by presenting case studies and the code they use. If you're familiar with linear algebra, probability, and statistics, and have programming experience, this book is an ideal introduction to data science. Topics include: Statistical inference, exploratory data analysis, and the data science process Algorithms Spam filters, Naive Bayes, and data wrangling Logistic regression Financial modeling Recommendation engines and causality Data visualization Social networks and data journalism Data engineering, MapReduce, Pregel, and Hadoop Doing Data Science is collaboration between course instructor Rachel Schutt, Senior VP of Data Science at News Corp, and data science consultant Cathy O'Neil, a senior data scientist at Johnson Research Labs, who attended and blogged about the course.",peopl awar data make differ elect busi model data scienc occup gain ground get start work widerang interdisciplinari field that cloud hype insight book base columbia univers introduct data scienc class tell need know mani chapterlong lectur data scientist compani googl microsoft ebay share new algorithm method model present case studi code use your familiar linear algebra probabl statist program experi book ideal introduct data scienc topic includ statist infer exploratori data analysi data scienc process algorithm spam filter naiv bay data wrangl logist regress financi model recommend engin causal data visual social network data journal data engin mapreduc pregel hadoop data scienc collabor cours instructor rachel schutt senior vp data scienc news corp data scienc consult cathi oneil senior data scientist johnson research lab attend blog cours
379e9576dea9690cf88d9132287edbefb7626232,Data Smart: Using Data Science to Transform Information into Insight,"Data Science gets thrown around in the press like it's magic. Major retailers are predicting everything from when their customers are pregnant to when they want a new pair of Chuck Taylors. It's a brave new world where seemingly meaningless data can be transformed into valuable insight to drive smart business decisions.But how does one exactly do data science? Do you have to hire one of these priests of the dark arts, the ""data scientist,"" to extract this gold from your data? Nope.Data science is little more than using straight-forward steps to process raw data into actionable insight. And inData Smart, author and data scientist John Foreman will show you how that's done within the familiar environment of a spreadsheet.",data scienc get thrown around press like magic major retail predict everyth custom pregnant want new pair chuck taylor brave new world seemingli meaningless data transform valuabl insight drive smart busi decisionsbut one exactli data scienc hire one priest dark art data scientist extract gold data nopedata scienc littl use straightforward step process raw data action insight indata smart author data scientist john foreman show that done within familiar environ spreadsheet
6a324214a73610d8819e004e7ebd7dd23107d1f8,Computing: A vision for data science,,nan
010a8ed71c6a80c2c02c7f55e1718151f91ff35a,Web of Science as a data source for research on scientific and scholarly activity,"Abstract Web of Science (WoS) is the world’s oldest, most widely used and authoritative database of research publications and citations. Based on the Science Citation Index, founded by Eugene Garfield in 1964, it has expanded its selective, balanced, and complete coverage of the world’s leading research to cover around 34,000 journals today. A wide range of use cases are supported by WoS from daily search and discovery by researchers worldwide through to the supply of analytical data sets and the provision of specialized access to raw data for bibliometric partners. A long- and well-established network of such partners enables the Institute for Scientific Information (ISI) to continue to work closely with bibliometric groups around the world to the benefit of both the community and the services that the company provides to researchers and analysts.",abstract web scienc wo world oldest wide use authorit databas research public citat base scienc citat index found eugen garfield expand select balanc complet coverag world lead research cover around journal today wide rang use case support wo daili search discoveri research worldwid suppli analyt data set provis special access raw data bibliometr partner long wellestablish network partner enabl institut scientif inform isi continu work close bibliometr group around world benefit commun servic compani provid research analyst
dd4f9aa21cf34994c07d2d74fc7f633194564224,"Large-scale comparison of bibliographic data sources: Scopus, Web of Science, Dimensions, Crossref, and Microsoft Academic","We present a large-scale comparison of five multidisciplinary bibliographic data sources: Scopus, Web of Science, Dimensions, Crossref, and Microsoft Academic. The comparison considers scientific documents from the period 2008–2017 covered by these data sources. Scopus is compared in a pairwise manner with each of the other data sources. We first analyze differences between the data sources in the coverage of documents, focusing for instance on differences over time, differences per document type, and differences per discipline. We then study differences in the completeness and accuracy of citation links. Based on our analysis, we discuss the strengths and weaknesses of the different data sources. We emphasize the importance of combining a comprehensive coverage of the scientific literature with a flexible set of filters for making selections of the literature.",present largescal comparison five multidisciplinari bibliograph data sourc scopu web scienc dimens crossref microsoft academ comparison consid scientif document period cover data sourc scopu compar pairwis manner data sourc first analyz differ data sourc coverag document focus instanc differ time differ per document type differ per disciplin studi differ complet accuraci citat link base analysi discuss strength weak differ data sourc emphas import combin comprehens coverag scientif literatur flexibl set filter make select literatur
30c9e3fcb1ead2a827f91ff5cd203aa0d8058bff,Data-Driven Science and Engineering,,nan
425744cb05e854071d06af0da2b8ef2d677f33d5,Harnessing the GPS Data Explosion for Interdisciplinary Science,"More GPS stations, faster data delivery, and better data processing provide an abundance of information for all kinds of Earth scientists.",gp station faster data deliveri better data process provid abund inform kind earth scientist
46d55edae7cf5f065bb037462a7951c220f42618,"Active learning increases student performance in science, engineering, and mathematics","Significance The President’s Council of Advisors on Science and Technology has called for a 33% increase in the number of science, technology, engineering, and mathematics (STEM) bachelor’s degrees completed per year and recommended adoption of empirically validated teaching practices as critical to achieving that goal. The studies analyzed here document that active learning leads to increases in examination performance that would raise average grades by a half a letter, and that failure rates under traditional lecturing increase by 55% over the rates observed under active learning. The analysis supports theory claiming that calls to increase the number of students receiving STEM degrees could be answered, at least in part, by abandoning traditional lecturing in favor of active learning. To test the hypothesis that lecturing maximizes learning and course performance, we metaanalyzed 225 studies that reported data on examination scores or failure rates when comparing student performance in undergraduate science, technology, engineering, and mathematics (STEM) courses under traditional lecturing versus active learning. The effect sizes indicate that on average, student performance on examinations and concept inventories increased by 0.47 SDs under active learning (n = 158 studies), and that the odds ratio for failing was 1.95 under traditional lecturing (n = 67 studies). These results indicate that average examination scores improved by about 6% in active learning sections, and that students in classes with traditional lecturing were 1.5 times more likely to fail than were students in classes with active learning. Heterogeneity analyses indicated that both results hold across the STEM disciplines, that active learning increases scores on concept inventories more than on course examinations, and that active learning appears effective across all class sizes—although the greatest effects are in small (n ≤ 50) classes. Trim and fill analyses and fail-safe n calculations suggest that the results are not due to publication bias. The results also appear robust to variation in the methodological rigor of the included studies, based on the quality of controls over student quality and instructor identity. This is the largest and most comprehensive metaanalysis of undergraduate STEM education published to date. The results raise questions about the continued use of traditional lecturing as a control in research studies, and support active learning as the preferred, empirically validated teaching practice in regular classrooms.",signific presid council advisor scienc technolog call increas number scienc technolog engin mathemat stem bachelor degre complet per year recommend adopt empir valid teach practic critic achiev goal studi analyz document activ learn lead increas examin perform would rais averag grade half letter failur rate tradit lectur increas rate observ activ learn analysi support theori claim call increas number student receiv stem degre could answer least part abandon tradit lectur favor activ learn test hypothesi lectur maxim learn cours perform metaanalyz studi report data examin score failur rate compar student perform undergradu scienc technolog engin mathemat stem cours tradit lectur versu activ learn effect size indic averag student perform examin concept inventori increas sd activ learn n studi odd ratio fail tradit lectur n studi result indic averag examin score improv activ learn section student class tradit lectur time like fail student class activ learn heterogen analys indic result hold across stem disciplin activ learn increas score concept inventori cours examin activ learn appear effect across class sizesalthough greatest effect small n class trim fill analys failsaf n calcul suggest result due public bia result also appear robust variat methodolog rigor includ studi base qualiti control student qualiti instructor ident largest comprehens metaanalysi undergradu stem educ publish date result rais question continu use tradit lectur control research studi support activ learn prefer empir valid teach practic regular classroom
abc0a9eb3ae901ece2f532f504c336fbb6ba81ca,"Data‐Driven Materials Science: Status, Challenges, and Perspectives","Data‐driven science is heralded as a new paradigm in materials science. In this field, data is the new resource, and knowledge is extracted from materials datasets that are too big or complex for traditional human reasoning—typically with the intent to discover new or improved materials or materials phenomena. Multiple factors, including the open science movement, national funding, and progress in information technology, have fueled its development. Such related tools as materials databases, machine learning, and high‐throughput methods are now established as parts of the materials research toolset. However, there are a variety of challenges that impede progress in data‐driven materials science: data veracity, integration of experimental and computational data, data longevity, standardization, and the gap between industrial interests and academic efforts. In this perspective article, the historical development and current state of data‐driven materials science, building from the early evolution of open science to the rapid expansion of materials data infrastructures are discussed. Key successes and challenges so far are also reviewed, providing a perspective on the future development of the field.",datadriven scienc herald new paradigm materi scienc field data new resourc knowledg extract materi dataset big complex tradit human reasoningtyp intent discov new improv materi materi phenomena multipl factor includ open scienc movement nation fund progress inform technolog fuel develop relat tool materi databas machin learn highthroughput method establish part materi research toolset howev varieti challeng imped progress datadriven materi scienc data verac integr experiment comput data data longev standard gap industri interest academ effort perspect articl histor develop current state datadriven materi scienc build earli evolut open scienc rapid expans materi data infrastructur discuss key success challeng far also review provid perspect futur develop field
1110da1c238a7b09258136e7a2e7d558fb16f272,TENDL: Complete Nuclear Data Library for Innovative Nuclear Science and Technology,,nan
ee5825861645ec9b9d11a2882f3aa15ec9e6e4dd,"ENDF/B-VII.1 Nuclear Data for Science and Technology: Cross Sections, Covariances, Fission Product Yields and Decay Data",,nan
e60d9464935582cda41becd7c1455c09392a2a93,The Science of Visual Data Communication: What Works,"Effectively designed data visualizations allow viewers to use their powerful visual systems to understand patterns in data across science, education, health, and public policy. But ineffectively designed visualizations can cause confusion, misunderstanding, or even distrust—especially among viewers with low graphical literacy. We review research-backed guidelines for creating effective and intuitive visualizations oriented toward communicating data to students, coworkers, and the general public. We describe how the visual system can quickly extract broad statistics from a display, whereas poorly designed displays can lead to misperceptions and illusions. Extracting global statistics is fast, but comparing between subsets of values is slow. Effective graphics avoid taxing working memory, guide attention, and respect familiar conventions. Data visualizations can play a critical role in teaching and communication, provided that designers tailor those visualizations to their audience.",effect design data visual allow viewer use power visual system understand pattern data across scienc educ health public polici ineffect design visual caus confus misunderstand even distrustespeci among viewer low graphic literaci review researchback guidelin creat effect intuit visual orient toward commun data student cowork gener public describ visual system quickli extract broad statist display wherea poorli design display lead mispercept illus extract global statist fast compar subset valu slow effect graphic avoid tax work memori guid attent respect familiar convent data visual play critic role teach commun provid design tailor visual audienc
283a00005b90bbf9bdc44d8fba89084a4e61bff7,Extending the Global Mass Change Data Record: GRACE Follow‐On Instrument and Science Data Performance,"Since June, 2018, the Gravity Recovery and Climate Experiment Follow‐On (GRACE‐FO) is extending the 15‐year monthly mass change record of the GRACE mission, which ended in June 2017. The GRACE‐FO instrument and flight system performance has improved over GRACE. Better attitude solutions and enhanced pointing performance result in reduced fuel consumption and gravity range rate post‐fit residuals. One accelerometer requires additional calibrations due to unexpected measurement noise. The GRACE‐FO gravity and mass change fields from June 2018 through December 2019 continue the GRACE record at an equivalent precision and spatiotemporal sampling. During this period, GRACE‐FO observed large interannual terrestrial water variations associated with excess rainfall (Central US, Middle East), drought (Europe, Australia), and ice melt (Greenland). These observations are consistent with independent mass change estimates, providing high confidence that no intermission biases exist from GRACE to GRACE‐FO, despite the 11‐month gap. GRACE‐FO has also successfully demonstrated satellite‐to‐satellite laser ranging interferometry.",sinc june graviti recoveri climat experi followon gracefo extend year monthli mass chang record grace mission end june gracefo instrument flight system perform improv grace better attitud solut enhanc point perform result reduc fuel consumpt graviti rang rate postfit residu one acceleromet requir addit calibr due unexpect measur nois gracefo graviti mass chang field june decemb continu grace record equival precis spatiotempor sampl period gracefo observ larg interannu terrestri water variat associ excess rainfal central us middl east drought europ australia ice melt greenland observ consist independ mass chang estim provid high confid intermiss bias exist grace gracefo despit month gap gracefo also success demonstr satellitetosatellit laser rang interferometri
ee013b1477e8f81cb5c66a9a93a342281f740042,Assessing data quality in citizen science (preprint),"Ecological and environmental citizen science projects have enormous potential to advance science, influence policy, and guide resource management by producing datasets that are otherwise infeasible to generate. This potential can only be realized, though, if the datasets are of high quality. While scientists are often skeptical of the ability of unpaid volunteers to produce accurate datasets, a growing body of publications clearly shows that diverse types of citizen science projects can produce data with accuracy equal to or surpassing that of professionals. Successful projects rely on a suite of methods to boost data accuracy and account for bias, including iterative project development, volunteer training and testing, expert validation, replication across volunteers, and statistical modeling of systematic error. Each citizen science dataset should therefore be judged individually, according to project design and application, rather than assumed to be substandard simply because volunteers generated it.",ecolog environment citizen scienc project enorm potenti advanc scienc influenc polici guid resourc manag produc dataset otherwis infeas gener potenti realiz though dataset high qualiti scientist often skeptic abil unpaid volunt produc accur dataset grow bodi public clearli show divers type citizen scienc project produc data accuraci equal surpass profession success project reli suit method boost data accuraci account bia includ iter project develop volunt train test expert valid replic across volunt statist model systemat error citizen scienc dataset therefor judg individu accord project design applic rather assum substandard simpli volunt gener
e257edf34abd9a191fea1023a423abb497cca70f,The data science education dilemma,"The need for people fluent in working with data is growing rapidly and enormously, but U.S. K–12 education does not provide meaningful learning experiences designed to develop understanding of data science concepts or a fluency with data science skills. Data science is inherently inter- disciplinary, so it makes sense to integrate it with existing content areas, but difficulties abound. Consideration of the work involved in doing data science and the habits of mind that lie behind it leads to a way of thinking about integrating data science with mathematics and science. Examples drawn from current activity development in the Data Games project shed some light on what technology-based, data-driven might be like. The project’s ongoing research on learners’ conceptions of organizing data and the relevance to data science education is explained.",need peopl fluent work data grow rapidli enorm us k educ provid meaning learn experi design develop understand data scienc concept fluenci data scienc skill data scienc inher inter disciplinari make sens integr exist content area difficulti abound consider work involv data scienc habit mind lie behind lead way think integr data scienc mathemat scienc exampl drawn current activ develop data game project shed light technologybas datadriven might like project ongo research learner concept organ data relev data scienc educ explain
40de1c316a7f4de8e547a717c905013642378996,The Critical Importance of Citizen Science Data,"Citizen science is an important vehicle for democratizing science and promoting the goal of universal and equitable access to scientific data and information. Data generated by citizen science groups have become an increasingly important source for scientists, applied users and those pursuing the 2030 Agenda for Sustainable Development. Citizen science data are used extensively in studies of biodiversity and pollution; crowdsourced data are being used by UN operational agencies for humanitarian activities; and citizen scientists are providing data relevant to monitoring the sustainable development goals (SDGs). This article provides an International Science Council (ISC) perspective on citizen science data generating activities in support of the 2030 Agenda and on needed improvements to the citizen science community's data stewardship practices for the benefit of science and society by presenting results of research undertaken by an ISC-sponsored Task Group.",citizen scienc import vehicl democrat scienc promot goal univers equit access scientif data inform data gener citizen scienc group becom increasingli import sourc scientist appli user pursu agenda sustain develop citizen scienc data use extens studi biodivers pollut crowdsourc data use un oper agenc humanitarian activ citizen scientist provid data relev monitor sustain develop goal sdg articl provid intern scienc council isc perspect citizen scienc data gener activ support agenda need improv citizen scienc commun data stewardship practic benefit scienc societi present result research undertaken iscsponsor task group
00a4bdc5158945a0b9463a29da4810838e474875,Perspective: Materials informatics and big data: Realization of the “fourth paradigm” of science in materials science,"Our ability to collect “big data” has greatly surpassed our capability to analyze it, underscoring the emergence of the fourth paradigm of science, which is data-driven discovery. The need for data informatics is also emphasized by the Materials Genome Initiative (MGI), further boosting the emerging field of materials informatics. In this article, we look at how data-driven techniques are playing a big role in deciphering processing-structure-property-performance relationships in materials, with illustrative examples of both forward models (property prediction) and inverse models (materials discovery). Such analytics can significantly reduce time-to-insight and accelerate cost-effective materials discovery, which is the goal of MGI.",abil collect big data greatli surpass capabl analyz underscor emerg fourth paradigm scienc datadriven discoveri need data informat also emphas materi genom initi mgi boost emerg field materi informat articl look datadriven techniqu play big role deciph processingstructurepropertyperform relationship materi illustr exampl forward model properti predict invers model materi discoveri analyt significantli reduc timetoinsight acceler costeffect materi discoveri goal mgi
8e981ddb4877615f7d5f944a8d64789d1388ee87,LSST: From Science Drivers to Reference Design and Anticipated Data Products,"We describe here the most ambitious survey currently planned in the optical, the Large Synoptic Survey Telescope (LSST). The LSST design is driven by four main science themes: probing dark energy and dark matter, taking an inventory of the solar system, exploring the transient optical sky, and mapping the Milky Way. LSST will be a large, wide-field ground-based system designed to obtain repeated images covering the sky visible from Cerro Pachón in northern Chile. The telescope will have an 8.4 m (6.5 m effective) primary mirror, a 9.6 deg2 field of view, a 3.2-gigapixel camera, and six filters (ugrizy) covering the wavelength range 320–1050 nm. The project is in the construction phase and will begin regular survey operations by 2022. About 90% of the observing time will be devoted to a deep-wide-fast survey mode that will uniformly observe a 18,000 deg2 region about 800 times (summed over all six bands) during the anticipated 10 yr of operations and will yield a co-added map to r ∼ 27.5. These data will result in databases including about 32 trillion observations of 20 billion galaxies and a similar number of stars, and they will serve the majority of the primary science programs. The remaining 10% of the observing time will be allocated to special projects such as Very Deep and Very Fast time domain surveys, whose details are currently under discussion. We illustrate how the LSST science drivers led to these choices of system parameters, and we describe the expected data products and their characteristics.",describ ambiti survey current plan optic larg synopt survey telescop lsst lsst design driven four main scienc theme probe dark energi dark matter take inventori solar system explor transient optic sky map milki way lsst larg widefield groundbas system design obtain repeat imag cover sky visibl cerro pachón northern chile telescop effect primari mirror deg field view gigapixel camera six filter ugrizi cover wavelength rang nm project construct phase begin regular survey oper observ time devot deepwidefast survey mode uniformli observ deg region time sum six band anticip yr oper yield coad map r data result databas includ trillion observ billion galaxi similar number star serv major primari scienc program remain observ time alloc special project deep fast time domain survey whose detail current discuss illustr lsst scienc driver led choic system paramet describ expect data product characterist
7ec947261f5a3eabdaddb8e53d58a36b986c4e71,ENDF/B-VII.0: Next Generation Evaluated Nuclear Data Library for Nuclear Science and Technology,,nan
27041544c90c4b7646e0be8360194597065400a2,DATA SCIENCE,". Among the KM processes that function to guarantee access to knowledge is knowledge sharing. This process allows knowledge assets and experiences possessed by the organization to be accessed by anyone in the organization. Especially by using IT, this process can be done more optimally by capturing existing knowledge into a system so that this valuable information can be monitored anytime and anywhere. There are times when the knowledge possessed by experts is difficult to capture and represent in the system as in the case of tacit knowledgesuch as instincts, insights, and experiences of the experts. One of the challenges in inventorying these experts is the process of creating expert profiles automatically based on a particular approach. This research create an Expert Locator for lecturers who are considered as experts in their field of research using publication data produced by these lecturers as an indication of their expertise. The search feature is made as an implementation of the extraction results that can be used by other parties to find experts by entering keywords in the form of the desired expertise",among km process function guarante access knowledg knowledg share process allow knowledg asset experi possess organ access anyon organ especi use process done optim captur exist knowledg system valuabl inform monitor anytim anywher time knowledg possess expert difficult captur repres system case tacit knowledgesuch instinct insight experi expert one challeng inventori expert process creat expert profil automat base particular approach research creat expert locat lectur consid expert field research use public data produc lectur indic expertis search featur made implement extract result use parti find expert enter keyword form desir expertis
9efd15dcde5e0431c6915f86f201b27d4fdd6491,DATA SCIENCE,". The field of computer vision is increasingly becoming an active area of research with tremendous efforts being put towards giving computers the capability of sight. As human beings we are able to see, distinguish between different objects based on their unique features and even trace their movements if they are within our view. For computers to really see they also need to have the capability of identifying different objects and equally track them. This paper focuses on that aspect of identifying objects which the user chooses; the object chosen is differentiated from other objects by comparison of pixel characteristics. The chosen object is then to be tracked with a bounding box for ease of identification of the object's location. A real time video feed captured by a web camera is to be utilized and it’s from this environment visible within the camera view that an object is to be selected and tracked. The scope of this paper mainly focuses on the development of a software application that will achieve real time object tracking. The software module will allow the user to identify the object of interest someone wishes to track, while the algorithm employed will enable noise and size filtering for ease of tracking of the object.",field comput vision increasingli becom activ area research tremend effort put toward give comput capabl sight human be abl see distinguish differ object base uniqu featur even trace movement within view comput realli see also need capabl identifi differ object equal track paper focus aspect identifi object user choos object chosen differenti object comparison pixel characterist chosen object track bound box eas identif object locat real time video feed captur web camera util environ visibl within camera view object select track scope paper mainli focus develop softwar applic achiev real time object track softwar modul allow user identifi object interest someon wish track algorithm employ enabl nois size filter eas track object
81e1dbe1e8152d0ddbf89e861468d799dbebe367,Social media data for conservation science: A methodological overview,,nan
7281fb2c44f4d73c86ffefd1fde7e4f8a1f5e75c,Engagement in science through citizen science: Moving beyond data collection,"""To date, most studies of citizen science engagement focus on quantifiable measures related to the contribution of data or other output measures. Few studies have attempted to qualitatively characterize citizen science engagement across multiple projects and from the perspective of the participants. Building on pertinent literature and sociocultural learning theories, this study operationalizes engagement in citizen science through an analysis of interviews of 72 participants from six different environmentally based projects. We document engagement in citizen science through an examination of cognitive, affective, social, behavioral, and motivational dimensions. We assert that engagement in citizen science is enhanced by acknowledging these multiple dimensions and creating opportunities for volunteers to find personal relevance in their work with scientists. A Dimensions of Engagement framework is presented that can facilitate the innovation of new questions and methodologies for studying engagement in citizen science and other forms of informal science education.""",date studi citizen scienc engag focu quantifi measur relat contribut data output measur studi attempt qualit character citizen scienc engag across multipl project perspect particip build pertin literatur sociocultur learn theori studi operation engag citizen scienc analysi interview particip six differ environment base project document engag citizen scienc examin cognit affect social behavior motiv dimens assert engag citizen scienc enhanc acknowledg multipl dimens creat opportun volunt find person relev work scientist dimens engag framework present facilit innov new question methodolog studi engag citizen scienc form inform scienc educ
40b2324cde863db7670178f0151fae400a9a2b93,Analyzing Incomplete Political Science Data: An Alternative Algorithm for Multiple Imputation,"We propose a remedy for the discrepancy between the way political scientists analyze data with missing values and the recommendations of the statistics community. Methodologists and statisticians agree that “multiple imputation” is a superior approach to the problem of missing data scattered through one’s explanatory and dependent variables than the methods currently used in applied data analysis. The discrepancy occurs because the computational algorithms used to apply the best multiple imputation models have been slow, difficult to implement, impossible to run with existing commercial statistical packages, and have demanded considerable expertise. We adapt an algorithm and use it to implement a general-purpose, multiple imputation model for missing data. This algorithm is considerably faster and easier to use than the leading method recommended in the statistics literature. We also quantify the risks of current missing data practices, illustrate how to use the new procedure, and evaluate this alternative through simulated data as well as actual empirical examples. Finally, we offer easy-to-use software that implements all methods discussed.",propos remedi discrep way polit scientist analyz data miss valu recommend statist commun methodologist statistician agre multipl imput superior approach problem miss data scatter one explanatori depend variabl method current use appli data analysi discrep occur comput algorithm use appli best multipl imput model slow difficult implement imposs run exist commerci statist packag demand consider expertis adapt algorithm use implement generalpurpos multipl imput model miss data algorithm consider faster easier use lead method recommend statist literatur also quantifi risk current miss data practic illustr use new procedur evalu altern simul data well actual empir exampl final offer easytous softwar implement method discuss
ca5e7580993170b1fe621bc16383ad2dfa6803b5,Utilization of text mining as a big data analysis tool for food science and nutrition.,"Big data analysis has found applications in many industries due to its ability to turn huge amounts of data into insights for informed business and operational decisions. Advanced data mining techniques have been applied in many sectors of supply chains in the food industry. However, the previous work has mainly focused on the analysis of instrument-generated data such as those from hyperspectral imaging, spectroscopy, and biometric receptors. The importance of digital text data in the food and nutrition has only recently gained attention due to advancements in big data analytics. The purpose of this review is to provide an overview of the data sources, computational methods, and applications of text data in the food industry. Text mining techniques such as word-level analysis (e.g., frequency analysis), word association analysis (e.g., network analysis), and advanced techniques (e.g., text classification, text clustering, topic modeling, information retrieval, and sentiment analysis) will be discussed. Applications of text data analysis will be illustrated with respect to food safety and food fraud surveillance, dietary pattern characterization, consumer-opinion mining, new-product development, food knowledge discovery, food supply-chain management, and online food services. The goal is to provide insights for intelligent decision-making to improve food production, food safety, and human nutrition.",big data analysi found applic mani industri due abil turn huge amount data insight inform busi oper decis advanc data mine techniqu appli mani sector suppli chain food industri howev previou work mainli focus analysi instrumentgener data hyperspectr imag spectroscopi biometr receptor import digit text data food nutrit recent gain attent due advanc big data analyt purpos review provid overview data sourc comput method applic text data food industri text mine techniqu wordlevel analysi eg frequenc analysi word associ analysi eg network analysi advanc techniqu eg text classif text cluster topic model inform retriev sentiment analysi discuss applic text data analysi illustr respect food safeti food fraud surveil dietari pattern character consumeropinion mine newproduct develop food knowledg discoveri food supplychain manag onlin food servic goal provid insight intellig decisionmak improv food product food safeti human nutrit
fff51615943e08d05080682009c9c656321ef0b2,NOMAD: The FAIR concept for big data-driven materials science,"Data are a crucial raw material of this century. The amount of data that have been created in materials science thus far and that continues to be created every day is immense. Without a proper infrastructure that allows for collecting and sharing data, the envisioned success of big data-driven materials science will be hampered. For the field of computational materials science, the NOMAD (Novel Materials Discovery) Center of Excellence (CoE) has changed the scientific culture toward comprehensive and findable, accessible, interoperable, and reusable (FAIR) data, opening new avenues for mining materials science big data. Novel data-analytics concepts and tools turn data into knowledge and help in the prediction of new materials and in the identification of new properties of already known materials.",data crucial raw materi centuri amount data creat materi scienc thu far continu creat everi day immens without proper infrastructur allow collect share data envis success big datadriven materi scienc hamper field comput materi scienc nomad novel materi discoveri center excel coe chang scientif cultur toward comprehens findabl access interoper reusabl fair data open new avenu mine materi scienc big data novel dataanalyt concept tool turn data knowledg help predict new materi identif new properti alreadi known materi
e27acaf97f5b2eae4257bb5d8278fbe0e6405c39,Creating the CIPRES Science Gateway for inference of large phylogenetic trees,"Understanding the evolutionary history of living organisms is a central problem in biology. Until recently the ability to infer evolutionary relationships was limited by the amount of DNA sequence data available, but new DNA sequencing technologies have largely removed this limitation. As a result, DNA sequence data are readily available or obtainable for a wide spectrum of organisms, thus creating an unprecedented opportunity to explore evolutionary relationships broadly and deeply across the Tree of Life. Unfortunately, the algorithms used to infer evolutionary relationships are NP-hard, so the dramatic increase in available DNA sequence data has created a commensurate increase in the need for access to powerful computational resources. Local laptop or desktop machines are no longer viable for analysis of the larger data sets available today, and progress in the field relies upon access to large, scalable high-performance computing resources. This paper describes development of the CIPRES Science Gateway, a web portal designed to provide researchers with transparent access to the fastest available community codes for inference of phylogenetic relationships, and implementation of these codes on scalable computational resources. Meeting the needs of the community has included developing infrastructure to provide access, working with the community to improve existing community codes, developing infrastructure to insure the portal is scalable to the entire systematics community, and adopting strategies that make the project sustainable by the community. The CIPRES Science Gateway has allowed more than 1800 unique users to run jobs that required 2.5 million Service Units since its release in December 2009. (A Service Unit is a CPU-hour at unit priority).",understand evolutionari histori live organ central problem biolog recent abil infer evolutionari relationship limit amount dna sequenc data avail new dna sequenc technolog larg remov limit result dna sequenc data readili avail obtain wide spectrum organ thu creat unpreced opportun explor evolutionari relationship broadli deepli across tree life unfortun algorithm use infer evolutionari relationship nphard dramat increas avail dna sequenc data creat commensur increas need access power comput resourc local laptop desktop machin longer viabl analysi larger data set avail today progress field reli upon access larg scalabl highperform comput resourc paper describ develop cipr scienc gateway web portal design provid research transpar access fastest avail commun code infer phylogenet relationship implement code scalabl comput resourc meet need commun includ develop infrastructur provid access work commun improv exist commun code develop infrastructur insur portal scalabl entir systemat commun adopt strategi make project sustain commun cipr scienc gateway allow uniqu user run job requir million servic unit sinc releas decemb servic unit cpuhour unit prioriti
0e00f0dbfc381661826f8ddbafe73e33bcfe040f,Using Semistructured Surveys to Improve Citizen Science Data for Monitoring Biodiversity,"Abstract Biodiversity is being lost at an unprecedented rate, and monitoring is crucial for understanding the causal drivers and assessing solutions. Most biodiversity monitoring data are collected by volunteers through citizen science projects, and often crucial information is lacking to account for the inevitable biases that observers introduce during data collection. We contend that citizen science projects intended to support biodiversity monitoring must gather information about the observation process as well as species occurrence. We illustrate this using eBird, a global citizen science project that collects information on bird occurrences as well as vital contextual information on the observation process while maintaining broad participation. Our fundamental argument is that regardless of what species are being monitored, when citizen science projects collect a small set of basic information about how participants make their observations, the scientific value of the data collected will be dramatically improved.",abstract biodivers lost unpreced rate monitor crucial understand causal driver assess solut biodivers monitor data collect volunt citizen scienc project often crucial inform lack account inevit bias observ introduc data collect contend citizen scienc project intend support biodivers monitor must gather inform observ process well speci occurr illustr use ebird global citizen scienc project collect inform bird occurr well vital contextu inform observ process maintain broad particip fundament argument regardless speci monitor citizen scienc project collect small set basic inform particip make observ scientif valu data collect dramat improv
4a6e74d4bf4fd0106891e5518692a77c7aa8811d,Outlier Detection in High Dimensional Data,"Artificial intelligence (AI) is the science that allows
computers to replicate human intelligence in areas such as
decision-making, text processing, visual perception. Artificial
Intelligence is the broader field that contains several subfields
such as machine learning, robotics, and computer vision.
Machine Learning is a branch of Artificial Intelligence that
allows a machine to learn and improve at a task over time. Deep
Learning is a subset of machine learning that makes use of deep
artificial neural networks for training. The paper proposed on
outlier detection for multivariate high dimensional data for
Autoencoder unsupervised model.",artifici intellig ai scienc allow comput replic human intellig area decisionmak text process visual percept artifici intellig broader field contain sever subfield machin learn robot comput vision machin learn branch artifici intellig allow machin learn improv task time deep learn subset machin learn make use deep artifici neural network train paper propos outlier detect multivari high dimension data autoencod unsupervis model
8a9f26a4cee210e51c96f4016737605e31d490ee,A data ecosystem to support machine learning in materials science,"Facilitating the application of machine learning (ML) to materials science problems requires enhancing the data ecosystem to enable discovery and collection of data from many sources, automated dissemination of new data across the ecosystem, and the connecting of data with materials-specific ML models. Here, we present two projects, the Materials Data Facility (MDF) and the Data and Learning Hub for Science (DLHub), that address these needs. We use examples to show how MDF and DLHub capabilities can be leveraged to link data with ML models and how users can access those capabilities through web and programmatic interfaces.",facilit applic machin learn ml materi scienc problem requir enhanc data ecosystem enabl discoveri collect data mani sourc autom dissemin new data across ecosystem connect data materialsspecif ml model present two project materi data facil mdf data learn hub scienc dlhub address need use exampl show mdf dlhub capabl leverag link data ml model user access capabl web programmat interfac
3fe3924a5315fbb5b5cd0edf98533b8c61a3bbdf,Machine intelligence and the data-driven future of marine science,"
 Oceans constitute over 70% of the earth's surface, and the marine environment and ecosystems are central to many global challenges. Not only are the oceans an important source of food and other resources, but they also play a important roles in the earth's climate and provide crucial ecosystem services. To monitor the environment and ensure sustainable exploitation of marine resources, extensive data collection and analysis efforts form the backbone of management programmes on global, regional, or national levels. Technological advances in sensor technology, autonomous platforms, and information and communications technology now allow marine scientists to collect data in larger volumes than ever before. But our capacity for data analysis has not progressed comparably, and the growing discrepancy is becoming a major bottleneck for effective use of the available data, as well as an obstacle to scaling up data collection further. Recent years have seen rapid advances in the fields of artificial intelligence and machine learning, and in particular, so-called deep learning systems are now able to solve complex tasks that previously required human expertise. This technology is directly applicable to many important data analysis problems and it will provide tools that are needed to solve many complex challenges in marine science and resource management. Here we give a brief review of recent developments in deep learning, and highlight the many opportunities and challenges for effective adoption of this technology across the marine sciences.",ocean constitut earth surfac marin environ ecosystem central mani global challeng ocean import sourc food resourc also play import role earth climat provid crucial ecosystem servic monitor environ ensur sustain exploit marin resourc extens data collect analysi effort form backbon manag programm global region nation level technolog advanc sensor technolog autonom platform inform commun technolog allow marin scientist collect data larger volum ever capac data analysi progress compar grow discrep becom major bottleneck effect use avail data well obstacl scale data collect recent year seen rapid advanc field artifici intellig machin learn particular socal deep learn system abl solv complex task previous requir human expertis technolog directli applic mani import data analysi problem provid tool need solv mani complex challeng marin scienc resourc manag give brief review recent develop deep learn highlight mani opportun challeng effect adopt technolog across marin scienc
3f809897b51d824846cf5a56f2a7b4292f7bc4a4,Materials science: Share corrosion data,,nan
6a697a4b3bdbbfb7681d9f9a518fc0be73744037,Big data of materials science: critical role of the descriptor.,"Statistical learning of materials properties or functions so far starts with a largely silent, nonchallenged step: the choice of the set of descriptive parameters (termed descriptor). However, when the scientific connection between the descriptor and the actuating mechanisms is unclear, the causality of the learned descriptor-property relation is uncertain. Thus, a trustful prediction of new promising materials, identification of anomalies, and scientific advancement are doubtful. We analyze this issue and define requirements for a suitable descriptor. For a classic example, the energy difference of zinc blende or wurtzite and rocksalt semiconductors, we demonstrate how a meaningful descriptor can be found systematically.",statist learn materi properti function far start larg silent nonchalleng step choic set descript paramet term descriptor howev scientif connect descriptor actuat mechan unclear causal learn descriptorproperti relat uncertain thu trust predict new promis materi identif anomali scientif advanc doubt analyz issu defin requir suitabl descriptor classic exampl energi differ zinc blend wurtzit rocksalt semiconductor demonstr meaning descriptor found systemat
652c77a90d84df639622efdc9cd7475e96a248c9,Data-driven modeling and learning in science and engineering,,nan
0db731c99879bb74c3850c53923d1df2c510f8c3,"AIRS/AMSU/HSB on the Aqua mission: design, science objectives, data products, and processing systems","The Atmospheric Infrared Sounder (AIRS), the Advanced Microwave Sounding Unit (AMSU), and the Humidity Sounder for Brazil (HSB) form an integrated cross-track scanning temperature and humidity sounding system on the Aqua satellite of the Earth Observing System (EOS). AIRS is an infrared spectrometer/radiometer that covers the 3.7-15.4-/spl mu/m spectral range with 2378 spectral channels. AMSU is a 15-channel microwave radiometer operating between 23 and 89 GHz. HSB is a four-channel microwave radiometer that makes measurements between 150 and 190 GHz. In addition to supporting the National Aeronautics and Space Administration's interest in process study and climate research, AIRS is the first hyperspectral infrared radiometer designed to support the operational requirements for medium-range weather forecasting of the National Ocean and Atmospheric Administration's National Centers for Environmental Prediction (NCEP) and other numerical weather forecasting centers. AIRS, together with the AMSU and HSB microwave radiometers, will achieve global retrieval accuracy of better than 1 K in the lower troposphere under clear and partly cloudy conditions. This paper presents an overview of the science objectives, AIRS/AMSU/HSB data products, retrieval algorithms, and the ground-data processing concepts. The EOS Aqua was launched on May 4, 2002 from Vandenberg AFB, CA, into a 705-km-high, sun-synchronous orbit. Based on the excellent radiometric and spectral performance demonstrated by AIRS during prelaunch testing, which has by now been verified during on-orbit testing, we expect the assimilation of AIRS data into the numerical weather forecast to result in significant forecast range and reliability improvements.",atmospher infrar sounder air advanc microwav sound unit amsu humid sounder brazil hsb form integr crosstrack scan temperatur humid sound system aqua satellit earth observ system eo air infrar spectrometerradiomet cover spl mum spectral rang spectral channel amsu channel microwav radiomet oper ghz hsb fourchannel microwav radiomet make measur ghz addit support nation aeronaut space administr interest process studi climat research air first hyperspectr infrar radiomet design support oper requir mediumrang weather forecast nation ocean atmospher administr nation center environment predict ncep numer weather forecast center air togeth amsu hsb microwav radiomet achiev global retriev accuraci better k lower tropospher clear partli cloudi condit paper present overview scienc object airsamsuhsb data product retriev algorithm grounddata process concept eo aqua launch may vandenberg afb ca kmhigh sunsynchron orbit base excel radiometr spectral perform demonstr air prelaunch test verifi onorbit test expect assimil air data numer weather forecast result signific forecast rang reliabl improv
4e2f43dab69d690dc86422949e410ebf37f522d4,Bayesian data analysis.,"Bayesian methods have garnered huge interest in cognitive science as an approach to models of cognition and perception. On the other hand, Bayesian methods for data analysis have not yet made much headway in cognitive science against the institutionalized inertia of 20th century null hypothesis significance testing (NHST). Ironically, specific Bayesian models of cognition and perception may not long endure the ravages of empirical verification, but generic Bayesian methods for data analysis will eventually dominate. It is time that Bayesian data analysis became the norm for empirical methods in cognitive science. This article reviews a fatal flaw of NHST and introduces the reader to some benefits of Bayesian data analysis. The article presents illustrative examples of multiple comparisons in Bayesian analysis of variance and Bayesian approaches to statistical power. Copyright © 2010 John Wiley & Sons, Ltd. For further resources related to this article, please visit the WIREs website.",bayesian method garner huge interest cognit scienc approach model cognit percept hand bayesian method data analysi yet made much headway cognit scienc institution inertia th centuri null hypothesi signific test nhst iron specif bayesian model cognit percept may long endur ravag empir verif gener bayesian method data analysi eventu domin time bayesian data analysi becam norm empir method cognit scienc articl review fatal flaw nhst introduc reader benefit bayesian data analysi articl present illustr exampl multipl comparison bayesian analysi varianc bayesian approach statist power copyright john wiley son ltd resourc relat articl pleas visit wire websit
22737046fbbe822deaaffddddb8f16be076d3f95,"Open Science, Open Data, and Open Scholarship: European Policies to Make Science Fit for the Twenty-First Century","Open science will make science more efficient, reliable, and responsive to societal challenges. The European Commission has sought to advance open science policy from its inception in a holistic and integrated way, covering all aspects of the research cycle from scientific discovery and review to sharing knowledge, publishing, and outreach. We present the steps taken with a forward-looking perspective on the challenges laying ahead, in particular the necessary change of the rewards and incentives system for researchers (for which various actors are co-responsible and which goes beyond the mandate of the European Commission). Finally, we discuss the role of artificial intelligence (AI) within an open science perspective.",open scienc make scienc effici reliabl respons societ challeng european commiss sought advanc open scienc polici incept holist integr way cover aspect research cycl scientif discoveri review share knowledg publish outreach present step taken forwardlook perspect challeng lay ahead particular necessari chang reward incent system research variou actor corespons goe beyond mandat european commiss final discuss role artifici intellig ai within open scienc perspect
f4c01d8780c86abdcfdd52c60843a2499fd5c1b6,Using Smartphones to Collect Behavioral Data in Psychological Science,"Smartphones now offer the promise of collecting behavioral data unobtrusively, in situ, as it unfolds in the course of daily life. Data can be collected from the onboard sensors and other phone logs embedded in today’s off-the-shelf smartphone devices. These data permit fine-grained, continuous collection of people’s social interactions (e.g., speaking rates in conversation, size of social groups, calls, and text messages), daily activities (e.g., physical activity and sleep), and mobility patterns (e.g., frequency and duration of time spent at various locations). In this article, we have drawn on the lessons from the first wave of smartphone-sensing research to highlight areas of opportunity for psychological research, present practical considerations for designing smartphone studies, and discuss the ongoing methodological and ethical challenges associated with research in this domain. It is our hope that these practical guidelines will facilitate the use of smartphones as a behavioral observation tool in psychological science.",smartphon offer promis collect behavior data unobtrus situ unfold cours daili life data collect onboard sensor phone log embed today offtheshelf smartphon devic data permit finegrain continu collect peopl social interact eg speak rate convers size social group call text messag daili activ eg physic activ sleep mobil pattern eg frequenc durat time spent variou locat articl drawn lesson first wave smartphonesens research highlight area opportun psycholog research present practic consider design smartphon studi discuss ongo methodolog ethic challeng associ research domain hope practic guidelin facilit use smartphon behavior observ tool psycholog scienc
4436ca7e9f91b7ad9ad6a09dbe12f48d9f6c3e7f,Data-driven predictions in the science of science,"The desire to predict discoveries—to have some idea, in advance, of what will be discovered, by whom, when, and where—pervades nearly all aspects of modern science, from individual scientists to publishers, from funding agencies to hiring committees. In this Essay, we survey the emerging and interdisciplinary field of the “science of science” and what it teaches us about the predictability of scientific discovery. We then discuss future opportunities for improving predictions derived from the science of science and its potential impact, positive and negative, on the scientific community.",desir predict discoveriesto idea advanc discov wherepervad nearli aspect modern scienc individu scientist publish fund agenc hire committe essay survey emerg interdisciplinari field scienc scienc teach us predict scientif discoveri discuss futur opportun improv predict deriv scienc scienc potenti impact posit neg scientif commun
2ff6d7e05b1f74e0b17dbf97a59ac0d75ef65efc,FAIR Data and Services in Biodiversity Science and Geoscience,"We examine the intersection of the FAIR principles (Findable, Accessible, Interoperable and Reusable), the challenges and opportunities presented by the aggregation of widely distributed and heterogeneous data about biological and geological specimens, and the use of the Digital Object Architecture (DOA) data model and components as an approach to solving those challenges that offers adherence to the FAIR principles as an integral characteristic. This approach will be prototyped in the Distributed System of Scientific Collections (DiSSCo) project, the pan-European Research Infrastructure which aims to unify over 110 natural science collections across 21 countries. We take each of the FAIR principles, discuss them as requirements in the creation of a seamless virtual collection of bio/geo specimen data, and map those requirements to Digital Object components and facilities such as persistent identification, extended data typing, and the use of an additional level of abstraction to normalize existing heterogeneous data structures. The FAIR principles inform and motivate the work and the DO Architecture provides the technical vision to create the seamless virtual collection vitally needed to address scientific questions of societal importance.",examin intersect fair principl findabl access interoper reusabl challeng opportun present aggreg wide distribut heterogen data biolog geolog specimen use digit object architectur doa data model compon approach solv challeng offer adher fair principl integr characterist approach prototyp distribut system scientif collect dissco project paneuropean research infrastructur aim unifi natur scienc collect across countri take fair principl discuss requir creation seamless virtual collect biogeo specimen data map requir digit object compon facil persist identif extend data type use addit level abstract normal exist heterogen data structur fair principl inform motiv work architectur provid technic vision creat seamless virtual collect vital need address scientif question societ import
d1db1c83c64f556fd4005cc12bddf7963f82a77f,Open science resources for the discovery and analysis of Tara Oceans data,,nan
bd8a307efcffbf57d2e5c3c23577de44d883d865,MedRec: Using Blockchain for Medical Data Access and Permission Management,"Years of heavy regulation and bureaucratic inefficiency have slowed innovation for electronic medical records (EMRs). We now face a critical need for such innovation, as personalization and data science prompt patients to engage in the details of their healthcare and restore agency over their medical data. In this paper, we propose MedRec: a novel, decentralized record management system to handle EMRs, using blockchain technology. Our system gives patients a comprehensive, immutable log and easy access to their medical information across providers and treatment sites. Leveraging unique blockchain properties, MedRec manages authentication, confidentiality, accountability and data sharing- crucial considerations when handling sensitive information. A modular design integrates with providers' existing, local data storage solutions, facilitating interoperability and making our system convenient and adaptable. We incentivize medical stakeholders (researchers, public health authorities, etc.) to participate in the network as blockchain “miners”. This provides them with access to aggregate, anonymized data as mining rewards, in return for sustaining and securing the network via Proof of Work. MedRec thus enables the emergence of data economics, supplying big data to empower researchers while engaging patients and providers in the choice to release metadata. The purpose of this short paper is to expose, prior to field tests, a working prototype through which we analyze and discuss our approach.",year heavi regul bureaucrat ineffici slow innov electron medic record emr face critic need innov person data scienc prompt patient engag detail healthcar restor agenc medic data paper propos medrec novel decentr record manag system handl emr use blockchain technolog system give patient comprehens immut log easi access medic inform across provid treatment site leverag uniqu blockchain properti medrec manag authent confidenti account data share crucial consider handl sensit inform modular design integr provid exist local data storag solut facilit interoper make system conveni adapt incentiv medic stakehold research public health author etc particip network blockchain miner provid access aggreg anonym data mine reward return sustain secur network via proof work medrec thu enabl emerg data econom suppli big data empow research engag patient provid choic releas metadata purpos short paper expos prior field test work prototyp analyz discuss approach
02a9428b5b28d85ea330033fb990dc10cd15cc4e,Occupancy models for citizen‐science data,"Large‐scale citizen‐science projects, such as atlases of species distribution, are an important source of data for macroecological research, for understanding the effects of climate change and other drivers on biodiversity, and for more applied conservation tasks, such as early‐warning systems for biodiversity loss. However, citizen‐science data are challenging to analyse because the observation process has to be taken into account. Typically, the observation process leads to heterogeneous and non‐random sampling, false absences, false detections, and spatial correlations in the data. Increasingly, occupancy models are being used to analyse atlas data. We advocate a dual approach to strengthen inference from citizen science data for the questions the programme is intended to address: (a) the survey design should be chosen with a particular set of questions and associated analysis strategy in mind and (b) the statistical methods should be tailored not only to those questions but also to the specific characteristics of the data. We review the consequences of particular survey design choices that typically need to be made in atlas‐style citizen‐science projects. These include spatial resolution of the sampling units, allocation of effort in space, and collection of information about the observation process. On the analysis side, we review extensions of the basic occupancy models that are frequently necessary with atlas data, including methods for dealing with heterogeneity, non‐independent detections, false detections, and violation of the closure assumption. New technologies, such as cell‐phone apps and fixed remote detection devices, are revolutionizing citizen‐science projects. There is an opportunity to maximize the usefulness of the resulting datasets if the protocols are rooted in robust statistical designs and data analysis issues are being considered. Our review provides guidelines for designing new projects and an overview of the current methods that can be used to analyse data from such projects.",largescal citizensci project atlas speci distribut import sourc data macroecolog research understand effect climat chang driver biodivers appli conserv task earlywarn system biodivers loss howev citizensci data challeng analys observ process taken account typic observ process lead heterogen nonrandom sampl fals absenc fals detect spatial correl data increasingli occup model use analys atla data advoc dual approach strengthen infer citizen scienc data question programm intend address survey design chosen particular set question associ analysi strategi mind b statist method tailor question also specif characterist data review consequ particular survey design choic typic need made atlasstyl citizensci project includ spatial resolut sampl unit alloc effort space collect inform observ process analysi side review extens basic occup model frequent necessari atla data includ method deal heterogen nonindepend detect fals detect violat closur assumpt new technolog cellphon app fix remot detect devic revolution citizensci project opportun maxim use result dataset protocol root robust statist design data analysi issu consid review provid guidelin design new project overview current method use analys data project
63ba116c6e87a54230e49e013ae9bcb2a05a453c,COMBIgor: Data-Analysis Package for Combinatorial Materials Science.,"Combinatorial experiments involve synthesis of sample libraries with lateral composition gradients requiring spatially resolved characterization of structure and properties. Because of the maturation of combinatorial methods and their successful application in many fields, the modern combinatorial laboratory produces diverse and complex data sets requiring advanced analysis and visualization techniques. In order to utilize these large data sets to uncover new knowledge, the combinatorial scientist must engage in data science. For data science tasks, most laboratories adopt common-purpose data management and visualization software. However, processing and cross-correlating data from various measurement tools is no small task for such generic programs. Here we describe COMBIgor, a purpose-built open-source software package written in the commercial Igor Pro environment and designed to offer a systematic approach to loading, storing, processing, and visualizing combinatorial data. It includes (1) methods for loading and storing data sets from combinatorial libraries, (2) routines for streamlined data processing, and (3) data-analysis and -visualization features to construct figures. Most importantly, COMBIgor is designed to be easily customized by a laboratory, group, or individual in order to integrate additional instruments and data-processing algorithms. Utilizing the capabilities of COMBIgor can significantly reduce the burden of data management on the combinatorial scientist.",combinatori experi involv synthesi sampl librari later composit gradient requir spatial resolv character structur properti matur combinatori method success applic mani field modern combinatori laboratori produc divers complex data set requir advanc analysi visual techniqu order util larg data set uncov new knowledg combinatori scientist must engag data scienc data scienc task laboratori adopt commonpurpos data manag visual softwar howev process crosscorrel data variou measur tool small task gener program describ combigor purposebuilt opensourc softwar packag written commerci igor pro environ design offer systemat approach load store process visual combinatori data includ method load store data set combinatori librari routin streamlin data process dataanalysi visual featur construct figur importantli combigor design easili custom laboratori group individu order integr addit instrument dataprocess algorithm util capabl combigor significantli reduc burden data manag combinatori scientist
2660fbc3b666145a87f05de10066fc2a3e7467dd,The Science Of Real Time Data Capture Self Reports In Health Research,"The National Cancer Institute (NCI) has designated the topic of real-time data capture as an important and innovative research area. As such, the NCI sponsored a national meeting of distinguished research scientists to discuss the state of the science in this emerging and burgeoning field. This book reflects the findings of the conference and discusses the state of the science of real-time data capture and its application to health and cancer research. It provides a conceptual framework for minute-by-minute data captureecological momentary assessments (EMA)and discusses health-related topics where these assessements have been applied. In addition, future directions in real-time data capture assessment, interventions, methodology, and technology are discussed.",nation cancer institut nci design topic realtim data captur import innov research area nci sponsor nation meet distinguish research scientist discuss state scienc emerg burgeon field book reflect find confer discuss state scienc realtim data captur applic health cancer research provid conceptu framework minutebyminut data captureecolog momentari assess emaand discuss healthrel topic assess appli addit futur direct realtim data captur assess intervent methodolog technolog discuss
51995dc568874ea34911833355234b1f696dacfc,Science Mapping: A Systematic Review of the Literature,"Abstract Purpose We present a systematic review of the literature concerning major aspects of science mapping to serve two primary purposes: First, to demonstrate the use of a science mapping approach to perform the review so that researchers may apply the procedure to the review of a scientific domain of their own interest, and second, to identify major areas of research activities concerning science mapping, intellectual milestones in the development of key specialties, evolutionary stages of major specialties involved, and the dynamics of transitions from one specialty to another. Design/methodology/approach We first introduce a theoretical framework of the evolution of a scientific specialty. Then we demonstrate a generic search strategy that can be used to construct a representative dataset of bibliographic records of a domain of research. Next, progressively synthesized co-citation networks are constructed and visualized to aid visual analytic studies of the domain’s structural and dynamic patterns and trends. Finally, trajectories of citations made by particular types of authors and articles are presented to illustrate the predictive potential of the analytic approach. Findings The evolution of the science mapping research involves the development of a number of interrelated specialties. Four major specialties are discussed in detail in terms of four evolutionary stages: conceptualization, tool construction, application, and codification. Underlying connections between major specialties are also explored. The predictive analysis demonstrates citations trajectories of potentially transformative contributions. Research limitations The systematic review is primarily guided by citation patterns in the dataset retrieved from the literature. The scope of the data is limited by the source of the retrieval, i.e. the Web of Science, and the composite query used. An iterative query refinement is possible if one would like to improve the data quality, although the current approach serves our purpose adequately. More in-depth analyses of each specialty would be more revealing by incorporating additional methods such as citation context analysis and studies of other aspects of scholarly publications. Practical implications The underlying analytic process of science mapping serves many practical needs, notably bibliometric mapping, knowledge domain visualization, and visualization of scientific literature. In order to master such a complex process of science mapping, researchers often need to develop a diverse set of skills and knowledge that may span multiple disciplines. The approach demonstrated in this article provides a generic method for conducting a systematic review. Originality/value Incorporating the evolutionary stages of a specialty into the visual analytic study of a research domain is innovative. It provides a systematic methodology for researchers to achieve a good understanding of how scientific fields evolve, to recognize potentially insightful patterns from visually encoded signs, and to synthesize various information so as to capture the state of the art of the domain.",abstract purpos present systemat review literatur concern major aspect scienc map serv two primari purpos first demonstr use scienc map approach perform review research may appli procedur review scientif domain interest second identifi major area research activ concern scienc map intellectu mileston develop key specialti evolutionari stage major specialti involv dynam transit one specialti anoth designmethodologyapproach first introduc theoret framework evolut scientif specialti demonstr gener search strategi use construct repres dataset bibliograph record domain research next progress synthes cocit network construct visual aid visual analyt studi domain structur dynam pattern trend final trajectori citat made particular type author articl present illustr predict potenti analyt approach find evolut scienc map research involv develop number interrel specialti four major specialti discuss detail term four evolutionari stage conceptu tool construct applic codif underli connect major specialti also explor predict analysi demonstr citat trajectori potenti transform contribut research limit systemat review primarili guid citat pattern dataset retriev literatur scope data limit sourc retriev ie web scienc composit queri use iter queri refin possibl one would like improv data qualiti although current approach serv purpos adequ indepth analys specialti would reveal incorpor addit method citat context analysi studi aspect scholarli public practic implic underli analyt process scienc map serv mani practic need notabl bibliometr map knowledg domain visual visual scientif literatur order master complex process scienc map research often need develop divers set skill knowledg may span multipl disciplin approach demonstr articl provid gener method conduct systemat review originalityvalu incorpor evolutionari stage specialti visual analyt studi research domain innov provid systemat methodolog research achiev good understand scientif field evolv recogn potenti insight pattern visual encod sign synthes variou inform captur state art domain
87f7c170aecf8f3465b26a11b9a384fef934337b,Measurement and Data Analysis for Engineering and Science,"Fundamentals of Experimentation Introduction Experiments Chapter Overview Experimental Approach Role of Experiments The Experiment Classification of Experiments Plan for Successful Experimentation Hypothesis Testing* Design of Experiments* Factorial Design* Problems Bibliography Fundamental Electronics Chapter Overview Concepts and Definitions Circuit Elements RLC Combinations Elementary DC Circuit Analysis Elementary AC Circuit Analysis Equivalent Circuits* Meters* Impedance Matching and Loading Error* Electrical Noise* Problems Bibliography Measurement Systems: Sensors and Transducers Chapter Overview Measurement System Overview Sensor Domains Sensor Characteristics Physical Principles of Sensors Electric Piezoelectric Fluid Mechanic Optic Photoelastic Thermoelectric Electrochemical Sensor Scaling* Problems Bibliography Measurement Systems: Other Components Chapter Overview Signal Conditioning, Processing, and Recording Amplifiers Filters Analog-to-Digital Converters Smart Measurement Systems Other Example Measurement Systems Problems Bibliography Measurement Systems: Calibration and Response Chapter Overview Static Response Characterization by Calibration Dynamic Response Characterization Zero-Order System Dynamic Response First-Order System Dynamic Response Second-Order System Dynamic Response Measurement System Dynamic Response Problems Bibliography Measurement Systems: Design-Stage Uncertainty Chapter Overview Design-Stage Uncertainty Analysis Design-Stage Uncertainty Estimate of a Measurand Design-Stage Uncertainty Estimate of a Result Problems Bibliography Signal Characteristics Chapter Overview Signal Classification Signal Variables Signal Statistical Parameters Problems Bibliography The Fourier Transform Chapter Overview Fourier Series of a Periodic Signal Complex Numbers and Waves Exponential Fourier Series Spectral Representations Continuous Fourier Transform Continuous Fourier Transform Properties* Discrete Fourier Transform Fast Fourier Transform Problems Bibliography Digital Signal Analysis Chapter Overview Digital Sampling Digital Sampling Errors Windowing* Determining a Sample Period Problems Bibliography Probability Chapter Overview Relation to Measurements Basic Probability Concepts Sample versus Population Plotting Statistical Information Probability Density Function Various Probability Density Functions Central Moments Probability Distribution Function Problems Bibliography Statistics Chapter Overview Normal Distribution Normalized Variables Student's t Distribution Rejection of Data Standard Deviation of the Means Chi-Square Distribution Pooling Samples* Problems Bibliography Uncertainty Analysis Chapter Overview Modeling and Experimental Uncertainties Probabilistic Basis of Uncertainty Identifying Sources of Error Systematic and Random Errors Quantifying Systematic and Random Errors Measurement Uncertainty Analysis Uncertainty Analysis of a Multiple-Measurement Result Uncertainty Analyses for Other Measurement Situations Uncertainty Analysis Summary Finite-Difference Uncertainties* Uncertainty Based upon Interval Statistics* Problems Bibliography Regression and Correlation Chapter Overview Least-Squares Approach Least-Squares Regression Analysis Linear Analysis Higher-Order Analysis* Multi-Variable Linear Analysis* Determining the Appropriate Fit Regression Confidence Intervals Regression Parameters Linear Correlation Analysis Signal Correlations in Time* Problems Bibliography Units and Significant Figures Chapter Overview English and Metric Systems Systems of Units SI Standards Technical English and SI Conversion Factors Prefixes Significant Figures Problems Bibliography Technical Communication Chapter Overview Guidelines for Writing Technical Memo Technical Report Oral Technical Presentation Problems Bibliography A Glossary B Symbols C Review Problem Answers Index",fundament experiment introduct experi chapter overview experiment approach role experi experi classif experi plan success experiment hypothesi test design experi factori design problem bibliographi fundament electron chapter overview concept definit circuit element rlc combin elementari dc circuit analysi elementari ac circuit analysi equival circuit meter imped match load error electr nois problem bibliographi measur system sensor transduc chapter overview measur system overview sensor domain sensor characterist physic principl sensor electr piezoelectr fluid mechan optic photoelast thermoelectr electrochem sensor scale problem bibliographi measur system compon chapter overview signal condit process record amplifi filter analogtodigit convert smart measur system exampl measur system problem bibliographi measur system calibr respons chapter overview static respons character calibr dynam respons character zeroord system dynam respons firstord system dynam respons secondord system dynam respons measur system dynam respons problem bibliographi measur system designstag uncertainti chapter overview designstag uncertainti analysi designstag uncertainti estim measurand designstag uncertainti estim result problem bibliographi signal characterist chapter overview signal classif signal variabl signal statist paramet problem bibliographi fourier transform chapter overview fourier seri period signal complex number wave exponenti fourier seri spectral represent continu fourier transform continu fourier transform properti discret fourier transform fast fourier transform problem bibliographi digit signal analysi chapter overview digit sampl digit sampl error window determin sampl period problem bibliographi probabl chapter overview relat measur basic probabl concept sampl versu popul plot statist inform probabl densiti function variou probabl densiti function central moment probabl distribut function problem bibliographi statist chapter overview normal distribut normal variabl student distribut reject data standard deviat mean chisquar distribut pool sampl problem bibliographi uncertainti analysi chapter overview model experiment uncertainti probabilist basi uncertainti identifi sourc error systemat random error quantifi systemat random error measur uncertainti analysi uncertainti analysi multiplemeasur result uncertainti analys measur situat uncertainti analysi summari finitediffer uncertainti uncertainti base upon interv statist problem bibliographi regress correl chapter overview leastsquar approach leastsquar regress analysi linear analysi higherord analysi multivari linear analysi determin appropri fit regress confid interv regress paramet linear correl analysi signal correl time problem bibliographi unit signific figur chapter overview english metric system system unit si standard technic english si convers factor prefix signific figur problem bibliographi technic commun chapter overview guidelin write technic memo technic report oral technic present problem bibliographi glossari b symbol c review problem answer index
2809d4876e34b8c64fc1783fe6a0a278770505b0,A survey of data provenance in e-science,"Data management is growing in complexity as large-scale applications take advantage of the loosely coupled resources brought together by grid middleware and by abundant storage capacity. Metadata describing the data products used in and generated by these applications is essential to disambiguate the data and enable reuse. Data provenance, one kind of metadata, pertains to the derivation history of a data product starting from its original sources.In this paper we create a taxonomy of data provenance characteristics and apply it to current research efforts in e-science, focusing primarily on scientific workflow approaches. The main aspect of our taxonomy categorizes provenance systems based on why they record provenance, what they describe, how they represent and store provenance, and ways to disseminate it. The survey culminates with an identification of open research problems in the field.",data manag grow complex largescal applic take advantag loos coupl resourc brought togeth grid middlewar abund storag capac metadata describ data product use gener applic essenti disambigu data enabl reus data proven one kind metadata pertain deriv histori data product start origin sourcesin paper creat taxonomi data proven characterist appli current research effort escienc focus primarili scientif workflow approach main aspect taxonomi categor proven system base record proven describ repres store proven way dissemin survey culmin identif open research problem field
439ede62248e5f6202982afead02b33d3feffae7,TCGAbiolinks: an R/Bioconductor package for integrative analysis of TCGA data,"The Cancer Genome Atlas (TCGA) research network has made public a large collection of clinical and molecular phenotypes of more than 10 000 tumor patients across 33 different tumor types. Using this cohort, TCGA has published over 20 marker papers detailing the genomic and epigenomic alterations associated with these tumor types. Although many important discoveries have been made by TCGA's research network, opportunities still exist to implement novel methods, thereby elucidating new biological pathways and diagnostic markers. However, mining the TCGA data presents several bioinformatics challenges, such as data retrieval and integration with clinical data and other molecular data types (e.g. RNA and DNA methylation). We developed an R/Bioconductor package called TCGAbiolinks to address these challenges and offer bioinformatics solutions by using a guided workflow to allow users to query, download and perform integrative analyses of TCGA data. We combined methods from computer science and statistics into the pipeline and incorporated methodologies developed in previous TCGA marker studies and in our own group. Using four different TCGA tumor types (Kidney, Brain, Breast and Colon) as examples, we provide case studies to illustrate examples of reproducibility, integrative analysis and utilization of different Bioconductor packages to advance and accelerate novel discoveries.",cancer genom atla tcga research network made public larg collect clinic molecular phenotyp tumor patient across differ tumor type use cohort tcga publish marker paper detail genom epigenom alter associ tumor type although mani import discoveri made tcga research network opportun still exist implement novel method therebi elucid new biolog pathway diagnost marker howev mine tcga data present sever bioinformat challeng data retriev integr clinic data molecular data type eg rna dna methyl develop rbioconductor packag call tcgabiolink address challeng offer bioinformat solut use guid workflow allow user queri download perform integr analys tcga data combin method comput scienc statist pipelin incorpor methodolog develop previou tcga marker studi group use four differ tcga tumor type kidney brain breast colon exampl provid case studi illustr exampl reproduc integr analysi util differ bioconductor packag advanc acceler novel discoveri
b5fb74dfc71c92113c84a0e8f0502e0e76b4dbda,The role of administrative data in the big data revolution in social science research.,,nan
9445423239efb633f5c15791a7abe352199ce678,General Data Protection Regulation,"Presentacio sobre l'Oficina de Proteccio de Dades Personals de la UAB i la politica Open Science. Va formar part de la conferencia ""Les politiques d'Open Data / Open Acces: Implicacions a la recerca"" orientada a investigadors i gestors de projectes europeus que va tenir lloc el 20 de setembre de 2018 a la Universitat Autonoma de Barcelona",presentacio sobr loficina de proteccio de dade person de la uab la politica open scienc va formar part de la conferencia le politiqu dopen data open acc implicacion la recerca orientada investigador gestor de project europeu que va tenir lloc el de setembr de la universitat autonoma de barcelona
33aeb033401ec748633bdd5b806db4f58288ee69,The Accuracy of Citizen Science Data: A Quantitative Review,"Author(s): Aceves-Bueno, Erendira; Adeleye, Adeyemi S; Feraud, Marina; Huang, Yuxiong; Tao, Mengya; Yang, Yi; Anderson, Sarah E",author acevesbueno erendira adeley adeyemi feraud marina huang yuxiong tao mengya yang yi anderson sarah e
16f4135a229c79e60fa25259100c8cdcedfab8cc,Patent citation data in social science research: Overview and best practices,"The last 2 decades have witnessed a dramatic increase in the use of patent citation data in social science research. Facilitated by digitization of the patent data and increasing computing power, a community of practice has grown up that has developed methods for using these data to: measure attributes of innovations such as impact and originality; to trace flows of knowledge across individuals, institutions and regions; and to map innovation networks. The objective of this article is threefold. First, it takes stock of these main uses. Second, it discusses 4 pitfalls associated with patent citation data, related to office, time and technology, examiner, and strategic effects. Third, it highlights gaps in our understanding and offers directions for future research.",last decad wit dramat increas use patent citat data social scienc research facilit digit patent data increas comput power commun practic grown develop method use data measur attribut innov impact origin trace flow knowledg across individu institut region map innov network object articl threefold first take stock main use second discuss pitfal associ patent citat data relat offic time technolog examin strateg effect third highlight gap understand offer direct futur research
233e702fa7ccfd55061680e3af9bd2f7efe5e08f,Science of Science,"The whys and wherefores of SciSci The science of science (SciSci) is based on a transdisciplinary approach that uses large data sets to study the mechanisms underlying the doing of science—from the choice of a research problem to career trajectories and progress within a field. In a Review, Fortunato et al. explain that the underlying rationale is that with a deeper understanding of the precursors of impactful science, it will be possible to develop systems and policies that improve each scientist's ability to succeed and enhance the prospects of science as a whole. Science, this issue p. eaao0185 BACKGROUND The increasing availability of digital data on scholarly inputs and outputs—from research funding, productivity, and collaboration to paper citations and scientist mobility—offers unprecedented opportunities to explore the structure and evolution of science. The science of science (SciSci) offers a quantitative understanding of the interactions among scientific agents across diverse geographic and temporal scales: It provides insights into the conditions underlying creativity and the genesis of scientific discovery, with the ultimate goal of developing tools and policies that have the potential to accelerate science. In the past decade, SciSci has benefited from an influx of natural, computational, and social scientists who together have developed big data–based capabilities for empirical analysis and generative modeling that capture the unfolding of science, its institutions, and its workforce. The value proposition of SciSci is that with a deeper understanding of the factors that drive successful science, we can more effectively address environmental, societal, and technological problems. ADVANCES Science can be described as a complex, self-organizing, and evolving network of scholars, projects, papers, and ideas. This representation has unveiled patterns characterizing the emergence of new scientific fields through the study of collaboration networks and the path of impactful discoveries through the study of citation networks. Microscopic models have traced the dynamics of citation accumulation, allowing us to predict the future impact of individual papers. SciSci has revealed choices and trade-offs that scientists face as they advance both their own careers and the scientific horizon. For example, measurements indicate that scholars are risk-averse, preferring to study topics related to their current expertise, which constrains the potential of future discoveries. Those willing to break this pattern engage in riskier careers but become more likely to make major breakthroughs. Overall, the highest-impact science is grounded in conventional combinations of prior work but features unusual combinations. Last, as the locus of research is shifting into teams, SciSci is increasingly focused on the impact of team research, finding that small teams tend to disrupt science and technology with new ideas drawing on older and less prevalent ones. In contrast, large teams tend to develop recent, popular ideas, obtaining high, but often short-lived, impact. OUTLOOK SciSci offers a deep quantitative understanding of the relational structure between scientists, institutions, and ideas because it facilitates the identification of fundamental mechanisms responsible for scientific discovery. These interdisciplinary data-driven efforts complement contributions from related fields such as scientometrics and the economics and sociology of science. Although SciSci seeks long-standing universal laws and mechanisms that apply across various fields of science, a fundamental challenge going forward is accounting for undeniable differences in culture, habits, and preferences between different fields and countries. This variation makes some cross-domain insights difficult to appreciate and associated science policies difficult to implement. The differences among the questions, data, and skills specific to each discipline suggest that further insights can be gained from domain-specific SciSci studies, which model and identify opportunities adapted to the needs of individual research fields. The complexity of science. Science can be seen as an expanding and evolving network of ideas, scholars, and papers. SciSci searches for universal and domain-specific laws underlying the structure and dynamics of science. ILLUSTRATION: NICOLE SAMAY Identifying fundamental drivers of science and developing predictive models to capture its evolution are instrumental for the design of policies that can improve the scientific enterprise—for example, through enhanced career paths for scientists, better performance evaluation for organizations hosting research, discovery of novel effective funding vehicles, and even identification of promising regions along the scientific frontier. The science of science uses large-scale data on the production of science to search for universal and domain-specific patterns. Here, we review recent developments in this transdisciplinary field.",whi wherefor scisci scienc scienc scisci base transdisciplinari approach use larg data set studi mechan underli sciencefrom choic research problem career trajectori progress within field review fortunato et al explain underli rational deeper understand precursor impact scienc possibl develop system polici improv scientist abil succeed enhanc prospect scienc whole scienc issu p eaao background increas avail digit data scholarli input outputsfrom research fund product collabor paper citat scientist mobilityoff unpreced opportun explor structur evolut scienc scienc scienc scisci offer quantit understand interact among scientif agent across divers geograph tempor scale provid insight condit underli creativ genesi scientif discoveri ultim goal develop tool polici potenti acceler scienc past decad scisci benefit influx natur comput social scientist togeth develop big databas capabl empir analysi gener model captur unfold scienc institut workforc valu proposit scisci deeper understand factor drive success scienc effect address environment societ technolog problem advanc scienc describ complex selforgan evolv network scholar project paper idea represent unveil pattern character emerg new scientif field studi collabor network path impact discoveri studi citat network microscop model trace dynam citat accumul allow us predict futur impact individu paper scisci reveal choic tradeoff scientist face advanc career scientif horizon exampl measur indic scholar riskavers prefer studi topic relat current expertis constrain potenti futur discoveri will break pattern engag riskier career becom like make major breakthrough overal highestimpact scienc ground convent combin prior work featur unusu combin last locu research shift team scisci increasingli focus impact team research find small team tend disrupt scienc technolog new idea draw older less preval one contrast larg team tend develop recent popular idea obtain high often shortliv impact outlook scisci offer deep quantit understand relat structur scientist institut idea facilit identif fundament mechan respons scientif discoveri interdisciplinari datadriven effort complement contribut relat field scientometr econom sociolog scienc although scisci seek longstand univers law mechan appli across variou field scienc fundament challeng go forward account undeni differ cultur habit prefer differ field countri variat make crossdomain insight difficult appreci associ scienc polici difficult implement differ among question data skill specif disciplin suggest insight gain domainspecif scisci studi model identifi opportun adapt need individu research field complex scienc scienc seen expand evolv network idea scholar paper scisci search univers domainspecif law underli structur dynam scienc illustr nicol samay identifi fundament driver scienc develop predict model captur evolut instrument design polici improv scientif enterprisefor exampl enhanc career path scientist better perform evalu organ host research discoveri novel effect fund vehicl even identif promis region along scientif frontier scienc scienc use largescal data product scienc search univers domainspecif pattern review recent develop transdisciplinari field
362f50f59a280d7cc526fb626fdf44ad382cee57,The journal coverage of Web of Science and Scopus: a comparative analysis,,nan
08a2ef1648fa5ea539ebe1718da577dc79124a21,Prospects and challenges for social media data in conservation science,"Social media data have been extensively used in numerous fields of science, but examples of their use in conservation science are still very limited. In this paper, we propose a framework on how social media data could be useful for conservation science and practice. We present the commonly used social media platforms and discuss how their content could be providing new data and information for conservation science. Based on this, we discuss how future work in conservation science and practice would benefit from social media data.",social media data extens use numer field scienc exampl use conserv scienc still limit paper propos framework social media data could use conserv scienc practic present commonli use social media platform discuss content could provid new data inform conserv scienc base discuss futur work conserv scienc practic would benefit social media data
1e4709c0b8fe3bf759cd64dc1ede695d6e5316f0,Deep learning applications and challenges in big data analytics,,nan
06a81f63fc4ccfcf02934647a7c17454b91853b0,Machine Learning - The Art and Science of Algorithms that Make Sense of Data,"As one of the most comprehensive machine learning texts around, this book does justice to the field's incredible richness, but without losing sight of the unifying principles. Peter Flach's clear, example-based approach begins by discussing how a spam filter works, which gives an immediate introduction to machine learning in action, with a minimum of technical fuss. Flach provides case studies of increasing complexity and variety with well-chosen examples and illustrations throughout. He covers a wide range of logical, geometric and statistical models and state-of-the-art topics such as matrix factorisation and ROC analysis. Particular attention is paid to the central role played by features. The use of established terminology is balanced with the introduction of new and useful concepts, and summaries of relevant background material are provided with pointers for revision if necessary. These features ensure Machine Learning will set a new standard as an introductory textbook.",one comprehens machin learn text around book justic field incred rich without lose sight unifi principl peter flach clear examplebas approach begin discuss spam filter work give immedi introduct machin learn action minimum technic fuss flach provid case studi increas complex varieti wellchosen exampl illustr throughout cover wide rang logic geometr statist model stateoftheart topic matrix factoris roc analysi particular attent paid central role play featur use establish terminolog balanc introduct new use concept summari relev background materi provid pointer revis necessari featur ensur machin learn set new standard introductori textbook
54d9fc3ed4937ee546ed45aee7bef16b4ae3775d,Statistics for citizen science: extracting signals of change from noisy ecological data,"Policy‐makers increasingly demand robust measures of biodiversity change over short time periods. Long‐term monitoring schemes provide high‐quality data, often on an annual basis, but are taxonomically and geographically restricted. By contrast, opportunistic biological records are relatively unstructured but vast in quantity. Recently, these data have been applied to increasingly elaborate science and policy questions, using a range of methods. At present, we lack a firm understanding of which methods, if any, are capable of delivering unbiased trend estimates on policy‐relevant time‐scales. We identified a set of candidate methods that employ data filtering criteria and/or correction factors to deal with variation in recorder activity. We designed a computer simulation to compare the statistical properties of these methods under a suite of realistic data collection scenarios. We measured the Type I error rates of each method–scenario combination, as well as the power to detect genuine trends. We found that simple methods produce biased trend estimates, and/or had low power. Most methods are robust to variation in sampling effort, but biases in spatial coverage, sampling effort per visit, and detectability, as well as turnover in community composition, all induced some methods to fail. No method was wholly unaffected by all forms of variation in recorder activity, although some performed well enough to be useful. We warn against the use of simple methods. Sophisticated methods that model the data collection process offer the greatest potential to estimate timely trends, notably Frescalo and occupancy–detection models. The potential of these methods and the value of opportunistic data would be further enhanced by assessing the validity of model assumptions and by capturing small amounts of information about sampling intensity at the point of data collection.",policymak increasingli demand robust measur biodivers chang short time period longterm monitor scheme provid highqual data often annual basi taxonom geograph restrict contrast opportunist biolog record rel unstructur vast quantiti recent data appli increasingli elabor scienc polici question use rang method present lack firm understand method capabl deliv unbias trend estim policyrelev timescal identifi set candid method employ data filter criteria andor correct factor deal variat record activ design comput simul compar statist properti method suit realist data collect scenario measur type error rate methodscenario combin well power detect genuin trend found simpl method produc bias trend estim andor low power method robust variat sampl effort bias spatial coverag sampl effort per visit detect well turnov commun composit induc method fail method wholli unaffect form variat record activ although perform well enough use warn use simpl method sophist method model data collect process offer greatest potenti estim time trend notabl frescalo occupancydetect model potenti method valu opportunist data would enhanc assess valid model assumpt captur small amount inform sampl intens point data collect
ad3d83248eae66580d4deada76e72e3be9a9b44c,Named data networking,"Named Data Networking (NDN) is one of five projects funded by the U.S. National Science Foundation under its Future Internet Architecture Program. NDN has its roots in an earlier project, Content-Centric Networking (CCN), which Van Jacobson first publicly presented in 2006. The NDN project investigates Jacobson's proposed evolution from today's host-centric network architecture (IP) to a data-centric network architecture (NDN). This conceptually simple shift has far-reaching implications for how we design, develop, deploy, and use networks and applications. We describe the motivation and vision of this new architecture, and its basic components and operations. We also provide a snapshot of its current design, development status, and research challenges. More information about the project, including prototype implementations, publications, and annual reports, is available on named-data.net.",name data network ndn one five project fund us nation scienc foundat futur internet architectur program ndn root earlier project contentcentr network ccn van jacobson first publicli present ndn project investig jacobson propos evolut today hostcentr network architectur ip datacentr network architectur ndn conceptu simpl shift farreach implic design develop deploy use network applic describ motiv vision new architectur basic compon oper also provid snapshot current design develop statu research challeng inform project includ prototyp implement public annual report avail nameddatanet
30d6f200f8b4bae78dbb4f69f1730bcad131d523,The Materials Data Facility: Data Services to Advance Materials Science Research,,nan
391a5f286f814d852dddcab1b2b68e5c1af6c79e,Data mining with big data,"Big Data concern large-volume, complex, growing data sets with multiple, autonomous sources. With the fast development of networking, data storage, and the data collection capacity, Big Data are now rapidly expanding in all science and engineering domains, including physical, biological and biomedical sciences. This paper presents a HACE theorem that characterizes the features of the Big Data revolution, and proposes a Big Data processing model, from the data mining perspective. This data-driven model involves demand-driven aggregation of information sources, mining and analysis, user interest modeling, and security and privacy considerations. We analyze the challenging issues in the data-driven model and also in the Big Data revolution.",big data concern largevolum complex grow data set multipl autonom sourc fast develop network data storag data collect capac big data rapidli expand scienc engin domain includ physic biolog biomed scienc paper present hace theorem character featur big data revolut propos big data process model data mine perspect datadriven model involv demanddriven aggreg inform sourc mine analysi user interest model secur privaci consider analyz challeng issu datadriven model also big data revolut
16cecb0173adc68762b6e70daecb25089a5a6b6a,ProteomeXchange provides globally co-ordinated proteomics data submission and dissemination,,nan
d2a595c5efb4b26245c4353d5d85cbe6c7ecac0f,Machine learning for data-driven discovery in solid Earth geoscience,"Automating geoscience analysis Solid Earth geoscience is a field that has very large set of observations, which are ideal for analysis with machine-learning methods. Bergen et al. review how these methods can be applied to solid Earth datasets. Adopting machine-learning techniques is important for extracting information and for understanding the increasing amount of complex data collected in the geosciences. Science, this issue p. eaau0323 BACKGROUND The solid Earth, oceans, and atmosphere together form a complex interacting geosystem. Processes relevant to understanding Earth’s geosystem behavior range in spatial scale from the atomic to the planetary, and in temporal scale from milliseconds to billions of years. Physical, chemical, and biological processes interact and have substantial influence on this complex geosystem, and humans interact with it in ways that are increasingly consequential to the future of both the natural world and civilization as the finiteness of Earth becomes increasingly apparent and limits on available energy, mineral resources, and fresh water increasingly affect the human condition. Earth is subject to a variety of geohazards that are poorly understood, yet increasingly impactful as our exposure grows through increasing urbanization, particularly in hazard-prone areas. We have a fundamental need to develop the best possible predictive understanding of how the geosystem works, and that understanding must be informed by both the present and the deep past. This understanding will come through the analysis of increasingly large geo-datasets and from computationally intensive simulations, often connected through inverse problems. Geoscientists are faced with the challenge of extracting as much useful information as possible and gaining new insights from these data, simulations, and the interplay between the two. Techniques from the rapidly evolving field of machine learning (ML) will play a key role in this effort. ADVANCES The confluence of ultrafast computers with large memory, rapid progress in ML algorithms, and the ready availability of large datasets place geoscience at the threshold of dramatic progress. We anticipate that this progress will come from the application of ML across three categories of research effort: (i) automation to perform a complex prediction task that cannot easily be described by a set of explicit commands; (ii) modeling and inverse problems to create a representation that approximates numerical simulations or captures relationships; and (iii) discovery to reveal new and often unanticipated patterns, structures, or relationships. Examples of automation include geologic mapping using remote-sensing data, characterizing the topology of fracture systems to model subsurface transport, and classifying volcanic ash particles to infer eruptive mechanism. Examples of modeling include approximating the viscoelastic response for complex rheology, determining wave speed models directly from tomographic data, and classifying diverse seismic events. Examples of discovery include predicting laboratory slip events using observations of acoustic emissions, detecting weak earthquake signals using similarity search, and determining the connectivity of subsurface reservoirs using groundwater tracer observations. OUTLOOK The use of ML in solid Earth geosciences is growing rapidly, but is still in its early stages and making uneven progress. Much remains to be done with existing datasets from long-standing data sources, which in many cases are largely unexplored. Newer, unconventional data sources such as light detection and ranging (LiDAR), fiber-optic sensing, and crowd-sourced measurements may demand new approaches through both the volume and the character of information that they present. Practical steps could accelerate and broaden the use of ML in the geosciences. Wider adoption of open-science principles such as open source code, open data, and open access will better position the solid Earth community to take advantage of rapid developments in ML and artificial intelligence. Benchmark datasets and challenge problems have played an important role in driving progress in artificial intelligence research by enabling rigorous performance comparison and could play a similar role in the geosciences. Testing on high-quality datasets produces better models, and benchmark datasets make these data widely available to the research community. They also help recruit expertise from allied disciplines. Close collaboration between geoscientists and ML researchers will aid in making quick progress in ML geoscience applications. Extracting maximum value from geoscientific data will require new approaches for combining data-driven methods, physical modeling, and algorithms capable of learning with limited, weak, or biased labels. Funding opportunities that target the intersection of these disciplines, as well as a greater component of data science and ML education in the geosciences, could help bring this effort to fruition. Digital geology. Digital representation of the geology of the conterminous United States. [Geology of the Conterminous United States at 1:2,500,000 scale; a digital representation of the 1974 P. B. King and H. M. Beikman map by P. G. Schruben, R. E. Arndt, W. J. Bawiec] The list of author affiliations is available in the full article online. Understanding the behavior of Earth through the diverse fields of the solid Earth geosciences is an increasingly important task. It is made challenging by the complex, interacting, and multiscale processes needed to understand Earth’s behavior and by the inaccessibility of nearly all of Earth’s subsurface to direct observation. Substantial increases in data availability and in the increasingly realistic character of computer simulations hold promise for accelerating progress, but developing a deeper understanding based on these capabilities is itself challenging. Machine learning will play a key role in this effort. We review the state of the field and make recommendations for how progress might be broadened and accelerated.",autom geoscienc analysi solid earth geoscienc field larg set observ ideal analysi machinelearn method bergen et al review method appli solid earth dataset adopt machinelearn techniqu import extract inform understand increas amount complex data collect geoscienc scienc issu p eaau background solid earth ocean atmospher togeth form complex interact geosystem process relev understand earth geosystem behavior rang spatial scale atom planetari tempor scale millisecond billion year physic chemic biolog process interact substanti influenc complex geosystem human interact way increasingli consequenti futur natur world civil finit earth becom increasingli appar limit avail energi miner resourc fresh water increasingli affect human condit earth subject varieti geohazard poorli understood yet increasingli impact exposur grow increas urban particularli hazardpron area fundament need develop best possibl predict understand geosystem work understand must inform present deep past understand come analysi increasingli larg geodataset comput intens simul often connect invers problem geoscientist face challeng extract much use inform possibl gain new insight data simul interplay two techniqu rapidli evolv field machin learn ml play key role effort advanc confluenc ultrafast comput larg memori rapid progress ml algorithm readi avail larg dataset place geoscienc threshold dramat progress anticip progress come applic ml across three categori research effort autom perform complex predict task cannot easili describ set explicit command ii model invers problem creat represent approxim numer simul captur relationship iii discoveri reveal new often unanticip pattern structur relationship exampl autom includ geolog map use remotesens data character topolog fractur system model subsurfac transport classifi volcan ash particl infer erupt mechan exampl model includ approxim viscoelast respons complex rheolog determin wave speed model directli tomograph data classifi divers seismic event exampl discoveri includ predict laboratori slip event use observ acoust emiss detect weak earthquak signal use similar search determin connect subsurfac reservoir use groundwat tracer observ outlook use ml solid earth geoscienc grow rapidli still earli stage make uneven progress much remain done exist dataset longstand data sourc mani case larg unexplor newer unconvent data sourc light detect rang lidar fiberopt sens crowdsourc measur may demand new approach volum charact inform present practic step could acceler broaden use ml geoscienc wider adopt opensci principl open sourc code open data open access better posit solid earth commun take advantag rapid develop ml artifici intellig benchmark dataset challeng problem play import role drive progress artifici intellig research enabl rigor perform comparison could play similar role geoscienc test highqual dataset produc better model benchmark dataset make data wide avail research commun also help recruit expertis alli disciplin close collabor geoscientist ml research aid make quick progress ml geoscienc applic extract maximum valu geoscientif data requir new approach combin datadriven method physic model algorithm capabl learn limit weak bias label fund opportun target intersect disciplin well greater compon data scienc ml educ geoscienc could help bring effort fruition digit geolog digit represent geolog contermin unit state geolog contermin unit state scale digit represent p b king h beikman map p g schruben r e arndt w j bawiec list author affili avail full articl onlin understand behavior earth divers field solid earth geoscienc increasingli import task made challeng complex interact multiscal process need understand earth behavior inaccess nearli earth subsurfac direct observ substanti increas data avail increasingli realist charact comput simul hold promis acceler progress develop deeper understand base capabl challeng machin learn play key role effort review state field make recommend progress might broaden acceler
c36991759325bedd19f69264f72d1cbf59a6158c,Data Mining: Concepts and Techniques,"The increasing volume of data in modern business and science calls for more complex and sophisticated tools. Although advances in data mining technology have made extensive data collection much easier, it's still always evolving and there is a constant need for new techniques and tools that can help us transform this data into useful information and knowledge. Since the previous edition's publication, great advances have been made in the field of data mining. Not only does the third of edition of Data Mining: Concepts and Techniques continue the tradition of equipping you with an understanding and application of the theory and practice of discovering patterns hidden in large data sets, it also focuses on new, important topics in the field: data warehouses and data cube technology, mining stream, mining social networks, and mining spatial, multimedia and other complex data. Each chapter is a stand-alone guide to a critical topic, presenting proven algorithms and sound implementations ready to be used directly or with strategic modification against live data. This is the resource you need if you want to apply today's most powerful data mining techniques to meet real business challenges. * Presents dozens of algorithms and implementation examples, all in pseudo-code and suitable for use in real-world, large-scale data mining projects. * Addresses advanced topics such as mining object-relational databases, spatial databases, multimedia databases, time-series databases, text databases, the World Wide Web, and applications in several fields. *Provides a comprehensive, practical look at the concepts and techniques you need to get the most out of real business data",increas volum data modern busi scienc call complex sophist tool although advanc data mine technolog made extens data collect much easier still alway evolv constant need new techniqu tool help us transform data use inform knowledg sinc previou edit public great advanc made field data mine third edit data mine concept techniqu continu tradit equip understand applic theori practic discov pattern hidden larg data set also focus new import topic field data warehous data cube technolog mine stream mine social network mine spatial multimedia complex data chapter standalon guid critic topic present proven algorithm sound implement readi use directli strateg modif live data resourc need want appli today power data mine techniqu meet real busi challeng present dozen algorithm implement exampl pseudocod suitabl use realworld largescal data mine project address advanc topic mine objectrel databas spatial databas multimedia databas timeseri databas text databas world wide web applic sever field provid comprehens practic look concept techniqu need get real busi data
d4825585c5b036bb789ad183635cc2d4d89ff394,Opening the archive: How free data has enabled the science and monitoring promise of Landsat,,nan
8d76672d52622d9c45014d630717ce911d1292ba,Bayesian Data Analysis,"Inference is the process of going from observed effects to underlying causes, and is the inverse process to deduction. Whereas deduction is exact, inference is imprecise, and necessarily probabilistic. Inference is the basis of science: we are always faced with observations we would like to explain in terms of underlying physical causes. Bayesian inference is an approach to the problem based on an identity in conditional probability (Bayes’s theorem). Notable Bayesians have included Pierre-Simon Laplace (who inferred the mass of Saturn from contemporary observations using Bayesian methods, and obtained a value consistent with modern estimates), the economist John Maynard Keynes, and the applied mathematician and geophysicist Harold Jeffreys. Bayesian inference has at times been controversial, because of its incorporation of subjective prior information into the process of inference. Historically the Bayesian approach was referred to as “subjective probability.” In recent decades there has",infer process go observ effect underli caus invers process deduct wherea deduct exact infer imprecis necessarili probabilist infer basi scienc alway face observ would like explain term underli physic caus bayesian infer approach problem base ident condit probabl bayess theorem notabl bayesian includ pierresimon laplac infer mass saturn contemporari observ use bayesian method obtain valu consist modern estim economist john maynard keyn appli mathematician geophysicist harold jeffrey bayesian infer time controversi incorpor subject prior inform process infer histor bayesian approach refer subject probabl recent decad
a461233e56079fc5af6e48d75f38be8c9ff87c1e,Machine Learning: New Ideas and Tools in Environmental Science and Engineering.,"The rapid increase in both the quantity and complexity of data that are being generated daily in the field of environmental science and engineering (ESE) demands accompanied advancement in data analytics. Advanced data analysis approaches, such as machine learning (ML), have become indispensable tools for revealing hidden patterns or deducing correlations for which conventional analytical methods face limitations or challenges. However, ML concepts and practices have not been widely utilized by researchers in ESE. This feature explores the potential of ML to revolutionize data analysis and modeling in the ESE field, and covers the essential knowledge needed for such applications. First, we use five examples to illustrate how ML addresses complex ESE problems. We then summarize four major types of applications of ML in ESE: making predictions; extracting feature importance; detecting anomalies; and discovering new materials or chemicals. Next, we introduce the essential knowledge required and current shortcomings in ML applications in ESE, with a focus on three important but often overlooked components when applying ML: correct model development, proper model interpretation, and sound applicability analysis. Finally, we discuss challenges and future opportunities in the application of ML tools in ESE to highlight the potential of ML in this field.",rapid increas quantiti complex data gener daili field environment scienc engin ese demand accompani advanc data analyt advanc data analysi approach machin learn ml becom indispens tool reveal hidden pattern deduc correl convent analyt method face limit challeng howev ml concept practic wide util research ese featur explor potenti ml revolution data analysi model ese field cover essenti knowledg need applic first use five exampl illustr ml address complex ese problem summar four major type applic ml ese make predict extract featur import detect anomali discov new materi chemic next introduc essenti knowledg requir current shortcom ml applic ese focu three import often overlook compon appli ml correct model develop proper model interpret sound applic analysi final discuss challeng futur opportun applic ml tool ese highlight potenti ml field
969f983d000ac68ca77548b5bba2e8d1b89086c4,Materials science with large-scale data and informatics: Unlocking new opportunities,"Universal access to abundant scientific data, and the software to analyze the data at scale, could fundamentally transform the field of materials science. Today, the materials community faces serious challenges to bringing about this data-accelerated research paradigm, including diversity of research areas within materials, lack of data standards, and missing incentives for sharing, among others. Nonetheless, the landscape is rapidly changing in ways that should benefit the entire materials research enterprise. We provide an overview of the current state of the materials data and informatics landscape, highlighting a few selected efforts that make more data freely available and useful to materials researchers.",univers access abund scientif data softwar analyz data scale could fundament transform field materi scienc today materi commun face seriou challeng bring dataacceler research paradigm includ divers research area within materi lack data standard miss incent share among other nonetheless landscap rapidli chang way benefit entir materi research enterpris provid overview current state materi data informat landscap highlight select effort make data freeli avail use materi research
2f35b305b6c56046b631b0cdb6d2f08e4ee577a7,TurkPrime.com: A versatile crowdsourcing data acquisition platform for the behavioral sciences,,nan
b48a917258f4e7e2b78a41289d005513db1de8c9,Earth Observation Open Science: Enhancing Reproducible Science Using Data Cubes,"Earth Observation Data Cubes (EODC) have emerged as a promising solution to efficiently and effectively handle Big Earth Observation (EO) Data generated by satellites and made freely and openly available from different data repositories. The aim of this Special Issue, “Earth Observation Data Cube”, in Data, is to present the latest advances in EODC development and implementation, including innovative approaches for the exploitation of satellite EO data using multi-dimensional (e.g., spatial, temporal, spectral) approaches. This Special Issue contains 14 articles covering a wide range of topics such as Synthetic Aperture Radar (SAR), Analysis Ready Data (ARD), interoperability, thematic applications (e.g., land cover, snow cover mapping), capacity development, semantics, processing techniques, as well as national implementations and best practices. These papers made significant contributions to the advancement of a more Open and Reproducible Earth Observation Science, reducing the gap between users’ expectations for decision-ready products and current Big Data analytical capabilities, and ultimately unlocking the information power of EO data by transforming them into actionable knowledge.",earth observ data cube eodc emerg promis solut effici effect handl big earth observ eo data gener satellit made freeli openli avail differ data repositori aim special issu earth observ data cube data present latest advanc eodc develop implement includ innov approach exploit satellit eo data use multidimension eg spatial tempor spectral approach special issu contain articl cover wide rang topic synthet apertur radar sar analysi readi data ard interoper themat applic eg land cover snow cover map capac develop semant process techniqu well nation implement best practic paper made signific contribut advanc open reproduc earth observ scienc reduc gap user expect decisionreadi product current big data analyt capabl ultim unlock inform power eo data transform action knowledg
88bcdfd021d935a28f245e178792207881b14794,Learning from Imbalanced Data Sets,,nan
7bd598f6a7c6eb4265fe5a9ca64504d1d639684a,Educational data mining and learning analytics: An updated survey,"This survey is an updated and improved version of the previous one published in 2013 in this journal with the title “data mining in education”. It reviews in a comprehensible and very general way how Educational Data Mining and Learning Analytics have been applied over educational data. In the last decade, this research area has evolved enormously and a wide range of related terms are now used in the bibliography such as Academic Analytics, Institutional Analytics, Teaching Analytics, Data‐Driven Education, Data‐Driven Decision‐Making in Education, Big Data in Education, and Educational Data Science. This paper provides the current state of the art by reviewing the main publications, the key milestones, the knowledge discovery cycle, the main educational environments, the specific tools, the free available datasets, the most used methods, the main objectives, and the future trends in this research area.",survey updat improv version previou one publish journal titl data mine educ review comprehens gener way educ data mine learn analyt appli educ data last decad research area evolv enorm wide rang relat term use bibliographi academ analyt institut analyt teach analyt datadriven educ datadriven decisionmak educ big data educ educ data scienc paper provid current state art review main public key mileston knowledg discoveri cycl main educ environ specif tool free avail dataset use method main object futur trend research area
3aa1b70fdc97ae96091c5fb39cd911015ac5253e,Novel methods improve prediction of species' distributions from occurrence data,"Prediction of species' distributions is central to diverse applications in ecology, evolution and conservation science. There is increasing electronic access to vast sets of occurrence records in museums and herbaria, yet little effective guidance on how best to use this information in the context of numerous approaches for modelling distributions. To meet this need, we compared 16 modelling methods over 226 species from 6 regions of the world, creating the most comprehensive set of model comparisons to date. We used presence-only data to fit models, and independent presence-absence data to evaluate the predictions. Along with well-established modelling methods such as generalised additive models and GARP and BIOCLIM, we explored methods that either have been developed recently or have rarely been applied to modelling species' distributions. These include machine-learning methods and community models, both of which have features that may make them particularly well suited to noisy or sparse information, as is typical of species' occurrence data. Presence-only data were effective for modelling species' distributions for many species and regions. The novel methods consistently outperformed more established methods. The results of our analysis are promising for the use of data from museums and herbaria, especially as methods suited to the noise inherent in such data improve.",predict speci distribut central divers applic ecolog evolut conserv scienc increas electron access vast set occurr record museum herbaria yet littl effect guidanc best use inform context numer approach model distribut meet need compar model method speci region world creat comprehens set model comparison date use presenceonli data fit model independ presenceabs data evalu predict along wellestablish model method generalis addit model garp bioclim explor method either develop recent rare appli model speci distribut includ machinelearn method commun model featur may make particularli well suit noisi spars inform typic speci occurr data presenceonli data effect model speci distribut mani speci region novel method consist outperform establish method result analysi promis use data museum herbaria especi method suit nois inher data improv
e0634f2945b43d4c13a0aa2ff31f2c1c5fe597b9,The Role of Anomalous Data in Knowledge Acquisition: A Theoretical Framework and Implications for Science Instruction,"Understanding how science students respond to anomalous data is essential to understanding knowledge acquisition in science classrooms. This article presents a detailed analysis of the ways in which scientists and science students respond to such data. We postulate that there are seven distinct forms of response to anomalous data, only one of which is to accept the data and change theories. The other six responses involve discounting the data in various ways in order to protect the preinstructional theory. We analyze the factors that influence which of these seven forms of response a scientist or student will choose, giving special attention to the factors that make theory change more likely. Finally, we discuss the implications of our framework for science instruction.",understand scienc student respond anomal data essenti understand knowledg acquisit scienc classroom articl present detail analysi way scientist scienc student respond data postul seven distinct form respons anomal data one accept data chang theori six respons involv discount data variou way order protect preinstruct theori analyz factor influenc seven form respons scientist student choos give special attent factor make theori chang like final discuss implic framework scienc instruct
b7d5dda24d0c540929cd58b0226eac8a85e9769b,Consistent Covariance Matrix Estimation with Spatially Dependent Panel Data,"Many panel data sets encountered in macroeconomics, international economics, regional science, and finance are characterized by cross-sectional or spatial dependence. Standard techniques that fail to account for this dependence will result in inconsistently estimated standard errors. In this paper we present conditions under which a simple extension of common nonparametric covariance matrix estimation techniques yields standard error estimates that are robust to very general forms of spatial and temporal dependence as the time dimension becomes large. We illustrate the relevance of this approach using Monte Carlo simulations and a number of empirical examples.",mani panel data set encount macroeconom intern econom region scienc financ character crosssect spatial depend standard techniqu fail account depend result inconsist estim standard error paper present condit simpl extens common nonparametr covari matrix estim techniqu yield standard error estim robust gener form spatial tempor depend time dimens becom larg illustr relev approach use mont carlo simul number empir exampl
5703617b9d9d40e90b6c8ffa21a52734d9822d60,Defining Computational Thinking for Mathematics and Science Classrooms,,nan
efa5558bddd68abe4adc81adbbef6f739e648392,Big Data: Astronomical or Genomical?,"Genomics is a Big Data science and is going to get much bigger, very soon, but it is not known whether the needs of genomics will exceed other Big Data domains. Projecting to the year 2025, we compared genomics with three other major generators of Big Data: astronomy, YouTube, and Twitter. Our estimates show that genomics is a “four-headed beast”—it is either on par with or the most demanding of the domains analyzed here in terms of data acquisition, storage, distribution, and analysis. We discuss aspects of new technologies that will need to be developed to rise up and meet the computational challenges that genomics poses for the near future. Now is the time for concerted, community-wide planning for the “genomical” challenges of the next decade.",genom big data scienc go get much bigger soon known whether need genom exceed big data domain project year compar genom three major gener big data astronomi youtub twitter estim show genom fourhead beastit either par demand domain analyz term data acquisit storag distribut analysi discuss aspect new technolog need develop rise meet comput challeng genom pose near futur time concert communitywid plan genom challeng next decad
da619a6c524f5ab800b44c8728db3cef3d3b25d9,"Big Data, new epistemologies and paradigm shifts","This article examines how the availability of Big Data, coupled with new data analytics, challenges established epistemologies across the sciences, social sciences and humanities, and assesses the extent to which they are engendering paradigm shifts across multiple disciplines. In particular, it critically explores new forms of empiricism that declare ‘the end of theory’, the creation of data-driven rather than knowledge-driven science, and the development of digital humanities and computational social sciences that propose radically different ways to make sense of culture, history, economy and society. It is argued that: (1) Big Data and new data analytics are disruptive innovations which are reconfiguring in many instances how research is conducted; and (2) there is an urgent need for wider critical reflection within the academy on the epistemological implications of the unfolding data revolution, a task that has barely begun to be tackled despite the rapid changes in research practices presently taking place. After critically reviewing emerging epistemological positions, it is contended that a potentially fruitful approach would be the development of a situated, reflexive and contextually nuanced epistemology.",articl examin avail big data coupl new data analyt challeng establish epistemolog across scienc social scienc human assess extent engend paradigm shift across multipl disciplin particular critic explor new form empiric declar end theori creation datadriven rather knowledgedriven scienc develop digit human comput social scienc propos radic differ way make sens cultur histori economi societi argu big data new data analyt disrupt innov reconfigur mani instanc research conduct urgent need wider critic reflect within academi epistemolog implic unfold data revolut task bare begun tackl despit rapid chang research practic present take place critic review emerg epistemolog posit contend potenti fruit approach would develop situat reflex contextu nuanc epistemolog
7fc70d4cc5118fdbc8e8807979eae8b61948ff91,"The elements of statistical learning: data mining, inference and prediction",,nan
0870c1ea2b7d5a515c7b5b954f1433b379fe1e02,Principles and methods of scaling geospatial Earth science data,,nan
f2b66923db74a16169d040a51ada555d5b6f8851,Data Mining and Analysis: Fundamental Concepts and Algorithms,"The fundamental algorithms in data mining and analysis form the basis for the emerging field of data science, which includes automated methods to analyze patterns and models for all kinds of data, with applications ranging from scientific discovery to business intelligence and analytics. This textbook for senior undergraduate and graduate data mining courses provides a broad yet in-depth overview of data mining, integrating related concepts from machine learning and statistics. The main parts of the book include exploratory data analysis, pattern mining, clustering, and classification. The book lays the basic foundations of these tasks, and also covers cutting-edge topics such as kernel methods, high-dimensional data analysis, and complex graphs and networks. With its comprehensive coverage, algorithmic perspective, and wealth of examples, this book offers solid guidance in data mining for students, researchers, and practitioners alike. Key features: Covers both core methods and cutting-edge research Algorithmic approach with open-source implementations Minimal prerequisites: all key mathematical concepts are presented, as is the intuition behind the formulas Short, self-contained chapters with class-tested examples and exercises allow for flexibility in designing a course and for easy reference Supplementary website with lecture slides, videos, project ideas, and more",fundament algorithm data mine analysi form basi emerg field data scienc includ autom method analyz pattern model kind data applic rang scientif discoveri busi intellig analyt textbook senior undergradu graduat data mine cours provid broad yet indepth overview data mine integr relat concept machin learn statist main part book includ exploratori data analysi pattern mine cluster classif book lay basic foundat task also cover cuttingedg topic kernel method highdimension data analysi complex graph network comprehens coverag algorithm perspect wealth exampl book offer solid guidanc data mine student research practition alik key featur cover core method cuttingedg research algorithm approach opensourc implement minim prerequisit key mathemat concept present intuit behind formula short selfcontain chapter classtest exampl exercis allow flexibl design cours easi refer supplementari websit lectur slide video project idea
fb3140c9766a5bc92400ac8ce9d48a4272bba69e,A New Kind of Science,"nationwide data set of losses from 1975 to 1998 was compiled to assess the trends. Temporal patterns of deaths and injuries, monetary damages, and—in some cases—the number of events are systematically examined by year in chapter 5, and the authors undertake a systematic spatial assessment of the statewide totals in chapter 6. Explanations for some of the patterns are offered, particularly for the most significant disasters and for the states with most events or the greatest losses. Further refinement and evaluation of patterns of economic losses and death are undertaken by normalizing losses by population, land area, and gross domestic product (GDP). The authors advance the discussion from simple descriptions of loss patterns to explanations of the patterns of disaster-loss burden, and some surprises emerge from the arithmetic. For instance, North Dakota, Iowa, andMississippi not only suffered the greatest monetary losses per capita during the period, but also suffered the greatest losses of property and crops compared to their state GDP!For afinal analysis, the authors created an overall hazard score (averaged proportion of the states’ contributions to the national totals of events, deaths, and damages) and used it to rank the states. Using this ranking, states were assigned to categories of ‘‘proneness,’’ from highest (Florida, Texas, andCalifornia) to lowest (Rhode Island, Delaware, Alaska and other small or lightly populated states). The conclusion we are to draw is that the amount of loss a state has experienced indicates its disaster proneness. Finally, ‘‘Charting a Course for theNext Two Decades’’ by Cutter describes what is needed to produce the models and data appropriate for mitigation and planning assessments. In order for an effective assessment of events and losses to occur, progress is required in several areas: development of vulnerability science, the creation of a national hazard events and losses database, and the establishment of a national loss inventory and events clearinghouse. To do so, Cutter argues, we need to rethink thewaywe monitor, assess, andmanage our vulnerabilities. She briefly describes the shifts needed in data gathering and provision, sustainability and distributive justice, strategic planning, research funding, and societal awareness of issues that influence the prospects for disaster. While American Hazardscapes is intended to provide a broadunderstanding of the geography of loss due to hazards in the United States, it suffers from its openly acknowledged limitations. Though criticizing the quality of currently available data, the authors use those data to indicate the prospects for future disasters. The elimination of extreme events is no longer believed tobe the key loss reduction. Instead,we must identify and avoid places too dynamic for permanent occupation and adjust to the inevitable events in ways that limit prospects for loss. Mitigation must address the vulnerabilities that cause greater exposure and profound upset of our social systems and create more complex catastrophes. The data employed in this assessment describe (however imperfectly) the losses suffered over two and a half decades. The largest disasters overwhelm the patterns of loss in their analysis. The authors imply, based on proneness rankings, that those who lost the most are the most prone to loss. But in reality, losses are byproducts of the interplay of two dynamic geographies: the pattern of extreme events and the pattern of human use of the landscape. The former is often poorly understood, may not behave consistently, andmay operate on greater than twenty-five-year cycles. The latter may change so rapidly that it surpasses our capacity to measure it and map it, and postdisaster land use and human perception may be radically changed. These geographies were outside the scope of this book, however, and given new homeland security efforts and reorganization of the Federal Emergency Management Agency, the past is an even poorer indicator of the future.",nationwid data set loss compil assess trend tempor pattern death injuri monetari damag andin casesth number event systemat examin year chapter author undertak systemat spatial assess statewid total chapter explan pattern offer particularli signific disast state event greatest loss refin evalu pattern econom loss death undertaken normal loss popul land area gross domest product gdp author advanc discuss simpl descript loss pattern explan pattern disasterloss burden surpris emerg arithmet instanc north dakota iowa andmississippi suffer greatest monetari loss per capita period also suffer greatest loss properti crop compar state gdpfor afin analysi author creat overal hazard score averag proport state contribut nation total event death damag use rank state use rank state assign categori prone highest florida texa andcalifornia lowest rhode island delawar alaska small lightli popul state conclus draw amount loss state experienc indic disast prone final chart cours thenext two decad cutter describ need produc model data appropri mitig plan assess order effect assess event loss occur progress requir sever area develop vulner scienc creation nation hazard event loss databas establish nation loss inventori event clearinghous cutter argu need rethink thewayw monitor assess andmanag vulner briefli describ shift need data gather provis sustain distribut justic strateg plan research fund societ awar issu influenc prospect disast american hazardscap intend provid broadunderstand geographi loss due hazard unit state suffer openli acknowledg limit though critic qualiti current avail data author use data indic prospect futur disast elimin extrem event longer believ tobe key loss reduct insteadw must identifi avoid place dynam perman occup adjust inevit event way limit prospect loss mitig must address vulner caus greater exposur profound upset social system creat complex catastroph data employ assess describ howev imperfectli loss suffer two half decad largest disast overwhelm pattern loss analysi author impli base prone rank lost prone loss realiti loss byproduct interplay two dynam geographi pattern extrem event pattern human use landscap former often poorli understood may behav consist andmay oper greater twentyfiveyear cycl latter may chang rapidli surpass capac measur map postdisast land use human percept may radic chang geographi outsid scope book howev given new homeland secur effort reorgan feder emerg manag agenc past even poorer indic futur
7579330e89bffd736fee19d25359ab3ae65bf5f7,rioja: Analysis of Quaternary Science Data,,nan
6802bbeea45ea9c44b8e9f69ee1d775f5af0717f,Ethical Issues Relating to Scientific Discovery in Exercise Science.,"This work aims to present concepts related to ethical issues in conducting and reporting scientific research in a clear and straightforward manner. Considerations around research design including authorship, sound research practices, non-discrimination in subject recruitment, objectivity, respect for intellectual property, and financial interests are detailed. Further, concepts relating to the conducting of research including the competency of the researcher, conflicts of interest, accurately representing data, and ethical practices in human and animal research are presented. Attention pertaining to the dissemination of research including plagiarism, duplicate submission, redundant publication, and figure manipulation is offered. Other considerations including responsible mentoring, respect for colleagues, and social responsibility are set forth. The International Journal of Exercise Science will now require a statement in all subsequent published manuscripts that the authors have complied with each of the ethics statements contained in this work.",work aim present concept relat ethic issu conduct report scientif research clear straightforward manner consider around research design includ authorship sound research practic nondiscrimin subject recruit object respect intellectu properti financi interest detail concept relat conduct research includ compet research conflict interest accur repres data ethic practic human anim research present attent pertain dissemin research includ plagiar duplic submiss redund public figur manipul offer consider includ respons mentor respect colleagu social respons set forth intern journal exercis scienc requir statement subsequ publish manuscript author compli ethic statement contain work
28aecd08b2488c5300abf399feeb83a1f9c19890,Open Government Data,"Story Slides Slide 1 W3C eGovernment Community: Data Science Slide 2 Agenda Slide 3 The Changing Landscape of Federal Information Technology Slide 4 Cloud: SOA, Semantic, & Data Science: September 10-11th Slide 5 Opportunities for Data Science Slide 6 Discussion 1 Slide 7 Discussion 2 Slide 8 Discussion 3 Slide 9 Discussion 4 Slide 10 Discussion 5 Spotfire Dashboard Research Notes Joshua Tauberer’s Blog Open Government Data 1 Big Data Meets Open Government Figure 1 The New Federal Register 2.0 Figure 2 This animated visualization of live wind speeds and directions Figure 3 Data is like refrigerator poetry Figure 4 http://www.GovTrack.us Figure 5 John Oliver parodies Schoolhouse Rock’s “I’m Just a Bill” References 1 2 3 4 5 6 7",stori slide slide wc egovern commun data scienc slide agenda slide chang landscap feder inform technolog slide cloud soa semant data scienc septemb th slide opportun data scienc slide discuss slide discuss slide discuss slide discuss slide discuss spotfir dashboard research note joshua tauber blog open govern data big data meet open govern figur new feder regist figur anim visual live wind speed direct figur data like refriger poetri figur httpwwwgovtracku figur john oliv parodi schoolhous rock im bill refer
24931dc3ddedfc2db5405af236e3ca84944d66d7,Big Data and Social Science: A Practical Guide to Methods and Tools,"Both Traditional Students and Working Professionals Acquire the Skills to Analyze Social Problems. Big Data and Social Science: A Practical Guide to Methods and Tools shows how to apply data science to real-world problems in both research and the practice. The book provides practical guidance on combining methods and tools from computer science, statistics, and social science. This concrete approach is illustrated throughout using an important national problem, the quantitative study of innovation. The text draws on the expertise of prominent leaders in statistics, the social sciences, data science, and computer science to teach students how to use modern social science research principles as well as the best analytical and computational tools. It uses a real-world challenge to introduce how these tools are used to identify and capture appropriate data, apply data science models and tools to that data, and recognize and respond to data errors and limitations. For more information, including sample chapters and news, please visit the author's website.",tradit student work profession acquir skill analyz social problem big data social scienc practic guid method tool show appli data scienc realworld problem research practic book provid practic guidanc combin method tool comput scienc statist social scienc concret approach illustr throughout use import nation problem quantit studi innov text draw expertis promin leader statist social scienc data scienc comput scienc teach student use modern social scienc research principl well best analyt comput tool use realworld challeng introduc tool use identifi captur appropri data appli data scienc model tool data recogn respond data error limit inform includ sampl chapter news pleas visit author websit
a07a64ba110e0f9f7156f3bd1e376f0d2e1cddf1,The Extent and Consequences of P-Hacking in Science,"A focus on novel, confirmatory, and statistically significant results leads to substantial bias in the scientific literature. One type of bias, known as “p-hacking,” occurs when researchers collect or select data or statistical analyses until nonsignificant results become significant. Here, we use text-mining to demonstrate that p-hacking is widespread throughout science. We then illustrate how one can test for p-hacking when performing a meta-analysis and show that, while p-hacking is probably common, its effect seems to be weak relative to the real effect sizes being measured. This result suggests that p-hacking probably does not drastically alter scientific consensuses drawn from meta-analyses.",focu novel confirmatori statist signific result lead substanti bia scientif literatur one type bia known phack occur research collect select data statist analys nonsignific result becom signific use textmin demonstr phack widespread throughout scienc illustr one test phack perform metaanalysi show phack probabl common effect seem weak rel real effect size measur result suggest phack probabl drastic alter scientif consensus drawn metaanalys
b970f9c088beee99666a40374dd5ccb06eeda112,Understanding the paradigm shift to computational social science in the presence of big data,,nan
cebed64039064dfe950587b919ddc01dee7d871f,From Little Science to Big Science,"In Little Science, Big Science (1963), Derek J. de Solla Price undertook a sociology of science that dealt with the growth and changing shape of scientific publishing and the social organization of science. The focus of Price’s work was on the long-term, gradual shift from “little science,” with the solo scientist, small laboratory, and minimal research funds, to “big science,” with collaborative research teams, large-scale research hardware, extensive funding, and corporate-political suitors of scientists. We extend Price’s focus on scientific publications by moving beyond his analysis of practices in physics and chemistry to examine a social science; namely, sociology. Specifically, we analyze 3,000 articles in four long-standing sociology journals over the fifty-year period from 1960-2010 to determine the gender of authors, the prestige of authors’ departments, length of articles, number of references, sources of data for studies, and patterns of funding for research. We find that sociology is not immune from the shift from “little science” to “big science.”",littl scienc big scienc derek j de solla price undertook sociolog scienc dealt growth chang shape scientif publish social organ scienc focu price work longterm gradual shift littl scienc solo scientist small laboratori minim research fund big scienc collabor research team largescal research hardwar extens fund corporatepolit suitor scientist extend price focu scientif public move beyond analysi practic physic chemistri examin social scienc name sociolog specif analyz articl four longstand sociolog journal fiftyyear period determin gender author prestig author depart length articl number refer sourc data studi pattern fund research find sociolog immun shift littl scienc big scienc
eaf5a5e0b32a055e288d5edcc5cd39f9f4d335ad,The misuse of colour in science communication,,nan
ac8db14cbc7ad0119d0130e88f98ccb3ec61780f,"Big Data, Digital Media, and Computational Social Science",forecasts and misrepresent,forecast misrepres
0b510ee69a507407008661aacb2345f73c70f8cb,Strategies Employed by Citizen Science Programs to Increase the Credibility of Their Data,"The success of citizen science in producing important and unique data is attracting interest from scientists and resource managers. Nonetheless, questions remain about the credibility of citizen science data. Citizen science programs desire to meet the same standards of credibility as academic science, but they usually work within a different context, for example, training and managing significant numbers of volunteers with limited resources. We surveyed the credibility-building strategies of 30 citizen science programs that monitor environmental aspects of the California coast. We identified a total of twelve strategies: Three that are applied during training and planning; four that are applied during data collection; and five that are applied during data analysis and program evaluation. Variation in the application of these strategies by program is related to factors such as the number of participants, the focus on group or individual work, and the time commitment required of volunteers. The structure of each program and available resources require program designers to navigate tradeoffs in the choices of their credibility strategies. Our results illustrate those tradeoffs and provide a framework for the necessary discussions between citizen science programs and potential users of their data—including scientists and decision makers—about shared expectations for credibility and practical approaches for meeting those expectations. This article has been corrected here: http://dx.doi.org/10.5334/cstp.91",success citizen scienc produc import uniqu data attract interest scientist resourc manag nonetheless question remain credibl citizen scienc data citizen scienc program desir meet standard credibl academ scienc usual work within differ context exampl train manag signific number volunt limit resourc survey credibilitybuild strategi citizen scienc program monitor environment aspect california coast identifi total twelv strategi three appli train plan four appli data collect five appli data analysi program evalu variat applic strategi program relat factor number particip focu group individu work time commit requir volunt structur program avail resourc requir program design navig tradeoff choic credibl strategi result illustr tradeoff provid framework necessari discuss citizen scienc program potenti user datainclud scientist decis makersabout share expect credibl practic approach meet expect articl correct httpdxdoiorgcstp
46d71d947231f86e1f9d4581e61212385debbe14,OpenML: networked science in machine learning,"Many sciences have made significant breakthroughs by adopting online tools that help organize, structure and mine information that is too detailed to be printed in journals. In this paper, we introduce OpenML, a place for machine learning researchers to share and organize data in fine detail, so that they can work more effectively, be more visible, and collaborate with others to tackle harder problems. We discuss how OpenML relates to other examples of networked science and what benefits it brings for machine learning research, individual scientists, as well as students and practitioners.",mani scienc made signific breakthrough adopt onlin tool help organ structur mine inform detail print journal paper introduc openml place machin learn research share organ data fine detail work effect visibl collabor other tackl harder problem discuss openml relat exampl network scienc benefit bring machin learn research individu scientist well student practition
b598b8dd79654dc865b02c2af0a0bdb565d24049,Taking a ‘Big Data’ approach to data quality in a citizen science project,,nan
cf83811d697dc3419a52c9853807afb410eb3943,Tree-Based Models for Political Science Data,"Political scientists often find themselves analyzing data sets with a large number of observations, a large number of variables, or both. Yet, traditional statistical techniques fail to take full advantage of the opportunities inherent in “big data,” as they are too rigid to recover nonlinearities and do not facilitate the easy exploration of interactions in high-dimensional data sets. In this article, we introduce a family of tree-based nonparametric techniques that may, in some circumstances, be more appropriate than traditional methods for confronting these data challenges. In particular, tree models are very effective for detecting nonlinearities and interactions, even in data sets with many (potentially irrelevant) covariates. We introduce the basic logic of tree-based models, provide an overview of the most prominent methods in the literature, and conduct three analyses that illustrate how the methods can be implemented while highlighting both their advantages and limitations. Replication Materials: The data, code, and any additional materials required to replicate all analyses in this article are available on the American Journal of Political Science Dataverse within the Harvard Dataverse Network at: https://doi.org/10.7910/DVN/8ZJBLI. Social science scholars often work with data sets containing a large number of observations, many potential covariates, or (increasingly) both. Indeed, political scientists now regularly analyze data with levels of complexity unimaginable just two decades ago. Widely used surveys, for instance, interview tens of thousands of respondents about hundreds of topics. Scholars of institutions can quickly assemble data sets with thousands of observations using resources like the Comparative Agendas Project. Moreover, new measurement methods, such as text analysis, have combined with data sources, such as Twitter, to generate databases of almost unmanageable sizes. It is clear that political science, like all areas of the social sciences, will increasingly have access to a deluge of data so vast that it will dwarf everything that has come before. What statistical methods are needed in this datasaturated world? Surely, there is no one correct answer. Yet, just as surely, traditional statistical models are not always equipped to take full advantage of new data sources. Traditional models—largely variants of linear regressions—are ideal for evaluating theories that imply specific functional forms relating outcomes to predictors. In particular, they excel in their ability to leverage assumptions about the data-generating process, or DGP (additivity, linearity in the parameters, homoskedasticity, Jacob M. Montgomery is Associate Professor, Department of Political Science, Washington University in St. Louis, Campus Box 1063, One Brookings Drive, St. Louis, MO 63130 (jacob.montgomery@wustl.edu). Santiago Olivella is Assistant Professor, Department of Political Science, University of North Carolina at Chapel Hill, Hamilton Hall 361, CB 3265, Chapel Hill, NC 27599 (olivella@unc.edu). etc.) to make valid inferences despite inherent data limitations. Although appropriate when testing theories that conform with these assumptions, standard models are often insufficiently flexible to capture nuances in the data—such as complex nonlinear functional forms and deep interactions—when no clear a priori expectations exist. In this article, we introduce a family of tree-based nonparametric techniques from the machine learning literature. We argue that, under specific circumstances, regression and classification tree models are an appropriate standard choice for analyzing high-dimensional data sets. In particular, past research has shown tree-based methods to be very useful for making accurate predictions when the underlying DGP includes nonlinearities, discontinuities, and interactions among many covariates. Further, tree models require few assumptions. Rather than imposing a presumed structure on the DGP, tree-based methods allow the data to “speak for themselves.” Thus, our goal in this article is to introduce political scientists to this promising family of methods, which are well suited for today’s data analysis demands. In the next sections, we discuss the promise and perils of high-dimensional, “large”-N data sets and introduce the basic logic of tree models. We then provide an overview of the most prominent methods in the literature. American Journal of Political Science, Vol. 62, No. 3, July 2018, Pp. 729–744 C ©2018, Midwest Political Science Association DOI: 10.1111/ajps.12361",polit scientist often find analyz data set larg number observ larg number variabl yet tradit statist techniqu fail take full advantag opportun inher big data rigid recov nonlinear facilit easi explor interact highdimension data set articl introduc famili treebas nonparametr techniqu may circumst appropri tradit method confront data challeng particular tree model effect detect nonlinear interact even data set mani potenti irrelev covari introduc basic logic treebas model provid overview promin method literatur conduct three analys illustr method implement highlight advantag limit replic materi data code addit materi requir replic analys articl avail american journal polit scienc datavers within harvard datavers network httpsdoiorgdvnzjbl social scienc scholar often work data set contain larg number observ mani potenti covari increasingli inde polit scientist regularli analyz data level complex unimagin two decad ago wide use survey instanc interview ten thousand respond hundr topic scholar institut quickli assembl data set thousand observ use resourc like compar agenda project moreov new measur method text analysi combin data sourc twitter gener databas almost unmanag size clear polit scienc like area social scienc increasingli access delug data vast dwarf everyth come statist method need datasatur world sure one correct answer yet sure tradit statist model alway equip take full advantag new data sourc tradit modelslarg variant linear regressionsar ideal evalu theori impli specif function form relat outcom predictor particular excel abil leverag assumpt datagener process dgp addit linear paramet homoskedast jacob montgomeri associ professor depart polit scienc washington univers st loui campu box one brook drive st loui mo jacobmontgomerywustledu santiago olivella assist professor depart polit scienc univers north carolina chapel hill hamilton hall cb chapel hill nc olivellauncedu etc make valid infer despit inher data limit although appropri test theori conform assumpt standard model often insuffici flexibl captur nuanc datasuch complex nonlinear function form deep interactionswhen clear priori expect exist articl introduc famili treebas nonparametr techniqu machin learn literatur argu specif circumst regress classif tree model appropri standard choic analyz highdimension data set particular past research shown treebas method use make accur predict underli dgp includ nonlinear discontinu interact among mani covari tree model requir assumpt rather impos presum structur dgp treebas method allow data speak thu goal articl introduc polit scientist promis famili method well suit today data analysi demand next section discuss promis peril highdimension largen data set introduc basic logic tree model provid overview promin method literatur american journal polit scienc vol juli pp c midwest polit scienc associ doi ajp
938a6209fe95dd4e5f801a14b6b650dc7b2f6108,Could Big Data be the end of theory in science?,"Afew years ago, Chris Anderson, former editor in chief of Wired magazine, published a provocative and thought‐provoking article: “The end of theory: the data deluge makes the scientific method obsolete” (http://archive.wired.com/science/discoveries/magazine/16-07/pb_theory/). As the title indicates, Anderson asserted that in the era of petabyte information and supercomputing, the traditional, hypothesis‐driven scientific method would become obsolete. No more theories or hypotheses, no more discussions whether the experimental results refute or support the original hypotheses. In this new era, what counts are sophisticated algorithms and statistical tools to sift through a massive amount of data to find information that could be turned into knowledge.

> … [an] imagined future in which the long‐established way of doing scientific research is replaced by computers that divulge knowledge from data at the press of a button…

Anderson's essay started an intense discussion about the relative merits of data‐driven research versus hypothesis‐driven research that has much relevance for many areas of research, including bioinformatics, systems biology, epidemiology and ecology. Yet, his imagined future in which the long‐established way of doing scientific research is replaced by computers that divulge knowledge from data at the press of a button deserves some inquiry from an epistemological point of view. Is data‐driven research a genuine mode of knowledge production, or is it above all a tool to identify potentially useful information? Given the amount of scientific data available, is it now possible to dismiss the role of theoretical assumptions and hypotheses? Should this new mode of gathering information supersede the old way of doing research?

The scientific method encompasses an ongoing process of formulate a hypothesis‐test with an experiment–analyze the results‐reformulate the hypothesis. Such a way of proceeding has been in use for centuries and is basically accepted in our Western society as the most reliable way to produce robust knowledge.

However, Anderson is not the …",afew year ago chri anderson former editor chief wire magazin publish provoc thoughtprovok articl end theori data delug make scientif method obsolet httparchivewiredcomsciencediscoveriesmagazinepb_theori titl indic anderson assert era petabyt inform supercomput tradit hypothesisdriven scientif method would becom obsolet theori hypothes discuss whether experiment result refut support origin hypothes new era count sophist algorithm statist tool sift massiv amount data find inform could turn knowledg imagin futur longestablish way scientif research replac comput divulg knowledg data press button anderson essay start intens discuss rel merit datadriven research versu hypothesisdriven research much relev mani area research includ bioinformat system biolog epidemiolog ecolog yet imagin futur longestablish way scientif research replac comput divulg knowledg data press button deserv inquiri epistemolog point view datadriven research genuin mode knowledg product tool identifi potenti use inform given amount scientif data avail possibl dismiss role theoret assumpt hypothes new mode gather inform supersed old way research scientif method encompass ongo process formul hypothesistest experimentanalyz resultsreformul hypothesi way proceed use centuri basic accept western societi reliabl way produc robust knowledg howev anderson
993c9eb9bba80e2d8993e8c99acca1825cd0302f,Next Steps for Citizen Science,"Strategic investments and coordination are needed for citizen science to reach its full potential. Around the globe, thousands of research projects are engaging millions of individuals—many of whom are not trained as scientists—in collecting, categorizing, transcribing, or analyzing scientific data. These projects, known as citizen science, cover a breadth of topics from microbiomes to native bees to water quality to galaxies. Most projects obtain or manage scientific information at scales or resolutions unattainable by individual researchers or research teams, whether enrolling thousands of individuals collecting data across several continents, enlisting small armies of participants in categorizing vast quantities of online data, or organizing small groups of volunteers to tackle local problems.",strateg invest coordin need citizen scienc reach full potenti around globe thousand research project engag million individualsmani train scientistsin collect categor transcrib analyz scientif data project known citizen scienc cover breadth topic microbiom nativ bee water qualiti galaxi project obtain manag scientif inform scale resolut unattain individu research research team whether enrol thousand individu collect data across sever contin enlist small armi particip categor vast quantiti onlin data organ small group volunt tackl local problem
48fc9c42522184c652742255fdf31f7b9ed7ebae,Brief introduction of medical database and data mining technology in big data era,"Data mining technology can search for potentially valuable knowledge from a large amount of data, mainly divided into data preparation and data mining, and expression and analysis of results. It is a mature information processing technology and applies database technology. Database technology is a software science that researches manages, and applies databases. The data in the database are processed and analyzed by studying the underlying theory and implementation methods of the structure, storage, design, management, and application of the database. We have introduced several databases and data mining techniques to help a wide range of clinical researchers better understand and apply database technology.",data mine technolog search potenti valuabl knowledg larg amount data mainli divid data prepar data mine express analysi result matur inform process technolog appli databas technolog databas technolog softwar scienc research manag appli databas data databas process analyz studi underli theori implement method structur storag design manag applic databas introduc sever databas data mine techniqu help wide rang clinic research better understand appli databas technolog
500b73ecdf8ff5590718edb03367e3836a368485,Secondary Data Analysis: A Method of which the Time Has Come,"Technological advances have led to vast amounts of data that has been collected, compiled, and archived, and that is now easily accessible for research. As a result, utilizing existing data for research is becoming more prevalent, and therefore secondary data analysis. While secondary analysis is flexible and can be utilized in several ways, it is also an empirical exercise and a systematic method with procedural and evaluative steps, just as in collecting and evaluating primary data. This paper asserts that secondary data analysis is a viable method to utilize in the process of inquiry when a systematic procedure is followed and presents an illustrative research application utilizing secondary data analysis in library and information science research.",technolog advanc led vast amount data collect compil archiv easili access research result util exist data research becom preval therefor secondari data analysi secondari analysi flexibl util sever way also empir exercis systemat method procedur evalu step collect evalu primari data paper assert secondari data analysi viabl method util process inquiri systemat procedur follow present illustr research applic util secondari data analysi librari inform scienc research
b8f75b848b6cef0f2b5a1a11b794332ca9bccb45,A review of machine learning applications in wildfire science and management,"Artificial intelligence has been applied in wildfire science and management since the 1990s, with early applications including neural networks and expert systems. Since then, the field has rapidly progressed congruently with the wide adoption of machine learning (ML) methods in the environmental sciences. Here, we present a scoping review of ML applications in wildfire science and management. Our overall objective is to improve awareness of ML methods among wildfire researchers and managers, as well as illustrate the diverse and challenging range of problems in wildfire science available to ML data scientists. To that end, we first present an overview of popular ML approaches used in wildfire science to date and then review the use of ML in wildfire science as broadly categorized into six problem domains, including (i) fuels characterization, fire detection, and mapping; (ii) fire weather and climate change; (iii) fire occurrence, susceptibility, and risk; (iv) fire behavior prediction; (v) fire effects; and (vi) fire management. Furthermore, we discuss the advantages and limitations of various ML approaches relating to data size, computational requirements, generalizability, and interpretability, as well as identify opportunities for future advances in the science and management of wildfires within a data science context. In total, to the end of 2019, we identified 300 relevant publications in which the most frequently used ML methods across problem domains included random forests, MaxEnt, artificial neural networks, decision trees, support vector machines, and genetic algorithms. As such, there exists opportunities to apply more current ML methods — including deep learning and agent-based learning — in the wildfire sciences, especially in instances involving very large multivariate datasets. We must recognize, however, that despite the ability of ML models to learn on their own, expertise in wildfire science is necessary to ensure realistic modelling of fire processes across multiple scales, while the complexity of some ML methods such as deep learning requires a dedicated and sophisticated knowledge of their application. Finally, we stress that the wildfire research and management communities play an active role in providing relevant, high-quality, and freely available wildfire data for use by practitioners of ML methods.",artifici intellig appli wildfir scienc manag sinc earli applic includ neural network expert system sinc field rapidli progress congruent wide adopt machin learn ml method environment scienc present scope review ml applic wildfir scienc manag overal object improv awar ml method among wildfir research manag well illustr divers challeng rang problem wildfir scienc avail ml data scientist end first present overview popular ml approach use wildfir scienc date review use ml wildfir scienc broadli categor six problem domain includ fuel character fire detect map ii fire weather climat chang iii fire occurr suscept risk iv fire behavior predict v fire effect vi fire manag furthermor discuss advantag limit variou ml approach relat data size comput requir generaliz interpret well identifi opportun futur advanc scienc manag wildfir within data scienc context total end identifi relev public frequent use ml method across problem domain includ random forest maxent artifici neural network decis tree support vector machin genet algorithm exist opportun appli current ml method includ deep learn agentbas learn wildfir scienc especi instanc involv larg multivari dataset must recogn howev despit abil ml model learn expertis wildfir scienc necessari ensur realist model fire process across multipl scale complex ml method deep learn requir dedic sophist knowledg applic final stress wildfir research manag commun play activ role provid relev highqual freeli avail wildfir data use practition ml method
cf9ecfbbd0095687c4cfbbbfa0546914e651b109,"Calibration of the Computer Science and Applications, Inc. accelerometer.","PURPOSE
We established accelerometer count ranges for the Computer Science and Applications, Inc. (CSA) activity monitor corresponding to commonly employed MET categories.


METHODS
Data were obtained from 50 adults (25 males, 25 females) during treadmill exercise at three different speeds (4.8, 6.4, and 9.7 km x h(-1)).


RESULTS
Activity counts and steady-state oxygen consumption were highly correlated (r = 0.88), and count ranges corresponding to light, moderate, hard, and very hard intensity levels were < or = 1951, 1952-5724, 5725-9498, > or = 9499 cnts x min(-1), respectively. A model to predict energy expenditure from activity counts and body mass was developed using data from a random sample of 35 subjects (r2 = 0.82, SEE = 1.40 kcal x min(-1)). Cross validation with data from the remaining 15 subjects revealed no significant differences between actual and predicted energy expenditure at any treadmill speed (SEE = 0.50-1.40 kcal x min(-1)).


CONCLUSIONS
These data provide a template on which patterns of activity can be classified into intensity levels using the CSA accelerometer.",purpos establish acceleromet count rang comput scienc applic inc csa activ monitor correspond commonli employ met categori method data obtain adult male femal treadmil exercis three differ speed km x h result activ count steadyst oxygen consumpt highli correl r count rang correspond light moder hard hard intens level cnt x min respect model predict energi expenditur activ count bodi mass develop use data random sampl subject r see kcal x min cross valid data remain subject reveal signific differ actual predict energi expenditur treadmil speed see kcal x min conclus data provid templat pattern activ classifi intens level use csa acceleromet
c8bad3f510224e5cb010ca422149bf6ebcaa1d7f,Impact of data sources on citation counts and rankings of LIS faculty: Web of science versus scopus and google scholar,"The Institute for Scientific Information's (ISI, now Thomson Scientific, Philadelphia, PA) citation databases have been used for decades as a starting point and often as the only tools for locating citations andsor conducting citation analyses. The ISI databases (or Web of Science [WoS]), however, may no longer be sufficient because new databases and tools that allow citation searching are now available. Using citations to the work of 25 library and information science (LIS) faculty members as a case study, the authors examine the effects of using Scopus and Google Scholar (GS) on the citation counts and rankings of scholars as measured by WoS. Overall, more than 10,000 citing and purportedly citing documents were examined. Results show that Scopus significantly alters the relative ranking of those scholars that appear in the middle of the rankings and that GS stands out in its coverage of conference proceedings as well as international, non-English language journals. The use of Scopus and GS, in addition to WoS, helps reveal a more accurate and comprehensive picture of the scholarly impact of authors. The WoS data took about 100 hours of collecting and processing time, Scopus consumed 200 hours, and GS a grueling 3,000 hours. © 2007 Wiley Periodicals, Inc.",institut scientif inform isi thomson scientif philadelphia pa citat databas use decad start point often tool locat citat andsor conduct citat analys isi databas web scienc wo howev may longer suffici new databas tool allow citat search avail use citat work librari inform scienc li faculti member case studi author examin effect use scopu googl scholar gs citat count rank scholar measur wo overal cite purportedli cite document examin result show scopu significantli alter rel rank scholar appear middl rank gs stand coverag confer proceed well intern nonenglish languag journal use scopu gs addit wo help reveal accur comprehens pictur scholarli impact author wo data took hour collect process time scopu consum hour gs gruel hour wiley period inc
2daffab3ebd3fc034f8f78d6a546606c33a5d398,"Google Scholar, Scopus and the Web of Science: a longitudinal and cross-disciplinary comparison",,nan
fe5bb5d8d6b7ac251d87bc16e75ea5889cc92425,Explaining Fixed Effects: Random Effects Modeling of Time-Series Cross-Sectional and Panel Data*,"This article challenges Fixed Effects (FE) modeling as the ‘default’ for time-series-cross-sectional and panel data. Understanding different within and between effects is crucial when choosing modeling strategies. The downside of Random Effects (RE) modeling—correlated lower-level covariates and higher-level residuals—is omitted-variable bias, solvable with Mundlak's (1978a) formulation. Consequently, RE can provide everything that FE promises and more, as confirmed by Monte-Carlo simulations, which additionally show problems with Plümper and Troeger's FE Vector Decomposition method when data are unbalanced. As well as incorporating time-invariant variables, RE models are readily extendable, with random coefficients, cross-level interactions and complex variance functions. We argue not simply for technical solutions to endogeneity, but for the substantive importance of context/heterogeneity, modeled using RE. The implications extend beyond political science to all multilevel datasets. However, omitted variables could still bias estimated higher-level variable effects; as with any model, care is required in interpretation.",articl challeng fix effect fe model default timeseriescrosssect panel data understand differ within effect crucial choos model strategi downsid random effect modelingcorrel lowerlevel covari higherlevel residualsi omittedvari bia solvabl mundlak formul consequ provid everyth fe promis confirm montecarlo simul addit show problem plümper troeger fe vector decomposit method data unbalanc well incorpor timeinvari variabl model readili extend random coeffici crosslevel interact complex varianc function argu simpli technic solut endogen substant import contextheterogen model use implic extend beyond polit scienc multilevel dataset howev omit variabl could still bia estim higherlevel variabl effect model care requir interpret
5b5332e79aefa3b913d42a434b8ddb09b31b5b2e,Voronoi diagrams—a survey of a fundamental geometric data structure,"Computational geometry is concerned with the design and analysis of algorithms for geometrical problems. In addition, other more practically oriented, areas of computer science— such as computer graphics, computer-aided design, robotics, pattern recognition, and operations research—give rise to problems that inherently are geometrical. This is one reason computational geometry has attracted enormous research interest in the past decade and is a well-established area today. (For standard sources, we refer to the survey article by Lee and Preparata [19841 and to the textbooks by Preparata and Shames [1985] and Edelsbrunner [1987bl.) Readers familiar with the literature of computational geometry will have noticed, especially in the last few years, an increasing interest in a geometrical construct called the Voronoi diagram. This trend can also be observed in combinatorial geometry and in a considerable number of articles in natural science journals that address the Voronoi diagram under different names specific to the respective area. Given some number of points in the plane, their Voronoi diagram divides the plane according to the nearest-neighbor",comput geometri concern design analysi algorithm geometr problem addit practic orient area comput scienc comput graphic computeraid design robot pattern recognit oper researchg rise problem inher geometr one reason comput geometri attract enorm research interest past decad wellestablish area today standard sourc refer survey articl lee preparata textbook preparata shame edelsbrunn bl reader familiar literatur comput geometri notic especi last year increas interest geometr construct call voronoi diagram trend also observ combinatori geometri consider number articl natur scienc journal address voronoi diagram differ name specif respect area given number point plane voronoi diagram divid plane accord nearestneighbor
b9921fb4d1448058642897797e77bdaf8f444404,Text as Data: The Promise and Pitfalls of Automatic Content Analysis Methods for Political Texts,"Politics and political conflict often occur in the written and spoken word. Scholars have long recognized this, but the massive costs of analyzing even moderately sized collections of texts have hindered their use in political science research. Here lies the promise of automated text analysis: it substantially reduces the costs of analyzing large collections of text. We provide a guide to this exciting new area of research and show how, in many instances, the methods have already obtained part of their promise. But there are pitfalls to using automated methods—they are no substitute for careful thought and close reading and require extensive and problem-specific validation. We survey a wide range of new methods, provide guidance on how to validate the output of the models, and clarify misconceptions and errors in the literature. To conclude, we argue that for automated text methods to become a standard tool for political scientists, methodologists must contribute new methods and new methods of validation.",polit polit conflict often occur written spoken word scholar long recogn massiv cost analyz even moder size collect text hinder use polit scienc research lie promis autom text analysi substanti reduc cost analyz larg collect text provid guid excit new area research show mani instanc method alreadi obtain part promis pitfal use autom methodsthey substitut care thought close read requir extens problemspecif valid survey wide rang new method provid guidanc valid output model clarifi misconcept error literatur conclud argu autom text method becom standard tool polit scientist methodologist must contribut new method new method valid
8e600778160ff986b5460bc2584066148e55e5d4,Protein structure determination using metagenome sequence data,"Filling in the protein fold picture Fewer than a third of the 14,849 known protein families have at least one member with an experimentally determined structure. This leaves more than 5000 protein families with no structural information. Protein modeling using residue-residue contacts inferred from evolutionary data has been successful in modeling unknown structures, but it requires large numbers of aligned sequences. Ovchinnikov et al. augmented such sequence alignments with metagenome sequence data (see the Perspective by Söding). They determined the number of sequences required to allow modeling, developed criteria for model quality, and, where possible, improved modeling by matching predicted contacts to known structures. Their method predicted quality structural models for 614 protein families, of which about 140 represent newly discovered protein folds. Science, this issue p. 294; see also p. 248 Combining metagenome data with protein structure prediction generates models for 614 families with unknown structures. Despite decades of work by structural biologists, there are still ~5200 protein families with unknown structure outside the range of comparative modeling. We show that Rosetta structure prediction guided by residue-residue contacts inferred from evolutionary information can accurately model proteins that belong to large families and that metagenome sequence data more than triple the number of protein families with sufficient sequences for accurate modeling. We then integrate metagenome data, contact-based structure matching, and Rosetta structure calculations to generate models for 614 protein families with currently unknown structures; 206 are membrane proteins and 137 have folds not represented in the Protein Data Bank. This approach provides the representative models for large protein families originally envisioned as the goal of the Protein Structure Initiative at a fraction of the cost.",fill protein fold pictur fewer third known protein famili least one member experiment determin structur leav protein famili structur inform protein model use residueresidu contact infer evolutionari data success model unknown structur requir larg number align sequenc ovchinnikov et al augment sequenc align metagenom sequenc data see perspect söding determin number sequenc requir allow model develop criteria model qualiti possibl improv model match predict contact known structur method predict qualiti structur model protein famili repres newli discov protein fold scienc issu p see also p combin metagenom data protein structur predict gener model famili unknown structur despit decad work structur biologist still protein famili unknown structur outsid rang compar model show rosetta structur predict guid residueresidu contact infer evolutionari inform accur model protein belong larg famili metagenom sequenc data tripl number protein famili suffici sequenc accur model integr metagenom data contactbas structur match rosetta structur calcul gener model protein famili current unknown structur membran protein fold repres protein data bank approach provid repres model larg protein famili origin envis goal protein structur initi fraction cost
bfcf1ed94050a4c60d459cd02456dfd9f08fdb4c,"Statistics for experimenters : an introduction to design, data analysis, and model building","Science and Statistics. COMPARING TWO TREATMENTS. Use of External Reference Distribution to Compare Two Means. Random Sampling and the Declaration of Independence. Randomization and Blocking with Paired Comparisons. Significance Tests and Confidence Intervals for Means, Variances, Proportions and Frequences. COMPARING MORE THAN TWO TREATMENTS. Experiments to Compare k Treatment Means. Randomized Block and Two--Way Factorial Designs. Designs with More Than One Blocking Variable. MEASURING THE EFFECTS OF VARIABLES. Empirical Modeling. Factorial Designs at Two Levels. More Applications of Factorial Designs. Fractional Factorial Designs at Two Levels. More Applications of Fractional Factorial Designs. BUILDING MODELS AND USING THEM. Simple Modeling with Least Squares (Regression Analysis). Response Surface Methods. Mechanistic Model Building. Study of Variation. Modeling Dependence: Times Series. Appendix Tables. Index.",scienc statist compar two treatment use extern refer distribut compar two mean random sampl declar independ random block pair comparison signific test confid interv mean varianc proport frequenc compar two treatment experi compar k treatment mean random block twoway factori design design one block variabl measur effect variabl empir model factori design two level applic factori design fraction factori design two level applic fraction factori design build model use simpl model least squar regress analysi respons surfac method mechanist model build studi variat model depend time seri appendix tabl index
88a55ee54aae117f06441459d1ad2330ce18d7e0,Emerging problems of data quality in citizen science,,nan
bf96377353bf9daa8dc0e98eee17335f54cbcc60,Data science as an academic discipline,"I recall being a proud young academic about 1970; I had just received a research grant to build and study a scientific database, and I had joined CODATA. I was looking forward to the future in this new exciting discipline when the head of my department, an internationally known professor, advised me that data was “a low level activity” not suitable for an academic. I recall my dismay. What can we do to ensure that this does not happen again and that data science is universally recognized as a worthwhile academic activity? Incidentally, I did not take that advice, or I would not be writing this essay, but moved into computer science. I will use my experience to draw comparisons between the problems computer science had to become academically recognized and those faced by data science.",recal proud young academ receiv research grant build studi scientif databas join codata look forward futur new excit disciplin head depart intern known professor advis data low level activ suitabl academ recal dismay ensur happen data scienc univers recogn worthwhil academ activ incident take advic would write essay move comput scienc use experi draw comparison problem comput scienc becom academ recogn face data scienc
1842a5fb9739149dadba962c94dd7243a5f62242,What is Data Science ? Fundamental Concepts and a Heuristic Example,,nan
09ee0ba924ffd21fc7e14ad3147284133cf2f576,"Color Science, Concepts and Methods. Quantitative Data and Formulas","G. Wyszecki and W. S. Stiles London: John Wiley. 1967. Pp. xiv + 628. Price £11. This remarkable and unusual book is by two outstanding authorities on the science of colour: Dr. Stiles, for many years a senior member of the Light Division at the National Physical Laboratory, and Dr. Wyszecki, currently in charge of the Radiation Optics Section of the Canadian National Research Council. The authors' aim has been to provide a comprehensive source book of data required by the practical and theoretical worker in the field of colour and they have achieved this aim so successfully that their book is likely to become the standard work on the subject and to remain so for a good many years.",g wyszecki w stile london john wiley pp xiv price remark unusu book two outstand author scienc colour dr stile mani year senior member light divis nation physic laboratori dr wyszecki current charg radiat optic section canadian nation research council author aim provid comprehens sourc book data requir practic theoret worker field colour achiev aim success book like becom standard work subject remain good mani year
06ba782753bad19254db5d28ad4155556f286ee0,Data Management and Analysis Methods,"This chapter is about methods for managing and analyzing qualitative data. By qualitative data the authors mean text: newspapers, movies, sitcoms, e-mail traffic, folktales, life histories. They also mean narratives--narratives about getting divorced, about being sick, about surviving hand-to-hand combat, about selling sex, about trying to quit smoking. In fact, most of the archaeologically recoverable information about human thought and human behavior is text, the good stuff of social science.",chapter method manag analyz qualit data qualit data author mean text newspap movi sitcom email traffic folktal life histori also mean narrativesnarr get divorc sick surviv handtohand combat sell sex tri quit smoke fact archaeolog recover inform human thought human behavior text good stuff social scienc
116927fbe4c9732fd1e392035a100c33b14e9d59,Big Data and cloud computing: innovation opportunities and challenges,"ABSTRACT Big Data has emerged in the past few years as a new paradigm providing abundant data and opportunities to improve and/or enable research and decision-support applications with unprecedented value for digital earth applications including business, sciences and engineering. At the same time, Big Data presents challenges for digital earth to store, transport, process, mine and serve the data. Cloud computing provides fundamental support to address the challenges with shared computing resources including computing, storage, networking and analytical software; the application of these resources has fostered impressive Big Data advancements. This paper surveys the two frontiers – Big Data and cloud computing – and reviews the advantages and consequences of utilizing cloud computing to tackling Big Data in the digital earth and relevant science domains. From the aspects of a general introduction, sources, challenges, technology status and research opportunities, the following observations are offered: (i) cloud computing and Big Data enable science discoveries and application developments; (ii) cloud computing provides major solutions for Big Data; (iii) Big Data, spatiotemporal thinking and various application domains drive the advancement of cloud computing and relevant technologies with new requirements; (iv) intrinsic spatiotemporal principles of Big Data and geospatial sciences provide the source for finding technical and theoretical solutions to optimize cloud computing and processing Big Data; (v) open availability of Big Data and processing capability pose social challenges of geospatial significance and (vi) a weave of innovations is transforming Big Data into geospatial research, engineering and business values. This review introduces future innovations and a research agenda for cloud computing supporting the transformation of the volume, velocity, variety and veracity into values of Big Data for local to global digital earth science and applications.",abstract big data emerg past year new paradigm provid abund data opportun improv andor enabl research decisionsupport applic unpreced valu digit earth applic includ busi scienc engin time big data present challeng digit earth store transport process mine serv data cloud comput provid fundament support address challeng share comput resourc includ comput storag network analyt softwar applic resourc foster impress big data advanc paper survey two frontier big data cloud comput review advantag consequ util cloud comput tackl big data digit earth relev scienc domain aspect gener introduct sourc challeng technolog statu research opportun follow observ offer cloud comput big data enabl scienc discoveri applic develop ii cloud comput provid major solut big data iii big data spatiotempor think variou applic domain drive advanc cloud comput relev technolog new requir iv intrins spatiotempor principl big data geospati scienc provid sourc find technic theoret solut optim cloud comput process big data v open avail big data process capabl pose social challeng geospati signific vi weav innov transform big data geospati research engin busi valu review introduc futur innov research agenda cloud comput support transform volum veloc varieti verac valu big data local global digit earth scienc applic
ff1068a7e2acaa41fae2a8e1b180264434f06ce8,Liberating field science samples and data,"Promote reproducibility by moving beyond “available upon request” Transparency and reproducibility enhance the integrity of research results for scientific and public uses and empower novel research applications. Access to data, samples, methods, and reagents used to conduct research and analysis, as well as to the code used to analyze and process data and samples, is a fundamental requirement for transparency and reproducibility. The field sciences (e.g., geology, ecology, and archaeology), where each study is temporally (and often spatially) unique, provide exemplars for the importance of preserving data and samples for further analysis. Yet field sciences, if they even address such access, commonly do so by simply noting “data and samples available upon request.” They lag behind some laboratory sciences in making data and samples available to the broader research community. It is time for this to change. We discuss cultural, financial, and technical barriers to change and ways in which funders, publishers, scientific societies, and others are responding.",promot reproduc move beyond avail upon request transpar reproduc enhanc integr research result scientif public use empow novel research applic access data sampl method reagent use conduct research analysi well code use analyz process data sampl fundament requir transpar reproduc field scienc eg geolog ecolog archaeolog studi tempor often spatial uniqu provid exemplar import preserv data sampl analysi yet field scienc even address access commonli simpli note data sampl avail upon request lag behind laboratori scienc make data sampl avail broader research commun time chang discuss cultur financi technic barrier chang way funder publish scientif societi other respond
ecb81c5d18e38b29316da77f69c8a36d5b98f196,scmap: projection of single-cell RNA-seq data across data sets,,nan
952241d28abed7d221fc059845043a6463a522bc,Qualitative Descriptive Methods in Health Science Research,"Objective: The purpose of this methodology paper is to describe an approach to qualitative design known as qualitative descriptive that is well suited to junior health sciences researchers because it can be used with a variety of theoretical approaches, sampling techniques, and data collection strategies. Background: It is often difficult for junior qualitative researchers to pull together the tools and resources they need to embark on a high-quality qualitative research study and to manage the volumes of data they collect during qualitative studies. This paper seeks to pull together much needed resources and provide an overview of methods. Methods: A step-by-step guide to planning a qualitative descriptive study and analyzing the data is provided, utilizing exemplars from the authors’ research. Results: This paper presents steps to conducting a qualitative descriptive study under the following headings: describing the qualitative descriptive approach, designing a qualitative descriptive study, steps to data analysis, and ensuring rigor of findings. Conclusions: The qualitative descriptive approach results in a summary in everyday, factual language that facilitates understanding of a selected phenomenon across disciplines of health science researchers.",object purpos methodolog paper describ approach qualit design known qualit descript well suit junior health scienc research use varieti theoret approach sampl techniqu data collect strategi background often difficult junior qualit research pull togeth tool resourc need embark highqual qualit research studi manag volum data collect qualit studi paper seek pull togeth much need resourc provid overview method method stepbystep guid plan qualit descript studi analyz data provid util exemplar author research result paper present step conduct qualit descript studi follow head describ qualit descript approach design qualit descript studi step data analysi ensur rigor find conclus qualit descript approach result summari everyday factual languag facilit understand select phenomenon across disciplin health scienc research
915cd8e2b39eb02723553913d592b2237d4d9960,Data science: An action plan for expanding the technical areas of the field of statistics,"An action plan to expand the technical areas of statistics focuses on the data analyst. The plan sets out six technical areas of work for a university department and advocates a specific allocation of resources devoted to research in each area and to courses in each area. The value of technical work is judged by the extent to which it benefits the data analyst, either directly or indirectly. The plan is also applicable to government research labs and corporate research organizations.",action plan expand technic area statist focus data analyst plan set six technic area work univers depart advoc specif alloc resourc devot research area cours area valu technic work judg extent benefit data analyst either directli indirectli plan also applic govern research lab corpor research organ
d62126bfe0e1b299c9383bb30ee099c77aee5222,"Interpreting Qualitative Data: Methods for Analysing Talk, Text and Interaction","This a much expanded and updated version of David Silvermans best-selling introductory textbook for the beginning qualitative researcher. 
 
Features of the New Edition: 
• Takes account of the flood of qualitative work since the 1990s 
• All chapters have been substantially rewritten with the aim of greater clarity 
• A new chapter on Visual Images and a considerably expanded treatment of discourse analysis are provided 
• The number of student exercises has been considerably increased and are now present at the end of every chapter 
• An even greater degree of student accessibility: Key Points and Recommended Readings appear at the end of each chapter and technical terms are highlighted and appear in a Glossary 
• A more inter-disciplinary social science text which takes account of the growing interest in qualitative research outside sociology and anthropology from psychology to geography, information systems, health promotion, management and many other disciplines 
• Expanded coverage 50% longer than the First Edition 
This book has a more recent edition (2006)",much expand updat version david silverman bestsel introductori textbook begin qualit research featur new edit take account flood qualit work sinc chapter substanti rewritten aim greater clariti new chapter visual imag consider expand treatment discours analysi provid number student exercis consider increas present end everi chapter even greater degre student access key point recommend read appear end chapter technic term highlight appear glossari interdisciplinari social scienc text take account grow interest qualit research outsid sociolog anthropolog psycholog geographi inform system health promot manag mani disciplin expand coverag longer first edit book recent edit
835a5484292f32a3c02f507cbd8fb1f5d9f4aacf,The natural selection of bad science,"Poor research design and data analysis encourage false-positive findings. Such poor methods persist despite perennial calls for improvement, suggesting that they result from something more than just misunderstanding. The persistence of poor methods results partly from incentives that favour them, leading to the natural selection of bad science. This dynamic requires no conscious strategizing—no deliberate cheating nor loafing—by scientists, only that publication is a principal factor for career advancement. Some normative methods of analysis have almost certainly been selected to further publication instead of discovery. In order to improve the culture of science, a shift must be made away from correcting misunderstandings and towards rewarding understanding. We support this argument with empirical evidence and computational modelling. We first present a 60-year meta-analysis of statistical power in the behavioural sciences and show that power has not improved despite repeated demonstrations of the necessity of increasing power. To demonstrate the logical consequences of structural incentives, we then present a dynamic model of scientific communities in which competing laboratories investigate novel or previously published hypotheses using culturally transmitted research methods. As in the real world, successful labs produce more ‘progeny,’ such that their methods are more often copied and their students are more likely to start labs of their own. Selection for high output leads to poorer methods and increasingly high false discovery rates. We additionally show that replication slows but does not stop the process of methodological deterioration. Improving the quality of research requires change at the institutional level.",poor research design data analysi encourag falseposit find poor method persist despit perenni call improv suggest result someth misunderstand persist poor method result partli incent favour lead natur select bad scienc dynam requir consciou strategizingno deliber cheat loafingbi scientist public princip factor career advanc norm method analysi almost certainli select public instead discoveri order improv cultur scienc shift must made away correct misunderstand toward reward understand support argument empir evid comput model first present year metaanalysi statist power behaviour scienc show power improv despit repeat demonstr necess increas power demonstr logic consequ structur incent present dynam model scientif commun compet laboratori investig novel previous publish hypothes use cultur transmit research method real world success lab produc progeni method often copi student like start lab select high output lead poorer method increasingli high fals discoveri rate addit show replic slow stop process methodolog deterior improv qualiti research requir chang institut level
c3665722a7cc81caca8c90ac3c5b0572f7bba055,Can citizen science enhance public understanding of science?,"Over the past 20 years, thousands of citizen science projects engaging millions of participants in collecting and/or processing data have sprung up around the world. Here we review documented outcomes from four categories of citizen science projects which are defined by the nature of the activities in which their participants engage – Data Collection, Data Processing, Curriculum-based, and Community Science. We find strong evidence that scientific outcomes of citizen science are well documented, particularly for Data Collection and Data Processing projects. We find limited but growing evidence that citizen science projects achieve participant gains in knowledge about science knowledge and process, increase public awareness of the diversity of scientific research, and provide deeper meaning to participants’ hobbies. We also find some evidence that citizen science can contribute positively to social well-being by influencing the questions that are being addressed and by giving people a voice in local environmental decision making. While not all citizen science projects are intended to achieve a greater degree of public understanding of science, social change, or improved science -society relationships, those projects that do require effort and resources in four main categories: (1) project design, (2) outcomes measurement, (3) engagement of new audiences, and (4) new directions for research.",past year thousand citizen scienc project engag million particip collect andor process data sprung around world review document outcom four categori citizen scienc project defin natur activ particip engag data collect data process curriculumbas commun scienc find strong evid scientif outcom citizen scienc well document particularli data collect data process project find limit grow evid citizen scienc project achiev particip gain knowledg scienc knowledg process increas public awar divers scientif research provid deeper mean particip hobbi also find evid citizen scienc contribut posit social wellb influenc question address give peopl voic local environment decis make citizen scienc project intend achiev greater degre public understand scienc social chang improv scienc societi relationship project requir effort resourc four main categori project design outcom measur engag new audienc new direct research
e281464d9a558cc1d25084687efb75683e65d4f0,Growth rates of modern science: A bibliometric analysis based on the number of publications and cited references,"Many studies (in information science) have looked at the growth of science. In this study, we reexamine the question of the growth of science. To do this we (a) use current data up to publication year 2012 and (b) analyze the data across all disciplines and also separately for the natural sciences and for the medical and health sciences. Furthermore, the data were analyzed with an advanced statistical technique—segmented regression analysis—which can identify specific segments with similar growth rates in the history of science. The study is based on two different sets of bibliometric data: (a) the number of publications held as source items in the Web of Science (WoS, Thomson Reuters) per publication year and (b) the number of cited references in the publications of the source items per cited reference year. We looked at the rate at which science has grown since the mid‐1600s. In our analysis of cited references we identified three essential growth phases in the development of science, which each led to growth rates tripling in comparison with the previous phase: from less than 1% up to the middle of the 18th century, to 2 to 3% up to the period between the two world wars, and 8 to 9% to 2010.",mani studi inform scienc look growth scienc studi reexamin question growth scienc use current data public year b analyz data across disciplin also separ natur scienc medic health scienc furthermor data analyz advanc statist techniqueseg regress analysiswhich identifi specif segment similar growth rate histori scienc studi base two differ set bibliometr data number public held sourc item web scienc wo thomson reuter per public year b number cite refer public sourc item per cite refer year look rate scienc grown sinc mid analysi cite refer identifi three essenti growth phase develop scienc led growth rate tripl comparison previou phase less middl th centuri period two world war
ff7a79011e4ddba98474efe776432ac2b4431473,Citizen science and the United Nations Sustainable Development Goals,,nan
43d75d3a22db904d052d4c435e2d1f22be3887e0,Outlier Detection for Temporal Data: A Survey,"In the statistics community, outlier detection for time series data has been studied for decades. Recently, with advances in hardware and software technology, there has been a large body of work on temporal outlier detection from a computational perspective within the computer science community. In particular, advances in hardware technology have enabled the availability of various forms of temporal data collection mechanisms, and advances in software technology have enabled a variety of data management mechanisms. This has fueled the growth of different kinds of data sets such as data streams, spatio-temporal data, distributed streams, temporal networks, and time series data, generated by a multitude of applications. There arises a need for an organized and detailed study of the work done in the area of outlier detection with respect to such temporal datasets. In this survey, we provide a comprehensive and structured overview of a large set of interesting outlier definitions for various forms of temporal data, novel techniques, and application scenarios in which specific definitions and techniques have been widely used.",statist commun outlier detect time seri data studi decad recent advanc hardwar softwar technolog larg bodi work tempor outlier detect comput perspect within comput scienc commun particular advanc hardwar technolog enabl avail variou form tempor data collect mechan advanc softwar technolog enabl varieti data manag mechan fuel growth differ kind data set data stream spatiotempor data distribut stream tempor network time seri data gener multitud applic aris need organ detail studi work done area outlier detect respect tempor dataset survey provid comprehens structur overview larg set interest outlier definit variou form tempor data novel techniqu applic scenario specif definit techniqu wide use
023eb29b711014b1a3d2895e19a0fc2aed7a6ab4,Data Science and Classification,,nan
e048f6fdb0a728638af5d8684a32b3dc2ee83259,Big Data and Science: Myths and Reality,,nan
de5acd80c5fd8db442a4a5e5ffbc3f3f51161237,"Data Science, Classification and Related Methods",,nan
f03a847c6325d7d5973efd687d2ca86a9c06dd76,Advances in data science and classification,,nan
197b30ab1460fe200dba90dc3392ad49a92c2ca4,Between Data Science and Applied Data Analysis,,nan
cff7b1b98da6de583bf2d5ffd496c2e6d70a794c,From DFT to machine learning: recent approaches to materials science–a review,"Recent advances in experimental and computational methods are increasing the quantity and complexity of generated data. This massive amount of raw data needs to be stored and interpreted in order to advance the materials science field. Identifying correlations and patterns from large amounts of complex data is being performed by machine learning algorithms for decades. Recently, the materials science community started to invest in these methodologies to extract knowledge and insights from the accumulated data. This review follows a logical sequence starting from density functional theory as the representative instance of electronic structure methods, to the subsequent high-throughput approach, used to generate large amounts of data. Ultimately, data-driven strategies which include data mining, screening, and machine learning techniques, employ the data generated. We show how these approaches to modern computational materials science are being used to uncover complexities and design novel materials with enhanced properties. Finally, we point to the present research problems, challenges, and potential future perspectives of this new exciting field.",recent advanc experiment comput method increas quantiti complex gener data massiv amount raw data need store interpret order advanc materi scienc field identifi correl pattern larg amount complex data perform machin learn algorithm decad recent materi scienc commun start invest methodolog extract knowledg insight accumul data review follow logic sequenc start densiti function theori repres instanc electron structur method subsequ highthroughput approach use gener larg amount data ultim datadriven strategi includ data mine screen machin learn techniqu employ data gener show approach modern comput materi scienc use uncov complex design novel materi enhanc properti final point present research problem challeng potenti futur perspect new excit field
7ac8f533a18f584387dd412a0a27feb9af1c5c93,A Systematic Review on Imbalanced Data Challenges in Machine Learning,"In machine learning, the data imbalance imposes challenges to perform data analytics in almost all areas of real-world research. The raw primary data often suffers from the skewed perspective of data distribution of one class over the other as in the case of computer vision, information security, marketing, and medical science. The goal of this article is to present a comparative analysis of the approaches from the reference of data pre-processing, algorithmic and hybrid paradigms for contemporary imbalance data analysis techniques, and their comparative study in lieu of different data distribution and their application areas.",machin learn data imbal impos challeng perform data analyt almost area realworld research raw primari data often suffer skew perspect data distribut one class case comput vision inform secur market medic scienc goal articl present compar analysi approach refer data preprocess algorithm hybrid paradigm contemporari imbal data analysi techniqu compar studi lieu differ data distribut applic area
4d12b00963aa6e0d9b9b84a62f0543de608fccb5,"If We Share Data, Will Anyone Use Them? Data Sharing and Reuse in the Long Tail of Science and Technology","Research on practices to share and reuse data will inform the design of infrastructure to support data collection, management, and discovery in the long tail of science and technology. These are research domains in which data tend to be local in character, minimally structured, and minimally documented. We report on a ten-year study of the Center for Embedded Network Sensing (CENS), a National Science Foundation Science and Technology Center. We found that CENS researchers are willing to share their data, but few are asked to do so, and in only a few domain areas do their funders or journals require them to deposit data. Few repositories exist to accept data in CENS research areas.. Data sharing tends to occur only through interpersonal exchanges. CENS researchers obtain data from repositories, and occasionally from registries and individuals, to provide context, calibration, or other forms of background for their studies. Neither CENS researchers nor those who request access to CENS data appear to use external data for primary research questions or for replication of studies. CENS researchers are willing to share data if they receive credit and retain first rights to publish their results. Practices of releasing, sharing, and reusing of data in CENS reaffirm the gift culture of scholarship, in which goods are bartered between trusted colleagues rather than treated as commodities.",research practic share reus data inform design infrastructur support data collect manag discoveri long tail scienc technolog research domain data tend local charact minim structur minim document report tenyear studi center embed network sens cen nation scienc foundat scienc technolog center found cen research will share data ask domain area funder journal requir deposit data repositori exist accept data cen research area data share tend occur interperson exchang cen research obtain data repositori occasion registri individu provid context calibr form background studi neither cen research request access cen data appear use extern data primari research question replic studi cen research will share data receiv credit retain first right publish result practic releas share reus data cen reaffirm gift cultur scholarship good barter trust colleagu rather treat commod
27245e65a27bde90b5b0bb25d157bb75a0ad8b5a,A survey of machine learning for big data processing,,nan
2e096b5fe420e09e3a7ea3b1e8f1501495d8b07e,Operationalizing the CARE and FAIR Principles for Indigenous data futures,,nan
0efa865dd45bcee8194bfe709b0f81789f6d5341,Data sharing practices and data availability upon request differ across scientific disciplines,,nan
27245e65a27bde90b5b0bb25d157bb75a0ad8b5a,A survey of machine learning for big data processing,,nan
2e096b5fe420e09e3a7ea3b1e8f1501495d8b07e,Operationalizing the CARE and FAIR Principles for Indigenous data futures,,nan
0efa865dd45bcee8194bfe709b0f81789f6d5341,Data sharing practices and data availability upon request differ across scientific disciplines,,nan
d11eb2610f099db2490434d04543afcdd49ac532,Data Feminism,"Feminism, at its very core, aims to dismantle systems of oppression; however, the identification of which systems are oppressive and what kinds of beings are harmed by them has been the subject of debate in feminist circles for more than a century. Across the many waves of feminist movements and throughout the halls of humanities and social sciences departments around the world, feminist thought and feminist practices are heavily contested and often come into conflict. From difference and discord arise efforts to make both feminism and the world a more inclusive and just place. Yet there remain strong tensions over how to define feminism, how to realize feminists’ demands, how to apply feminist theory to a wide variety of subject matter, and how to bridge the gaps between theory and practice to build a better world for all. In an ambitious attempt to resolve some of those tensions in the field of data science, Catherine D’Ignazio and Lauren F. Klein’s 2021 book, Data Feminism, poses seven principles and strategies that are worthy of examination for those of us who might not hold the title of “data scientist,” but work with data nonetheless. As geographers and geography departments engage in efforts to improve our approaches to justice and equity, the principles of data feminism can be effective tools to guide our discussions for how to integrate feminism into our research practices and pedagogy, as well for how we apply geography in the public sphere.",femin core aim dismantl system oppress howev identif system oppress kind be harm subject debat feminist circl centuri across mani wave feminist movement throughout hall human social scienc depart around world feminist thought feminist practic heavili contest often come conflict differ discord aris effort make femin world inclus place yet remain strong tension defin femin realiz feminist demand appli feminist theori wide varieti subject matter bridg gap theori practic build better world ambiti attempt resolv tension field data scienc catherin dignazio lauren f klein book data femin pose seven principl strategi worthi examin us might hold titl data scientist work data nonetheless geograph geographi depart engag effort improv approach justic equiti principl data femin effect tool guid discuss integr femin research practic pedagogi well appli geographi public sphere
846883b7761cb5fe4468d42bf9d328b5d1030175,"The Zwicky Transient Facility: Data Processing, Products, and Archive","The Zwicky Transient Facility (ZTF) is a new robotic time-domain survey currently in progress using the Palomar 48-inch Schmidt Telescope. ZTF uses a 47 square degree field with a 600 megapixel camera to scan the entire northern visible sky at rates of ∼3760 square degrees/hour to median depths of g ∼ 20.8 and r ∼ 20.6 mag (AB, 5σ in 30 sec). We describe the Science Data System that is housed at IPAC, Caltech. This comprises the data-processing pipelines, alert production system, data archive, and user interfaces for accessing and analyzing the products. The real-time pipeline employs a novel image-differencing algorithm, optimized for the detection of point-source transient events. These events are vetted for reliability using a machine-learned classifier and combined with contextual information to generate data-rich alert packets. The packets become available for distribution typically within 13 minutes (95th percentile) of observation. Detected events are also linked to generate candidate moving-object tracks using a novel algorithm. Objects that move fast enough to streak in the individual exposures are also extracted and vetted. We present some preliminary results of the calibration performance delivered by the real-time pipeline. The reconstructed astrometric accuracy per science image with respect to Gaia DR1 is typically 45 to 85 milliarcsec. This is the RMS per-axis on the sky for sources extracted with photometric S/N ≥ 10 and hence corresponds to the typical astrometric uncertainty down to this limit. The derived photometric precision (repeatability) at bright unsaturated fluxes varies between 8 and 25 millimag. The high end of these ranges corresponds to an airmass approaching ∼2—the limit of the public survey. Photometric calibration accuracy with respect to Pan-STARRS1 is generally better than 2%. The products support a broad range of scientific applications: fast and young supernovae; rare flux transients; variable stars; eclipsing binaries; variability from active galactic nuclei; counterparts to gravitational wave sources; a more complete census of Type Ia supernovae; and solar-system objects.",zwicki transient facil ztf new robot timedomain survey current progress use palomar inch schmidt telescop ztf use squar degre field megapixel camera scan entir northern visibl sky rate squar degreeshour median depth g r mag ab σ sec describ scienc data system hous ipac caltech compris dataprocess pipelin alert product system data archiv user interfac access analyz product realtim pipelin employ novel imagedifferenc algorithm optim detect pointsourc transient event event vet reliabl use machinelearn classifi combin contextu inform gener datarich alert packet packet becom avail distribut typic within minut th percentil observ detect event also link gener candid movingobject track use novel algorithm object move fast enough streak individu exposur also extract vet present preliminari result calibr perform deliv realtim pipelin reconstruct astrometr accuraci per scienc imag respect gaia dr typic milliarcsec rm peraxi sky sourc extract photometr sn henc correspond typic astrometr uncertainti limit deriv photometr precis repeat bright unsatur flux vari millimag high end rang correspond airmass approach limit public survey photometr calibr accuraci respect panstarr gener better product support broad rang scientif applic fast young supernova rare flux transient variabl star eclips binari variabl activ galact nuclei counterpart gravit wave sourc complet censu type ia supernova solarsystem object
d65d64c3f6ea322d9e85138fe5c8e85acbf661e3,A Bibliometric Analysis and Visualization of Medical Big Data Research,"With the rapid development of “Internet plus”, medical care has entered the era of big data. However, there is little research on medical big data (MBD) from the perspectives of bibliometrics and visualization. The substantive research on the basic aspects of MBD itself is also rare. This study aims to explore the current status of medical big data through visualization analysis on the journal papers related to MBD. We analyze a total of 988 references which were downloaded from the Science Citation Index Expanded and the Social Science Citation Index databases from Web of Science and the time span was defined as “all years”. The GraphPad Prism 5, VOSviewer and CiteSpace softwares are used for analysis. Many results concerning the annual trends, the top players in terms of journal and institute levels, the citations and H-index in terms of country level, the keywords distribution, the highly cited papers, the co-authorship status and the most influential journals and authors are presented in this paper. This study points out the development status and trends on MBD. It can help people in the medical profession to get comprehensive understanding on the state of the art of MBD. It also has reference values for the research and application of the MBD visualization methods.",rapid develop internet plu medic care enter era big data howev littl research medic big data mbd perspect bibliometr visual substant research basic aspect mbd also rare studi aim explor current statu medic big data visual analysi journal paper relat mbd analyz total refer download scienc citat index expand social scienc citat index databas web scienc time span defin year graphpad prism vosview citespac softwar use analysi mani result concern annual trend top player term journal institut level citat hindex term countri level keyword distribut highli cite paper coauthorship statu influenti journal author present paper studi point develop statu trend mbd help peopl medic profess get comprehens understand state art mbd also refer valu research applic mbd visual method
c1e49d830e67269d4d2053a5f124ea773c79b740,Computational social science: Obstacles and opportunities,"Data sharing, research ethics, and incentives must improve The field of computational social science (CSS) has exploded in prominence over the past decade, with thousands of papers published using observational data, experimental designs, and large-scale simulations that were once unfeasible or unavailable to researchers. These studies have greatly improved our understanding of important phenomena, ranging from social inequality to the spread of infectious diseases. The institutions supporting CSS in the academy have also grown substantially, as evidenced by the proliferation of conferences, workshops, and summer schools across the globe, across disciplines, and across sources of data. But the field has also fallen short in important ways. Many institutional structures around the field—including research ethics, pedagogy, and data infrastructure—are still nascent. We suggest opportunities to address these issues, especially in improving the alignment between the organization of the 20th-century university and the intellectual requirements of the field.",data share research ethic incent must improv field comput social scienc css explod promin past decad thousand paper publish use observ data experiment design largescal simul unfeas unavail research studi greatli improv understand import phenomena rang social inequ spread infecti diseas institut support css academi also grown substanti evidenc prolifer confer workshop summer school across globe across disciplin across sourc data field also fallen short import way mani institut structur around fieldinclud research ethic pedagogi data infrastructurear still nascent suggest opportun address issu especi improv align organ thcenturi univers intellectu requir field
3859aef8d52ef1bad6351ec25c4fe4009b184689,Characterization of the LIGO detectors during their sixth science run,"In 2009-2010, the Laser Interferometer Gravitational-wave Observa- tory (LIGO) operated together with international partners Virgo and GEO600 as a network to search for gravitational waves of astrophysical origin. The sensitiv- ity of these detectors was limited by a combination of noise sources inherent to the instrumental design and its environment, often localized in time or frequency, that couple into the gravitational-wave readout. Here we review the performance of the LIGO instruments during this epoch, the work done to characterize the de- tectors and their data, and the effect that transient and continuous noise artefacts have on the sensitivity of LIGO to a variety of astrophysical sources.",laser interferomet gravitationalwav observa tori ligo oper togeth intern partner virgo geo network search gravit wave astrophys origin sensitiv iti detector limit combin nois sourc inher instrument design environ often local time frequenc coupl gravitationalwav readout review perform ligo instrument epoch work done character de tector data effect transient continu nois artefact sensit ligo varieti astrophys sourc
ecef432e7f6c9f431d5b34706a8de1fdebec46f9,From Big Data to Precision Medicine,"For over a decade the term “Big data” has been used to describe the rapid increase in volume, variety and velocity of information available, not just in medical research but in almost every aspect of our lives. As scientists, we now have the capacity to rapidly generate, store and analyse data that, only a few years ago, would have taken many years to compile. However, “Big data” no longer means what it once did. The term has expanded and now refers not to just large data volume, but to our increasing ability to analyse and interpret those data. Tautologies such as “data analytics” and “data science” have emerged to describe approaches to the volume of available information as it grows ever larger. New methods dedicated to improving data collection, storage, cleaning, processing and interpretation continue to be developed, although not always by, or for, medical researchers. Exploiting new tools to extract meaning from large volume information has the potential to drive real change in clinical practice, from personalized therapy and intelligent drug design to population screening and electronic health record mining. As ever, where new technology promises “Big Advances,” significant challenges remain. Here we discuss both the opportunities and challenges posed to biomedical research by our increasing ability to tackle large datasets. Important challenges include the need for standardization of data content, format, and clinical definitions, a heightened need for collaborative networks with sharing of both data and expertise and, perhaps most importantly, a need to reconsider how and when analytic methodology is taught to medical researchers. We also set “Big data” analytics in context: recent advances may appear to promise a revolution, sweeping away conventional approaches to medical science. However, their real promise lies in their synergy with, not replacement of, classical hypothesis-driven methods. The generation of novel, data-driven hypotheses based on interpretable models will always require stringent validation and experimental testing. Thus, hypothesis-generating research founded on large datasets adds to, rather than replaces, traditional hypothesis driven science. Each can benefit from the other and it is through using both that we can improve clinical practice.",decad term big data use describ rapid increas volum varieti veloc inform avail medic research almost everi aspect live scientist capac rapidli gener store analys data year ago would taken mani year compil howev big data longer mean term expand refer larg data volum increas abil analys interpret data tautolog data analyt data scienc emerg describ approach volum avail inform grow ever larger new method dedic improv data collect storag clean process interpret continu develop although alway medic research exploit new tool extract mean larg volum inform potenti drive real chang clinic practic person therapi intellig drug design popul screen electron health record mine ever new technolog promis big advanc signific challeng remain discuss opportun challeng pose biomed research increas abil tackl larg dataset import challeng includ need standard data content format clinic definit heighten need collabor network share data expertis perhap importantli need reconsid analyt methodolog taught medic research also set big data analyt context recent advanc may appear promis revolut sweep away convent approach medic scienc howev real promis lie synergi replac classic hypothesisdriven method gener novel datadriven hypothes base interpret model alway requir stringent valid experiment test thu hypothesisgener research found larg dataset add rather replac tradit hypothesi driven scienc benefit use improv clinic practic
04e5f980428e1ec35429356b3e43ea611fc0e975,Using Twitter for Demographic and Social Science Research: Tools for Data Collection and Processing,"Despite recent and growing interest in using Twitter to examine human behavior and attitudes, there is still significant room for growth regarding the ability to leverage Twitter data for social science research. In particular, gleaning demographic information about Twitter users—a key component of much social science research—remains a challenge. This article develops an accurate and reliable data processing approach for social science researchers interested in using Twitter data to examine behaviors and attitudes, as well as the demographic characteristics of the populations expressing or engaging in them. Using information gathered from Twitter users who state an intention to not vote in the 2012 presidential election, we describe and evaluate a method for processing data to retrieve demographic information reported by users that is not encoded as text (e.g., details of images) and evaluate the reliability of these techniques. We end by assessing the challenges of this data collection strategy and discussing how large-scale social media data may benefit demographic researchers.",despit recent grow interest use twitter examin human behavior attitud still signific room growth regard abil leverag twitter data social scienc research particular glean demograph inform twitter usersa key compon much social scienc researchremain challeng articl develop accur reliabl data process approach social scienc research interest use twitter data examin behavior attitud well demograph characterist popul express engag use inform gather twitter user state intent vote presidenti elect describ evalu method process data retriev demograph inform report user encod text eg detail imag evalu reliabl techniqu end assess challeng data collect strategi discuss largescal social media data may benefit demograph research
d33d879ea94fd36363dc7f015896ac6c0236acac,Data Preprocessing in Data Mining,,nan
238517ecdc0466ec6a25b79319c3a6b473a897c8,Deep mutational scanning: a new style of protein science,,nan
db019eec15d8080086bbc7dc8f5832e431202e0e,Jupyter: Thinking and Storytelling With Code and Data,"Project Jupyter is an open-source project for interactive computing widely used in data science, machine learning, and scientific computing. We argue that even though Jupyter helps users perform complex, technical work, Jupyter itself solves problems that are fundamentally human in nature. Namely, Jupyter helps humans to think and tell stories with code and data. We illustrate this by describing three dimensions of Jupyter: 1) interactive computing; 2) computational narratives; and 3) the idea that Jupyter is more than software. We illustrate the impact of these dimensions on a community of practice in earth and climate science.",project jupyt opensourc project interact comput wide use data scienc machin learn scientif comput argu even though jupyt help user perform complex technic work jupyt solv problem fundament human natur name jupyt help human think tell stori code data illustr describ three dimens jupyt interact comput comput narr idea jupyt softwar illustr impact dimens commun practic earth climat scienc
86b05bc7e953e683fa839ad01d6100a8f99558df,Concrete mathematics - a foundation for computer science,"From the Publisher: 
This book introduces the mathematics that supports advanced computer programming and the analysis of algorithms. The primary aim of its well-known authors is to provide a solid and relevant base of mathematical skills - the skills needed to solve complex problems, to evaluate horrendous sums, and to discover subtle patterns in data. It is an indispensable text and reference not only for computer scientists - the authors themselves rely heavily on it! - but for serious users of mathematics in virtually every discipline. 
 
Concrete Mathematics is a blending of CONtinuous and disCRETE mathematics. ""More concretely,"" the authors explain, ""it is the controlled manipulation of mathematical formulas, using a collection of techniques for solving problems."" The subject matter is primarily an expansion of the Mathematical Preliminaries section in Knuth's classic Art of Computer Programming, but the style of presentation is more leisurely, and individual topics are covered more deeply. Several new topics have been added, and the most significant ideas have been traced to their historical roots. The book includes more than 500 exercises, divided into six categories. Complete answers are provided for all exercises, except research problems, making the book particularly valuable for self-study. 
 
Major topics include: 
 
Sums 
Recurrences 
Integer functions 
Elementary number theory 
Binomial coefficients 
Generating functions 
Discrete probability 
Asymptotic methods 
 
 
This second edition includes important new material about mechanical summation. In response to the widespread use ofthe first edition as a reference book, the bibliography and index have also been expanded, and additional nontrivial improvements can be found on almost every page. Readers will appreciate the informal style of Concrete Mathematics. Particularly enjoyable are the marginal graffiti contributed by students who have taken courses based on this material. The authors want to convey not only the importance of the techniques presented, but some of the fun in learning and using them.",publish book introduc mathemat support advanc comput program analysi algorithm primari aim wellknown author provid solid relev base mathemat skill skill need solv complex problem evalu horrend sum discov subtl pattern data indispens text refer comput scientist author reli heavili seriou user mathemat virtual everi disciplin concret mathemat blend continu discret mathemat concret author explain control manipul mathemat formula use collect techniqu solv problem subject matter primarili expans mathemat preliminari section knuth classic art comput program style present leisur individu topic cover deepli sever new topic ad signific idea trace histor root book includ exercis divid six categori complet answer provid exercis except research problem make book particularli valuabl selfstudi major topic includ sum recurr integ function elementari number theori binomi coeffici gener function discret probabl asymptot method second edit includ import new materi mechan summat respons widespread use ofth first edit refer book bibliographi index also expand addit nontrivi improv found almost everi page reader appreci inform style concret mathemat particularli enjoy margin graffiti contribut student taken cours base materi author want convey import techniqu present fun learn use
4b4b63405efd22a96cc45b22c08124d62a475d6f,Big healthcare data: preserving security and privacy,,nan
db8335198bd47c8865d0b3408b97e547abfd9ba2,The Fourth Paradigm: Data-Intensive Scientific Discovery,"This presentation will set out the eScience agenda by explaining the current scientific data deluge and the case for a “Fourth Paradigm” for scientific exploration. Examples of data intensive science will be used to illustrate the explosion of data and the associated new challenges for data capture, curation, analysis, and sharing. The role of cloud computing, collaboration services, and research repositories will be discussed.",present set escienc agenda explain current scientif data delug case fourth paradigm scientif explor exampl data intens scienc use illustr explos data associ new challeng data captur curat analysi share role cloud comput collabor servic research repositori discuss
fd40e458a67f9a3854834fd42b66b0d6ed43ab8d,Educational Data Mining and Learning Analytics,,nan
c278f3e91bf11c72be6808972f00810f15d877a4,Mapping citizen science contributions to the UN sustainable development goals,,nan
a4b603ca6aaaa18968e08ac1b0ee093db8a99a6b,Topology and data,"An important feature of modern science and engineering is that data of various kinds is being produced at an unprecedented rate. This is so in part because of new experimental methods, and in part because of the increase in the availability of high powered computing technology. It is also clear that the nature of the data we are obtaining is significantly different. For example, it is now often the case that we are given data in the form of very long vectors, where all but a few of the coordinates turn out to be irrelevant to the questions of interest, and further that we don’t necessarily know which coordinates are the interesting ones. A related fact is that the data is often very high-dimensional, which severely restricts our ability to visualize it. The data obtained is also often much noisier than in the past and has more missing information (missing data). This is particularly so in the case of biological data, particularly high throughput data from microarray or other sources. Our ability to analyze this data, both in terms of quantity and the nature of the data, is clearly not keeping pace with the data being produced. In this paper, we will discuss how geometry and topology can be applied to make useful contributions to the analysis of various kinds of data. Geometry and topology are very natural tools to apply in this direction, since geometry can be regarded as the study of distance functions, and what one often works with are distance functions on large finite sets of data. The mathematical formalism which has been developed for incorporating geometric and topological techniques deals with point clouds, i.e. finite sets of points equipped with a distance function. It then adapts tools from the various branches of geometry to the study of point clouds. The point clouds are intended to be thought of as finite samples taken from a geometric object, perhaps with noise. Here are some of the key points which come up when applying these geometric methods to data analysis. • Qualitative information is needed: One important goal of data analysis is to allow the user to obtain knowledge about the data, i.e. to understand how it is organized on a large scale. For example, if we imagine that we are looking at a data set constructed somehow from diabetes patients, it would be important to develop the understanding that there are two types of the disease, namely the juvenile and adult onset forms. Once that is established, one of course wants to develop quantitative methods for distinguishing them, but the first insight about the distinct forms of the disease is key.",import featur modern scienc engin data variou kind produc unpreced rate part new experiment method part increas avail high power comput technolog also clear natur data obtain significantli differ exampl often case given data form long vector coordin turn irrelev question interest dont necessarili know coordin interest one relat fact data often highdimension sever restrict abil visual data obtain also often much noisier past miss inform miss data particularli case biolog data particularli high throughput data microarray sourc abil analyz data term quantiti natur data clearli keep pace data produc paper discuss geometri topolog appli make use contribut analysi variou kind data geometri topolog natur tool appli direct sinc geometri regard studi distanc function one often work distanc function larg finit set data mathemat formal develop incorpor geometr topolog techniqu deal point cloud ie finit set point equip distanc function adapt tool variou branch geometri studi point cloud point cloud intend thought finit sampl taken geometr object perhap nois key point come appli geometr method data analysi qualit inform need one import goal data analysi allow user obtain knowledg data ie understand organ larg scale exampl imagin look data set construct somehow diabet patient would import develop understand two type diseas name juvenil adult onset form establish one cours want develop quantit method distinguish first insight distinct form diseas key
8cd71d704f9d3eeb5eb697e412ba54b680f00636,Big Data and Clinicians: A Review on the State of the Science,"Background In the past few decades, medically related data collection saw a huge increase, referred to as big data. These huge datasets bring challenges in storage, processing, and analysis. In clinical medicine, big data is expected to play an important role in identifying causality of patient symptoms, in predicting hazards of disease incidence or reoccurrence, and in improving primary-care quality. Objective The objective of this review was to provide an overview of the features of clinical big data, describe a few commonly employed computational algorithms, statistical methods, and software toolkits for data manipulation and analysis, and discuss the challenges and limitations in this realm. Methods We conducted a literature review to identify studies on big data in medicine, especially clinical medicine. We used different combinations of keywords to search PubMed, Science Direct, Web of Knowledge, and Google Scholar for literature of interest from the past 10 years. Results This paper reviewed studies that analyzed clinical big data and discussed issues related to storage and analysis of this type of data. Conclusions Big data is becoming a common feature of biological and clinical studies. Researchers who use clinical big data face multiple challenges, and the data itself has limitations. It is imperative that methodologies for data analysis keep pace with our ability to collect and store data.",background past decad medic relat data collect saw huge increas refer big data huge dataset bring challeng storag process analysi clinic medicin big data expect play import role identifi causal patient symptom predict hazard diseas incid reoccurr improv primarycar qualiti object object review provid overview featur clinic big data describ commonli employ comput algorithm statist method softwar toolkit data manipul analysi discuss challeng limit realm method conduct literatur review identifi studi big data medicin especi clinic medicin use differ combin keyword search pubm scienc direct web knowledg googl scholar literatur interest past year result paper review studi analyz clinic big data discuss issu relat storag analysi type data conclus big data becom common featur biolog clinic studi research use clinic big data face multipl challeng data limit imper methodolog data analysi keep pace abil collect store data
0578dfb2a28b77abde19b32de777e0365df3020e,Data-driven materials research enabled by natural language processing and information extraction,"Given the emergence of data science and machine learning throughout all aspects of society, but particularly in the scientific domain, there is increased importance placed on obtaining data. Data in materials science are particularly heterogeneous, based on the significant range in materials classes that are explored and the variety of materials properties that are of interest. This leads to data that range many orders of magnitude, and these data may manifest as numerical text or image-based information, which requires quantitative interpretation. The ability to automatically consume and codify the scientific literature across domains—enabled by techniques adapted from the field of natural language processing—therefore has immense potential to unlock and generate the rich datasets necessary for data science and machine learning. This review focuses on the progress and practices of natural language processing and text mining of materials science literature and highlights opportunities for extracting additional information beyond text contained in figures and tables in articles. We discuss and provide examples for several reasons for the pursuit of natural language processing for materials, including data compilation, hypothesis development, and understanding the trends within and across fields. Current and emerging natural language processing methods along with their applications to materials science are detailed. We, then, discuss natural language processing and data challenges within the materials science domain where future directions may prove valuable.",given emerg data scienc machin learn throughout aspect societi particularli scientif domain increas import place obtain data data materi scienc particularli heterogen base signific rang materi class explor varieti materi properti interest lead data rang mani order magnitud data may manifest numer text imagebas inform requir quantit interpret abil automat consum codifi scientif literatur across domainsen techniqu adapt field natur languag processingtherefor immens potenti unlock gener rich dataset necessari data scienc machin learn review focus progress practic natur languag process text mine materi scienc literatur highlight opportun extract addit inform beyond text contain figur tabl articl discuss provid exampl sever reason pursuit natur languag process materi includ data compil hypothesi develop understand trend within across field current emerg natur languag process method along applic materi scienc detail discuss natur languag process data challeng within materi scienc domain futur direct may prove valuabl
851a4c4e9d9bf8f023bc4cd29e023e4c43957b7d,The Art and Science of Data-Driven Journalism,"Journalists have been using data in their stories for as long as the profession has existed. A revolution in computing in the 20th century created opportunities for data integration into investigations, as journalists began to bring technology into their work. In the 21st century, a revolution in connectivity is leading the media toward new horizons. The Internet, cloud computing, agile development, mobile devices, and open source software have transformed the practice of journalism, leading to the emergence of a new term: data journalism. Although journalists have been using data in their stories for as long as they have been engaged in reporting, data journalism is more than traditional journalism with more data. Decades after early pioneers successfully applied computer-assisted reporting and social science to investigative journalism, journalists are creating news apps and interactive features that help people understand data, explore it, and act upon the insights derived from it. New business models are emerging in which data is a raw material for profit, impact, and insight, co-created with an audience that was formerly reduced to passive consumption. Journalists around the world are grappling with the excitement and the challenge of telling compelling stories by harnessing the vast quantity of data that our increasingly networked lives, devices, businesses, and governments produce every day. While the potential of data journalism is immense, the pitfalls and challenges to its adoption throughout the media are similarly significant, from digital literacy to competition for scarce resources in newsrooms. Global threats to press freedom, digital security, and limited access to data create difficult working conditions for journalists in many countries. A combination of peer-to-peer learning, mentorship, online training, open data initiatives, and new programs at journalism schools rising to the challenge, however, offer reasons to be optimistic about more journalists learning to treat data as a source.",journalist use data stori long profess exist revolut comput th centuri creat opportun data integr investig journalist began bring technolog work st centuri revolut connect lead media toward new horizon internet cloud comput agil develop mobil devic open sourc softwar transform practic journal lead emerg new term data journal although journalist use data stori long engag report data journal tradit journal data decad earli pioneer success appli computerassist report social scienc investig journal journalist creat news app interact featur help peopl understand data explor act upon insight deriv new busi model emerg data raw materi profit impact insight cocreat audienc formerli reduc passiv consumpt journalist around world grappl excit challeng tell compel stori har vast quantiti data increasingli network live devic busi govern produc everi day potenti data journal immens pitfal challeng adopt throughout media similarli signific digit literaci competit scarc resourc newsroom global threat press freedom digit secur limit access data creat difficult work condit journalist mani countri combin peertop learn mentorship onlin train open data initi new program journal school rise challeng howev offer reason optimist journalist learn treat data sourc
8958efba7a02e3653f27c0e759882b2f3352e896,"Materials Cloud, a platform for open computational science",,nan
fbd9ddc0a3862512ce7a0ba2bb9cb159da0a9d2f,Editorial - Marketing Science and Big Data,"This article was downloaded by: [128.97.27.20] On: 25 May 2016, At: 09:44 Publisher: Institute for Operations Research and the Management Sciences (INFORMS) INFORMS is located in Maryland, USA Marketing Science Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org Editorial—Marketing Science and Big Data Pradeep Chintagunta, Dominique M. Hanssens, John R. Hauser To cite this article: Pradeep Chintagunta, Dominique M. Hanssens, John R. Hauser (2016) Editorial—Marketing Science and Big Data. Marketing Science 35(3):341-342. http://dx.doi.org/10.1287/mksc.2016.0996 Full terms and conditions of use: http://pubsonline.informs.org/page/terms-and-conditions This article may be used only for the purposes of research, teaching, and/or private study. Commercial use or systematic downloading (by robots or other automatic processes) is prohibited without explicit Publisher approval, unless otherwise noted. For more information, contact permissions@informs.org. The Publisher does not warrant or guarantee the article’s accuracy, completeness, merchantability, fitness for a particular purpose, or non-infringement. Descriptions of, or references to, products or publications, or inclusion of an advertisement in this article, neither constitutes nor implies a guarantee, endorsement, or support of claims made of that product, publication, or service. Copyright © 2016, INFORMS Please scroll down for article—it is on subsequent pages INFORMS is the largest professional society in the world for professionals in the fields of operations research, management science, and analytics. For more information on INFORMS, its publications, membership, or meetings visit http://www.informs.org",articl download may publish institut oper research manag scienc inform inform locat maryland usa market scienc public detail includ instruct author subscript inform httppubsonlineinformsorg editorialmarket scienc big data pradeep chintagunta dominiqu hanssen john r hauser cite articl pradeep chintagunta dominiqu hanssen john r hauser editorialmarket scienc big data market scienc httpdxdoiorgmksc full term condit use httppubsonlineinformsorgpagetermsandcondit articl may use purpos research teach andor privat studi commerci use systemat download robot automat process prohibit without explicit publish approv unless otherwis note inform contact permissionsinformsorg publish warrant guarante articl accuraci complet merchant fit particular purpos noninfring descript refer product public inclus advertis articl neither constitut impli guarante endors support claim made product public servic copyright inform pleas scroll articleit subsequ page inform largest profession societi world profession field oper research manag scienc analyt inform inform public membership meet visit httpwwwinformsorg
64ad643e8084486ca7d3312ed491a814d3fe440c,The Synthetic Data Vault,"The goal of this paper is to build a system that automatically creates synthetic data to enable data science endeavors. To achieve this, we present the Synthetic Data Vault (SDV), a system that builds generative models of relational databases. We are able to sample from the model and create synthetic data, hence the name SDV. When implementing the SDV, we also developed an algorithm that computes statistics at the intersection of related database tables. We then used a state-of-the-art multivariate modeling approach to model this data. The SDV iterates through all possible relations, ultimately creating a model for the entire database. Once this model is computed, the same relational information allows the SDV to synthesize data by sampling from any part of the database. After building the SDV, we used it to generate synthetic data for five different publicly available datasets. We then published these datasets, and asked data scientists to develop predictive models for them as part of a crowdsourced experiment. By analyzing the outcomes, we show that synthetic data can successfully replace original data for data science. Our analysis indicates that there is no significant difference in the work produced by data scientists who used synthetic data as opposed to real data. We conclude that the SDV is a viable solution for synthetic data generation.",goal paper build system automat creat synthet data enabl data scienc endeavor achiev present synthet data vault sdv system build gener model relat databas abl sampl model creat synthet data henc name sdv implement sdv also develop algorithm comput statist intersect relat databas tabl use stateoftheart multivari model approach model data sdv iter possibl relat ultim creat model entir databas model comput relat inform allow sdv synthes data sampl part databas build sdv use gener synthet data five differ publicli avail dataset publish dataset ask data scientist develop predict model part crowdsourc experi analyz outcom show synthet data success replac origin data data scienc analysi indic signific differ work produc data scientist use synthet data oppos real data conclud sdv viabl solut synthet data gener
2e888654c68524163fbf7a54396488249e73a702,Citizen Science: A Developing Tool for Expanding Science Knowledge and Scientific Literacy,"Citizen science enlists the public in collecting large quantities of data across an array of habitats and locations over long spans of time. Citizen science projects have been remarkably successful in advancing scientific knowledge, and contributions from citizen scientists now provide a vast quantity of data about species occurrence and distribution around the world. Most citizen science projects also strive to help participants learn about the organisms they are observing and to experience the process by which scientific investigations are conducted. Developing and implementing public data-collection projects that yield both scientific and educational outcomes requires significant effort. This article describes the model for building and operating citizen science projects that has evolved at the Cornell Lab of Ornithology over the past two decades. We hope that our model will inform the fields of biodiversity monitoring, biological research, and science education while providing a window into the culture of citizen science.",citizen scienc enlist public collect larg quantiti data across array habitat locat long span time citizen scienc project remark success advanc scientif knowledg contribut citizen scientist provid vast quantiti data speci occurr distribut around world citizen scienc project also strive help particip learn organ observ experi process scientif investig conduct develop implement public datacollect project yield scientif educ outcom requir signific effort articl describ model build oper citizen scienc project evolv cornel lab ornitholog past two decad hope model inform field biodivers monitor biolog research scienc educ provid window cultur citizen scienc
d43e2d9b90c0f509c9f569b9d4bd431ebd711f4f,Sharing Data and Materials in Psychological Science,,nan
53834f0ee8df731cf0e629cd594dce0afaaa3d97,The inevitable application of big data to health care.,"THE AMOUNT OF DATA BEING DIGITALLY COLLECTED AND stored is vast and expanding rapidly. As a result, the science of data management and analysis is also advancing to enable organizations to convert this vast resource into information and knowledge that helps them achieve their objectives. Computer scientists have invented the term big data to describe this evolving technology. Big data has been successfully used in astronomy (eg, the Sloan Digital Sky Survey of telescopic information), retail sales (eg, Walmart’s expansive number of transactions), search engines (eg, Google’s customization of individual searches based on previous web data), and politics (eg, a campaign’s focus of political advertisements on people most likely to support their candidate based on web searches). In this Viewpoint, we discuss the application of big data to health care, using an economic framework to highlight the opportunities it will offer and the roadblocks to implementation. We suggest that leveraging the collection of patient and practitioner data could be an important way to improve quality and efficiency of health care delivery. Widespread uptake of electronic health records (EHRs) has generated massive data sets. A survey by the American Hospital Association showed that adoption of EHRs has doubled from 2009 to 2011, partly a result of funding provided by the Health Information Technology for Economic and Clinical Health Act of 2009. Most EHRs now contain quantitative data (eg, laboratory values), qualitative data (eg, text-based documents and demographics), and transactional data (eg, a record of medication delivery). However, much of this rich data set is currently perceived as a byproduct of health care delivery, rather than a central asset to improve its efficiency. The transition of data from refuse to riches has been key in the big data revolution of other industries. Advances in analytic techniques in the computer sciences, especially in machine learning, have been a major catalyst for dealing with these large information sets. These analytic techniques are in contrast to traditional statistical methods (derived from the social and physical sciences), which are largely not useful for analysis of unstructured data such as text-based documents that do not fit into relational tables. One estimate suggests that 80% of business-related data exist in an unstructured format. The same could probably be said for health care data, a large proportion of which is text-based. In contrast to most consumer service industries, medicine adopted a practice of generating evidence from experimental (randomized trials) and quasi-experimental studies to inform patients and clinicians. The evidence-based movement is founded on the belief that scientific inquiry is superior to expert opinion and testimonials. In this way, medicine was ahead of many other industries in terms of recognizing the value of data and information guiding rational decision making. However, health care has lagged in uptake of newer techniques to leverage the rich information contained in EHRs. There are 4 ways big data may advance the economic mission of health care delivery by improving quality and efficiency. First, big data may greatly expand the capacity to generate new knowledge. The cost of answering many clinical questions prospectively, and even retrospectively, by collecting structured data is prohibitive. Analyzing the unstructured data contained within EHRs using computational techniques (eg, natural language processing to extract medical concepts from free-text documents) permits finer data acquisition in an automated fashion. For instance, automated identification within EHRs using natural language processing was superior in detecting postoperative complications compared with patient safety indicators based on discharge coding. Big data offers the potential to create an observational evidence base for clinical questions that would otherwise not be possible and may be especially helpful with issues of generalizability. The latter issue limits the application of conclusions derived from randomized trials performed on a narrow spectrum of participants to patients who exhibit very different characteristics. Second, big data may help with knowledge dissemination. Most physicians struggle to stay current with the latest evidence guiding clinical practice. The digitization of medical literature has greatly improved access; however, the sheer",amount data digit collect store vast expand rapidli result scienc data manag analysi also advanc enabl organ convert vast resourc inform knowledg help achiev object comput scientist invent term big data describ evolv technolog big data success use astronomi eg sloan digit sky survey telescop inform retail sale eg walmart expans number transact search engin eg googl custom individu search base previou web data polit eg campaign focu polit advertis peopl like support candid base web search viewpoint discuss applic big data health care use econom framework highlight opportun offer roadblock implement suggest leverag collect patient practition data could import way improv qualiti effici health care deliveri widespread uptak electron health record ehr gener massiv data set survey american hospit associ show adopt ehr doubl partli result fund provid health inform technolog econom clinic health act ehr contain quantit data eg laboratori valu qualit data eg textbas document demograph transact data eg record medic deliveri howev much rich data set current perceiv byproduct health care deliveri rather central asset improv effici transit data refus rich key big data revolut industri advanc analyt techniqu comput scienc especi machin learn major catalyst deal larg inform set analyt techniqu contrast tradit statist method deriv social physic scienc larg use analysi unstructur data textbas document fit relat tabl one estim suggest businessrel data exist unstructur format could probabl said health care data larg proport textbas contrast consum servic industri medicin adopt practic gener evid experiment random trial quasiexperiment studi inform patient clinician evidencebas movement found belief scientif inquiri superior expert opinion testimoni way medicin ahead mani industri term recogn valu data inform guid ration decis make howev health care lag uptak newer techniqu leverag rich inform contain ehr way big data may advanc econom mission health care deliveri improv qualiti effici first big data may greatli expand capac gener new knowledg cost answer mani clinic question prospect even retrospect collect structur data prohibit analyz unstructur data contain within ehr use comput techniqu eg natur languag process extract medic concept freetext document permit finer data acquisit autom fashion instanc autom identif within ehr use natur languag process superior detect postop complic compar patient safeti indic base discharg code big data offer potenti creat observ evid base clinic question would otherwis possibl may especi help issu generaliz latter issu limit applic conclus deriv random trial perform narrow spectrum particip patient exhibit differ characterist second big data may help knowledg dissemin physician struggl stay current latest evid guid clinic practic digit medic literatur greatli improv access howev sheer
720400bf69c1af50795d7ec1b58e95c682d217aa,Best Practices in Data Analysis and Sharing in Neuroimaging using MRI,"Neuroimaging enables rich noninvasive measurements of human brain activity, but translating such data into neuroscientific insights and clinical applications requires complex analyses and collaboration among a diverse array of researchers. The open science movement is reshaping scientific culture and addressing the challenges of transparency and reproducibility of research. To advance open science in neuroimaging the Organization for Human Brain Mapping created the Committee on Best Practice in Data Analysis and Sharing (COBIDAS), charged with creating a report that collects best practice recommendations from experts and the entire brain imaging community. The purpose of this work is to elaborate the principles of open and reproducible research for neuroimaging using Magnetic Resonance Imaging (MRI), and then distill these principles to specific research practices. Many elements of a study are so varied that practice cannot be prescribed, but for these areas we detail the information that must be reported to fully understand and potentially replicate a study. For other elements of a study, like statistical modelling where specific poor practices can be identified, and the emerging areas of data sharing and reproducibility, we detail both good practice and reporting standards. For each of seven areas of a study we provide tabular listing of over 100 items to help plan, execute, report and share research in the most transparent fashion. Whether for individual scientists, or for editors and reviewers, we hope these guidelines serve as a benchmark, to raise the standards of practice and reporting in neuroimaging using MRI.",neuroimag enabl rich noninvas measur human brain activ translat data neuroscientif insight clinic applic requir complex analys collabor among divers array research open scienc movement reshap scientif cultur address challeng transpar reproduc research advanc open scienc neuroimag organ human brain map creat committe best practic data analysi share cobida charg creat report collect best practic recommend expert entir brain imag commun purpos work elabor principl open reproduc research neuroimag use magnet reson imag mri distil principl specif research practic mani element studi vari practic cannot prescrib area detail inform must report fulli understand potenti replic studi element studi like statist model specif poor practic identifi emerg area data share reproduc detail good practic report standard seven area studi provid tabular list item help plan execut report share research transpar fashion whether individu scientist editor review hope guidelin serv benchmark rais standard practic report neuroimag use mri
8807a8327e27298fd601fc65e6a9ccfae1cca195,What Is Citizen Science? – A Scientometric Meta-Analysis,"Context The concept of citizen science (CS) is currently referred to by many actors inside and outside science and research. Several descriptions of this purportedly new approach of science are often heard in connection with large datasets and the possibilities of mobilizing crowds outside science to assists with observations and classifications. However, other accounts refer to CS as a way of democratizing science, aiding concerned communities in creating data to influence policy and as a way of promoting political decision processes involving environment and health. Objective In this study we analyse two datasets (N = 1935, N = 633) retrieved from the Web of Science (WoS) with the aim of giving a scientometric description of what the concept of CS entails. We account for its development over time, and what strands of research that has adopted CS and give an assessment of what scientific output has been achieved in CS-related projects. To attain this, scientometric methods have been combined with qualitative approaches to render more precise search terms. Results Results indicate that there are three main focal points of CS. The largest is composed of research on biology, conservation and ecology, and utilizes CS mainly as a methodology of collecting and classifying data. A second strand of research has emerged through geographic information research, where citizens participate in the collection of geographic data. Thirdly, there is a line of research relating to the social sciences and epidemiology, which studies and facilitates public participation in relation to environmental issues and health. In terms of scientific output, the largest body of articles are to be found in biology and conservation research. In absolute numbers, the amount of publications generated by CS is low (N = 1935), but over the past decade a new and very productive line of CS based on digital platforms has emerged for the collection and classification of data.",context concept citizen scienc cs current refer mani actor insid outsid scienc research sever descript purportedli new approach scienc often heard connect larg dataset possibl mobil crowd outsid scienc assist observ classif howev account refer cs way democrat scienc aid concern commun creat data influenc polici way promot polit decis process involv environ health object studi analys two dataset n n retriev web scienc wo aim give scientometr descript concept cs entail account develop time strand research adopt cs give assess scientif output achiev csrelat project attain scientometr method combin qualit approach render precis search term result result indic three main focal point cs largest compos research biolog conserv ecolog util cs mainli methodolog collect classifi data second strand research emerg geograph inform research citizen particip collect geograph data thirdli line research relat social scienc epidemiolog studi facilit public particip relat environment issu health term scientif output largest bodi articl found biolog conserv research absolut number amount public gener cs low n past decad new product line cs base digit platform emerg collect classif data
c8b3f78bdead3596c4e7cb3aaad07a79cfa86ce4,Calling Bullshit: The Art of Skepticism in a Data-Driven World,"This week on the Science podcast, evolutionary biologist Carl Bergstrom explains how to identify data-driven misinformation and disinformation.",week scienc podcast evolutionari biologist carl bergstrom explain identifi datadriven misinform disinform
0131258a516da6f9d86795fc6ed4968206dba005,A Criteria-based Assessment of the Coverage of Scopus and Web of Science,"Abstract Purpose The purpose of this study is to assess the coverage of the scientific literature in Scopus and Web of Science from the perspective of research evaluation. Design/methodology/approach The academic communities of Norway have agreed on certain criteria for what should be included as original research publications in research evaluation and funding contexts. These criteria have been applied since 2004 in a comprehensive bibliographic database called the Norwegian Science Index (NSI). The relative coverages of Scopus and Web of Science are compared with regard to publication type, field of research and language. Findings Our results show that Scopus covers 72 percent of the total Norwegian scientific and scholarly publication output in 2015 and 2016, while the corresponding figure for Web of Science Core Collection is 69 percent. The coverages are most comprehensive in medicine and health (89 and 87 percent) and in the natural sciences and technology (85 and 84 percent). The social sciences (48 percent in Scopus and 40 percent in Web of Science Core Collection) and particularly the humanities (27 and 23 percent) are much less covered in the two international data sources. Research limitation Comparing with data from only one country is a limitation of the study, but the criteria used to define a country’s scientific output as well as the identification of patterns of field-dependent partial representations in Scopus and Web of Science should be recognizable and useful also for other countries. Originality/value The novelty of this study is the criteria-based approach to studying coverage problems in the two data sources.",abstract purpos purpos studi assess coverag scientif literatur scopu web scienc perspect research evalu designmethodologyapproach academ commun norway agre certain criteria includ origin research public research evalu fund context criteria appli sinc comprehens bibliograph databas call norwegian scienc index nsi rel coverag scopu web scienc compar regard public type field research languag find result show scopu cover percent total norwegian scientif scholarli public output correspond figur web scienc core collect percent coverag comprehens medicin health percent natur scienc technolog percent social scienc percent scopu percent web scienc core collect particularli human percent much less cover two intern data sourc research limit compar data one countri limit studi criteria use defin countri scientif output well identif pattern fielddepend partial represent scopu web scienc recogniz use also countri originalityvalu novelti studi criteriabas approach studi coverag problem two data sourc
377f1e43c5a48f12b0592b09a142322e74729409,Genetic Algorithms in the Fields of Artificial Intelligence and Data Sciences,,nan
e1ababf08c9ec103db854a2c1b4db611142cfdb7,Linear Mixed Models for Longitudinal Data,,nan
1a46465ab69ec13d3c84d66166e979989afa596d,Comment on “Estimating the reproducibility of psychological science”,"A paper from the Open Science Collaboration (Research Articles, 28 August 2015, aac4716) attempting to replicate 100 published studies suggests that the reproducibility of psychological science is surprisingly low. We show that this article contains three statistical errors and provides no support for such a conclusion. Indeed, the data are consistent with the opposite conclusion, namely, that the reproducibility of psychological science is quite high.",paper open scienc collabor research articl august aac attempt replic publish studi suggest reproduc psycholog scienc surprisingli low show articl contain three statist error provid support conclus inde data consist opposit conclus name reproduc psycholog scienc quit high
edacaedb1b2312023c4b0cf1d42bbdbed2793c65,The Electric and Magnetic Field Instrument Suite and Integrated Science (EMFISIS) on RBSP,,nan
760d38a08bff329ff67719935c18fa1631e3ded8,The View from Above: Applications of Satellite Data in Economics,"The past decade or so has seen a dramatic change in the way that economists can learn by watching our planet from above. A revolution has taken place in remote sensing and allied fields such as computer science, engineering, and geography. Petabytes of satellite imagery have become publicly accessible at increasing resolution, many algorithms for extracting meaningful social science information from these images are now routine, and modern cloud-based processing power allows these algorithms to be run at global scale. This paper seeks to introduce economists to the science of remotely sensed data, and to give a flavor of how this new source of data has been used by economists so far and what might be done in the future.",past decad seen dramat chang way economist learn watch planet revolut taken place remot sens alli field comput scienc engin geographi petabyt satellit imageri becom publicli access increas resolut mani algorithm extract meaning social scienc inform imag routin modern cloudbas process power allow algorithm run global scale paper seek introduc economist scienc remot sens data give flavor new sourc data use economist far might done futur
97156d041b6cae2095dd29d76e24e0017a7ec799,Functional Data Analysis,,nan
929607741b2a12656ff8d3360ca96fe76a6557a4,Next Generation Science Standards,"Science and Engineering Practices that connect to garden-based education (all 8): • Asking questions (for science) and defining problems (for engineering) • Developing and using models • Planning and carrying out investigations • Analyzing and interpreting data • Using mathematics and computational thinking • Constructing explanations (for science) and designing solutions (for engineering) • Engaging in argument from evidence • Obtaining, evaluating, and communicating information",scienc engin practic connect gardenbas educ ask question scienc defin problem engin develop use model plan carri investig analyz interpret data use mathemat comput think construct explan scienc design solut engin engag argument evid obtain evalu commun inform
299bab6b327e34c3e4f97cc8d0f9c64c9741fa99,Where are human subjects in Big Data research? The emerging ethics divide,"There are growing discontinuities between the research practices of data science and established tools of research ethics regulation. Some of the core commitments of existing research ethics regulations, such as the distinction between research and practice, cannot be cleanly exported from biomedical research to data science research. Such discontinuities have led some data science practitioners and researchers to move toward rejecting ethics regulations outright. These shifts occur at the same time as a proposal for major revisions to the Common Rule—the primary regulation governing human-subjects research in the USA—is under consideration for the first time in decades. We contextualize these revisions in long-running complaints about regulation of social science research and argue data science should be understood as continuous with social sciences in this regard. The proposed regulations are more flexible and scalable to the methods of non-biomedical research, yet problematically largely exclude data science methods from human-subjects regulation, particularly uses of public datasets. The ethical frameworks for Big Data research are highly contested and in flux, and the potential harms of data science research are unpredictable. We examine several contentious cases of research harms in data science, including the 2014 Facebook emotional contagion study and the 2016 use of geographical data techniques to identify the pseudonymous artist Banksy. To address disputes about application of human-subjects research ethics in data science, critical data studies should offer a historically nuanced theory of “data subjectivity” responsive to the epistemic methods, harms and benefits of data science and commerce.",grow discontinu research practic data scienc establish tool research ethic regul core commit exist research ethic regul distinct research practic cannot cleanli export biomed research data scienc research discontinu led data scienc practition research move toward reject ethic regul outright shift occur time propos major revis common ruleth primari regul govern humansubject research usai consider first time decad contextu revis longrun complaint regul social scienc research argu data scienc understood continu social scienc regard propos regul flexibl scalabl method nonbiomed research yet problemat larg exclud data scienc method humansubject regul particularli use public dataset ethic framework big data research highli contest flux potenti harm data scienc research unpredict examin sever contenti case research harm data scienc includ facebook emot contagion studi use geograph data techniqu identifi pseudonym artist banksi address disput applic humansubject research ethic data scienc critic data studi offer histor nuanc theori data subject respons epistem method harm benefit data scienc commerc
917943472ec4a00443d78bb696ed4d8f8d8c7f0a,Understanding the Science Experiences of Successful Women of Color: Science Identity as an Analytic Lens.,"In this study, we develop a model of science identity to make sense of the science experiences of 15 successful women of color over the course of their undergraduate and graduate studies in science and into science-related careers. In our view, science identity accounts both for how women make meaning of science experiences and how society structures possible meanings. Primary data included ethnographic interviews during students' undergraduate careers, follow-up interviews 6 years later, and ongoing member-checking. Our results highlight the importance of recognition by others for women in the three science identity trajectories: research scientist; altruistic scientist; and disrupted scientist. The women with research scientist identities were passionate about science and recognized themselves and were recognized by science faculty as science people. The women with altruistic scientist identities regarded science as a vehicle for altruism and created innovative meanings of ''science,'' ''recognition by others,'' and ''woman of color in science.'' The women with disrupted scientist identities sought, but did not often receive, recognition by meaningful scientific others. Although they were ultimately successful, their trajectories were more difficult because, in part, their bids for recognition were disrupted by the interaction with gendered, ethnic, and racial factors. This study clarifies theoretical conceptions of science identity, promotes a rethinking of recruitment and retention efforts, and illuminates various ways women of color experience, make meaning of, and negotiate the culture of science. 2007 Wiley Periodicals, Inc. J Res Sci Teach 44: 1187-1218, 2007.",studi develop model scienc ident make sens scienc experi success women color cours undergradu graduat studi scienc sciencerel career view scienc ident account women make mean scienc experi societi structur possibl mean primari data includ ethnograph interview student undergradu career followup interview year later ongo membercheck result highlight import recognit other women three scienc ident trajectori research scientist altruist scientist disrupt scientist women research scientist ident passion scienc recogn recogn scienc faculti scienc peopl women altruist scientist ident regard scienc vehicl altruism creat innov mean scienc recognit other woman color scienc women disrupt scientist ident sought often receiv recognit meaning scientif other although ultim success trajectori difficult part bid recognit disrupt interact gender ethnic racial factor studi clarifi theoret concept scienc ident promot rethink recruit retent effort illumin variou way women color experi make mean negoti cultur scienc wiley period inc j re sci teach
d90f276316589f503690d541392989031f9d046b,Online Citizen Science: A Systematic Review of Effects on Learning and Scientific Literacy,"Participation in online citizen science is increasingly popular, yet studies that examine the impact on participants’ learning are limited. The aims of this paper are to identify the learning impact on volunteers who participate in online citizen science projects and to explore the methods used to study the impact. The ten empirical studies, examined in this systematic review, report learning impacts on citizens’ attitudes towards science, on their understanding of the nature of science, on topic-specific knowledge, on science knowledge, and on generic knowledge. These impacts were measured using self-reports, content analysis of contributed data and of forum posts, accuracy checks of contributed data, science and project-specific quizzes, and instruments for measuring scientific attitudes and beliefs. The findings highlight that certain technological affordances in online citizen science projects can cultivate citizens’ knowledge and skills, and they point to unexplored areas, including the lack of experimental and long-term studies, and studies in formal education settings.",particip onlin citizen scienc increasingli popular yet studi examin impact particip learn limit aim paper identifi learn impact volunt particip onlin citizen scienc project explor method use studi impact ten empir studi examin systemat review report learn impact citizen attitud toward scienc understand natur scienc topicspecif knowledg scienc knowledg gener knowledg impact measur use selfreport content analysi contribut data forum post accuraci check contribut data scienc projectspecif quizz instrument measur scientif attitud belief find highlight certain technolog afford onlin citizen scienc project cultiv citizen knowledg skill point unexplor area includ lack experiment longterm studi studi formal educ set
25e0d93ca47d86510d6a0f9cda9ae3594f3d05b2,"Color Science: Concepts and Methods, Quantitative Data and Formulas","Eventually, you will agreed discover a further experience and achievement by spending more cash. still when? attain you acknowledge that you require to acquire those every needs in imitation of having significantly cash? Why don't you try to acquire something basic in the beginning? That's something that will lead you to comprehend even more in the region of the globe, experience, some places, later than history, amusement, and a lot more?",eventu agre discov experi achiev spend cash still attain acknowledg requir acquir everi need imit significantli cash dont tri acquir someth basic begin that someth lead comprehend even region globe experi place later histori amus lot
40f19bdaa4e869ab9784880fec5e9e229a2a61ab,The Pan-STARRS1 Database and Data Products,"This paper describes the organization of the database and the catalog data products from the Pan-STARRS1 3π Steradian Survey. The catalog data products are available in the form of an SQL-based relational database from MAST, the Mikulski Archive for Space Telescopes at STScI. The database is described in detail, including the construction of the database, the provenance of the data, the schema, and how the database tables are related. Examples of queries for a range of science goals are included.",paper describ organ databas catalog data product panstarr π steradian survey catalog data product avail form sqlbase relat databas mast mikulski archiv space telescop stsci databas describ detail includ construct databas proven data schema databas tabl relat exampl queri rang scienc goal includ
c8bc2d5edb9307b5c420adc4eee3cf641a781b14,Online analysis enhances use of NASA Earth science data,"Giovanni, the Goddard Earth Sciences Data and Information Services Center (GES DISC) Interactive Online Visualization and Analysis Infrastructure, has provided researchers with advanced capabilities to perform data exploration and analysis with observational data from NASA Earth observation satellites. In the past 5–10 years, examining geophysical events and processes with remote-sensing data required a multistep process of data discovery, data acquisition, data management, and ultimately data analysis. Giovanni accelerates this process by enabling basic visualization and analysis directly on the World Wide Web. In the last two years, Giovanni has added new data acquisition functions and expanded analysis options to increase its usefulness to the Earth science research community.",giovanni goddard earth scienc data inform servic center ge disc interact onlin visual analysi infrastructur provid research advanc capabl perform data explor analysi observ data nasa earth observ satellit past year examin geophys event process remotesens data requir multistep process data discoveri data acquisit data manag ultim data analysi giovanni acceler process enabl basic visual analysi directli world wide web last two year giovanni ad new data acquisit function expand analysi option increas use earth scienc research commun
6d962e9f04c653f732da82073a3446f75a371055,The KDD process for extracting useful knowledge from volumes of data,"AS WE MARCH INTO THE AGE of digital information, the problem of data overload looms ominously ahead. Our ability to analyze and understand massive datasets lags far behind our ability to gather and store the data. A new generation of computational techniques and tools is required to support the extraction of useful knowledge from the rapidly growing volumes of data. These techniques and tools are the subject of the emerging field of knowledge discovery in databases (KDD) and data mining. Large databases of digital information are ubiquitous. Data from the neighborhood store’s checkout register, your bank’s credit card authorization device, records in your doctor’s office, patterns in your telephone calls, and many more applications generate streams of digital records archived in huge databases, sometimes in so-called data warehouses. Current hardware and database technology allow efficient and inexpensive reliable data storage and access. However, whether the context is business, medicine, science, or government, the datasets themselves (in raw form) are of little direct value. What is of value is the knowledge that can be inferred from the data and put to use. For example, the marketing database of a consumer U s a m a F a y y a d ,",march age digit inform problem data overload loom omin ahead abil analyz understand massiv dataset lag far behind abil gather store data new gener comput techniqu tool requir support extract use knowledg rapidli grow volum data techniqu tool subject emerg field knowledg discoveri databas kdd data mine larg databas digit inform ubiquit data neighborhood store checkout regist bank credit card author devic record doctor offic pattern telephon call mani applic gener stream digit record archiv huge databas sometim socal data warehous current hardwar databas technolog allow effici inexpens reliabl data storag access howev whether context busi medicin scienc govern dataset raw form littl direct valu valu knowledg infer data put use exampl market databas consum u f
43789305e5d2212da05f9c16b148e84aae5614b2,Citizen Science and Volunteered Geographic Information: Overview and Typology of Participation,,nan
62e0c6cf57bc345026d56fd654e80beaf9315c92,JENDL-4.0: A New Library for Nuclear Science and Engineering,"The fourth version of the Japanese Evaluated Nuclear Data Library has been produced in cooperation with the Japanese Nuclear Data Committee. In the new library, much emphasis is placed on the improvements of fission product and minor actinoid data. Two nuclear model codes were developed in order to evaluate the cross sections of fission products and minor actinoids. Coupled-channel optical model parameters, which can be applied to wide mass and energy regions, were obtained for nuclear model calculations. Thermal cross sections of actinoids were carefully examined by considering experimental data or by the systematics of neighboring nuclei. Most of the fission cross sections were derived from experimental data. A simultaneous evaluation was performed for the fission cross sections of important uranium and plutonium isotopes above 10 keV. New evaluations were performed for the thirty fissionproduct nuclides that had not been contained in the previous library JENDL-3.3. The data for light elements and structural materials were partly reevaluated. Moreover, covariances were estimated mainly for actinoids. The new library was released as JENDL-4.0, and the data can be retrieved from the Web site of the JAEA Nuclear Data Center.",fourth version japanes evalu nuclear data librari produc cooper japanes nuclear data committe new librari much emphasi place improv fission product minor actinoid data two nuclear model code develop order evalu cross section fission product minor actinoid coupledchannel optic model paramet appli wide mass energi region obtain nuclear model calcul thermal cross section actinoid care examin consid experiment data systemat neighbor nuclei fission cross section deriv experiment data simultan evalu perform fission cross section import uranium plutonium isotop kev new evalu perform thirti fissionproduct nuclid contain previou librari jendl data light element structur materi partli reevalu moreov covari estim mainli actinoid new librari releas jendl data retriev web site jaea nuclear data center
a971f856fcf4a4a7589dbf711dd2544f51c5e9b2,Linked Data - A Paradigm Shift for Geographic Information Science,,nan
b7118fca8e7cd69d76090a5c145e89f303249eb8,The current state of citizen science as a tool for ecological research and public engagement,"Approaches to citizen science – an indispensable means of combining ecological research with environmental education and natural history observation – range from community-based monitoring to the use of the internet to “crowd-source” various scientific tasks, from data collection to discovery. With new tools and mechanisms for engaging learners, citizen science pushes the envelope of what ecologists can achieve, both in expanding the potential for spatial ecology research and in supplementing existing, but localized, research programs. The primary impacts of citizen science are seen in biological studies of global climate change, including analyses of phenology, landscape ecology, and macro-ecology, as well as in sub-disciplines focused on species (rare and invasive), disease, populations, communities, and ecosystems. Citizen science and the resulting ecological data can be viewed as a public good that is generated through increasingly collaborative tools and resources, while supporting public participation in science and Earth stewardship.",approach citizen scienc indispens mean combin ecolog research environment educ natur histori observ rang communitybas monitor use internet crowdsourc variou scientif task data collect discoveri new tool mechan engag learner citizen scienc push envelop ecologist achiev expand potenti spatial ecolog research supplement exist local research program primari impact citizen scienc seen biolog studi global climat chang includ analys phenolog landscap ecolog macroecolog well subdisciplin focus speci rare invas diseas popul commun ecosystem citizen scienc result ecolog data view public good gener increasingli collabor tool resourc support public particip scienc earth stewardship
0bc97adfb3c77f27397d19395af2fdff9f04aaa0,The TESS science processing operations center,"The Transiting Exoplanet Survey Satellite (TESS) will conduct a search for Earth's closest cousins starting in early 2018 and is expected to discover ∼1,000 small planets with Rp < 4 R⊕ and measure the masses of at least 50 of these small worlds. The Science Processing Operations Center (SPOC) is being developed at NASA Ames Research Center based on the Kepler science pipeline and will generate calibrated pixels and light curves on the NASA Advanced Supercomputing Division's Pleiades supercomputer. The SPOC will also search for periodic transit events and generate validation products for the transit-like features in the light curves. All TESS SPOC data products will be archived to the Mikulski Archive for Space Telescopes (MAST).",transit exoplanet survey satellit tess conduct search earth closest cousin start earli expect discov small planet rp r measur mass least small world scienc process oper center spoc develop nasa ame research center base kepler scienc pipelin gener calibr pixel light curv nasa advanc supercomput divis pleiad supercomput spoc also search period transit event gener valid product transitlik featur light curv tess spoc data product archiv mikulski archiv space telescop mast
05859c8d47b16ce84c817c16d29ad6ec9d1d3a33,The Science DMZ: A network design pattern for data-intensive science,"The ever-increasing scale of scientific data has become a significant challenge for researchers that rely on networks to interact with remote computing systems and transfer results to collaborators worldwide. Despite the availability of high-capacity connections, scientists struggle with inadequate cyberinfrastructure that cripples data transfer performance, and impedes scientific progress. The Science DMZ paradigm comprises a proven set of network design patterns that collectively address these problems for scientists. We explain the Science DMZ model, including network architecture, system configuration, cybersecurity, and performance tools, that creates an optimized network environment for science. We describe use cases from universities, supercomputing centers and research laboratories, highlighting the effectiveness of the Science DMZ model in diverse operational settings. In all, the Science DMZ model is a solid platform that supports any science workflow, and flexibly accommodates emerging network technologies. As a result, the Science DMZ vastly improves collaboration, accelerating scientific discovery.",everincreas scale scientif data becom signific challeng research reli network interact remot comput system transfer result collabor worldwid despit avail highcapac connect scientist struggl inadequ cyberinfrastructur crippl data transfer perform imped scientif progress scienc dmz paradigm compris proven set network design pattern collect address problem scientist explain scienc dmz model includ network architectur system configur cybersecur perform tool creat optim network environ scienc describ use case univers supercomput center research laboratori highlight effect scienc dmz model divers oper set scienc dmz model solid platform support scienc workflow flexibl accommod emerg network technolog result scienc dmz vastli improv collabor acceler scientif discoveri
b55fda1f58af7fd9ecde8f1dc193ddd6ab6e9d26,Handbook of theoretical computer science - Part A: Algorithms and complexity; Part B: Formal models and semantics,"""Of all the books I have covered in the Forum to date, this set is the most unique and possibly the most useful to the SIGACT community, in support both of teaching and research.... The books can be used by anyone wanting simply to gain an understanding of one of these areas, or by someone desiring to be in research in a topic, or by instructors wishing to find timely information on a subject they are teaching outside their major areas of expertise."" -- Rocky Ross, ""SIGACT News"" ""This is a reference which has a place in every computer science library."" -- Raymond Lauzzana, ""Languages of Design"" The Handbook of Theoretical Computer Science provides professionals and students with a comprehensive overview of the main results and developments in this rapidly evolving field. Volume A covers models of computation, complexity theory, data structures, and efficient computation in many recognized subdisciplines of theoretical computer science. Volume B takes up the theory of automata and rewriting systems, the foundations of modern programming languages, and logics for program specification and verification, and presents several studies on the theoretic modeling of advanced information processing. The two volumes contain thirty-seven chapters, with extensive chapter references and individual tables of contents for each chapter. There are 5,387 entry subject indexes that include notational symbols, and a list of contributors and affiliations in each volume.",book cover forum date set uniqu possibl use sigact commun support teach research book use anyon want simpli gain understand one area someon desir research topic instructor wish find time inform subject teach outsid major area expertis rocki ross sigact news refer place everi comput scienc librari raymond lauzzana languag design handbook theoret comput scienc provid profession student comprehens overview main result develop rapidli evolv field volum cover model comput complex theori data structur effici comput mani recogn subdisciplin theoret comput scienc volum b take theori automata rewrit system foundat modern program languag logic program specif verif present sever studi theoret model advanc inform process two volum contain thirtyseven chapter extens chapter refer individu tabl content chapter entri subject index includ notat symbol list contributor affili volum
90478017154dd6e4dbcb71895c64c9ddddebfb8c,Taxonomic bias in biodiversity data and societal preferences,,nan
a3324c0dcb1efaf5d88003b3fe22a3351b4c16da,"""Big Data"" : big gaps of knowledge in the field of internet science","Research on so-called ‘Big Data’ has received a considerable momentum and is expected to grow in the future. One very interesting stream of research on Big Data analyzes online networks. Many online networks are known to have some typical macro-characteristics, such as ‘small world’ properties. Much less is known about underlying micro-processes leading to these properties. The models used by Big Data researchers usually are inspired by mathematical ease of exposition. We propose to follow in addition a different strategy that leads to knowledge about micro-processes that match with actual online behavior. This knowledge can then be used for the selection of mathematically-tractable models of online network formation and evolution. Insight from social and behavioral research is needed for pursuing this strategy of knowledge generation about micro-processes. Accordingly, our proposal points to a unique role that social scientists could play in Big Data research.",research socal big data receiv consider momentum expect grow futur one interest stream research big data analyz onlin network mani onlin network known typic macrocharacterist small world properti much less known underli microprocess lead properti model use big data research usual inspir mathemat eas exposit propos follow addit differ strategi lead knowledg microprocess match actual onlin behavior knowledg use select mathematicallytract model onlin network format evolut insight social behavior research need pursu strategi knowledg gener microprocess accordingli propos point uniqu role social scientist could play big data research
85cd1c3c6346d8fe3b245cc41e2757631301bc27,The lure of rationality: Why does the deficit model persist in science communication?,"Science communication has been historically predicated on the knowledge deficit model. Yet, empirical research has shown that public communication of science is more complex than what the knowledge deficit model suggests. In this essay, we pose four lines of reasoning and present empirical data for why we believe the deficit model still persists in public communication of science. First, we posit that scientists’ training results in the belief that public audiences can and do process information in a rational manner. Second, the persistence of this model may be a product of current institutional structures. Many graduate education programs in science, technology, engineering, and math (STEM) fields generally lack formal training in public communication. We offer empirical evidence that demonstrates that scientists who have less positive attitudes toward the social sciences are more likely to adhere to the knowledge deficit model of science communication. Third, we present empirical evidence of how scientists conceptualize “the public” and link this to attitudes toward the deficit model. We find that perceiving a knowledge deficit in the public is closely tied to scientists’ perceptions of the individuals who comprise the public. Finally, we argue that the knowledge deficit model is perpetuated because it can easily influence public policy for science issues. We propose some ways to uproot the deficit model and move toward more effective science communication efforts, which include training scientists in communication methods grounded in social science research and using approaches that engage community members around scientific issues.",scienc commun histor predic knowledg deficit model yet empir research shown public commun scienc complex knowledg deficit model suggest essay pose four line reason present empir data believ deficit model still persist public commun scienc first posit scientist train result belief public audienc process inform ration manner second persist model may product current institut structur mani graduat educ program scienc technolog engin math stem field gener lack formal train public commun offer empir evid demonstr scientist less posit attitud toward social scienc like adher knowledg deficit model scienc commun third present empir evid scientist conceptu public link attitud toward deficit model find perceiv knowledg deficit public close tie scientist percept individu compris public final argu knowledg deficit model perpetu easili influenc public polici scienc issu propos way uproot deficit model move toward effect scienc commun effort includ train scientist commun method ground social scienc research use approach engag commun member around scientif issu
41692ed07f393c1c3e335db99c7e3c5a0d265a78,Citation indexes for science; a new dimension in documentation through association of ideas.,"‘The uncritical citation of disputed data by a writer, whether it be deliberate or not, is a serious matter. Of course, knowingly propagandizing unsubstantiated claims is particularly abhorrent, but just as many naive students may be swayed by unfounded assertions presented by a writer who is unaware of the criticisms. Buried in scholarly journals, critical notes are increasingly likely to be overlooked with the passage of time, while the studies to which they pertain, having been reported more widely, are apt to be rediscovered.’ 1",uncrit citat disput data writer whether deliber seriou matter cours knowingli propagand unsubstanti claim particularli abhorr mani naiv student may sway unfound assert present writer unawar critic buri scholarli journal critic note increasingli like overlook passag time studi pertain report wide apt rediscov
34ad09cda075101dc4ce3c04006ff804aca3ebf8,"Big data: Issues, challenges, tools and Good practices","Big data is defined as large amount of data which requires new technologies and architectures so that it becomes possible to extract value from it by capturing and analysis process. Due to such large size of data it becomes very difficult to perform effective analysis using the existing traditional techniques. Big data due to its various properties like volume, velocity, variety, variability, value and complexity put forward many challenges. Since Big data is a recent upcoming technology in the market which can bring huge benefits to the business organizations, it becomes necessary that various challenges and issues associated in bringing and adapting to this technology are brought into light. This paper introduces the Big data technology along with its importance in the modern world and existing projects which are effective and important in changing the concept of science into big science and society too. The various challenges and issues in adapting and accepting Big data technology, its tools (Hadoop) are also discussed in detail along with the problems Hadoop is facing. The paper concludes with the Good Big data practices to be followed.",big data defin larg amount data requir new technolog architectur becom possibl extract valu captur analysi process due larg size data becom difficult perform effect analysi use exist tradit techniqu big data due variou properti like volum veloc varieti variabl valu complex put forward mani challeng sinc big data recent upcom technolog market bring huge benefit busi organ becom necessari variou challeng issu associ bring adapt technolog brought light paper introduc big data technolog along import modern world exist project effect import chang concept scienc big scienc societi variou challeng issu adapt accept big data technolog tool hadoop also discuss detail along problem hadoop face paper conclud good big data practic follow
5ae073986408c9931bf6887fafb85e253866f7cc,Fuzzy-Set Social Science,"In this innovative approach to the practice of social science, Charles Ragin explores the use of fuzzy sets to bridge the divide between quantitative and qualitative methods. Paradoxically, the fuzzy set is a powerful tool because it replaces an unwieldy, ""fuzzy"" instrument—the variable, which establishes only the positions of cases relative to each other, with a precise one—degree of membership in a well-defined set. Ragin argues that fuzzy sets allow a far richer dialogue between ideas and evidence in social research than previously possible. They let quantitative researchers abandon ""homogenizing assumptions"" about cases and causes, they extend diversity-oriented research strategies, and they provide a powerful connection between theory and data analysis. Most important, fuzzy sets can be carefully tailored to fit evolving theoretical concepts, sharpening quantitative tools with in-depth knowledge gained through qualitative, case-oriented inquiry. This book will revolutionize research methods not only in sociology, political science, and anthropology but in any field of inquiry dealing with complex patterns of causation.",innov approach practic social scienc charl ragin explor use fuzzi set bridg divid quantit qualit method paradox fuzzi set power tool replac unwieldi fuzzi instrumentth variabl establish posit case rel precis onedegre membership welldefin set ragin argu fuzzi set allow far richer dialogu idea evid social research previous possibl let quantit research abandon homogen assumpt case caus extend diversityori research strategi provid power connect theori data analysi import fuzzi set care tailor fit evolv theoret concept sharpen quantit tool indepth knowledg gain qualit caseori inquiri book revolution research method sociolog polit scienc anthropolog field inquiri deal complex pattern causat
7a1b9cc42e6fc611970b451fbef795e72cbea46d,Ecoinformatics: supporting ecology as a data-intensive science.,,nan
9a7dfcd3c35ebfbce9e359a1a97d6892b83a37ec,Citizen Science as an Ecological Research Tool: Challenges and Benefits,"Citizen science, the involvement of volunteers in research, has increased the scale of ecological field studies with continent-wide, centralized monitoring efforts and, more rarely, tapping of volunteers to conduct large, coordinated, field experiments. The unique benefit for the field of ecology lies in understanding processes occurring at broad geographic scales and on private lands, which are impossible to sample extensively with traditional field research models. Citizen science produces large, longitudinal data sets, whose potential for error and bias is poorly understood. Because it does not usually aim to uncover mechanisms underlying ecological patterns, citizen science is best viewed as complementary to more localized, hypothesis-driven research. In the process of addressing the impacts of current, global “experiments” altering habitat and climate, large-scale citizen science has led to new, quantitative approaches to emerging questions about the distribution and abundance of organisms across spa...",citizen scienc involv volunt research increas scale ecolog field studi continentwid central monitor effort rare tap volunt conduct larg coordin field experi uniqu benefit field ecolog lie understand process occur broad geograph scale privat land imposs sampl extens tradit field research model citizen scienc produc larg longitudin data set whose potenti error bia poorli understood usual aim uncov mechan underli ecolog pattern citizen scienc best view complementari local hypothesisdriven research process address impact current global experi alter habitat climat largescal citizen scienc led new quantit approach emerg question distribut abund organ across spa
18a940ff6dce8bc140658da52d686291ca965979,The Analysis of Social Science Data with Missing Values,"Methods for handling missing data in social science data sets are reviewed. Limitations of common practical approaches, including complete-case analysis, available-case analysis and imputation, are illustrated on a simple missing-data problem with one complete and one incomplete variable. Two more principled approaches, namely maximum likelihood under a model for the data and missing-data mechanism and multiple imputation, are applied to the bivariate problem. General properties of these methods are outlined, and applications to more complex missing-data problems are discussed. The EM algorithm, a convenient method for computing maximum likelihood estimates in missing-data problems, is described and applied to two common models, the multivariate normal model for continuous data and the multinomial model for discrete data. Multiple imputation under explicit or implicit models is recommended as a method that retains the advantages of imputation and overcomes its limitations.",method handl miss data social scienc data set review limit common practic approach includ completecas analysi availablecas analysi imput illustr simpl missingdata problem one complet one incomplet variabl two principl approach name maximum likelihood model data missingdata mechan multipl imput appli bivari problem gener properti method outlin applic complex missingdata problem discuss em algorithm conveni method comput maximum likelihood estim missingdata problem describ appli two common model multivari normal model continu data multinomi model discret data multipl imput explicit implicit model recommend method retain advantag imput overcom limit
a6e594b11bd8195e96a1826f591fcec9a20fdcf3,"Frascati manual 2015 : guidelines for collecting and reporting data in research and experimental development: the measurement of scientific, technological and innovation activities.","The Frascati Manual is firmly based on experience gained from collecting R&D 
statistics in both OECD and non-member countries. It is a result of the collective work 
of national experts in NESTI, the OECD Working Party of National Experts on Science 
and Technology Indicators. This group, with support from the OECD Secretariat, has 
worked over now more than 50 years as an effective community of practitioners to 
implement measurement approaches for the concepts of science, technology and 
innovation. This effort has resulted in a series of methodological manuals known as the 
“Frascati Family”, which in addition to this manual includes guidance documents on 
the measurement of innovation (the Oslo Manual), human resources devoted to science 
and technology, patents, and technological balance of payments, but most importantly, 
it has provided the basis for the main statistics and indicators on science and technology 
that are currently used.",frascati manual firmli base experi gain collect rd statist oecd nonmemb countri result collect work nation expert nesti oecd work parti nation expert scienc technolog indic group support oecd secretariat work year effect commun practition implement measur approach concept scienc technolog innov effort result seri methodolog manual known frascati famili addit manual includ guidanc document measur innov oslo manual human resourc devot scienc technolog patent technolog balanc payment importantli provid basi main statist indic scienc technolog current use
954f2a7b1c6f28c4a845ccda5761eb09da032a64,Data sharing,"The Science family of journals is committed to sharing data relevant to public health emergencies, and therefore we are signatories to, and wholeheartedly endorse, the following statement by funders and journals.*",scienc famili journal commit share data relev public health emerg therefor signatori wholeheartedli endors follow statement funder journal
edf27bb5272ea6fe244deb3bbc8da0429bfe3ac5,The reusable holdout: Preserving validity in adaptive data analysis,"Testing hypotheses privately Large data sets offer a vast scope for testing already-formulated ideas and exploring new ones. Unfortunately, researchers who attempt to do both on the same data set run the risk of making false discoveries, even when testing and exploration are carried out on distinct subsets of data. Based on ideas drawn from differential privacy, Dwork et al. now provide a theoretical solution. Ideas are tested against aggregate information, whereas individual data set components remain confidential. Preserving that privacy also preserves statistical inference validity. Science, this issue p. 636 A statistical approach allows large data sets to be reanalyzed to test new hypotheses. Misapplication of statistical data analysis is a common cause of spurious discoveries in scientific research. Existing approaches to ensuring the validity of inferences drawn from data assume a fixed procedure to be performed, selected before the data are examined. In common practice, however, data analysis is an intrinsically adaptive process, with new analyses generated on the basis of data exploration, as well as the results of previous analyses on the same data. We demonstrate a new approach for addressing the challenges of adaptivity based on insights from privacy-preserving data analysis. As an application, we show how to safely reuse a holdout data set many times to validate the results of adaptively chosen analyses.",test hypothes privat larg data set offer vast scope test alreadyformul idea explor new one unfortun research attempt data set run risk make fals discoveri even test explor carri distinct subset data base idea drawn differenti privaci dwork et al provid theoret solut idea test aggreg inform wherea individu data set compon remain confidenti preserv privaci also preserv statist infer valid scienc issu p statist approach allow larg data set reanalyz test new hypothes misappl statist data analysi common caus spuriou discoveri scientif research exist approach ensur valid infer drawn data assum fix procedur perform select data examin common practic howev data analysi intrins adapt process new analys gener basi data explor well result previou analys data demonstr new approach address challeng adapt base insight privacypreserv data analysi applic show safe reus holdout data set mani time valid result adapt chosen analys
f6ce14f91b4641942947882062682125369847f7,The V–Dem Measurement Model: Latent Variable Analysis for Cross-National and Cross-Temporal Expert-Coded Data,"This material is based upon work supported by the National Science Foundation (SES-1423944, PI: Daniel Pemstein), Riksbankens Jubileumsfond (Grant M13-0559:1, PI: Staffan I. Lindberg), the Swedish Research Council (2013.0166, PI: Staffan I. Lindberg and Jan Teorell), the Knut and Alice Wallenberg Foundation (PI: Staffan I. Lindberg), and the University of Gothenburg (E 2013/43); as well as internal grants from the Vice-Chancellor’s office, the Dean of the College of Social Sciences, and the Department of Political Science at University of Gothenburg. Marquardt acknowledges research support from the Russian Academic Excellence Project ‘5-100.’ We performed simulations and other computational tasks using resources provided by the Notre Dame Center for Research Computing (CRC) through the High Performance Computing section and the Swedish National Infrastructure for Computing (SNIC) at the National Supercomputer Centre in Sweden (SNIC 2016/1-382, SNIC 2017/1-406 and 2017/1-68). We specifically acknowledge the assistance of In-Saeng Suh at CRC and Johan Raber and Peter Mu nger at SNIC in facilitating our use of their respective systems.",materi base upon work support nation scienc foundat se pi daniel pemstein riksbanken jubileumsfond grant pi staffan lindberg swedish research council pi staffan lindberg jan teorel knut alic wallenberg foundat pi staffan lindberg univers gothenburg e well intern grant vicechancellor offic dean colleg social scienc depart polit scienc univers gothenburg marquardt acknowledg research support russian academ excel project perform simul comput task use resourc provid notr dame center research comput crc high perform comput section swedish nation infrastructur comput snic nation supercomput centr sweden snic snic specif acknowledg assist insaeng suh crc johan raber peter mu nger snic facilit use respect system
69732dcf45024f28e5c43de68d1208f6e737eada,The BIG Data Center: from deposition to integration to translation,"Biological data are generated at unprecedentedly exponential rates, posing considerable challenges in big data deposition, integration and translation. The BIG Data Center, established at Beijing Institute of Genomics (BIG), Chinese Academy of Sciences, provides a suite of database resources, including (i) Genome Sequence Archive, a data repository specialized for archiving raw sequence reads, (ii) Gene Expression Nebulas, a data portal of gene expression profiles based entirely on RNA-Seq data, (iii) Genome Variation Map, a comprehensive collection of genome variations for featured species, (iv) Genome Warehouse, a centralized resource housing genome-scale data with particular focus on economically important animals and plants, (v) Methylation Bank, an integrated database of whole-genome single-base resolution methylomes and (vi) Science Wikis, a central access point for biological wikis developed for community annotations. The BIG Data Center is dedicated to constructing and maintaining biological databases through big data integration and value-added curation, conducting basic research to translate big data into big knowledge and providing freely open access to a variety of data resources in support of worldwide research activities in both academia and industry. All of these resources are publicly available and can be found at http://bigd.big.ac.cn.",biolog data gener unprecedentedli exponenti rate pose consider challeng big data deposit integr translat big data center establish beij institut genom big chines academi scienc provid suit databas resourc includ genom sequenc archiv data repositori special archiv raw sequenc read ii gene express nebula data portal gene express profil base entir rnaseq data iii genom variat map comprehens collect genom variat featur speci iv genom warehous central resourc hous genomescal data particular focu econom import anim plant v methyl bank integr databas wholegenom singlebas resolut methylom vi scienc wiki central access point biolog wiki develop commun annot big data center dedic construct maintain biolog databas big data integr valuead curat conduct basic research translat big data big knowledg provid freeli open access varieti data resourc support worldwid research activ academia industri resourc publicli avail found httpbigdbigaccn
9386590554c429e80402c082e9d6a2398bcc36b3,Data streams: algorithms and applications,"Data stream algorithms as an active research agenda emerged only over the past few years, even though the concept of making few passes over the data for performing computations has been around since the early days of Automata Theory. The data stream agenda now pervades many branches of Computer Science including databases, networking, knowledge discovery and data mining, and hardware systems. Industry is in synch too, with Data Stream Management Systems (DSMSs) and special hardware to deal with data speeds. Even beyond Computer Science, data stream concerns are emerging in physics, atmospheric science and statistics. Data Streams: Algorithms and Applications focuses on the algorithmic foundations of data streaming. In the data stream scenario, input arrives very rapidly and there is limited memory to store the input. Algorithms have to work with one or few passes over the data, space less than linear in the input size or time significantly less than the input size. In the past few years, a new theory has emerged for reasoning about algorithms that work within these constraints on space, time and number of passes. Some of the methods rely on metric embeddings, pseudo-random computations, sparse approximation theory and communication complexity. The applications for this scenario include IP network traffic analysis, mining text message streams and processing massive data sets in general. Data Streams: Algorithms and Applications surveys the emerging area of algorithms for processing data streams and associated applications. An extensive bibliography with over 200 entries points the reader to further resources for exploration.",data stream algorithm activ research agenda emerg past year even though concept make pass data perform comput around sinc earli day automata theori data stream agenda pervad mani branch comput scienc includ databas network knowledg discoveri data mine hardwar system industri synch data stream manag system dsmss special hardwar deal data speed even beyond comput scienc data stream concern emerg physic atmospher scienc statist data stream algorithm applic focus algorithm foundat data stream data stream scenario input arriv rapidli limit memori store input algorithm work one pass data space less linear input size time significantli less input size past year new theori emerg reason algorithm work within constraint space time number pass method reli metric embed pseudorandom comput spars approxim theori commun complex applic scenario includ ip network traffic analysi mine text messag stream process massiv data set gener data stream algorithm applic survey emerg area algorithm process data stream associ applic extens bibliographi entri point reader resourc explor
29196eb8c80a6fd6a159373f14ff323f081a8b7a,Physical and Virtual Laboratories in Science and Engineering Education,"The world needs young people who are skillful in and enthusiastic about science and who view science as their future career field. Ensuring that we will have such young people requires initiatives that engage students in interesting and motivating science experiences. Today, students can investigate scientific phenomena using the tools, data collection techniques, models, and theories of science in physical laboratories that support interactions with the material world or in virtual laboratories that take advantage of simulations. Here, we review a selection of the literature to contrast the value of physical and virtual investigations and to offer recommendations for combining the two to strengthen science learning.",world need young peopl skill enthusiast scienc view scienc futur career field ensur young peopl requir initi engag student interest motiv scienc experi today student investig scientif phenomena use tool data collect techniqu model theori scienc physic laboratori support interact materi world virtual laboratori take advantag simul review select literatur contrast valu physic virtual investig offer recommend combin two strengthen scienc learn
5952a9f10ef65983042794369d376e23d2682d7e,Openness in Political Science: Data Access and Research Transparency,"In 2012, the American Political Science Association (APSA) Council adopted new policies guiding data access and research transparency in political science. The policies appear as a revision to APSA's Guide to Professional Ethics in Political Science. The revisions were the product of an extended and broad consultation with a variety of APSA committees and the association's membership.",american polit scienc associ apsa council adopt new polici guid data access research transpar polit scienc polici appear revis apsa guid profession ethic polit scienc revis product extend broad consult varieti apsa committe associ membership
a418d8fd1cc0abb34cf131d81723bc5da8817c93,Politicization of Science in the Public Sphere,"This study explores time trends in public trust in science in the United States from 1974 to 2010. More precisely, I test Mooney’s (2005) claim that conservatives in the United States have become increasingly distrustful of science. Using data from the 1974 to 2010 General Social Survey, I examine group differences in trust in science and group-specific change in these attitudes over time. Results show that group differences in trust in science are largely stable over the period, except for respondents identifying as conservative. Conservatives began the period with the highest trust in science, relative to liberals and moderates, and ended the period with the lowest. The patterns for science are also unique when compared to public trust in other secular institutions. Results show enduring differences in trust in science by social class, ethnicity, gender, church attendance, and region. I explore the implications of these findings, specifically, the potential for political divisions to emerge over the cultural authority of science and the social role of experts in the formation of public policy.",studi explor time trend public trust scienc unit state precis test mooney claim conserv unit state becom increasingli distrust scienc use data gener social survey examin group differ trust scienc groupspecif chang attitud time result show group differ trust scienc larg stabl period except respond identifi conserv conserv began period highest trust scienc rel liber moder end period lowest pattern scienc also uniqu compar public trust secular institut result show endur differ trust scienc social class ethnic gender church attend region explor implic find specif potenti polit divis emerg cultur author scienc social role expert format public polici
c32b03c3b5bbc97b0ec30663da1ff555f30acd95,Principled Missing Data Treatments,,nan
1715fdc4df6774d95ed63f3feb58fa93a84dbed7,Data-intensive science applied to broad-scale citizen science.,,nan
8801ce73bea0c97f2d35f5e3bd4f4fdb49698461,Lessons from lady beetles: accuracy of monitoring data from US and UK citizen-science programs,"Citizen scientists have the potential to play a crucial role in the study of rapidly changing lady beetle (Coccinellidae) populations. We used data derived from three coccinellid-focused citizen-science programs to examine the costs and benefits of data collection from direct citizen-science (data used without verification) and verified citizen-science (observations verified by trained experts) programs. Data collated through direct citizen science overestimated species richness and diversity values in comparison to verified data, thereby influencing interpretation. The use of citizen scientists to collect data also influenced research costs; our analysis shows that verified citizen science was more cost effective than traditional science (in terms of data gathered per dollar). The ability to collect a greater number of samples through direct citizen science may compensate for reduced accuracy, depending on the type of data collected and the type(s) and extent of errors committed by volunteers.",citizen scientist potenti play crucial role studi rapidli chang ladi beetl coccinellida popul use data deriv three coccinellidfocus citizensci program examin cost benefit data collect direct citizensci data use without verif verifi citizensci observ verifi train expert program data collat direct citizen scienc overestim speci rich divers valu comparison verifi data therebi influenc interpret use citizen scientist collect data also influenc research cost analysi show verifi citizen scienc cost effect tradit scienc term data gather per dollar abil collect greater number sampl direct citizen scienc may compens reduc accuraci depend type data collect type extent error commit volunt
3954e2d220d9a7b7a46f9561cafb6251524d8ee5,Mars Reconnaissance Orbiter's High Resolution Imaging Science Experiment (HiRISE),"[1] The HiRISE camera features a 0.5 m diameter primary mirror, 12 m effective focal length, and a focal plane system that can acquire images containing up to 28 Gb (gigabits) of data in as little as 6 seconds. HiRISE will provide detailed images (0.25 to 1.3 m/pixel) covering ∼1% of the Martian surface during the 2-year Primary Science Phase (PSP) beginning November 2006. Most images will include color data covering 20% of the potential field of view. A top priority is to acquire ∼1000 stereo pairs and apply precision geometric corrections to enable topographic measurements to better than 25 cm vertical precision. We expect to return more than 12 Tb of HiRISE data during the 2-year PSP, and use pixel binning, conversion from 14 to 8 bit values, and a lossless compression system to increase coverage. HiRISE images are acquired via 14 CCD detectors, each with 2 output channels, and with multiple choices for pixel binning and number of Time Delay and Integration lines. HiRISE will support Mars exploration by locating and characterizing past, present, and future landing sites, unsuccessful landing sites, and past and potentially future rover traverses. We will investigate cratering, volcanism, tectonism, hydrology, sedimentary processes, stratigraphy, aeolian processes, mass wasting, landscape evolution, seasonal processes, climate change, spectrophotometry, glacial and periglacial processes, polar geology, and regolith properties. An Internet Web site (HiWeb) will enable anyone in the world to suggest HiRISE targets on Mars and to easily locate, view, and download HiRISE data products.",hiris camera featur diamet primari mirror effect focal length focal plane system acquir imag contain gb gigabit data littl second hiris provid detail imag mpixel cover martian surfac year primari scienc phase psp begin novemb imag includ color data cover potenti field view top prioriti acquir stereo pair appli precis geometr correct enabl topograph measur better cm vertic precis expect return tb hiris data year psp use pixel bin convers bit valu lossless compress system increas coverag hiris imag acquir via ccd detector output channel multipl choic pixel bin number time delay integr line hiris support mar explor locat character past present futur land site unsuccess land site past potenti futur rover travers investig crater volcan tecton hydrolog sedimentari process stratigraphi aeolian process mass wast landscap evolut season process climat chang spectrophotometri glacial periglaci process polar geolog regolith properti internet web site hiweb enabl anyon world suggest hiris target mar easili locat view download hiris data product
687e00a5fec7d747d18866f60b7a21973e80b04f,The ethics of smart cities and urban science,"Software-enabled technologies and urban big data have become essential to the functioning of cities. Consequently, urban operational governance and city services are becoming highly responsive to a form of data-driven urbanism that is the key mode of production for smart cities. At the heart of data-driven urbanism is a computational understanding of city systems that reduces urban life to logic and calculative rules and procedures, which is underpinned by an instrumental rationality and realist epistemology. This rationality and epistemology are informed by and sustains urban science and urban informatics, which seek to make cities more knowable and controllable. This paper examines the forms, practices and ethics of smart cities and urban science, paying particular attention to: instrumental rationality and realist epistemology; privacy, datafication, dataveillance and geosurveillance; and data uses, such as social sorting and anticipatory governance. It argues that smart city initiatives and urban science need to be re-cast in three ways: a re-orientation in how cities are conceived; a reconfiguring of the underlying epistemology to openly recognize the contingent and relational nature of urban systems, processes and science; and the adoption of ethical principles designed to realize benefits of smart cities and urban science while reducing pernicious effects. This article is part of the themed issue ‘The ethical impact of data science’.",softwareen technolog urban big data becom essenti function citi consequ urban oper govern citi servic becom highli respons form datadriven urban key mode product smart citi heart datadriven urban comput understand citi system reduc urban life logic calcul rule procedur underpin instrument ration realist epistemolog ration epistemolog inform sustain urban scienc urban informat seek make citi knowabl control paper examin form practic ethic smart citi urban scienc pay particular attent instrument ration realist epistemolog privaci dataf dataveil geosurveil data use social sort anticipatori govern argu smart citi initi urban scienc need recast three way reorient citi conceiv reconfigur underli epistemolog openli recogn conting relat natur urban system process scienc adopt ethic principl design realiz benefit smart citi urban scienc reduc pernici effect articl part theme issu ethic impact data scienc
04638c67b715b9d85ae5a44afd3730b83330fb66,Economics in the age of big data,"Background Economic science has evolved over several decades toward greater emphasis on empirical work. The data revolution of the past decade is likely to have a further and profound effect on economic research. Increasingly, economists make use of newly available large-scale administrative data or private sector data that often are obtained through collaborations with private firms, giving rise to new opportunities and challenges. The rising use of non–publicly available data in economic research. Here we show the percentage of papers published in the American Economic Review (AER) that obtained an exemption from the AER’s data availability policy, as a share of all papers published by the AER that relied on any form of data (excluding simulations and laboratory experiments). Notes and comments, as well as AER Papers and Proceedings issues, are not included in the analysis. We obtained a record of exemptions directly from the AER administrative staff and coded each exemption manually to reflect public sector versus private data. Our check of nonexempt papers suggests that the AER records may possibly understate the percentage of papers that actually obtained exemptions. The asterisk indicates that data run from when the AER started collecting these data (December 2005 issue) to the September 2014 issue. To make full use of the data, we define year 2006 to cover October 2005 through September 2006, year 2007 to cover October 2006 through September 2007, and so on. Advances These new data are affecting economic research along several dimensions. Many fields have shifted from a reliance on relatively small-sample government surveys to administrative data with universal or near-universal population coverage. This shift is transformative, as it allows researchers to rigorously examine variation in wages, health, productivity, education, and other measures across different subpopulations; construct consistent long-run statistical indices; generate new quasi-experimental research designs; and track diverse outcomes from natural and controlled experiments. Perhaps even more notable is the expansion of private sector data on economic activity. These data, sometimes available from public sources but other times obtained through data-sharing agreements with private firms, can help to create more granular and real-time measurement of aggregate economic statistics. The data also offer researchers a look inside the “black box” of firms and markets by providing meaningful statistics on economic behavior such as search and information gathering, communication, decision-making, and microlevel transactions. Collaborations with data-oriented firms also create new opportunities to conduct and evaluate randomized experiments. Economic theory plays an important role in the analysis of large data sets with complex structure. It can be difficult to organize and study this type of data (or even to decide which variables to construct) without a simplifying conceptual framework, which is where economic models become useful. Better data also allow for sharper tests of existing models and tests of theories that had previously been difficult to assess. Outlook The advent of big data is already allowing for better measurement of economic effects and outcomes and is enabling novel research designs across a range of topics. Over time, these data are likely to affect the types of questions economists pose, by allowing for more focus on population variation and the analysis of a broader range of economic activities and interactions. We also expect economists to increasingly adopt the large-data statistical methods that have been developed in neighboring fields and that often may complement traditional econometric techniques. These data opportunities also raise some important challenges. Perhaps the primary one is developing methods for researchers to access and explore data in ways that respect privacy and confidentiality concerns. This is a major issue in working with both government administrative data and private sector firms. Other challenges include developing the appropriate data management and programming capabilities, as well as designing creative and scalable approaches to summarize, describe, and analyze large-scale and relatively unstructured data sets. These challenges notwithstanding, the next few decades are likely to be a very exciting time for economic research. The quality and quantity of data on economic activity are expanding rapidly. Empirical research increasingly relies on newly available large-scale administrative data or private sector data that often is obtained through collaboration with private firms. Here we highlight some challenges in accessing and using these new data. We also discuss how new data sets may change the statistical methods used by economists and the types of questions posed in empirical research.",background econom scienc evolv sever decad toward greater emphasi empir work data revolut past decad like profound effect econom research increasingli economist make use newli avail largescal administr data privat sector data often obtain collabor privat firm give rise new opportun challeng rise use nonpublicli avail data econom research show percentag paper publish american econom review aer obtain exempt aer data avail polici share paper publish aer reli form data exclud simul laboratori experi note comment well aer paper proceed issu includ analysi obtain record exempt directli aer administr staff code exempt manual reflect public sector versu privat data check nonexempt paper suggest aer record may possibl underst percentag paper actual obtain exempt asterisk indic data run aer start collect data decemb issu septemb issu make full use data defin year cover octob septemb year cover octob septemb advanc new data affect econom research along sever dimens mani field shift relianc rel smallsampl govern survey administr data univers nearunivers popul coverag shift transform allow research rigor examin variat wage health product educ measur across differ subpopul construct consist longrun statist indic gener new quasiexperiment research design track divers outcom natur control experi perhap even notabl expans privat sector data econom activ data sometim avail public sourc time obtain datashar agreement privat firm help creat granular realtim measur aggreg econom statist data also offer research look insid black box firm market provid meaning statist econom behavior search inform gather commun decisionmak microlevel transact collabor dataori firm also creat new opportun conduct evalu random experi econom theori play import role analysi larg data set complex structur difficult organ studi type data even decid variabl construct without simplifi conceptu framework econom model becom use better data also allow sharper test exist model test theori previous difficult assess outlook advent big data alreadi allow better measur econom effect outcom enabl novel research design across rang topic time data like affect type question economist pose allow focu popul variat analysi broader rang econom activ interact also expect economist increasingli adopt largedata statist method develop neighbor field often may complement tradit econometr techniqu data opportun also rais import challeng perhap primari one develop method research access explor data way respect privaci confidenti concern major issu work govern administr data privat sector firm challeng includ develop appropri data manag program capabl well design creativ scalabl approach summar describ analyz largescal rel unstructur data set challeng notwithstand next decad like excit time econom research qualiti quantiti data econom activ expand rapidli empir research increasingli reli newli avail largescal administr data privat sector data often obtain collabor privat firm highlight challeng access use new data also discuss new data set may chang statist method use economist type question pose empir research
832139bd87f51f0a173b5bd9255944748bc31a96,Global multi-resolution terrain elevation data 2010 (GMTED2010),"For more information on the USGS—the Federal source for science about the Earth, its natural and living resources, natural hazards, and the environment, visit http://www.usgs.gov or call 1–888–ASK–USGS. For an overview of USGS information products, including maps, imagery, and publications, Any use of trade, product, or firm names is for descriptive purposes only and does not imply endorsement by the U.S. Government. Although this report is in the public domain, permission must be secured from the individual copyright owners to reproduce any copyrighted materials contained within this report. 10. Diagram showing the GMTED2010 layer extents (minimum and maximum latitude and longitude) are a result of the coordinate system inherited from the 1-arc-second SRTM",inform usgsth feder sourc scienc earth natur live resourc natur hazard environ visit httpwwwusgsgov call askusg overview usg inform product includ map imageri public use trade product firm name descript purpos impli endors us govern although report public domain permiss must secur individu copyright owner reproduc copyright materi contain within report diagram show gmted layer extent minimum maximum latitud longitud result coordin system inherit arcsecond srtm
e0b16bb5d747d61a0f689a73354a5736a909378d,Spatio-Temporal Data Mining,"Large volumes of spatio-temporal data are increasingly collected and studied in diverse domains, including climate science, social sciences, neuroscience, epidemiology, transportation, mobile health, and Earth sciences. Spatio-temporal data differ from relational data for which computational approaches are developed in the data-mining community for multiple decades in that both spatial and temporal attributes are available in addition to the actual measurements/attributes. The presence of these attributes introduces additional challenges that needs to be dealt with. Approaches for mining spatio-temporal data have been studied for over a decade in the data-mining community. In this article, we present a broad survey of this relatively young field of spatio-temporal data mining. We discuss different types of spatio-temporal data and the relevant data-mining questions that arise in the context of analyzing each of these datasets. Based on the nature of the data-mining problem studied, we classify literature on spatio-temporal data mining into six major categories: clustering, predictive learning, change detection, frequent pattern mining, anomaly detection, and relationship mining. We discuss the various forms of spatio-temporal data-mining problems in each of these categories.",larg volum spatiotempor data increasingli collect studi divers domain includ climat scienc social scienc neurosci epidemiolog transport mobil health earth scienc spatiotempor data differ relat data comput approach develop datamin commun multipl decad spatial tempor attribut avail addit actual measurementsattribut presenc attribut introduc addit challeng need dealt approach mine spatiotempor data studi decad datamin commun articl present broad survey rel young field spatiotempor data mine discuss differ type spatiotempor data relev datamin question aris context analyz dataset base natur datamin problem studi classifi literatur spatiotempor data mine six major categori cluster predict learn chang detect frequent pattern mine anomali detect relationship mine discuss variou form spatiotempor datamin problem categori
06d2a3fde80c5644f14f743b29a57f6b02e850d9,The iPlant Collaborative: Cyberinfrastructure for Enabling Data to Discovery for the Life Sciences,"The iPlant Collaborative provides life science research communities access to comprehensive, scalable, and cohesive computational infrastructure for data management; identity management; collaboration tools; and cloud, high-performance, high-throughput computing. iPlant provides training, learning material, and best practice resources to help all researchers make the best use of their data, expand their computational skill set, and effectively manage their data and computation when working as distributed teams. iPlant’s platform permits researchers to easily deposit and share their data and deploy new computational tools and analysis workflows, allowing the broader community to easily use and reuse those data and computational analyses.",iplant collabor provid life scienc research commun access comprehens scalabl cohes comput infrastructur data manag ident manag collabor tool cloud highperform highthroughput comput iplant provid train learn materi best practic resourc help research make best use data expand comput skill set effect manag data comput work distribut team iplant platform permit research easili deposit share data deploy new comput tool analysi workflow allow broader commun easili use reus data comput analys
59b2796c176636a3222d7b129c6209fa6e979aa7,Data infrastructure literacy,"A recent report from the UN makes the case for “global data literacy” in order to realise the opportunities afforded by the “data revolution”. Here and in many other contexts, data literacy is characterised in terms of a combination of numerical, statistical and technical capacities. In this article, we argue for an expansion of the concept to include not just competencies in reading and working with datasets but also the ability to account for, intervene around and participate in the wider socio-technical infrastructures through which data is created, stored and analysed – which we call “data infrastructure literacy”. We illustrate this notion with examples of “inventive data practice” from previous and ongoing research on open data, online platforms, data journalism and data activism. Drawing on these perspectives, we argue that data literacy initiatives might cultivate sensibilities not only for data science but also for data sociology, data politics as well as wider public engagement with digital data infrastructures. The proposed notion of data infrastructure literacy is intended to make space for collective inquiry, experimentation, imagination and intervention around data in educational programmes and beyond, including how data infrastructures can be challenged, contested, reshaped and repurposed to align with interests and publics other than those originally intended.",recent report un make case global data literaci order realis opportun afford data revolut mani context data literaci characteris term combin numer statist technic capac articl argu expans concept includ compet read work dataset also abil account interven around particip wider sociotechn infrastructur data creat store analys call data infrastructur literaci illustr notion exampl invent data practic previou ongo research open data onlin platform data journal data activ draw perspect argu data literaci initi might cultiv sensibl data scienc also data sociolog data polit well wider public engag digit data infrastructur propos notion data infrastructur literaci intend make space collect inquiri experiment imagin intervent around data educ programm beyond includ data infrastructur challeng contest reshap repurpos align interest public origin intend
8ee4eda834e95124aca1e5ff05a1b8ce7d1487ec,Why Are Big Data Matrices Approximately Low Rank?,"Matrices of (approximate) low rank are pervasive in data science, appearing in movie preferences, text documents, survey data, medical records, and genomics. While there is a vast literature on how...",matric approxim low rank pervas data scienc appear movi prefer text document survey data medic record genom vast literatur
951eab2b27c673e0ff1a20800f576d4792f60d5f,Crisis informatics—New data for extraordinary times,"Focus on behaviors, not on fetishizing social media tools Crisis informatics is a multidisciplinary field combining computing and social science knowledge of disasters; its central tenet is that people use personal information and communication technology to respond to disaster in creative ways to cope with uncertainty. We study and develop computational support for collection and sociobehavioral analysis of online participation (i.e., tweets and Facebook posts) to address challenges in disaster warning, response, and recovery. Because such data are rarely tidy, we offer lessons—learned the hard way, as we have made every mistake described below—with respect to the opportunities and limitations of social media research on crisis events.",focu behavior fetish social media tool crisi informat multidisciplinari field combin comput social scienc knowledg disast central tenet peopl use person inform commun technolog respond disast creativ way cope uncertainti studi develop comput support collect sociobehavior analysi onlin particip ie tweet facebook post address challeng disast warn respons recoveri data rare tidi offer lessonslearn hard way made everi mistak describ belowwith respect opportun limit social media research crisi event
f7d7f1eb559d8e2f410289fca37bb6cec7a3a907,Data politics,"The commentary raises political questions about the ways in which data has been constituted as an object vested with certain powers, influence, and rationalities. We place the emergence and transformation of professional practices such as ‘data science’, ‘data journalism’, ‘data brokerage’, ‘data mining’, ‘data storage’, and ‘data analysis’ as part of the reconfiguration of a series of fields of power and knowledge in the public and private accumulation of data. Data politics asks questions about the ways in which data has become such an object of power and explores how to critically intervene in its deployment as an object of knowledge. It is concerned with the conditions of possibility of data that involve things (infrastructures of servers, devices, and cables), language (code, programming, and algorithms), and people (scientists, entrepreneurs, engineers, information technologists, designers) that together create new worlds. We define ‘data politics’ as both the articulation of political questions about these worlds and the ways in which they provoke subjects to govern themselves and others by making rights claims. We contend that without understanding these conditions of possibility – of worlds, subjects and rights – it would be difficult to intervene in or shape data politics if by that it is meant the transformation of data subjects into data citizens.",commentari rais polit question way data constitut object vest certain power influenc ration place emerg transform profession practic data scienc data journal data brokerag data mine data storag data analysi part reconfigur seri field power knowledg public privat accumul data data polit ask question way data becom object power explor critic interven deploy object knowledg concern condit possibl data involv thing infrastructur server devic cabl languag code program algorithm peopl scientist entrepreneur engin inform technologist design togeth creat new world defin data polit articul polit question world way provok subject govern other make right claim contend without understand condit possibl world subject right would difficult interven shape data polit meant transform data subject data citizen
0d7a9a5233b1460941b51a50e032b3c5d3a711cc,The Interview: Data Collection in Descriptive Phenomenological Human Scientific Research*,"Abstract In this article, interviewing from a descriptive, phenomenological, human scientific perspective is examined. Methodological issues are raised in relation to evaluative criteria as well as reflective matters that concern the phenomenological researcher. The data collection issues covered are 1) the selection of participants, 2) the number of participants in a study, 3) the interviewer and the questions, and 4) data collection procedures. Certain conclusions were drawn indicating that phenomenological research methods cannot be evaluated on the basis of an empiricist theory of science, but must be critiqued from within a phenomenological theory of science. Some reflective matters, experienced by the phenomenological researcher, are also elaborated upon.",abstract articl interview descript phenomenolog human scientif perspect examin methodolog issu rais relat evalu criteria well reflect matter concern phenomenolog research data collect issu cover select particip number particip studi interview question data collect procedur certain conclus drawn indic phenomenolog research method cannot evalu basi empiricist theori scienc must critiqu within phenomenolog theori scienc reflect matter experienc phenomenolog research also elabor upon
e7f5ab8f486487dcefdf9b989d0eff2f0beff48c,A Qualitative Framework for Collecting and Analyzing Data in Focus Group Research,"Despite the abundance of published material on conducting focus groups, scant specific information exists on how to analyze focus group data in social science research. Thus, the authors provide a new qualitative framework for collecting and analyzing focus group data. First, they identify types of data that can be collected during focus groups. Second, they identify the qualitative data analysis techniques best suited for analyzing these data. Third, they introduce what they term as a micro-interlocutor analysis, wherein meticulous information about which participant responds to each question, the order in which each participant responds, response characteristics, the nonverbal communication used, and the like is collected, analyzed, and interpreted. They conceptualize how conversation analysis offers great potential for analyzing focus group data. They believe that their framework goes far beyond analyzing only the verbal communication of focus group participants, thereby increasing the rigor of focus group analyses in social science research.",despit abund publish materi conduct focu group scant specif inform exist analyz focu group data social scienc research thu author provid new qualit framework collect analyz focu group data first identifi type data collect focu group second identifi qualit data analysi techniqu best suit analyz data third introduc term microinterlocutor analysi wherein meticul inform particip respond question order particip respond respons characterist nonverb commun use like collect analyz interpret conceptu convers analysi offer great potenti analyz focu group data believ framework goe far beyond analyz verbal commun focu group particip therebi increas rigor focu group analys social scienc research
052fcf10e96f282c0fb50f778150afeaf92bb65d,Inquiry-based science instruction—what is it and does it matter? Results from a research synthesis years 1984 to 2002,"The goal of the Inquiry Synthesis Project was to synthesize findings from research conducted between 1984 and 2002 to address the research question, What is the impact of inquiry science instruction on K-12 student outcomes? The timeframe of 1984 to 2002 was selected to continue a line of synthesis work last completed in 1983 by Bredderman (Bredderman (1983) Review of Educational Research 53: 499-518) and Shymansky, Kyle, and Alport (Shymansky et al. (1983) Journal of Research in Science Teaching 20: 387-404), and to accommodate a practicable cut- off date given the research project timeline, which ran from 2001 to 2006. The research question for the project was addressed by developing a conceptual framework that clarifies and specifies what is meant by ''inquiry-based science instruction,'' and by using a mixed-methodology approach to analyze both numerical and text data describing the impact of instruction on K-12 student science conceptual learning. Various findings across 138 analyzed studies indicate a clear, positive trend favoring inquiry-based instructional practices, particularly instruction that emphasizes student active thinking and drawing conclusions from data. Teaching strategies that actively engage students in the learning process through scientific investigations are more likely to increase conceptual understanding than are strategies that rely on more passive techniques, which are often necessary in the current standardized-assessment laden educational environment.",goal inquiri synthesi project synthes find research conduct address research question impact inquiri scienc instruct k student outcom timefram select continu line synthesi work last complet bredderman bredderman review educ research shymanski kyle alport shymanski et al journal research scienc teach accommod practic cut date given research project timelin ran research question project address develop conceptu framework clarifi specifi meant inquirybas scienc instruct use mixedmethodolog approach analyz numer text data describ impact instruct k student scienc conceptu learn variou find across analyz studi indic clear posit trend favor inquirybas instruct practic particularli instruct emphas student activ think draw conclus data teach strategi activ engag student learn process scientif investig like increas conceptu understand strategi reli passiv techniqu often necessari current standardizedassess laden educ environ
e981f16fde9185373634b53d94baa1f9185ff890,A correlated topic model of Science,"Topic models, such as latent Dirichlet allocation (LDA), can be useful tools for the statistical analysis of document collections and other discrete data. The LDA model assumes that the words of each document arise from a mixture of topics, each of which is a distribution over the vocabulary. A limitation of LDA is the inability to model topic correlation even though, for example, a document about genetics is more likely to also be about disease than X-ray astronomy. This limitation stems from the use of the Dirichlet distribution to model the variability among the topic proportions. In this paper we develop the correlated topic model (CTM), where the topic proportions exhibit correlation via the logistic normal distribution [J. Roy. Statist. Soc. Ser. B 44 (1982) 139--177]. We derive a fast variational inference algorithm for approximate posterior inference in this model, which is complicated by the fact that the logistic normal is not conjugate to the multinomial. We apply the CTM to the articles from Science published from 1990--1999, a data set that comprises 57M words. The CTM gives a better fit of the data than LDA, and we demonstrate its use as an exploratory tool of large document collections.",topic model latent dirichlet alloc lda use tool statist analysi document collect discret data lda model assum word document aris mixtur topic distribut vocabulari limit lda inabl model topic correl even though exampl document genet like also diseas xray astronomi limit stem use dirichlet distribut model variabl among topic proport paper develop correl topic model ctm topic proport exhibit correl via logist normal distribut j roy statist soc ser b deriv fast variat infer algorithm approxim posterior infer model complic fact logist normal conjug multinomi appli ctm articl scienc publish data set compris word ctm give better fit data lda demonstr use exploratori tool larg document collect
411f9ebe18a885e687788841f4b3a60a0c3df3bc,Computational Social Science,,nan
7e95c6f943b7c47af1b2ef1651b86022a001ce81,A Review of Microsoft Academic Services for Science of Science Studies,"Since the relaunch of Microsoft Academic Services (MAS) 4 years ago, scholarly communications have undergone dramatic changes: more ideas are being exchanged online, more authors are sharing their data, and more software tools used to make discoveries and reproduce the results are being distributed openly. The sheer amount of information available is overwhelming for individual humans to keep up and digest. In the meantime, artificial intelligence (AI) technologies have made great strides and the cost of computing has plummeted to the extent that it has become practical to employ intelligent agents to comprehensively collect and analyze scholarly communications. MAS is one such effort and this paper describes its recent progresses since the last disclosure. As there are plenty of independent studies affirming the effectiveness of MAS, this paper focuses on the use of three key AI technologies that underlies its prowess in capturing scholarly communications with adequate quality and broad coverage: (1) natural language understanding in extracting factoids from individual articles at the web scale, (2) knowledge assisted inference and reasoning in assembling the factoids into a knowledge graph, and (3) a reinforcement learning approach to assessing scholarly importance for entities participating in scholarly communications, called the saliency, that serves both as an analytic and a predictive metric in MAS. These elements enhance the capabilities of MAS in supporting the studies of science of science based on the GOTO principle, i.e., good and open data with transparent and objective methodologies. The current direction of development and how to access the regularly updated data and tools from MAS, including the knowledge graph, a REST API and a website, are also described.",sinc relaunch microsoft academ servic ma year ago scholarli commun undergon dramat chang idea exchang onlin author share data softwar tool use make discoveri reproduc result distribut openli sheer amount inform avail overwhelm individu human keep digest meantim artifici intellig ai technolog made great stride cost comput plummet extent becom practic employ intellig agent comprehens collect analyz scholarli commun ma one effort paper describ recent progress sinc last disclosur plenti independ studi affirm effect ma paper focus use three key ai technolog underli prowess captur scholarli commun adequ qualiti broad coverag natur languag understand extract factoid individu articl web scale knowledg assist infer reason assembl factoid knowledg graph reinforc learn approach assess scholarli import entiti particip scholarli commun call salienc serv analyt predict metric ma element enhanc capabl ma support studi scienc scienc base goto principl ie good open data transpar object methodolog current direct develop access regularli updat data tool ma includ knowledg graph rest api websit also describ
eb286565b6a18e21b9daf5375c75d56513cd2853,Big Earth data: A new frontier in Earth and information sciences,"Abstract Big data is a revolutionary innovation that has allowed the development of many new methods in scientific research. This new way of thinking has encouraged the pursuit of new discoveries. Big data occupies the strategic high ground in the era of knowledge economies and also constitutes a new national and global strategic resource. “Big Earth data”, derived from, but not limited to, Earth observation has macro-level capabilities that enable rapid and accurate monitoring of the Earth, and is becoming a new frontier contributing to the advancement of Earth science and significant scientific discoveries. Within the context of the development of big data, this paper analyzes the characteristics of scientific big data and recognizes its great potential for development, particularly with regard to the role that big Earth data can play in promoting the development of Earth science. On this basis, the paper outlines the Big Earth Data Science Engineering Project (CASEarth) of the Chinese Academy of Sciences Strategic Priority Research Program. Big data is at the forefront of the integration of geoscience, information science, and space science and technology, and it is expected that big Earth data will provide new prospects for the development of Earth science.",abstract big data revolutionari innov allow develop mani new method scientif research new way think encourag pursuit new discoveri big data occupi strateg high ground era knowledg economi also constitut new nation global strateg resourc big earth data deriv limit earth observ macrolevel capabl enabl rapid accur monitor earth becom new frontier contribut advanc earth scienc signific scientif discoveri within context develop big data paper analyz characterist scientif big data recogn great potenti develop particularli regard role big earth data play promot develop earth scienc basi paper outlin big earth data scienc engin project casearth chines academi scienc strateg prioriti research program big data forefront integr geoscienc inform scienc space scienc technolog expect big earth data provid new prospect develop earth scienc
9e7be12082f58cbf7ebdb84a8cbdc897a4e41683,The Deluge of Spurious Correlations in Big Data,,nan
9355e60deaad86d1efea4b7767dd77103d647f37,Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"It is our great pleasure to welcome you to the 2016 ACM Conference on Knowledge Discovery and Data Mining -- KDD'16. We hope that the content and the professional network at KDD'16 will help you succeed professionally by enabling you to: identify technology trends early; make new/creative contributions; increase your productivity by using newer/better tools, processes or ways of organizing teams; identify new job opportunities; and hire new team members. 
 
We are living in an exciting time for our profession. On the one hand, we are witnessing the industrialization of data science, and the emergence of the industrial assembly line processes characterized by the division of labor, integrated processes/pipelines of work, standards, automation, and repeatability. Data science practitioners are organizing themselves in more sophisticated ways, embedding themselves in larger teams in many industry verticals, improving their productivity substantially, and achieving a much larger scale of social impact. On the other hand we are also witnessing astonishing progress from research in algorithms and systems -- for example the field of deep neural networks has revolutionized speech recognition, NLP, computer vision, image recognition, etc. By facilitating interaction between practitioners at large companies & startups on the one hand, and the algorithm development researchers including leading academics on the other, KDD'16 fosters technological and entrepreneurial innovation in the area of data science. 
 
This year's conference continues its tradition of being the premier forum for presentation of results in the field of data mining, both in the form of cutting edge research, and in the form of insights from the development and deployment of real world applications. Further, the conference continues with its tradition of a strong tutorial and workshop program on leading edge issues of data mining. The mission of this conference has broadened in recent years even as we placed a significant amount of focus on both the research and applied aspects of data mining. As an example of this broadened focus, this year we have introduced a strong hands-on tutorial program nduring the conference in which participants will learn how to use practical tools for data mining. KDD'16 also gives researchers and practitioners a unique opportunity to form professional networks, and to share their perspectives with others interested in the various aspects of data mining. For example, we have introduced office hours for budding entrepreneurs from our community to meet leading Venture Capitalists investing in this area. We hope that KDD 2016 conference will serve as a meeting ground for researchers, practitioners, funding agencies, and investors to help create new algorithms and commercial products. 
 
The call for papers attracted a significant number of submissions from countries all over the world. In particular, the research track attracted 784 submissions and the applied data science track attracted 331 submissions. Papers were accepted either as full papers or as posters. The overall acceptance rate either as full papers or posters was less than 20%. For full papers in the research track, the acceptance rate was lower than 10%. This is consistent with the fact that the KDD Conference is a premier conference in data mining and the acceptance rates historically tend to be low. It is noteworthy that the applied data science track received a larger number of submissions compared to previous years. We view this as an encouraging sign that research in data mining is increasingly becoming relevant to industrial applications. All papers were reviewed by at least three program committee members and then discussed by the PC members in a discussion moderated by a meta-reviewer. Borderline papers were thoroughly reviewed by the program chairs before final decisions were made.",great pleasur welcom acm confer knowledg discoveri data mine kdd hope content profession network kdd help succeed profession enabl identifi technolog trend earli make newcr contribut increas product use newerbett tool process way organ team identifi new job opportun hire new team member live excit time profess one hand wit industri data scienc emerg industri assembl line process character divis labor integr processespipelin work standard autom repeat data scienc practition organ sophist way embed larger team mani industri vertic improv product substanti achiev much larger scale social impact hand also wit astonish progress research algorithm system exampl field deep neural network revolution speech recognit nlp comput vision imag recognit etc facilit interact practition larg compani startup one hand algorithm develop research includ lead academ kdd foster technolog entrepreneuri innov area data scienc year confer continu tradit premier forum present result field data mine form cut edg research form insight develop deploy real world applic confer continu tradit strong tutori workshop program lead edg issu data mine mission confer broaden recent year even place signific amount focu research appli aspect data mine exampl broaden focu year introduc strong handson tutori program ndure confer particip learn use practic tool data mine kdd also give research practition uniqu opportun form profession network share perspect other interest variou aspect data mine exampl introduc offic hour bud entrepreneur commun meet lead ventur capitalist invest area hope kdd confer serv meet ground research practition fund agenc investor help creat new algorithm commerci product call paper attract signific number submiss countri world particular research track attract submiss appli data scienc track attract submiss paper accept either full paper poster overal accept rate either full paper poster less full paper research track accept rate lower consist fact kdd confer premier confer data mine accept rate histor tend low noteworthi appli data scienc track receiv larger number submiss compar previou year view encourag sign research data mine increasingli becom relev industri applic paper review least three program committe member discuss pc member discuss moder metareview borderlin paper thoroughli review program chair final decis made
ab2b6f43b0a99dc513f46e7f1684f55ce12de5d9,The end of theory: The data deluge makes the scientific method obsolete,"Illustration: Marian Bantjes The Petabyte Age: Sensors everywhere. Infinite storage. Clouds of processors. Our ability to capture, warehouse, and understand massive amounts of data is changing science, medicine, business, and technology. As our collection of facts and figures grows, so will the opportunity to find answers to fundamental questions. Because in the era of big data, more isn't just more. More is different. The End of Theory: Essay: The Data Deluge Makes the Scientific Method Obsolete",illustr marian bantj petabyt age sensor everywher infinit storag cloud processor abil captur warehous understand massiv amount data chang scienc medicin busi technolog collect fact figur grow opportun find answer fundament question era big data isnt differ end theori essay data delug make scientif method obsolet
c50dca78e97e335d362d6b991ae0e1448914e9a3,Reducing the Dimensionality of Data with Neural,"http://www.sciencemag.org/cgi/content/full/313/5786/504 version of this article at: including high-resolution figures, can be found in the online Updated information and services, http://www.sciencemag.org/cgi/content/full/313/5786/504/DC1 can be found at: Supporting Online Material found at: can be related to this article A list of selected additional articles on the Science Web sites http://www.sciencemag.org/cgi/content/full/313/5786/504#related-content http://www.sciencemag.org/cgi/content/full/313/5786/504#otherarticles , 6 of which can be accessed for free: cites 8 articles This article 15 article(s) on the ISI Web of Science. cited by This article has been http://www.sciencemag.org/cgi/content/full/313/5786/504#otherarticles 4 articles hosted by HighWire Press; see: cited by This article has been http://www.sciencemag.org/about/permissions.dtl in whole or in part can be found at: this article permission to reproduce of this article or about obtaining reprints Information about obtaining",httpwwwsciencemagorgcgicontentful version articl includ highresolut figur found onlin updat inform servic httpwwwsciencemagorgcgicontentfulldc found support onlin materi found relat articl list select addit articl scienc web site httpwwwsciencemagorgcgicontentfullrelatedcont httpwwwsciencemagorgcgicontentfullotherarticl access free cite articl articl articl isi web scienc cite articl httpwwwsciencemagorgcgicontentfullotherarticl articl host highwir press see cite articl httpwwwsciencemagorgaboutpermissionsdtl whole part found articl permiss reproduc articl obtain reprint inform obtain
53b9b242f8cb2007e8e3dd9db5cd11b88fa6c4a7,Nonparametric Statistics for the Behavioral Sciences,"diabetes statistics cdc ��glucagon megaroll.infoCorn oil, but not cocaine, is a more effective reinforcer Data Analysis of Students Marks with Descriptive StatisticsFriedman test WikipediaDownload Free any eBook PDF, Epub, Tuebl and MobiStatistics (STAT) < University of PennsylvaniaErik Sudderth Donald Bren School of Information and Bootstrapping (statistics) WikipediaRunze Li's Homepage Pennsylvania State UniversityCausal inference in statistics: An overviewFind a Doctor | Clinicians, Researchers & Nurses ETDAUndergraduate Course Descriptions Statistics DepartmentComputation of different effect sizes like d, f, r and Biography and Activities | Susan HolmesFaculty | Department of StatisticsNonparametric Method Definition InvestopediaStatistics Final Exam Flashcards | QuizletTest di Kruskal-Wallis WikipediaDepartment of Statistics and Data Science < Carnegie The use of statistics in social sciences | Emerald InsightBehavioral Genetics Psychology Oxford BibliographiesInterpreting statistics Introduction to statistics G*Power 3: a flexible statistical power analysis program Lifetime Data Analysis | Home SpringerWilcoxon Test Definition InvestopediaGraphPad Prism 9 Statistics Guide Interpreting results Log In BACBNonparametric Tests Boston UniversityTopic #1: Introduction to measurement and statisticsStatistics Assignment Help | Statistics Homework HelpStatistics (STAT) | Iowa State University CatalogEric J. Tchetgen Tchetgen – Department of Statistics and Journals American Statistical AssociationWhat is the rationale behind the magic number 30 in",diabet statist cdc glucagon megarollinfocorn oil cocain effect reinforc data analysi student mark descript statisticsfriedman test wikipediadownload free ebook pdf epub tuebl mobistatist stat univers pennsylvaniaerik sudderth donald bren school inform bootstrap statist wikipediarunz li homepag pennsylvania state universitycaus infer statist overviewfind doctor clinician research nurs etdaundergradu cours descript statist departmentcomput differ effect size like f r biographi activ susan holmesfaculti depart statisticsnonparametr method definit investopediastatist final exam flashcard quizlettest di kruskalw wikipediadepart statist data scienc carnegi use statist social scienc emerald insightbehavior genet psycholog oxford bibliographiesinterpret statist introduct statist gpower flexibl statist power analysi program lifetim data analysi home springerwilcoxon test definit investopediagraphpad prism statist guid interpret result log bacbnonparametr test boston universitytop introduct measur statisticsstatist assign help statist homework helpstatist stat iowa state univers cataloger j tchetgen tchetgen depart statist journal american statist associationwhat rational behind magic number
5a71eea4b4efc5fc25868bdf9ba7df2321f98c73,Data Journeys in the Sciences,,nan
6e78b1133713cb17aabbc3bf421a6e51bc538eca,Social Science in the Era of Big Data,"Digital technologies keep track of everything we do and say while we are online, and we spend online an increasing portion of our time. Databases hidden behind web services and applications are constantly fed with information of our movements and communication patterns, and a significant dimension of our lives, quantified to unprecedented levels, gets stored in those vast online repositories. This article considers some of the implications of this torrent of data for social science research, and for the types of questions we can ask of the world we inhabit. The goal of the article is twofold: to explain why, in spite of all the data, theory still matters to build credible stories of what the data reveal; and to show how this allows social scientists to revisit old questions at the intersection of new technologies and disciplinary approaches. The article also considers how Big Data research can transform policy making, with a focus on how it can help us improve communication and governance in policy-relevant domains.",digit technolog keep track everyth say onlin spend onlin increas portion time databas hidden behind web servic applic constantli fed inform movement commun pattern signific dimens live quantifi unpreced level get store vast onlin repositori articl consid implic torrent data social scienc research type question ask world inhabit goal articl twofold explain spite data theori still matter build credibl stori data reveal show allow social scientist revisit old question intersect new technolog disciplinari approach articl also consid big data research transform polici make focu help us improv commun govern policyrelev domain
2592aa0de9955a5b5bfc0039387dacb5874a1107,Conscientious Classification: A Data Scientist's Guide to Discrimination-Aware Classification,"Recent research has helped to cultivate growing awareness that machine-learning systems fueled by big data can create or exacerbate troubling disparities in society. Much of this research comes from outside of the practicing data science community, leaving its members with little concrete guidance to proactively address these concerns. This article introduces issues of discrimination to the data science community on its own terms. In it, we tour the familiar data-mining process while providing a taxonomy of common practices that have the potential to produce unintended discrimination. We also survey how discrimination is commonly measured, and suggest how familiar development processes can be augmented to mitigate systems' discriminatory potential. We advocate that data scientists should be intentional about modeling and reducing discriminatory outcomes. Without doing so, their efforts will result in perpetuating any systemic discrimination that may exist, but under a misleading veil of data-driven objectivity.",recent research help cultiv grow awar machinelearn system fuel big data creat exacerb troubl dispar societi much research come outsid practic data scienc commun leav member littl concret guidanc proactiv address concern articl introduc issu discrimin data scienc commun term tour familiar datamin process provid taxonomi common practic potenti produc unintend discrimin also survey discrimin commonli measur suggest familiar develop process augment mitig system discriminatori potenti advoc data scientist intent model reduc discriminatori outcom without effort result perpetu system discrimin may exist mislead veil datadriven object
7657d17d796659427e067f1cac93e4038d01725f,Big Scholarly Data: A Survey,"With the rapid growth of digital publishing, harvesting, managing, and analyzing scholarly information have become increasingly challenging. The term Big Scholarly Data is coined for the rapidly growing scholarly data, which contains information including millions of authors, papers, citations, figures, tables, as well as scholarly networks and digital libraries. Nowadays, various scholarly data can be easily accessed and powerful data analysis technologies are being developed, which enable us to look into science itself with a new perspective. In this paper, we examine the background and state of the art of big scholarly data. We first introduce the background of scholarly data management and relevant technologies. Second, we review data analysis methods, such as statistical analysis, social network analysis, and content analysis for dealing with big scholarly data. Finally, we look into representative research issues in this area, including scientific impact evaluation, academic recommendation, and expert finding. For each issue, the background, main challenges, and latest research are covered. These discussions aim to provide a comprehensive review of this emerging area. This survey paper concludes with a discussion of open issues and promising future directions.",rapid growth digit publish harvest manag analyz scholarli inform becom increasingli challeng term big scholarli data coin rapidli grow scholarli data contain inform includ million author paper citat figur tabl well scholarli network digit librari nowaday variou scholarli data easili access power data analysi technolog develop enabl us look scienc new perspect paper examin background state art big scholarli data first introduc background scholarli data manag relev technolog second review data analysi method statist analysi social network analysi content analysi deal big scholarli data final look repres research issu area includ scientif impact evalu academ recommend expert find issu background main challeng latest research cover discuss aim provid comprehens review emerg area survey paper conclud discuss open issu promis futur direct
afefe35db68dabf33fa548ab818b46c47c860e08,Big Data and Internet of Things: A Roadmap for Smart Environments,,nan
06fd9101e742ca920c23f3797c19022c13f5a9b5,"Science friction: Data, metadata, and collaboration","When scientists from two or more disciplines work together on related problems, they often face what we call ‘science friction’. As science becomes more data-driven, collaborative, and interdisciplinary, demand increases for interoperability among data, tools, and services. Metadata – usually viewed simply as ‘data about data’, describing objects such as books, journal articles, or datasets – serve key roles in interoperability. Yet we find that metadata may be a source of friction between scientific collaborators, impeding data sharing. We propose an alternative view of metadata, focusing on its role in an ephemeral process of scientific communication, rather than as an enduring outcome or product. We report examples of highly useful, yet ad hoc, incomplete, loosely structured, and mutable, descriptions of data found in our ethnographic studies of several large projects in the environmental sciences. Based on this evidence, we argue that while metadata products can be powerful resources, usually they must be supplemented with metadata processes. Metadata-as-process suggests the very large role of the ad hoc, the incomplete, and the unfinished in everyday scientific work.",scientist two disciplin work togeth relat problem often face call scienc friction scienc becom datadriven collabor interdisciplinari demand increas interoper among data tool servic metadata usual view simpli data data describ object book journal articl dataset serv key role interoper yet find metadata may sourc friction scientif collabor imped data share propos altern view metadata focus role ephemer process scientif commun rather endur outcom product report exampl highli use yet ad hoc incomplet loos structur mutabl descript data found ethnograph studi sever larg project environment scienc base evid argu metadata product power resourc usual must supplement metadata process metadataasprocess suggest larg role ad hoc incomplet unfinish everyday scientif work
825725943fe1774b1b490d69094ba6269cc9c6b2,SciMAT: A new science mapping analysis software tool,"This article presents a new open-source software tool, SciMAT, which performs science mapping analysis within a longitudinal framework. It provides different modules that help the analyst to carry out all the steps of the science mapping workflow. In addition, SciMAT presents three key features that are remarkable in respect to other science mapping software tools: (a) a powerful preprocessing module to clean the raw bibliographical data, (b) the use of bibliometric measures to study the impact of each studied element, and (c) a wizard to configure the analysis. © 2012 Wiley Periodicals, Inc.",articl present new opensourc softwar tool scimat perform scienc map analysi within longitudin framework provid differ modul help analyst carri step scienc map workflow addit scimat present three key featur remark respect scienc map softwar tool power preprocess modul clean raw bibliograph data b use bibliometr measur studi impact studi element c wizard configur analysi wiley period inc
4a6377c0d1512ee5c780320828699ed19e158323,Big data and the future of ecology,"The need for sound ecological science has escalated alongside the rise of the information age and “big data” across all sectors of society. Big data generally refer to massive volumes of data not readily handled by the usual data tools and practices and present unprecedented opportunities for advancing science and inform- ing resource management through data-intensive approaches. The era of big data need not be propelled only by “big science” – the term used to describe large-scale efforts that have had mixed success in the individual-driven culture of ecology. Collectively, ecologists already have big data to bolster the scientific effort – a large volume of distributed, high-value information – but many simply fail to contribute. We encourage ecologists to join the larger scientific community in global initiatives to address major scientific and societal problems by bringing their distributed data to the table and harnessing its collective power. The scientists who contribute such information will be at the forefront of socially relevant science – but will they be ecologists?",need sound ecolog scienc escal alongsid rise inform age big data across sector societi big data gener refer massiv volum data readili handl usual data tool practic present unpreced opportun advanc scienc inform ing resourc manag dataintens approach era big data need propel big scienc term use describ largescal effort mix success individualdriven cultur ecolog collect ecologist alreadi big data bolster scientif effort larg volum distribut highvalu inform mani simpli fail contribut encourag ecologist join larger scientif commun global initi address major scientif societ problem bring distribut data tabl har collect power scientist contribut inform forefront social relev scienc ecologist
4a1aa84c8f1d14afd53fe667a491176fed2aa46b,Human neuroimaging as a “Big Data” science,,nan
6f0ec43983a6e3aedd6e297fa94871116b401a07,BIG DATA ANALYTICS AND PRECISION ANIMAL AGRICULTURE SYMPOSIUM: Machine learning and data mining advance predictive big data analysis in precision animal agriculture,"Abstract Precision animal agriculture is poised to rise to prominence in the livestock enterprise in the domains of management, production, welfare, sustainability, health surveillance, and environmental footprint. Considerable progress has been made in the use of tools to routinely monitor and collect information from animals and farms in a less laborious manner than before. These efforts have enabled the animal sciences to embark on information technology-driven discoveries to improve animal agriculture. However, the growing amount and complexity of data generated by fully automated, high-throughput data recording or phenotyping platforms, including digital images, sensor and sound data, unmanned systems, and information obtained from real-time noninvasive computer vision, pose challenges to the successful implementation of precision animal agriculture. The emerging fields of machine learning and data mining are expected to be instrumental in helping meet the daunting challenges facing global agriculture. Yet, their impact and potential in “big data” analysis have not been adequately appreciated in the animal science community, where this recognition has remained only fragmentary. To address such knowledge gaps, this article outlines a framework for machine learning and data mining and offers a glimpse into how they can be applied to solve pressing problems in animal sciences.",abstract precis anim agricultur pois rise promin livestock enterpris domain manag product welfar sustain health surveil environment footprint consider progress made use tool routin monitor collect inform anim farm less labori manner effort enabl anim scienc embark inform technologydriven discoveri improv anim agricultur howev grow amount complex data gener fulli autom highthroughput data record phenotyp platform includ digit imag sensor sound data unman system inform obtain realtim noninvas comput vision pose challeng success implement precis anim agricultur emerg field machin learn data mine expect instrument help meet daunt challeng face global agricultur yet impact potenti big data analysi adequ appreci anim scienc commun recognit remain fragmentari address knowledg gap articl outlin framework machin learn data mine offer glimps appli solv press problem anim scienc
40e1ac2c42a7c9c1aeb80d3c0dab6de55b40eddd,The conundrum of sharing research data,"We must all accept that science is data and that data are science, and thus provide for, and justify the need for the support of, much-improved data curation. (Hanson, Sugden, & Alberts) 
 
Researchers are producing an unprecedented deluge of data by using new methods and instrumentation. Others may wish to mine these data for new discoveries and innovations. However, research data are not readily available as sharing is common in only a few fields such as astronomy and genomics. Data sharing practices in other fields vary widely. Moreover, research data take many forms, are handled in many ways, using many approaches, and often are difficult to interpret once removed from their initial context. Data sharing is thus a conundrum. Four rationales for sharing data are examined, drawing examples from the sciences, social sciences, and humanities: (1) to reproduce or to verify research, (2) to make results of publicly funded research available to the public, (3) to enable others to ask new questions of extant data, and (4) to advance the state of research and innovation. These rationales differ by the arguments for sharing, by beneficiaries, and by the motivations and incentives of the many stakeholders involved. The challenges are to understand which data might be shared, by whom, with whom, under what conditions, why, and to what effects. Answers will inform data policy and practice. © 2012 Wiley Periodicals, Inc.",must accept scienc data data scienc thu provid justifi need support muchimprov data curat hanson sugden albert research produc unpreced delug data use new method instrument other may wish mine data new discoveri innov howev research data readili avail share common field astronomi genom data share practic field vari wide moreov research data take mani form handl mani way use mani approach often difficult interpret remov initi context data share thu conundrum four rational share data examin draw exampl scienc social scienc human reproduc verifi research make result publicli fund research avail public enabl other ask new question extant data advanc state research innov rational differ argument share beneficiari motiv incent mani stakehold involv challeng understand data might share condit effect answer inform data polici practic wiley period inc
f41f3ad8c286a8dc509b2fa42b5febe81bcec9d8,The Open Knowledge Foundation: Open Data Means Better Science,"Open data leads to better science, but overcoming the barriers to widespread publication and availability of open scientific data requires a community effort. The Open Knowledge Foundation Open Data in Science Working Group describes their role in this movement.",open data lead better scienc overcom barrier widespread public avail open scientif data requir commun effort open knowledg foundat open data scienc work group describ role movement
361df482f4c74cb85d0f2fa897a4491fbf53ab6f,The Matthew effect in empirical data,"The Matthew effect describes the phenomenon that in societies, the rich tend to get richer and the potent even more powerful. It is closely related to the concept of preferential attachment in network science, where the more connected nodes are destined to acquire many more links in the future than the auxiliary nodes. Cumulative advantage and success-breads-success also both describe the fact that advantage tends to beget further advantage. The concept is behind the many power laws and scaling behaviour in empirical data, and it is at the heart of self-organization across social and natural sciences. Here, we review the methodology for measuring preferential attachment in empirical data, as well as the observations of the Matthew effect in patterns of scientific collaboration, socio-technical and biological networks, the propagation of citations, the emergence of scientific progress and impact, career longevity, the evolution of common English words and phrases, as well as in education and brain development. We also discuss whether the Matthew effect is due to chance or optimization, for example related to homophily in social systems or efficacy in technological systems, and we outline possible directions for future research.",matthew effect describ phenomenon societi rich tend get richer potent even power close relat concept preferenti attach network scienc connect node destin acquir mani link futur auxiliari node cumul advantag successbreadssuccess also describ fact advantag tend beget advantag concept behind mani power law scale behaviour empir data heart selforgan across social natur scienc review methodolog measur preferenti attach empir data well observ matthew effect pattern scientif collabor sociotechn biolog network propag citat emerg scientif progress impact career longev evolut common english word phrase well educ brain develop also discuss whether matthew effect due chanc optim exampl relat homophili social system efficaci technolog system outlin possibl direct futur research
c984f429334fb6d20041cf3959084c19ccdc27b8,"A Framework for Articulating and Measuring Individual Learning Outcomes
 from Participation in Citizen Science","Since first being introduced in the mid 1990s, the term “citizen science”—the intentional engagement of the public in scientific research—has seen phenomenal growth as measured by the number of projects developed, people involved, and articles published. In addition to contributing to scientific knowledge, many citizen science projects attempt to achieve learning outcomes among their participants, however, little guidance is available for practitioners regarding the types of learning that can be supported through citizen science or the measuring of learning outcomes. This study provides empirical data to understand how intended learning outcomes first described by the informal science education field have been employed and measured within the citizen science field. We also present a framework for describing learning outcomes that should help citizen science practitioners, researchers, and evaluators in designing projects and in studying and evaluating their impacts. This is a first step in building evaluation capacity across the field of citizen science.",sinc first introduc mid term citizen scienceth intent engag public scientif researchha seen phenomen growth measur number project develop peopl involv articl publish addit contribut scientif knowledg mani citizen scienc project attempt achiev learn outcom among particip howev littl guidanc avail practition regard type learn support citizen scienc measur learn outcom studi provid empir data understand intend learn outcom first describ inform scienc educ field employ measur within citizen scienc field also present framework describ learn outcom help citizen scienc practition research evalu design project studi evalu impact first step build evalu capac across field citizen scienc
8a88e9710ad9b4cb8db6a3086ede9c531d994917,The Service Revolution and the Transformation of Marketing Science,"The nature of marketing science is changing in a systematic, predictable, and irrevocable way. As information technology enables ubiquitous customer communication and big customer data, the fundamental nature of the firm's connection to the customer changes: better, more personalized service can be offered, from which service relationships are deepened, and consequently, more profitable customers grow the influence of service within the goods sector and expand the service sector in the economy. Marketing is becoming more personalized, and marketing science techniques that exploit customer heterogeneity are becoming more important. Information technology improvements also guarantee the increasing importance and usage of computationally intensive data processing and “big data.” Most importantly, these trends have already lasted for more than a century, and they will become even more pronounced in the coming years as a result of the monotonic nature of technology improvement. These changes imply a transformation of marketing science in both the topics to be emphasized and the methods to be employed. Increasingly, and inevitably, all of marketing will come to resemble to a greater degree the formerly specialized area of service marketing, only with an increased emphasis on marketing analytics.",natur market scienc chang systemat predict irrevoc way inform technolog enabl ubiquit custom commun big custom data fundament natur firm connect custom chang better person servic offer servic relationship deepen consequ profit custom grow influenc servic within good sector expand servic sector economi market becom person market scienc techniqu exploit custom heterogen becom import inform technolog improv also guarante increas import usag comput intens data process big data importantli trend alreadi last centuri becom even pronounc come year result monoton natur technolog improv chang impli transform market scienc topic emphas method employ increasingli inevit market come resembl greater degre formerli special area servic market increas emphasi market analyt
6390de1c0bce1f2f59c849dd7bcc8330636ee808,"Citizen science: a new approach to advance ecology, education, and conservation",,nan
16c30c6449182f6ad1235a58321d4bc4c297fbf6,An open science resource for establishing reliability and reproducibility in functional connectomics,,nan
1f53b2c6428ca6b4484b201e14b56d41db5c5ce1,Prognostics and Health Management: A Review on Data Driven Approaches,"Prognostics and health management (PHM) is a framework that offers comprehensive yet individualized solutions for managing system health. In recent years, PHM has emerged as an essential approach for achieving competitive advantages in the global market by improving reliability, maintainability, safety, and affordability. Concepts and components in PHM have been developed separately in many areas such as mechanical engineering, electrical engineering, and statistical science, under varied names. In this paper, we provide a concise review of mainstream methods in major aspects of the PHM framework, including the updated research from both statistical science and engineering, with a focus on data-driven approaches. Real world examples have been provided to illustrate the implementation of PHM in practice.",prognost health manag phm framework offer comprehens yet individu solut manag system health recent year phm emerg essenti approach achiev competit advantag global market improv reliabl maintain safeti afford concept compon phm develop separ mani area mechan engin electr engin statist scienc vari name paper provid concis review mainstream method major aspect phm framework includ updat research statist scienc engin focu datadriven approach real world exampl provid illustr implement phm practic
1fae0c586f66a9f08fdc76b8bf38ff27a7a08dc4,Enhancing the quality of argumentation in school science,"The research reported in this paper focussed on the design of learning environments that support the teaching and learning of argumentation in a scientific context. The research took place over two years between 1999 and 2001 in junior high schools in the greater London area. The research was conducted in two phases. In the first developmental phase, working with a group of 12 science teachers, the main emphasis was to develop sets of materials and strategies to support argumentation in the classroom and to assess teachers‘ development with teaching argumentation. Data were collected by videoing and audio recording the teachers attempts to implement these lessons at the beginning and end of the year. During this phase, analytical tools for evaluating the quality of argumentation were developed based on Toulmin‘s argument pattern. Analysis of the data shows that there was significant development in the majority of teachers use of argumentation across the year. Results indicate that the pattern of use of argumentation is teacher specific, as is the nature of the change. In the second phase of the project, teachers taught the experimental groups a minimum of nine lessons which involved socioscientific or scientific argumentation. In addition, these teachers taught similar lessons to a control group at the beginning and end of the year. Here the emphasis lay on assessing the progression in student capabilities with argumentation. Hence data were collected from several lessons of two groups of students engaging in argumentation. Using a framework for evaluating the nature of the discourse and its quality, the findings show that there was an improvement in the quality of students‘ argumentation. In addition, the research offers methodological developments for work in this field.",research report paper focuss design learn environ support teach learn argument scientif context research took place two year junior high school greater london area research conduct two phase first development phase work group scienc teacher main emphasi develop set materi strategi support argument classroom assess teacher develop teach argument data collect video audio record teacher attempt implement lesson begin end year phase analyt tool evalu qualiti argument develop base toulmin argument pattern analysi data show signific develop major teacher use argument across year result indic pattern use argument teacher specif natur chang second phase project teacher taught experiment group minimum nine lesson involv socioscientif scientif argument addit teacher taught similar lesson control group begin end year emphasi lay assess progress student capabl argument henc data collect sever lesson two group student engag argument use framework evalu natur discours qualiti find show improv qualiti student argument addit research offer methodolog develop work field
f7ddf5129b392cc23411c2ca28ece3bc0ad682d6,A Survey Of Blockchain Security Issues And Challenges,"Proceedings of Sixth International Congress on Information and Communication TechnologyBlockchain for BusinessArtificial IntelligenceBlockchain TechnologyHandbook of Research on Blockchain TechnologyResearch Anthology on Blockchain Technology in Business, Healthcare, Education, and GovernmentBlockchain for Cybersecurity and PrivacyBlockchain Cybersecurity, Trust and PrivacyTransforming Businesses With Bitcoin Mining and Blockchain ApplicationsPrinciples of Security and TrustProceedings of the Tenth International Conference on Soft Computing and Pattern Recognition (SoCPaR 2018)Blockchain Technology and the Internet of ThingsEnabling Blockchain Technology for Secure Networking and CommunicationsCommunications and NetworkingBlockchain for Smart CitiesProceedings of International Conference on Computational Intelligence, Data Science and Cloud ComputingCross-Industry Use of Blockchain Technology and Opportunities for the FutureLarge-Scale Data Streaming, Processing, and Blockchain SecurityBlockchain for Distributed Systems SecurityAdvances in Data Science, Cyber Security and IT ApplicationsRole of Blockchain Technology in IoT ApplicationsConvergence of Internet of Things and Blockchain TechnologiesComputational Intelligence in Pattern RecognitionBlockchains for Network SecurityBlockchain and AI Technology in the Industrial Internet of ThingsHandbook of Research on Cyber Crime and Information PrivacyCross-Industry Use of Blockchain Technology and Opportunities for the FutureBitcoin and Blockchain Security6G Mobile Wireless NetworksWeb, Artificial Intelligence and Network ApplicationsCommercializing BlockchainBlockchain Security in Cloud ComputingPractical CryptographyBlockchain and Trustworthy SystemsHands-On Cybersecurity with Blockchain2019 International Conference on System Science and Engineering (ICSSE)Smart BlockchainBlockchain Applications in IoT SecurityBlockchain in the Industrial Internet of ThingsBlockchain Technology for Data Privacy Management",proceed sixth intern congress inform commun technologyblockchain businessartifici intelligenceblockchain technologyhandbook research blockchain technologyresearch antholog blockchain technolog busi healthcar educ governmentblockchain cybersecur privacyblockchain cybersecur trust privacytransform busi bitcoin mine blockchain applicationsprincipl secur trustproceed tenth intern confer soft comput pattern recognit socpar blockchain technolog internet thingsen blockchain technolog secur network communicationscommun networkingblockchain smart citiesproceed intern confer comput intellig data scienc cloud computingcrossindustri use blockchain technolog opportun futurelargescal data stream process blockchain securityblockchain distribut system securityadv data scienc cyber secur applicationsrol blockchain technolog iot applicationsconverg internet thing blockchain technologiescomput intellig pattern recognitionblockchain network securityblockchain ai technolog industri internet thingshandbook research cyber crime inform privacycrossindustri use blockchain technolog opportun futurebitcoin blockchain securityg mobil wireless networksweb artifici intellig network applicationscommerci blockchainblockchain secur cloud computingpract cryptographyblockchain trustworthi systemshandson cybersecur blockchain intern confer system scienc engin icssesmart blockchainblockchain applic iot securityblockchain industri internet thingsblockchain technolog data privaci manag
112f5b6f640efcc03edef5ec2ab87194b80dbd24,USING TRADITIONAL ECOLOGICAL KNOWLEDGE IN SCIENCE: METHODS AND APPLICATIONS,"Advocates of Traditional Ecological Knowledge (TEK) have promoted its use in scientific research, impact assessment, and ecological understanding. While several examples illustrate the utility of applying TEK in these contexts, wider application of TEK- derived information remains elusive. In part, this is due to continued inertia in favor of established scientific practices and the need to describe TEK in Western scientific terms. In part, it is also due to the difficulty of accessing TEK, which is rarely written down and must in most cases be documented as a project on its own prior to its incorporation into another scientific undertaking. This formidable practical obstacle is exacerbated by the need to use social science methods to gather biological data, so that TEK research and application becomes a multidisciplinary undertaking. By examining case studies involving bowhead whales, beluga whales, and herring, this paper describes some of the benefits of using TEK in scientific and management contexts. It also reviews some of the methods that are available to do so, including semi-directive interviews, questionnaires, facilitated workshops, and collaborative field projects.",advoc tradit ecolog knowledg tek promot use scientif research impact assess ecolog understand sever exampl illustr util appli tek context wider applic tek deriv inform remain elus part due continu inertia favor establish scientif practic need describ tek western scientif term part also due difficulti access tek rare written must case document project prior incorpor anoth scientif undertak formid practic obstacl exacerb need use social scienc method gather biolog data tek research applic becom multidisciplinari undertak examin case studi involv bowhead whale beluga whale her paper describ benefit use tek scientif manag context also review method avail includ semidirect interview questionnair facilit workshop collabor field project
306d35707288caafb27e4c81d33eb83c0384f204,"Statistics : methods and applications : a comprehensive reference for science, industry, and data mining",Elementary concepts in statistics -- Basic statistics and tables -- ANOVA/MANOVA -- Association rules -- Boosting trees -- Canonical analysis -- CHAID analysis -- Classification and regression trees (CART) -- Classification trees -- Cluster analysis -- Correspondence analysis -- Data mining techniques -- Discriminant function analysis -- Distribution fitting -- Experimental design (Industrial DOE) -- Factor analysis and principal components -- General discrimination analysis (GDA) -- General linear models (GLM) -- General regression models (GRM) -- Generalized additive models (GAM) -- Generalized linear/nonlinear models (GLZ) -- Log linear analysis of frequency tables -- Machine learning -- Multivariate adaptive regression splines (MARSplines) -- Multidimensional scaling (MDS) -- Multiple linear regression -- Neural networks -- Nonlinear estimation -- Nonparametric statistics -- Partial least squares (PLS) -- Power analysis -- Process analysis -- Quality control charts -- Reliabilty/item analysis -- Structural equation modeling -- Survival/failure time analysis -- Text mining -- Time series/forecasting -- Variance components and mixed model ANOVA/ANCOVA.,elementari concept statist basic statist tabl anovamanova associ rule boost tree canon analysi chaid analysi classif regress tree cart classif tree cluster analysi correspond analysi data mine techniqu discrimin function analysi distribut fit experiment design industri doe factor analysi princip compon gener discrimin analysi gda gener linear model glm gener regress model grm gener addit model gam gener linearnonlinear model glz log linear analysi frequenc tabl machin learn multivari adapt regress spline marsplin multidimension scale md multipl linear regress neural network nonlinear estim nonparametr statist partial least squar pl power analysi process analysi qualiti control chart reliabiltyitem analysi structur equat model survivalfailur time analysi text mine time seriesforecast varianc compon mix model anovaancova
bc67533c42e092da2b1f5ab5f9d1749eb7066f03,BIM for heritage science: a review,,nan
8cb976b33c9f628afbfe16eb26b5b067001b24b5,The sequence read archive: explosive growth of sequencing data,"New generation sequencing platforms are producing data with significantly higher throughput and lower cost. A portion of this capacity is devoted to individual and community scientific projects. As these projects reach publication, raw sequencing datasets are submitted into the primary next-generation sequence data archive, the Sequence Read Archive (SRA). Archiving experimental data is the key to the progress of reproducible science. The SRA was established as a public repository for next-generation sequence data as a part of the International Nucleotide Sequence Database Collaboration (INSDC). INSDC is composed of the National Center for Biotechnology Information (NCBI), the European Bioinformatics Institute (EBI) and the DNA Data Bank of Japan (DDBJ). The SRA is accessible at www.ncbi.nlm.nih.gov/sra from NCBI, at www.ebi.ac.uk/ena from EBI and at trace.ddbj.nig.ac.jp from DDBJ. In this article, we present the content and structure of the SRA and report on updated metadata structures, submission file formats and supported sequencing platforms. We also briefly outline our various responses to the challenge of explosive data growth.",new gener sequenc platform produc data significantli higher throughput lower cost portion capac devot individu commun scientif project project reach public raw sequenc dataset submit primari nextgener sequenc data archiv sequenc read archiv sra archiv experiment data key progress reproduc scienc sra establish public repositori nextgener sequenc data part intern nucleotid sequenc databas collabor insdc insdc compos nation center biotechnolog inform ncbi european bioinformat institut ebi dna data bank japan ddbj sra access wwwncbinlmnihgovsra ncbi wwwebiacukena ebi traceddbjnigacjp ddbj articl present content structur sra report updat metadata structur submiss file format support sequenc platform also briefli outlin variou respons challeng explos data growth
f39f562f706e9f8771e6305d086fed159366b5a8,Assessing citizen science data quality: an invasive species case study,"An increase in the number of citizen science programs has prompted an examination of their ability to provide data of sufficient quality. We tested the ability of volunteers relative to professionals in identifying invasive plant species, mapping their distributions, and estimating their abundance within plots. We generally found that volunteers perform almost as well as professionals in some areas, but that we should be cautious about data quality in both groups. We analyzed predictors of volunteer success (age, education, experience, science literacy, attitudes) in training‐related skills, but these proved to be poor predictors of performance and could not be used as effective eligibility criteria. However, volunteer success with species identification increased with their self‐identified comfort level. Based on our case study results, we offer lessons learned and their application to other programs and provide recommendations for future research in this area.",increas number citizen scienc program prompt examin abil provid data suffici qualiti test abil volunt rel profession identifi invas plant speci map distribut estim abund within plot gener found volunt perform almost well profession area cautiou data qualiti group analyz predictor volunt success age educ experi scienc literaci attitud trainingrel skill prove poor predictor perform could use effect elig criteria howev volunt success speci identif increas selfidentifi comfort level base case studi result offer lesson learn applic program provid recommend futur research area
1a67f9a4624b4ea989e4ea9b14ea178a010017c0,Editors’ Introduction to the Special Section on Replicability in Psychological Science,"Is there currently a crisis of confidence in psychological science reflecting an unprecedented level of doubt among practitioners about the reliability of research findings in the field? It would certainly appear that there is. These doubts emerged and grew as a series of unhappy events unfolded in 2011: the Diederik Stapel fraud case (see Stroebe, Postmes, & Spears, 2012, this issue), the publication in a major social psychology journal of an article purporting to show evidence of extrasensory perception (Bem, 2011) followed by widespread public mockery (see Galak, LeBoeuf, Nelson, & Simmons, in press; Wagenmakers, Wetzels, Borsboom, & van der Maas, 2011), reports by Wicherts and colleagues that psychologists are often unwilling or unable to share their published data for reanalysis (Wicherts, Bakker, & Molenaar, 2011; see also Wicherts, Borsboom, Kats, & Molenaar, 2006), and the publication of an important article in Psychological Science showing how easily researchers can, in the absence of any real effects, nonetheless obtain statistically significant differences through various questionable research practices (QRPs) such as exploring multiple dependent variables or covariates and only reporting these when they yield significant results (Simmons, Nelson, & Simonsohn, 2011). For those psychologists who expected that the embarrassments of 2011 would soon recede into memory, 2012 offered instead a quick plunge from bad to worse, with new indications of outright fraud in the field of social cognition (Simonsohn, 2012), an article in Psychological Science showing that many psychologists admit to engaging in at least some of the QRPs examined by Simmons and colleagues (John, Loewenstein, & Prelec, 2012), troubling new meta-analytic evidence suggesting that the QRPs described by Simmons and colleagues may even be leaving telltale signs visible in the distribution of p values in the psychological literature (Masicampo & Lalande, in press; Simonsohn, 2012), and an acrimonious dust-up in science magazines and blogs centered around the problems some investigators were having in replicating well-known results from the field of social cognition (Bower, 2012; Yong, 2012). Although the very public problems experienced by psychology over this 2-year period are embarrassing to those of us working in the field, some have found comfort in the fact that, over the same period, similar concerns have been arising across the scientific landscape (triggered by revelations that will be described shortly). Some of the suspected causes of unreplicability, such as publication bias (the tendency to publish only positive findings) have been discussed for years; in fact, the phrase file-drawer problem was first coined by a distinguished psychologist several decades ago (Rosenthal, 1979). However, many have speculated that these problems have been exacerbated in recent years as academia reaps the harvest of a hypercompetitive academic climate and an incentive scheme that provides rich rewards for overselling one’s work and few rewards at all for caution and circumspection (see Giner-Sorolla, 2012, this issue). Equally disturbing, investigators seem to be replicating each others’ work even less often than they did in the past, again presumably reflecting an incentive scheme gone askew (a point discussed in several articles in this issue, e.g., Makel, Plucker, & Hegarty, 2012). The frequency with which errors appear in the psychological literature is not presently known, but a number of facts suggest it might be disturbingly high. Ioannidis (2005) has shown through simple mathematical modeling that any scientific field that ignores replication can easily come to the miserable state wherein (as the title of his most famous article puts it) “most published research findings are false” (see also Ioannidis, 2012, this issue, and Pashler & Harris, 2012, this issue). Meanwhile, reports emerging from cancer research have made such grim scenarios seem more plausible: In 2012, several large pharmaceutical companies revealed that their efforts to replicate exciting preclinical findings from published academic studies in cancer biology were only rarely verifying the original results (Begley & Ellis, 2012; see also Osherovich, 2011; Prinz, Schlange, & Asadullah, 2011).",current crisi confid psycholog scienc reflect unpreced level doubt among practition reliabl research find field would certainli appear doubt emerg grew seri unhappi event unfold diederik stapel fraud case see stroeb postm spear issu public major social psycholog journal articl purport show evid extrasensori percept bem follow widespread public mockeri see galak leboeuf nelson simmon press wagenmak wetzel borsboom van der maa report wichert colleagu psychologist often unwil unabl share publish data reanalysi wichert bakker molenaar see also wichert borsboom kat molenaar public import articl psycholog scienc show easili research absenc real effect nonetheless obtain statist signific differ variou question research practic qrp explor multipl depend variabl covari report yield signific result simmon nelson simonsohn psychologist expect embarrass would soon reced memori offer instead quick plung bad wors new indic outright fraud field social cognit simonsohn articl psycholog scienc show mani psychologist admit engag least qrp examin simmon colleagu john loewenstein prelec troubl new metaanalyt evid suggest qrp describ simmon colleagu may even leav telltal sign visibl distribut p valu psycholog literatur masicampo laland press simonsohn acrimoni dustup scienc magazin blog center around problem investig replic wellknown result field social cognit bower yong although public problem experienc psycholog year period embarrass us work field found comfort fact period similar concern aris across scientif landscap trigger revel describ shortli suspect caus unreplic public bia tendenc publish posit find discuss year fact phrase filedraw problem first coin distinguish psychologist sever decad ago rosenth howev mani specul problem exacerb recent year academia reap harvest hypercompetit academ climat incent scheme provid rich reward oversel one work reward caution circumspect see ginersorolla issu equal disturb investig seem replic other work even less often past presum reflect incent scheme gone askew point discuss sever articl issu eg makel plucker hegarti frequenc error appear psycholog literatur present known number fact suggest might disturbingli high ioannidi shown simpl mathemat model scientif field ignor replic easili come miser state wherein titl famou articl put publish research find fals see also ioannidi issu pashler harri issu meanwhil report emerg cancer research made grim scenario seem plausibl sever larg pharmaceut compani reveal effort replic excit preclin find publish academ studi cancer biolog rare verifi origin result begley elli see also osherovich prinz schlang asadullah
70ce1a955ed9fc08c427c03c15d9a04e5ce7a9bd,Causal inference from observational data.,"Randomized controlled trials have long been considered the 'gold standard' for causal inference in clinical research. In the absence of randomized experiments, identification of reliable intervention points to improve oral health is often perceived as a challenge. But other fields of science, such as social science, have always been challenged by ethical constraints to conducting randomized controlled trials. Methods have been established to make causal inference using observational data, and these methods are becoming increasingly relevant in clinical medicine, health policy and public health research. This study provides an overview of state-of-the-art methods specifically designed for causal inference in observational data, including difference-in-differences (DiD) analyses, instrumental variables (IV), regression discontinuity designs (RDD) and fixed-effects panel data analysis. The described methods may be particularly useful in dental research, not least because of the increasing availability of routinely collected administrative data and electronic health records ('big data').",random control trial long consid gold standard causal infer clinic research absenc random experi identif reliabl intervent point improv oral health often perceiv challeng field scienc social scienc alway challeng ethic constraint conduct random control trial method establish make causal infer use observ data method becom increasingli relev clinic medicin health polici public health research studi provid overview stateoftheart method specif design causal infer observ data includ differenceindiffer analys instrument variabl iv regress discontinu design rdd fixedeffect panel data analysi describ method may particularli use dental research least increas avail routin collect administr data electron health record big data
a4a582c6739c8f6d88f3ad01671b5b6733eb464c,Bridges: a uniquely flexible HPC resource for new communities and data analytics,"In this paper, we describe Bridges, a new HPC resource that will integrate advanced memory technologies with a uniquely flexible, user-focused, data-centric environment to empower new research communities, bring desktop convenience to HPC, connect to campuses, and drive complex workflows. Bridges will differ from traditional HPC systems and support new communities through extensive interactivity, gateways (convenient web interfaces that hide complex functionality and ease access to HPC resources) and tools for gateway building, persistent databases and web servers, high-productivity programming languages, and virtualization. Bridges will feature three tiers of processing nodes having 128GB, 3TB, and 12TB of hardware-enabled coherent shared memory per node to support memory-intensive applications and ease of use, together with persistent database and web nodes and nodes for logins, data transfer, and system management. State-of-the-art Intel® Xeon® CPUs and NVIDIA Tesla GPUs will power Bridges' compute nodes. Multiple filesystems will provide optimal handling for different data needs: a high-performance, parallel, shared filesystem, node-local filesystems, and memory filesystems. Bridges' nodes and parallel filesystem will be interconnected by the Intel Omni-Path Fabric, configured in a topology developed by PSC to be optimal for the anticipated data-centric workload. Bridges will be a resource on XSEDE, the NSF Extreme Science and Engineering Discovery Environment, and will interoperate with other advanced cyberinfrastructure resources. Through a pilot project with Temple University, Bridges will develop infrastructure and processes for campus bridging, consisting of offloading jobs at periods of unusually high load to the other site and facilitating cross-site data management. Education, training, and outreach activities will raise awareness of Bridges and data-intensive science across K-12 and university communities, industry, and the general public.",paper describ bridg new hpc resourc integr advanc memori technolog uniqu flexibl userfocus datacentr environ empow new research commun bring desktop conveni hpc connect campus drive complex workflow bridg differ tradit hpc system support new commun extens interact gateway conveni web interfac hide complex function eas access hpc resourc tool gateway build persist databas web server highproduct program languag virtual bridg featur three tier process node gb tb tb hardwareen coher share memori per node support memoryintens applic eas use togeth persist databas web node node login data transfer system manag stateoftheart intel xeon cpu nvidia tesla gpu power bridg comput node multipl filesystem provid optim handl differ data need highperform parallel share filesystem nodeloc filesystem memori filesystem bridg node parallel filesystem interconnect intel omnipath fabric configur topolog develop psc optim anticip datacentr workload bridg resourc xsede nsf extrem scienc engin discoveri environ interoper advanc cyberinfrastructur resourc pilot project templ univers bridg develop infrastructur process campu bridg consist offload job period unusu high load site facilit crosssit data manag educ train outreach activ rais awar bridg dataintens scienc across k univers commun industri gener public
9f14c7b599d3cbd1646215291b5e843d38d42b48,Cryptography and Data Security,"From the Preface (See Front Matter for full Preface) 
 
Electronic computers have evolved from exiguous experimental enterprises in the 1940s to prolific practical data processing systems in the 1980s. As we have come to rely on these systems to process and store data, we have also come to wonder about their ability to protect valuable data. 
 
Data security is the science and study of methods of protecting data in computer and communication systems from unauthorized disclosure and modification. The goal of this book is to introduce the mathematical principles of data security and to show how these principles apply to operating systems, database systems, and computer networks. The book is for students and professionals seeking an introduction to these principles. There are many references for those who would like to study specific topics further. 
 
Data security has evolved rapidly since 1975. We have seen exciting developments in cryptography: public-key encryption, digital signatures, the Data Encryption Standard (DES), key safeguarding schemes, and key distribution protocols. We have developed techniques for verifying that programs do not leak confidential data, or transmit classified data to users with lower security clearances. We have found new controls for protecting data in statistical databases--and new methods of attacking these databases. We have come to a better understanding of the theoretical and practical limitations to security.",prefac see front matter full prefac electron comput evolv exigu experiment enterpris prolif practic data process system come reli system process store data also come wonder abil protect valuabl data data secur scienc studi method protect data comput commun system unauthor disclosur modif goal book introduc mathemat principl data secur show principl appli oper system databas system comput network book student profession seek introduct principl mani refer would like studi specif topic data secur evolv rapidli sinc seen excit develop cryptographi publickey encrypt digit signatur data encrypt standard de key safeguard scheme key distribut protocol develop techniqu verifi program leak confidenti data transmit classifi data user lower secur clearanc found new control protect data statist databasesand new method attack databas come better understand theoret practic limit secur
abd6905fec5e1323dedb1311dbb7885e836c1877,Response to Comment on “Estimating the reproducibility of psychological science”,"Gilbert et al. conclude that evidence from the Open Science Collaboration’s Reproducibility Project: Psychology indicates high reproducibility, given the study methodology. Their very optimistic assessment is limited by statistical misconceptions and by causal inferences from selectively interpreted, correlational data. Using the Reproducibility Project: Psychology data, both optimistic and pessimistic conclusions about reproducibility are possible, and neither are yet warranted.",gilbert et al conclud evid open scienc collabor reproduc project psycholog indic high reproduc given studi methodolog optimist assess limit statist misconcept causal infer select interpret correl data use reproduc project psycholog data optimist pessimist conclus reproduc possibl neither yet warrant
40528227f7217e725a054258d1674fc207d38963,Data Sources,,nan
17cdb988ac355a292d7f358dd29893aaf229b859,Reflexive Accounts and Accounts of Reflexivity in Qualitative Data Analysis,"While the importance of being reflexive is acknowledged within social science research, the difficulties, practicalities and methods of doing it are rarely addressed. Thus, the implications of current theoretical and philosophical discussions about reflexivity, epistemology and the construction of knowledge for empirical sociological research practice, specifically the analysis of qualitative data, remain under-developed. Drawing on our doctoral experiences, we reflect on the possibilities and limits of reflexivity during the interpretive stages of research. We explore how reflexivity can be operationalized and discuss reflexivity in terms of the personal, interpersonal, institutional, pragmatic, emotional, theoretical, epistemological and ontological influences on our research and data analysis processes. We argue that data analysis methods are not just neutral techniques. They reflect, and are imbued with, theoretical, epistemological and ontological assumptions - including conceptions of subjects and subjectivities, and understandings of how knowledge is constructed and produced. In suggesting how epistemological and ontological positionings can be translated into research practice, our article contributes to current debates aiming to bridge the gap between abstract epistemological discussions and the nitty-gritty of research practice.",import reflex acknowledg within social scienc research difficulti practic method rare address thu implic current theoret philosoph discuss reflex epistemolog construct knowledg empir sociolog research practic specif analysi qualit data remain underdevelop draw doctor experi reflect possibl limit reflex interpret stage research explor reflex operation discuss reflex term person interperson institut pragmat emot theoret epistemolog ontolog influenc research data analysi process argu data analysi method neutral techniqu reflect imbu theoret epistemolog ontolog assumpt includ concept subject subject understand knowledg construct produc suggest epistemolog ontolog posit translat research practic articl contribut current debat aim bridg gap abstract epistemolog discuss nittygritti research practic
579c2aad3834e525a90740913fb58a8c8e9ef218,Big Data Methods,"Advances in data science, such as data mining, data visualization, and machine learning, are extremely well-suited to address numerous questions in the organizational sciences given the explosion of available data. Despite these opportunities, few scholars in our field have discussed the specific ways in which the lens of our science should be brought to bear on the topic of big data and big data's reciprocal impact on our science. The purpose of this paper is to provide an overview of the big data phenomenon and its potential for impacting organizational science in both positive and negative ways. We identifying the biggest opportunities afforded by big data along with the biggest obstacles, and we discuss specifically how we think our methods will be most impacted by the data analytics movement. We also provide a list of resources to help interested readers incorporate big data methods into their existing research. Our hope is that we stimulate interest in big data, motivate future research using big data sources, and encourage the application of associated data science techniques more broadly in the organizational sciences.",advanc data scienc data mine data visual machin learn extrem wellsuit address numer question organiz scienc given explos avail data despit opportun scholar field discuss specif way len scienc brought bear topic big data big data reciproc impact scienc purpos paper provid overview big data phenomenon potenti impact organiz scienc posit neg way identifi biggest opportun afford big data along biggest obstacl discuss specif think method impact data analyt movement also provid list resourc help interest reader incorpor big data method exist research hope stimul interest big data motiv futur research use big data sourc encourag applic associ data scienc techniqu broadli organiz scienc
5efc7309a02bc1954c9db5d29fb790c2ee97383b,Prospecting (in) the data sciences,"Data science is characterized by engaging heterogeneous data to tackle real world questions and problems. But data science has no data of its own and must seek it within real world domains. We call this search for data “prospecting” and argue that the dynamics of prospecting are pervasive in, even characteristic of, data science. Prospecting aims to render the data, knowledge, expertise, and practices of worldly domains available and tractable to data science method and epistemology. Prospecting precedes data synthesis, analysis, or visualization, and is constituted by the upstream work of discovering disordered or inaccessible data resources, thereafter to be ordered and rendered available for computation. Through this work, data science positions itself in the middle of all things—capable of engaging this, that, or any domain—and thus prospecting is a key driver of data science’s ongoing formation as a universal(izing) science.",data scienc character engag heterogen data tackl real world question problem data scienc data must seek within real world domain call search data prospect argu dynam prospect pervas even characterist data scienc prospect aim render data knowledg expertis practic worldli domain avail tractabl data scienc method epistemolog prospect preced data synthesi analysi visual constitut upstream work discov disord inaccess data resourc thereaft order render avail comput work data scienc posit middl thingscap engag domainand thu prospect key driver data scienc ongo format univers scienc
454a5afdeeee4b10b912ea9cca4d9dd13beb2aa4,Data validation in citizen science: a case study from Project FeederWatch,"To become more widely accepted as a valuable research tool, citizen-science projects must find ways to ensure that data gathered by large numbers of people with varying levels of expertise are of consistently high quality. Here, we describe a data validation protocol developed for Project FeederWatch, a continent-wide bird monitoring program, that is designed to increase researchers' and participants' confidence in the data being collected.",becom wide accept valuabl research tool citizensci project must find way ensur data gather larg number peopl vari level expertis consist high qualiti describ data valid protocol develop project feederwatch continentwid bird monitor program design increas research particip confid data collect
f92dfb398cea359297e2fac4f8ce7ac316158d9e,On the Reuse of Scientific Data,"While science policy promotes data sharing and open data, these are not ends in themselves. Arguments for data sharing are to reproduce research, to make public assets available to the public, to leverage investments in research, and to advance research and innovation. To achieve these expected benefits of data sharing, data must actually be reused by others. Data sharing practices, especially motivations and incentives, have received far more study than has data reuse, perhaps because of the array of contested concepts on which reuse rests and the disparate contexts in which it occurs. Here we explicate concepts of data, sharing, and open data as a means to examine data reuse. We explore distinctions between use and reuse of data. Lastly we propose six research questions on data reuse worthy of pursuit by the community: How can uses of data be distinguished from reuses? When is reproducibility an essential goal? When is data integration an essential goal? What are the tradeoffs between collecting new data and reusing existing data? How do motivations for data collection influence the ability to reuse data? How do standards and formats for data release influence reuse opportunities? We conclude by summarizing the implications of these questions for science policy and for investments in data reuse.",scienc polici promot data share open data end argument data share reproduc research make public asset avail public leverag invest research advanc research innov achiev expect benefit data share data must actual reus other data share practic especi motiv incent receiv far studi data reus perhap array contest concept reus rest dispar context occur explic concept data share open data mean examin data reus explor distinct use reus data lastli propos six research question data reus worthi pursuit commun use data distinguish reus reproduc essenti goal data integr essenti goal tradeoff collect new data reus exist data motiv data collect influenc abil reus data standard format data releas influenc reus opportun conclud summar implic question scienc polici invest data reus
ab55a0836880293c5e5e7b1ade89bb8f3106b11b,Community-driven data analysis training for biology,"The primary problem with the explosion of biomedical datasets is not the data itself, not computational resources, and not the required storage space, but the general lack of trained and skilled researchers to manipulate and analyze these data. Eliminating this problem requires development of comprehensive educational resources. Here we present a community-driven framework that enables modern, interactive teaching of data analytics in life sciences and facilitates the development of training materials. The key feature of our system is that it is not a static but a continuously improved collection of tutorials. By coupling tutorials with a web-based analysis framework, biomedical researchers can learn by performing computation themselves through a web-browser without the need to install software or search for example datasets. Our ultimate goal is to expand the breadth of training materials to include fundamental statistical and data science topics and to precipitate a complete re-engineering of undergraduate and graduate curricula in life sciences.",primari problem explos biomed dataset data comput resourc requir storag space gener lack train skill research manipul analyz data elimin problem requir develop comprehens educ resourc present communitydriven framework enabl modern interact teach data analyt life scienc facilit develop train materi key featur system static continu improv collect tutori coupl tutori webbas analysi framework biomed research learn perform comput webbrows without need instal softwar search exampl dataset ultim goal expand breadth train materi includ fundament statist data scienc topic precipit complet reengin undergradu graduat curricula life scienc
995ac6673fffac3d0f209077bab3ed77c8d69c88,Crowd-sourced Text Analysis: Reproducible and Agile Production of Political Data,"Empirical social science often relies on data that are not observed in the field, but are transformed into quantitative variables by expert researchers who analyze and interpret qualitative raw sources. While generally considered the most valid way to produce data, this expert-driven process is inherently difficult to replicate or to assess on grounds of reliability. Using crowd-sourcing to distribute text for reading and interpretation by massive numbers of nonexperts, we generate results comparable to those using experts to read and interpret the same texts, but do so far more quickly and flexibly. Crucially, the data we collect can be reproduced and extended transparently, making crowd-sourced datasets intrinsically reproducible. This focuses researchers’ attention on the fundamental scientific objective of specifying reliable and replicable methods for collecting the data needed, rather than on the content of any particular dataset. We also show that our approach works straightforwardly with different types of political text, written in different languages. While findings reported here concern text analysis, they have far-reaching implications for expert-generated data in the social sciences.",empir social scienc often reli data observ field transform quantit variabl expert research analyz interpret qualit raw sourc gener consid valid way produc data expertdriven process inher difficult replic assess ground reliabl use crowdsourc distribut text read interpret massiv number nonexpert gener result compar use expert read interpret text far quickli flexibl crucial data collect reproduc extend transpar make crowdsourc dataset intrins reproduc focus research attent fundament scientif object specifi reliabl replic method collect data need rather content particular dataset also show approach work straightforwardli differ type polit text written differ languag find report concern text analysi farreach implic expertgener data social scienc
62f2a0d676a2260a400c7ba675338958c5e95706,Modeling Multilevel Data Structures,"data are becoming quite common in political science and provide numerous opportunities for theory testing and development. Unfortunately this type of data typically generates a number of statistical problems, of which clustering is particularly impor? tant. To exploit the opportunities of? fered by multilevel data, and to solve the statistical problems inherent in them, special statistical techniques are required. In this article, we focus on a technique that has become popular in educational statistics and sociology?multilevel analysis. In multilevel analysis, researchers build models that capture the layered structure of multilevel data, and determine how layers interact and impact a dependent variable of interest. Our objective in this article is to introduce the logic and statistical theory behind multilevel models, to illustrate how such models can be applied fruitfully in political science, and to call atten? tion to some of the pitfalls in multilevel analysis.",data becom quit common polit scienc provid numer opportun theori test develop unfortun type data typic gener number statist problem cluster particularli impor tant exploit opportun fere multilevel data solv statist problem inher special statist techniqu requir articl focu techniqu becom popular educ statist sociologymultilevel analysi multilevel analysi research build model captur layer structur multilevel data determin layer interact impact depend variabl interest object articl introduc logic statist theori behind multilevel model illustr model appli fruit polit scienc call atten tion pitfal multilevel analysi
03c8beceda4a4a94fe71fe9e09bf53fee024c5e2,Optical storage arrays: a perspective for future big data storage,,nan
cfa6fd6a3979fcd3cb3a5436405cc46ef8250cd4,Data Products,,nan
a2b5e0c1d0b23d11fd8497f1b16fc9564246b482,The National Institutes of Health's Big Data to Knowledge (BD2K) initiative: capitalizing on biomedical big data,"Biomedical research has and will continue to generate large amounts of data (termed ‘big data’) in many formats and at all levels. Consequently, there is an increasing need to better understand and mine the data to further knowledge and foster new discovery. The National Institutes of Health (NIH) has initiated a Big Data to Knowledge (BD2K) initiative to maximize the use of biomedical big data. BD2K seeks to better define how to extract value from the data, both for the individual investigator and the overall research community, create the analytic tools needed to enhance utility of the data, provide the next generation of trained personnel, and develop data science concepts and tools that can be made available to all stakeholders.",biomed research continu gener larg amount data term big data mani format level consequ increas need better understand mine data knowledg foster new discoveri nation institut health nih initi big data knowledg bdk initi maxim use biomed big data bdk seek better defin extract valu data individu investig overal research commun creat analyt tool need enhanc util data provid next gener train personnel develop data scienc concept tool made avail stakehold
0c74b1d0e8b39b7900e04429a360b53d6cf8a599,The Origins of C4 Grasslands: Integrating Evolutionary and Ecosystem Science,"Grassland Emergence The evolution of the C4 photosynthetic pathway from the ancestral C3 pathway in grasses led to the establishment of grasslands in warm climates during the Late Miocene (8 to 3 million years ago). This was a major event in plant evolutionary history, and their high rates of foliage production sustained high levels of herbivore consumption. The past decade has seen significant advances in understanding C4 grassland ecosystem ecology, and now a wealth of data on the geological history of these ecosystems has accumulated and the phylogeny of grasses is much better known. Edwards et al. (p. 587) review this multidisciplinary research area and attempt to synthesize emerging knowledge about the evolution of grass species within the context of plant and ecosystem ecology. The evolution of grasses using C4 photosynthesis and their sudden rise to ecological dominance 3 to 8 million years ago is among the most dramatic examples of biome assembly in the geological record. A growing body of work suggests that the patterns and drivers of C4 grassland expansion were considerably more complex than originally assumed. Previous research has benefited substantially from dialog between geologists and ecologists, but current research must now integrate fully with phylogenetics. A synthesis of grass evolutionary biology with grassland ecosystem science will further our knowledge of the evolution of traits that promote dominance in grassland systems and will provide a new context in which to evaluate the relative importance of C4 photosynthesis in transforming ecosystems across large regions of Earth.",grassland emerg evolut c photosynthet pathway ancestr c pathway grass led establish grassland warm climat late miocen million year ago major event plant evolutionari histori high rate foliag product sustain high level herbivor consumpt past decad seen signific advanc understand c grassland ecosystem ecolog wealth data geolog histori ecosystem accumul phylogeni grass much better known edward et al p review multidisciplinari research area attempt synthes emerg knowledg evolut grass speci within context plant ecosystem ecolog evolut grass use c photosynthesi sudden rise ecolog domin million year ago among dramat exampl biom assembl geolog record grow bodi work suggest pattern driver c grassland expans consider complex origin assum previou research benefit substanti dialog geologist ecologist current research must integr fulli phylogenet synthesi grass evolutionari biolog grassland ecosystem scienc knowledg evolut trait promot domin grassland system provid new context evalu rel import c photosynthesi transform ecosystem across larg region earth
09614af5489d4c7db873fe33a9153a1eff28a40e,What difference does quantity make? On the epistemology of Big Data in biology,"Is Big Data science a whole new way of doing research? And what difference does data quantity make to knowledge production strategies and their outputs? I argue that the novelty of Big Data science does not lie in the sheer quantity of data involved, but rather in (1) the prominence and status acquired by data as commodity and recognised output, both within and outside of the scientific community and (2) the methods, infrastructures, technologies, skills and knowledge developed to handle data. These developments generate the impression that data-intensive research is a new mode of doing science, with its own epistemology and norms. To assess this claim, one needs to consider the ways in which data are actually disseminated and used to generate knowledge. Accordingly, this article reviews the development of sophisticated ways to disseminate, integrate and re-use data acquired on model organisms over the last three decades of work in experimental biology. I focus on online databases as prominent infrastructures set up to organise and interpret such data and examine the wealth and diversity of expertise, resources and conceptual scaffolding that such databases draw upon. This illuminates some of the conditions under which Big Data needs to be curated to support processes of discovery across biological subfields, which in turn highlights the difficulties caused by the lack of adequate curation for the vast majority of data in the life sciences. In closing, I reflect on the difference that data quantity is making to contemporary biology, the methodological and epistemic challenges of identifying and analysing data given these developments, and the opportunities and worries associated with Big Data discourse and methods.",big data scienc whole new way research differ data quantiti make knowledg product strategi output argu novelti big data scienc lie sheer quantiti data involv rather promin statu acquir data commod recognis output within outsid scientif commun method infrastructur technolog skill knowledg develop handl data develop gener impress dataintens research new mode scienc epistemolog norm assess claim one need consid way data actual dissemin use gener knowledg accordingli articl review develop sophist way dissemin integr reus data acquir model organ last three decad work experiment biolog focu onlin databas promin infrastructur set organis interpret data examin wealth divers expertis resourc conceptu scaffold databas draw upon illumin condit big data need curat support process discoveri across biolog subfield turn highlight difficulti caus lack adequ curat vast major data life scienc close reflect differ data quantiti make contemporari biolog methodolog epistem challeng identifi analys data given develop opportun worri associ big data discours method
c5dae4440044b015fd4ae8fd59aba43d7515c889,Big Data Analytics for Earth Sciences: the EarthServer approach,"Big Data Analytics is an emerging field since massive storage and computing capabilities have been made available by advanced e-infrastructures. Earth and Environmental sciences are likely to benefit from Big Data Analytics techniques supporting the processing of the large number of Earth Observation datasets currently acquired and generated through observations and simulations. However, Earth Science data and applications present specificities in terms of relevance of the geospatial information, wide heterogeneity of data models and formats, and complexity of processing. Therefore, Big Earth Data Analytics requires specifically tailored techniques and tools. The EarthServer Big Earth Data Analytics engine offers a solution for coverage-type datasets, built around a high performance array database technology, and the adoption and enhancement of standards for service interaction (OGC WCS and WCPS). The EarthServer solution, led by the collection of requirements from scientific communities and international initiatives, provides a holistic approach that ranges from query languages and scalability up to mobile access and visualization. The result is demonstrated and validated through the development of lighthouse applications in the Marine, Geology, Atmospheric, Planetary and Cryospheric science domains.",big data analyt emerg field sinc massiv storag comput capabl made avail advanc einfrastructur earth environment scienc like benefit big data analyt techniqu support process larg number earth observ dataset current acquir gener observ simul howev earth scienc data applic present specif term relev geospati inform wide heterogen data model format complex process therefor big earth data analyt requir specif tailor techniqu tool earthserv big earth data analyt engin offer solut coveragetyp dataset built around high perform array databas technolog adopt enhanc standard servic interact ogc wc wcp earthserv solut led collect requir scientif commun intern initi provid holist approach rang queri languag scalabl mobil access visual result demonstr valid develop lighthous applic marin geolog atmospher planetari cryospher scienc domain
681f6e6f0f754c5f6a73a2eafb05c564ca4ae235,Eliciting Expert Knowledge in Conservation Science,"Abstract:  Expert knowledge is used widely in the science and practice of conservation because of the complexity of problems, relative lack of data, and the imminent nature of many conservation decisions. Expert knowledge is substantive information on a particular topic that is not widely known by others. An expert is someone who holds this knowledge and who is often deferred to in its interpretation. We refer to predictions by experts of what may happen in a particular context as expert judgments. In general, an expert‐elicitation approach consists of five steps: deciding how information will be used, determining what to elicit, designing the elicitation process, performing the elicitation, and translating the elicited information into quantitative statements that can be used in a model or directly to make decisions. This last step is known as encoding. Some of the considerations in eliciting expert knowledge include determining how to work with multiple experts and how to combine multiple judgments, minimizing bias in the elicited information, and verifying the accuracy of expert information. We highlight structured elicitation techniques that, if adopted, will improve the accuracy and information content of expert judgment and ensure uncertainty is captured accurately. We suggest four aspects of an expert elicitation exercise be examined to determine its comprehensiveness and effectiveness: study design and context, elicitation design, elicitation method, and elicitation output. Just as the reliability of empirical data depends on the rigor with which it was acquired so too does that of expert knowledge.",abstract expert knowledg use wide scienc practic conserv complex problem rel lack data immin natur mani conserv decis expert knowledg substant inform particular topic wide known other expert someon hold knowledg often defer interpret refer predict expert may happen particular context expert judgment gener expertelicit approach consist five step decid inform use determin elicit design elicit process perform elicit translat elicit inform quantit statement use model directli make decis last step known encod consider elicit expert knowledg includ determin work multipl expert combin multipl judgment minim bia elicit inform verifi accuraci expert inform highlight structur elicit techniqu adopt improv accuraci inform content expert judgment ensur uncertainti captur accur suggest four aspect expert elicit exercis examin determin comprehens effect studi design context elicit design elicit method elicit output reliabl empir data depend rigor acquir expert knowledg
bbe72eaaef4f03ea9bf1028379ee81ee88416dfe,U.S. science policy. Agencies rally to tackle big data.,"A federal effort is under way to improve the nation9s ability to manage, understand, and act upon the 1.2 zettabytes (1021) of electronic data generated each year. Its goal is to increase fundamental understanding of the technologies needed to manipulate and mine massive amounts of information; apply that knowledge to other scientific fields; address national goals in health, energy, defense, and education; and train more researchers to work with those technologies. The impetus for the initiative, to be managed by the Office of Science and Technology Policy, comes from a December 2010 report by a presidential task force that concluded the nation was ""underinvesting"" in the field. Computer scientists welcome the spotlight that the White House is shining on big-data research.",feder effort way improv nation abil manag understand act upon zettabyt electron data gener year goal increas fundament understand technolog need manipul mine massiv amount inform appli knowledg scientif field address nation goal health energi defens educ train research work technolog impetu initi manag offic scienc technolog polici come decemb report presidenti task forc conclud nation underinvest field comput scientist welcom spotlight white hous shine bigdata research
3dc3e9fcc521c9e1a4f35ed9e215919b7ed957d2,Statistical Analysis of Network Data,,nan
751d5214126dd220996d7c83cd5646809ad30e31,Small data in the era of big data,,nan
747207ccbb45f72facaedfd2e62e1ae02e096fa4,The science of sustainable supply chains,"Recent advances in the science and technology of global supply chain management offer near–real-time demand-response systems for decision-makers across production networks. Technology is helping propel “fast fashion” and “lean manufacturing,” so that companies are better able to deliver products consumers want most. Yet companies know much less about the environmental and social impacts of their production networks. The failure to measure and manage these impacts can be explained in part by limitations in the science of sustainability measurement, as well as by weaknesses in systems to translate data into information that can be used by decision-makers inside corporations and government agencies. There also remain continued disincentives for firms to measure and pay the full costs of their supply chain impacts. I discuss the current state of monitoring, measuring, and analyzing information related to supply chain sustainability, as well as progress that has been made in translating this information into systems to advance more sustainable practices by corporations and consumers. Better data, decision-support tools, and incentives will be needed to move from simply managing supply chains for costs, compliance, and risk reduction to predicting and preventing unsustainable practices.",recent advanc scienc technolog global suppli chain manag offer nearrealtim demandrespons system decisionmak across product network technolog help propel fast fashion lean manufactur compani better abl deliv product consum want yet compani know much less environment social impact product network failur measur manag impact explain part limit scienc sustain measur well weak system translat data inform use decisionmak insid corpor govern agenc also remain continu disincent firm measur pay full cost suppli chain impact discuss current state monitor measur analyz inform relat suppli chain sustain well progress made translat inform system advanc sustain practic corpor consum better data decisionsupport tool incent need move simpli manag suppli chain cost complianc risk reduct predict prevent unsustain practic
2c86cbb4ffb6bf1b6d0d468d6d4a00b81c338dc7,Nursing Needs Big Data and Big Data Needs Nursing.,"PURPOSE
Contemporary big data initiatives in health care will benefit from greater integration with nursing science and nursing practice; in turn, nursing science and nursing practice has much to gain from the data science initiatives. Big data arises secondary to scholarly inquiry (e.g., -omics) and everyday observations like cardiac flow sensors or Twitter feeds. Data science methods that are emerging ensure that these data be leveraged to improve patient care.


ORGANIZING CONSTRUCT
Big data encompasses data that exceed human comprehension, that exist at a volume unmanageable by standard computer systems, that arrive at a velocity not under the control of the investigator and possess a level of imprecision not found in traditional inquiry. Data science methods are emerging to manage and gain insights from big data.


METHODS
The primary methods included investigation of emerging federal big data initiatives, and exploration of exemplars from nursing informatics research to benchmark where nursing is already poised to participate in the big data revolution. We provide observations and reflections on experiences in the emerging big data initiatives.


CONCLUSIONS
Existing approaches to large data set analysis provide a necessary but not sufficient foundation for nursing to participate in the big data revolution. Nursing's Social Policy Statement guides a principled, ethical perspective on big data and data science. There are implications for basic and advanced practice clinical nurses in practice, for the nurse scientist who collaborates with data scientists, and for the nurse data scientist.


CLINICAL RELEVANCE
Big data and data science has the potential to provide greater richness in understanding patient phenomena and in tailoring interventional strategies that are personalized to the patient.",purpos contemporari big data initi health care benefit greater integr nurs scienc nurs practic turn nurs scienc nurs practic much gain data scienc initi big data aris secondari scholarli inquiri eg omic everyday observ like cardiac flow sensor twitter feed data scienc method emerg ensur data leverag improv patient care organ construct big data encompass data exceed human comprehens exist volum unmanag standard comput system arriv veloc control investig possess level imprecis found tradit inquiri data scienc method emerg manag gain insight big data method primari method includ investig emerg feder big data initi explor exemplar nurs informat research benchmark nurs alreadi pois particip big data revolut provid observ reflect experi emerg big data initi conclus exist approach larg data set analysi provid necessari suffici foundat nurs particip big data revolut nurs social polici statement guid principl ethic perspect big data data scienc implic basic advanc practic clinic nurs practic nurs scientist collabor data scientist nurs data scientist clinic relev big data data scienc potenti provid greater rich understand patient phenomena tailor intervent strategi person patient
fe446b7f9e475ca4627f7b1ab44631a28db78813,Competing on Analytics: The New Science of Winning,"You have more information at hand about your business environment than ever before. But are you using it to ""out-think"" your rivals? If not, you may be missing out on a potent competitive tool. In ""Competing on Analytics: The New Science of Winning"" , Thomas H. Davenport and Jeanne G. Harris argue that the frontier for using data to make decisions has shifted dramatically. Certain high-performing enterprises are now building their competitive strategies around data-driven insights that in turn generate impressive business results. Their secret weapon: Analytics: sophisticated quantitative and statistical analysis and predictive modeling. Exemplars of analytics are using new tools to identify their most profitable customers and offer them the right price, to accelerate product innovation, to optimize supply chains, and to identify the true drivers of financial performance. A wealth of examples - from organizations as diverse as Amazon, Barclay's, Capital One, Harrah's, Procter & Gamble, Wachovia, and the Boston Red Sox - illuminate how to leverage the power of analytics.",inform hand busi environ ever use outthink rival may miss potent competit tool compet analyt new scienc win thoma h davenport jeann g harri argu frontier use data make decis shift dramat certain highperform enterpris build competit strategi around datadriven insight turn gener impress busi result secret weapon analyt sophist quantit statist analysi predict model exemplar analyt use new tool identifi profit custom offer right price acceler product innov optim suppli chain identifi true driver financi perform wealth exampl organ divers amazon barclay capit one harrah procter gambl wachovia boston red sox illumin leverag power analyt
611544418ca53cdad254df444addc7814abcfddc,An introduction to statistical learning with applications in R,"The fundamental mathematical tools needed to understand machine learning include linear algebra, analytic geometry, matrix decompositions, vector calculus, optimization, probability and statistics. These topics are traditionally taught in disparate courses, making it hard for data science or computer science students, or professionals, to efficiently learn the mathematics. This self-contained textbook bridges the gap between mathematical and machine learning texts, introducing the mathematical concepts with a minimum of prerequisites. It uses these concepts to derive four central machine learning methods: linear regression, principal component analysis, Gaussian mixture models and support vector machines. For students and others with a mathematical background, these derivations provide a starting point to machine learning texts. For those learning the mathematics for the first time, the methods help build intuition and practical experience with applying mathematical concepts. Every chapter includes worked examples and exercises to test understanding. Programming tutorials are offered on the book's web site. This textbook considers statistical learning applications when interest centers on the conditional distribution of a response variable, given a set of predictors, and in the absence of a credible model that can be specified before the data analysis begins. Consistent with modern data analytics, it emphasizes that a proper statistical learning data analysis depends in an integrated fashion on sound data collection, intelligent data management, appropriate statistical procedures, and an",fundament mathemat tool need understand machin learn includ linear algebra analyt geometri matrix decomposit vector calculu optim probabl statist topic tradit taught dispar cours make hard data scienc comput scienc student profession effici learn mathemat selfcontain textbook bridg gap mathemat machin learn text introduc mathemat concept minimum prerequisit use concept deriv four central machin learn method linear regress princip compon analysi gaussian mixtur model support vector machin student other mathemat background deriv provid start point machin learn text learn mathemat first time method help build intuit practic experi appli mathemat concept everi chapter includ work exampl exercis test understand program tutori offer book web site textbook consid statist learn applic interest center condit distribut respons variabl given set predictor absenc credibl model specifi data analysi begin consist modern data analyt emphas proper statist learn data analysi depend integr fashion sound data collect intellig data manag appropri statist procedur
af7bdb358b366260b657d0af92eb5e50e916c6b8,Advancing Science Through Collaborative Data Sharing and Synthesis,"The demand for researchers to share their data has increased dramatically in recent years. There is a need to replicate and confirm scientific findings to bolster confidence in many research areas. Data sharing also serves the critical function of allowing synthesis of findings across trials. As innovative statistical methods have helped resolve barriers to synthesis analyses, data sharing and synthesis can help answer research questions that cannot be answered by individual trials alone. However, the sharing of data among researchers remains challenging and infrequent. This article aims to (a) increase support for data sharing and synthesis collaborations among researchers to advance scientific knowledge and (b) provide a model for establishing these collaborations using the example of the ongoing National Institute of Mental Health’s Collaborative Data Synthesis on Adolescent Depression Trials. This study brings together datasets from existing prevention and treatment trials in adolescent depression, as well as researchers and stakeholders, to answer questions about “for whom interventions work” and “by what pathways interventions have their effects.” This is critical to improving interventions, including increasing knowledge about intervention efficacy among minority populations, or what we call “scientific equity.” The collaborative model described is relevant to fields with research questions that can only be addressed by synthesizing individual-level data.",demand research share data increas dramat recent year need replic confirm scientif find bolster confid mani research area data share also serv critic function allow synthesi find across trial innov statist method help resolv barrier synthesi analys data share synthesi help answer research question cannot answer individu trial alon howev share data among research remain challeng infrequ articl aim increas support data share synthesi collabor among research advanc scientif knowledg b provid model establish collabor use exampl ongo nation institut mental health collabor data synthesi adolesc depress trial studi bring togeth dataset exist prevent treatment trial adolesc depress well research stakehold answer question intervent work pathway intervent effect critic improv intervent includ increas knowledg intervent efficaci among minor popul call scientif equiti collabor model describ relev field research question address synthes individuallevel data
ca8b155e95d306e9b8c2e60f00a48001cabaf8f5,The science of climate change,"P i p 2 Variations in local Antarctic atmospheric temperature, as derived from oxygen isotopc data, as weU as concentrations of atmospheric carbon dioxidc and methane From Vostok. Antarctica ice core records. The fan that cold dimates aren't mainrainedwithout a depletion of greenhouse gases, and that warm dimates aren't maintained without an excess of these greenhouse gases is evident. Notice aLo that the current level of atmospheric CO2 (370 ppm) is ~ 2 0 % larger than at anyrime during the last 400,000 yun. Similarly, current levels of aunosphcric mcthane CH4 (1750 ppb) are morc dw double the maximum value found in thc 400,000 yea^ m r d . Notice also thar the increase in CO2 from 280 ppm to 370 ppm over the last 150 years, primarily due to fossil fuel burning, is about thc same as the incmase from the depths of the last ice age (21,000 years ago) to 1750 (190 ppm to 280 ppm) (from Petit et al., 1999).",p p variat local antarct atmospher temperatur deriv oxygen isotopc data weu concentr atmospher carbon dioxidc methan vostok antarctica ice core record fan cold dimat arent mainrainedwithout deplet greenhous gase warm dimat arent maintain without excess greenhous gase evid notic alo current level atmospher co ppm larger anyrim last yun similarli current level aunosphcr mcthane ch ppb morc dw doubl maximum valu found thc yea r notic also thar increas co ppm ppm last year primarili due fossil fuel burn thc incmas depth last ice age year ago ppm ppm petit et al
efc91095d187abafeab8785eb57bbdef66c82d1c,Data and Computer Communications,"Data and Computer Communications, 9e, is a two-time winner of the best Computer Science and Engineering textbook of the year award from the Textbook and Academic Authors Association. It is ideal for one/two-semester courses in Computer Networks, Data Communications, and Communications Networks in CS, CIS, and Electrical Engineering departments. With a focus on the most current technology and a convenient modular format, this best-selling text offers a clear and comprehensive survey of the entire data and computer communications field. Emphasizing both the fundamental principles as well as the critical role of performance in driving protocol and network design, it explores in detail all the critical technical areas in data communications, wide-area networking, local area networking, and protocol design.",data comput commun e twotim winner best comput scienc engin textbook year award textbook academ author associ ideal onetwosemest cours comput network data commun commun network cs ci electr engin depart focu current technolog conveni modular format bestsel text offer clear comprehens survey entir data comput commun field emphas fundament principl well critic role perform drive protocol network design explor detail critic technic area data commun widearea network local area network protocol design
a4a84f5b19aa8c1eb8b31db67d2534ad3565ccab,Visualization of Time-Oriented Data,,nan
07912741c6c96e6ad5b2c2d6c6c3b2de5c8a271b,Advances and Open Problems in Federated Learning,"Federated learning (FL) is a machine learning setting where many clients (e.g. mobile devices or whole organizations) collaboratively train a model under the orchestration of a central server (e.g. service provider), while keeping the training data decentralized. FL embodies the principles of focused data collection and minimization, and can mitigate many of the systemic privacy risks and costs resulting from traditional, centralized machine learning and data science approaches. Motivated by the explosive growth in FL research, this paper discusses recent advances and presents an extensive collection of open problems and challenges.",feder learn fl machin learn set mani client eg mobil devic whole organ collabor train model orchestr central server eg servic provid keep train data decentr fl embodi principl focus data collect minim mitig mani system privaci risk cost result tradit central machin learn data scienc approach motiv explos growth fl research paper discuss recent advanc present extens collect open problem challeng
cfa1d4b37ff51e28f9d263a662147bee9c6062b3,PISA 2006: Science Competencies for Tomorrow's World,"The US can draw on the most highly educated labor force among the principal industrialized nations, when measured in terms of the formal qualifications attained by 25-to-64-year-olds in the labor force. However, this advantage is largely a result of the “first-mover advantage” which the US gained after World War II by massively increasing enrolments. While the US had, well into the 1960s, the highest high school completion rates among OECD countries, in 2005 it ranked, with a high school completion rate of 76%, 21st among the 27 OECD countries with available data, followed only by Spain, New Zealand, Portugal, Turkey and Mexico. Similar trends are visible in college education, where the US slipped between 1995 and 2005 from the 2 nd to the 14 th rank, not because US college graduation rates declined, but because they rose so much faster in many OECD countries. Graduate output is particularly low in science, where the number of people with a college degree per 100,000 employed 25-to-34-year-olds was 1,100 compared with 1,295 on average across OECD countries and more than 2,000 in Australia, Finland, France and Korea (Education at a Glance, 2007).",us draw highli educ labor forc among princip industri nation measur term formal qualif attain toyearold labor forc howev advantag larg result firstmov advantag us gain world war ii massiv increas enrol us well highest high school complet rate among oecd countri rank high school complet rate st among oecd countri avail data follow spain new zealand portug turkey mexico similar trend visibl colleg educ us slip nd th rank us colleg graduat rate declin rose much faster mani oecd countri graduat output particularli low scienc number peopl colleg degre per employ toyearold compar averag across oecd countri australia finland franc korea educ glanc
fd6d8762bd76c58226653af12597fbcb893f183f,The Data Deluge: An e-Science Perspective,"This paper previews the imminent flood of scientific data expected from the next generation of experiments, simulations, sensors and satellites. In order to be exploited by search engines and data mining software tools, such experimental data needs to be annotated with relevant metadata giving information as to provenance, content, conditions and so on. The case for automating the process of going from raw data to information to knowledge is briefly discussed. The paper argues the case for creating new types of digital libraries for scientific data with the same sort of management services as conventional digital libraries in addition to other data-specific services. Some likely implications of both the Open Archives Initiative and e-Science data for the future role for university libraries are briefly mentioned. A substantial subset of this e-Science data needs to archived and curated for long-term preservation. Some of the issues involved in the digital preservation of both scientific data and of the programs needed to interpret the data are reviewed. Finally, the implications of this wealth of e-Science data for the Grid middleware infrastructure are highlighted. * Postal address: EPSRC, Polaris House, North Star Avenue, Swindon SN2 1 ET, UK + On secondment from the Department of Electronics and Computer Science, University of Southampton, Southampton SO17 1BJ, UK",paper preview immin flood scientif data expect next gener experi simul sensor satellit order exploit search engin data mine softwar tool experiment data need annot relev metadata give inform proven content condit case autom process go raw data inform knowledg briefli discuss paper argu case creat new type digit librari scientif data sort manag servic convent digit librari addit dataspecif servic like implic open archiv initi escienc data futur role univers librari briefli mention substanti subset escienc data need archiv curat longterm preserv issu involv digit preserv scientif data program need interpret data review final implic wealth escienc data grid middlewar infrastructur highlight postal address epsrc polari hous north star avenu swindon sn et uk second depart electron comput scienc univers southampton southampton bj uk
617df497461f76861ebba1b7ef926fb21a81e13a,Science as a Map in Technological Search,"A large body of work argues that scientific research increases the rate of technological advance, and with it economic growth. The precise mechanism through which science accelerates the rate of invention, however, remains an open question. Conceptualizing invention as a combinatorial search process, this paper argues that science alters inventors' search processes, by leading them more directly to useful combinations, eliminating fruitless paths of research, and motivating them to continue even in the face of negative feedback. These mechanisms prove most useful when inventors attempt to combine highly coupled components; therefore, the value of scientific research to invention varies systematically across applications. Empirical analyses of patent data support this thesis. Copyright © 2004 John Wiley & Sons, Ltd.",larg bodi work argu scientif research increas rate technolog advanc econom growth precis mechan scienc acceler rate invent howev remain open question conceptu invent combinatori search process paper argu scienc alter inventor search process lead directli use combin elimin fruitless path research motiv continu even face neg feedback mechan prove use inventor attempt combin highli coupl compon therefor valu scientif research invent vari systemat across applic empir analys patent data support thesi copyright john wiley son ltd
d422df8bff4e677a3077635db116679d25142bfc,"Machine learning: Trends, perspectives, and prospects","Machine learning addresses the question of how to build computers that improve automatically through experience. It is one of today’s most rapidly growing technical fields, lying at the intersection of computer science and statistics, and at the core of artificial intelligence and data science. Recent progress in machine learning has been driven both by the development of new learning algorithms and theory and by the ongoing explosion in the availability of online data and low-cost computation. The adoption of data-intensive machine-learning methods can be found throughout science, technology and commerce, leading to more evidence-based decision-making across many walks of life, including health care, manufacturing, education, financial modeling, policing, and marketing.",machin learn address question build comput improv automat experi one today rapidli grow technic field lie intersect comput scienc statist core artifici intellig data scienc recent progress machin learn driven develop new learn algorithm theori ongo explos avail onlin data lowcost comput adopt dataintens machinelearn method found throughout scienc technolog commerc lead evidencebas decisionmak across mani walk life includ health care manufactur educ financi model polic market
a197b5e02d4effb1df5a249d41b975a8aa70d9b5,A bibliometric approach to tracking big data research trends,,nan
d8b0544c58a3c84273ab7f4e5ca33863ac252808,Topological analysis of data,,nan
9a411034c3631e878008599d41b8214c36d95dfe,Is Big Data challenging criminology?,"The advent of ‘Big Data’ and machine learning algorithms is predicted to transform how we work and think. Specifically, it is said that the capacity of Big Data analytics to move from sampling to census, its ability to deal with messy data and the demonstrated utility of moving from causality to correlation have fundamentally changed the practice of social sciences. Some have even predicted the end of theory—where the question why is replaced by what—and an enduring challenge to disciplinary expertise. This article critically reviews the available literature against such claims and draws on the example of predictive policing to discuss the likely impact of Big Data analytics on criminological research and policy.",advent big data machin learn algorithm predict transform work think specif said capac big data analyt move sampl censu abil deal messi data demonstr util move causal correl fundament chang practic social scienc even predict end theorywher question replac whatand endur challeng disciplinari expertis articl critic review avail literatur claim draw exampl predict polic discuss like impact big data analyt criminolog research polici
835a0560a2a29fe396b99992699911ad9c18e553,The LIGO Open Science Center,"The LIGO Open Science Center (LOSC) fulfills LIGO's commitment to release, archive, and serve LIGO data in a broadly accessible way to the scientific community and to the public, and to provide the information and tools necessary to understand and use the data. In August 2014, the LOSC published the full dataset from Initial LIGO's “S5” run at design sensitivity, the first such large-scale release and a valuable testbed to explore the use of LIGO data by non-LIGO researchers and by the public, and to help teach gravitational-wave data analysis to students across the world. In addition to serving the S5 data, the LOSC web portal (losc.ligo.org) now offers documentation, data-location and data-quality queries, tutorials and example code, and more. We review the mission and plans of the LOSC, focusing on the S5 data release.",ligo open scienc center losc fulfil ligo commit releas archiv serv ligo data broadli access way scientif commun public provid inform tool necessari understand use data august losc publish full dataset initi ligo run design sensit first largescal releas valuabl testb explor use ligo data nonligo research public help teach gravitationalwav data analysi student across world addit serv data losc web portal loscligoorg offer document dataloc dataqu queri tutori exampl code review mission plan losc focus data releas
4dfddbf5b6b0815414313039d29f41900f47d003,"The Data Revolution. Big Data, Open Data, Data Infrastructures and Their Consequences","The last few years have witnessed an increasing production of data that have become open, accessible and available at low cost. Although many disciplines are already using ‘big data’ as instrument of analysis, social sciences have apparently missed the opportunity to exploit their potentialities fully. The purpose of this excellent book is to prove how these data do not exist independently from the ideas, techniques, technologies, people and context that produce, process, manage, analyze and store them. Moreover, the author explores the definition, characteristics and the technique to manage big data, but he also focuses his attention on the challenges of this way of thinking and on how big data are changing existing epistemology and science. Before the big data revolution, the scientific approach was based on computational science based on the simulation of complex phenomena. In the age of big data, however, an exploratory approach based on data-intensive, statistical exploration and data mining was used. In the age of big data, however, an exploratory approach based on data-intensive, statistical exploration and data mining is used. The author focuses his attention on how big data are changing the approaches and methodologies in four different fields, that is, governing people, managing organizations, leveraging value and producing capitals, creating better places in which to live. The aim of the book is threefold: to provide a detailed reflection on the nature of the data and their wider assemblages; to chart how these assemblages are shifting and mutating all along the development of new data infrastructures; and to reflect on the consequences that these new ways to assemble data may entail the making of sense and on the effects they produce in the world. The 11 chapters ideally can be divided into two main sections. The first section (chapters 1–6) deals with the big data characteristics and the techniques to manage them. The last section (chapters 7–11) consider how big data are changing the epistemology of science across all domains (arts and humanities, social and life sciences, engineering). The interest of these last chapters lies in the core idea of data being not self-meaningful, as their meaningfulness is proportionate to the information they can provide. This is particularly interesting as it fosters dense insights and ideas on further development in research. The book starts with the definition of big data and enhances the concept by which data do not exist independently from the ideas, instruments, practices, context and knowledge used to generate, process, analyze and draw conclusions from them. The book continues with an analysis of the data characteristics. Data vary by forms (qualitative and quantitative), structure (structured, semi-structured and unstructured), source (captured, derived, exhaust, transient), producer (primary, secondary, tertiary), and type (indexical, attribute, metadata). However, these different types of data share the same characteristic as they all form the basis of the knowledge pyramid where data precede information which, in turn, precedes knowledge. The latter precedes understanding and wisdom. In order to make sense of data, they are usually pooled into datasets and databases designed and organized to enable specific analysis. How they are structured has consequences on the queries and obtainable results. The author underlines the importance of the data assembly process as an issue that needs further attention and research. Chapter 4 explores big data characteristics, that is, volume, velocity, variety, exhaustivity, resolution/indexicality, relationality and flexibility/scalability. The author then examines the interest that the access to large data with those specific characteristics may have for society, governments and business organizations. Chapter 5 concerns the sources of big data. The starting point is that the production of big data has been facilitated by the confluence of five technological innovations: growing computational power, internet, pervasive and ubiquitous computing, indexical and machine readable identification, and massive distributed storage. The data production can be divided into three categories, that is, directed data (generated by traditional forms of surveillance), automated data (generated by automatic function of the device or systems) and volunteered data (traded or gifted by people to a system). Once again, with his critical approach, the author underlines the importance of developing empirical studies to examine in depth the various ways in which big data are being generated, Regional Studies, 2016",last year wit increas product data becom open access avail low cost although mani disciplin alreadi use big data instrument analysi social scienc appar miss opportun exploit potenti fulli purpos excel book prove data exist independ idea techniqu technolog peopl context produc process manag analyz store moreov author explor definit characterist techniqu manag big data also focus attent challeng way think big data chang exist epistemolog scienc big data revolut scientif approach base comput scienc base simul complex phenomena age big data howev exploratori approach base dataintens statist explor data mine use age big data howev exploratori approach base dataintens statist explor data mine use author focus attent big data chang approach methodolog four differ field govern peopl manag organ leverag valu produc capit creat better place live aim book threefold provid detail reflect natur data wider assemblag chart assemblag shift mutat along develop new data infrastructur reflect consequ new way assembl data may entail make sens effect produc world chapter ideal divid two main section first section chapter deal big data characterist techniqu manag last section chapter consid big data chang epistemolog scienc across domain art human social life scienc engin interest last chapter lie core idea data selfmeaning meaning proportion inform provid particularli interest foster dens insight idea develop research book start definit big data enhanc concept data exist independ idea instrument practic context knowledg use gener process analyz draw conclus book continu analysi data characterist data vari form qualit quantit structur structur semistructur unstructur sourc captur deriv exhaust transient produc primari secondari tertiari type index attribut metadata howev differ type data share characterist form basi knowledg pyramid data preced inform turn preced knowledg latter preced understand wisdom order make sens data usual pool dataset databas design organ enabl specif analysi structur consequ queri obtain result author underlin import data assembl process issu need attent research chapter explor big data characterist volum veloc varieti exhaust resolutionindex relation flexibilityscal author examin interest access larg data specif characterist may societi govern busi organ chapter concern sourc big data start point product big data facilit confluenc five technolog innov grow comput power internet pervas ubiquit comput index machin readabl identif massiv distribut storag data product divid three categori direct data gener tradit form surveil autom data gener automat function devic system volunt data trade gift peopl system critic approach author underlin import develop empir studi examin depth variou way big data gener region studi
d886362c98b22d2110d7c0d0da62511c5b315f12,Shedding Light on the Dark Data in the Long Tail of Science,"One of the primary outputs of the scientific enterprise is data, but many institutions such as libraries that are charged with preserving and disseminating scholarly output have largely ignored this form of documentation of scholarly activity. This paper focuses on a particularly troublesome class of data, termed dark data. “Dark data” is not carefully indexed and stored so it becomes nearly invisible to scientists and other potential users and therefore is more likely to remain underutilized and eventually lost. The article discusses how the concepts from long-tail economics can be used to understand potential solutions for better curation of this data. The paper describes why this data is critical to scientific progress, some of the properties of this data, as well as some social and technical barriers to proper management of this class of data. Many potentially useful institutional, social, and technical solutions are under development and are introduced in the last sections of the paper, but these solutions are largely unproven and require additional research and development.",one primari output scientif enterpris data mani institut librari charg preserv dissemin scholarli output larg ignor form document scholarli activ paper focus particularli troublesom class data term dark data dark data care index store becom nearli invis scientist potenti user therefor like remain underutil eventu lost articl discuss concept longtail econom use understand potenti solut better curat data paper describ data critic scientif progress properti data well social technic barrier proper manag class data mani potenti use institut social technic solut develop introduc last section paper solut larg unproven requir addit research develop
c7c3db5525baf365570e0a3ccc781a9bc01ca57d,The EBI RDF platform: linked open data for the life sciences,"Motivation: Resource description framework (RDF) is an emerging technology for describing, publishing and linking life science data. As a major provider of bioinformatics data and services, the European Bioinformatics Institute (EBI) is committed to making data readily accessible to the community in ways that meet existing demand. The EBI RDF platform has been developed to meet an increasing demand to coordinate RDF activities across the institute and provides a new entry point to querying and exploring integrated resources available at the EBI. Availability: http://www.ebi.ac.uk/rdf Contact: jupp@ebi.ac.uk",motiv resourc descript framework rdf emerg technolog describ publish link life scienc data major provid bioinformat data servic european bioinformat institut ebi commit make data readili access commun way meet exist demand ebi rdf platform develop meet increas demand coordin rdf activ across institut provid new entri point queri explor integr resourc avail ebi avail httpwwwebiacukrdf contact juppebiacuk
a714269fa44287c2d7c4c75d847cb72a823b7427,Data journeys: Capturing the socio-material constitution of data objects and flows,"In this paper, we discuss the development and piloting of a new methodology for illuminating the socio-material constitution of data objects and flows as data move between different sites of practice. The data journeys approach contributes to the development of critical, qualitative methodologies that can address the geographic and temporal scale of emerging knowledge infrastructures, and capture the ‘life of data’ from their initial generation through to re-use in different contexts. We discuss the theoretical development of the data journeys methodology and the application of the approach on a project examining meteorological data on their journey from initial production through to being re-used in climate science and financial markets. We then discuss three key conceptual findings from this project about: (1) the socio-material constitution of digital data objects, (2) ‘friction’ in the movement of data through space and time and (3) the mutability of digital data as a material property that contributes to driving the movement of data between different sites of practice.",paper discuss develop pilot new methodolog illumin sociomateri constitut data object flow data move differ site practic data journey approach contribut develop critic qualit methodolog address geograph tempor scale emerg knowledg infrastructur captur life data initi gener reus differ context discuss theoret develop data journey methodolog applic approach project examin meteorolog data journey initi product reus climat scienc financi market discuss three key conceptu find project sociomateri constitut digit data object friction movement data space time mutabl digit data materi properti contribut drive movement data differ site practic
ae7743e0252a3a81e4505fc3354b2009b1068236,Is Science for Us? Black Students’ and Parents’ Views of Science and Science Careers,"ABSTRACT There are widespread policy concerns to improve (widen and increase) science, technology, engineering, and mathematics participation, which remains stratified by ethnicity, gender, and social class. Despite being interested in and highly valuing science, Black students tend to express limited aspirations to careers in science and remain underrepresented in post‐16 science courses and careers, a pattern which is not solely explained by attainment. This paper draws on survey data from nationally representative student cohorts and longitudinal interview data collected over 4 years from 10 Black African/Caribbean students and their parents, who were tracked from age 10–14 (Y6–Y9), as part of a larger study on children's science and career aspirations. The paper uses an intersectional analysis of the qualitative data to examine why science careers are less “thinkable” for Black students. A case study is also presented of two young Black women who “bucked the trend” and aspired to science careers. The paper concludes with implications for science education policy and practice.",abstract widespread polici concern improv widen increas scienc technolog engin mathemat particip remain stratifi ethnic gender social class despit interest highli valu scienc black student tend express limit aspir career scienc remain underrepres post scienc cours career pattern sole explain attain paper draw survey data nation repres student cohort longitudin interview data collect year black africancaribbean student parent track age yy part larger studi children scienc career aspir paper use intersect analysi qualit data examin scienc career less thinkabl black student case studi also present two young black women buck trend aspir scienc career paper conclud implic scienc educ polici practic
6eb4ebbe7f99bc51b3f81d4daa7e57a97254310e,Principles of Data Mining,,nan
15fffafb4bfcf8f9b210de01ac5208b0d916147e,Trending: The Promises and the Challenges of Big Social Data,"Today the term "" big data "" is often used in popular media, business, computer science and computer industry. For instance, in June 2008 Wired magazine opened its special section on "" The Petabyte Age "" by stating: "" Our ability to capture, warehouse, and understand massive amounts of data is changing science, medicine, business, and technology. As our collection of facts and figures grows, so will the opportunity to find answers to fundamental questions "" ("" The Petabyte Age ""). In February 2010, Economist started its special report "" Data, data everywhere "" with the phrase "" the industrial revolution of data "" (coined by computer scientist Joe Hellerstein) and then went to note that "" The effect is being felt everywhere, from business to science, from government to the arts "" ("" Data, data everywhere ""). Discussions in popular media usually do not define "" big data "" in qualitative terms. However, in computer industry the term has a more precise meaning: "" Big Data is a term applied to data sets whose size is beyond the ability of commonly used software tools to capture, manage, and process the data within a tolerable elapsed time. Big data sizes are a constantly moving target currently ranging from a few dozen terabytes to many petabytes of data in a single data set "" ("" Big data "").. Since its formation in 2008, NEH Office of Digital Humanities has been systematically creating grant opportunities to help humanists work with large data sets. The following statement from 2011 grant competition organized by NEH together with a number of other research agencies in USA, Canada, UK, and Netherlands provides an excellent description of what is at stake: "" The idea behind the Digging into Data Challenge is to address how ""big data"" changes the research landscape for the humanities and social sciences. Now that we have massive databases of materials used by scholars in the humanities and social sciences-ranging from digitized books, newspapers, and music to transactional data like web searches, sensor data or cell phone records-what new, computationally-based research methods might we apply? As the world becomes increasingly digital, new techniques will be needed to search, analyze, and understand these everyday materials. "" ("" Digging into Data Challenge ""). The projects funded by 2009 Digging Into Data Challenge and earlier NEH 2008 Humanities High Performance Computing grant program begin to map the …",today term big data often use popular media busi comput scienc comput industri instanc june wire magazin open special section petabyt age state abil captur warehous understand massiv amount data chang scienc medicin busi technolog collect fact figur grow opportun find answer fundament question petabyt age februari economist start special report data data everywher phrase industri revolut data coin comput scientist joe hellerstein went note effect felt everywher busi scienc govern art data data everywher discuss popular media usual defin big data qualit term howev comput industri term precis mean big data term appli data set whose size beyond abil commonli use softwar tool captur manag process data within toler elaps time big data size constantli move target current rang dozen terabyt mani petabyt data singl data set big data sinc format neh offic digit human systemat creat grant opportun help humanist work larg data set follow statement grant competit organ neh togeth number research agenc usa canada uk netherland provid excel descript stake idea behind dig data challeng address big data chang research landscap human social scienc massiv databas materi use scholar human social sciencesrang digit book newspap music transact data like web search sensor data cell phone recordswhat new computationallybas research method might appli world becom increasingli digit new techniqu need search analyz understand everyday materi dig data challeng project fund dig data challeng earlier neh human high perform comput grant program begin map
5724121504a3cc1ed648dd61bc980ffa7c4e1fb5,Addressing big data issues in Scientific Data Infrastructure,"Big Data are becoming a new technology focus both in science and in industry. This paper discusses the challenges that are imposed by Big Data on the modern and future Scientific Data Infrastructure (SDI). The paper discusses a nature and definition of Big Data that include such features as Volume, Velocity, Variety, Value and Veracity. The paper refers to different scientific communities to define requirements on data management, access control and security. The paper introduces the Scientific Data Lifecycle Management (SDLM) model that includes all the major stages and reflects specifics in data management in modern e-Science. The paper proposes the SDI generic architecture model that provides a basis for building interoperable data or project centric SDI using modern technologies and best practices. The paper explains how the proposed models SDLM and SDI can be naturally implemented using modern cloud based infrastructure services provisioning model and suggests the major infrastructure components for Big Data.",big data becom new technolog focu scienc industri paper discuss challeng impos big data modern futur scientif data infrastructur sdi paper discuss natur definit big data includ featur volum veloc varieti valu verac paper refer differ scientif commun defin requir data manag access control secur paper introduc scientif data lifecycl manag sdlm model includ major stage reflect specif data manag modern escienc paper propos sdi gener architectur model provid basi build interoper data project centric sdi use modern technolog best practic paper explain propos model sdlm sdi natur implement use modern cloud base infrastructur servic provis model suggest major infrastructur compon big data
ad4f067304551c20b50a3c0f7e02e3e9d6946003,Automated data reduction workflows for astronomy,"Data from complex modern astronomical instruments often consist of a large number of different science and calibration files, and their reduction requires a variety of software tools. The execution chain of the tools represents a complex workflow that needs to be tuned and supervised, often by individual researchers that are not necessarily experts for any specific instrument. The efficiency of data reduction can be improved by using automatic workflows to organise data and execute the sequence of data reduction steps. To realize such efficiency gains, we designed a system that allows intuitive representation, execution and modification of the data reduction workflow, and has facilities for inspection and interaction with the data. The European Southern Observatory (ESO) has developed Reflex, an environment to automate data reduction workflows. Reflex is implemented as a package of customized components for the Kepler workflow engine. Kepler provides the graphical user interface to create an executable flowchart-like representation of the data reduction process. Key features of Reflex are a rule-based data organiser, infrastructure to re-use results, thorough book-keeping, data progeny tracking, interactive user interfaces, and a novel concept to exploit information created during data organisation for the workflow execution. Reflex includes novel concepts to increase the efficiency of astronomical data processing. While Reflex is a specific implementation of astronomical scientific workflows within the Kepler workflow engine, the overall design choices and methods can also be applied to other environments for running automated science workflows.",data complex modern astronom instrument often consist larg number differ scienc calibr file reduct requir varieti softwar tool execut chain tool repres complex workflow need tune supervis often individu research necessarili expert specif instrument effici data reduct improv use automat workflow organis data execut sequenc data reduct step realiz effici gain design system allow intuit represent execut modif data reduct workflow facil inspect interact data european southern observatori eso develop reflex environ autom data reduct workflow reflex implement packag custom compon kepler workflow engin kepler provid graphic user interfac creat execut flowchartlik represent data reduct process key featur reflex rulebas data organis infrastructur reus result thorough bookkeep data progeni track interact user interfac novel concept exploit inform creat data organis workflow execut reflex includ novel concept increas effici astronom data process reflex specif implement astronom scientif workflow within kepler workflow engin overal design choic method also appli environ run autom scienc workflow
d358825a09c1da5804434d0ed147cb03e2a7e491,Mechanisms for Data Quality and Validation in Citizen Science,"Data quality is a primary concern for researchers employing a public participation in scientific research (PPSR) or ``citizen science'' approach. This mode of scientific collaboration relies on contributions from a large, often unknown population of volunteers with variable expertise. In a survey of PPSR projects, we found that most projects employ multiple mechanisms to ensure data quality and appropriate levels of validation. We created a framework of 18 mechanisms commonly employed by PPSR projects for ensuring data quality, based on direct experience of the authors and a review of the survey data, noting two categories of sources of error (protocols, participants) and three potential intervention points (before, during and after participation), which can be used to guide project design.",data qualiti primari concern research employ public particip scientif research ppsr citizen scienc approach mode scientif collabor reli contribut larg often unknown popul volunt variabl expertis survey ppsr project found project employ multipl mechan ensur data qualiti appropri level valid creat framework mechan commonli employ ppsr project ensur data qualiti base direct experi author review survey data note two categori sourc error protocol particip three potenti intervent point particip use guid project design
1c4c52d27a07ee59f062304ad53e3b524bd2b4a2,Citizen Science: Can Volunteers Do Real Research?,ABSTRACT Collaborations between scientists and volunteers have the potential to broaden the scope of research and enhance the ability to collect scientific data. Interested members of the public may contribute valuable information as they learn about wildlife in their local communities.,abstract collabor scientist volunt potenti broaden scope research enhanc abil collect scientif data interest member public may contribut valuabl inform learn wildlif local commun
df9bf28634d6499d3f9cf876f02c0d0cb5c3322d,Data-Intensive Science: A New Paradigm for Biodiversity Studies,"The increasing availability of massive volumes of scientific data requires new synthetic analysis techniques to explore and identify interesting patterns that are otherwise not apparent. For biodiversity studies, a “data-driven” approach is necessary because of the complexity of ecological systems, particularly when viewed at large spatial and temporal scales. Data-intensive science organizes large volumes of data from multiple sources and fields and then analyzes them using techniques tailored to the discovery of complex patterns in high-dimensional data through visualizations, simulations, and various types of model building. Through interpreting and analyzing these models, truly novel and surprising patterns that are “born from the data” can be discovered. These patterns provide valuable insight for concrete hypotheses about the underlying ecological processes that created the observed data. Data-intensive science allows scientists to analyze bigger and more complex systems efficiently, and complements more traditional scientific processes of hypothesis generation and experimental testing to refine our understanding of the natural world.",increas avail massiv volum scientif data requir new synthet analysi techniqu explor identifi interest pattern otherwis appar biodivers studi datadriven approach necessari complex ecolog system particularli view larg spatial tempor scale dataintens scienc organ larg volum data multipl sourc field analyz use techniqu tailor discoveri complex pattern highdimension data visual simul variou type model build interpret analyz model truli novel surpris pattern born data discov pattern provid valuabl insight concret hypothes underli ecolog process creat observ data dataintens scienc allow scientist analyz bigger complex system effici complement tradit scientif process hypothesi gener experiment test refin understand natur world
b6e9921477cf2e8ad95e5362654246245f082ab3,Multisensor Data Fusion,,nan
93d772e4fb852e4dba92a56e2cd356f1fda03be1,The data paper: a mechanism to incentivize data publishing in biodiversity science,,nan
d13eb74d54385c1e1ea70a6ff536c086fa6e7422,The rate of growth in scientific publication and the decline in coverage provided by Science Citation Index,,nan
cf2dcb37a9cd154e9acdb1b9acc3b9b8d2c579fe,Challenges and Opportunities of Open Data in Ecology,"Ecology is a synthetic discipline benefiting from open access to data from the earth, life, and social sciences. Technological challenges exist, however, due to the dispersed and heterogeneous nature of these data. Standardization of methods and development of robust metadata can increase data access but are not sufficient. Reproducibility of analyses is also important, and executable workflows are addressing this issue by capturing data provenance. Sociological challenges, including inadequate rewards for sharing data, must also be resolved. The establishment of well-curated, federated data repositories will provide a means to preserve data while promoting attribution and acknowledgement of its use.",ecolog synthet disciplin benefit open access data earth life social scienc technolog challeng exist howev due dispers heterogen natur data standard method develop robust metadata increas data access suffici reproduc analys also import execut workflow address issu captur data proven sociolog challeng includ inadequ reward share data must also resolv establish wellcur feder data repositori provid mean preserv data promot attribut acknowledg use
b1d8a4b5f0c1788ac9a431f9c50a174e3cfb9dd5,International Journal of Data Warehousing and Mining,"1 Elasticity in Cloud databases and Their Query Processing Goetz Graefe, Research in Business Intelligence, Hewlett-Packard Laboratories, Palo Alto, CA, USA Anisoara Nica, SQL Anywhere Research and Development, Sybase (An SAP Company), Waterloo, ON, Canada Knut Stolze, Information Management Department, IBM Germany Research & Development, Böblingen, Germany Thomas Neumann, Technische Universität München, Garching, Germany Todd Eavis, Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada Ilia Petrov, Data Management Lab, School of Informatics, Reutlingen University, Germany Elaheh Pourabbas, Institute of Systems Analysis and Computer Science “Antonio Ruberti”, National Research Council, Rome, Italy David Fekete, Department of Information Systems, Universität Münster, Münster, Germany",elast cloud databas queri process goetz graef research busi intellig hewlettpackard laboratori palo alto ca usa anisoara nica sql anywher research develop sybas sap compani waterloo canada knut stolz inform manag depart ibm germani research develop böblingen germani thoma neumann technisch universität münchen garch germani todd eavi depart comput scienc softwar engin concordia univers montreal qc canada ilia petrov data manag lab school informat reutlingen univers germani elaheh pourabba institut system analysi comput scienc antonio ruberti nation research council rome itali david feket depart inform system universität münster münster germani
e1946e597b27cd4526ee71800f6454b8dcb5d4d1,Fuzzy mathematical models in engineering and management science,"Theoretical Concepts. Fuzzy Set Theory and System Modelling. Theory of Fuzzy Sets. Theory of Fuzzy Numbers. Linear Ordering of Fuzzy Numbers. Evaluation of Imprecision in Fuzzy Numbers. Triangular Approximation of Various Functions of Triangular Fuzzy Numbers. Deconvolution of the Fuzzy Equations A(+)B=C, and A( . )B=C in R. T-Norms and T-Conorms. Fuzzy Numbers in [0,1]. Fuzzy Numbers in [0,1] with Higher-Order Intervals of Confidence in [0,1]. Models in Engineering and Management Science. Modelling Issues in Engineering and Management Science. Fuzzy Zero-Base Budgeting (F.Z.B.B.). Fuzzy Delphi Method (F.D.M.) in Forecasting and Decision Making. Discounting Problem using Fuzzy Numbers. Smoothing (Filtering) of Fuzzy Data. Reliability Modelling and Evaluation with Fuzzy Data. Ordering of Fuzzy Quotients. Critical Path Method (C.P.M.) with Fuzzy Data. Investment Problem with Fuzzy Data. Transportation Optimization with Fuzzy Data: (Fuzzy Stepping Stone Method). A General View about the Fuzzification of Models in Engineering and Management Science. Appendices.",theoret concept fuzzi set theori system model theori fuzzi set theori fuzzi number linear order fuzzi number evalu imprecis fuzzi number triangular approxim variou function triangular fuzzi number deconvolut fuzzi equat abc bc r tnorm tconorm fuzzi number fuzzi number higherord interv confid model engin manag scienc model issu engin manag scienc fuzzi zerobas budget fzbb fuzzi delphi method fdm forecast decis make discount problem use fuzzi number smooth filter fuzzi data reliabl model evalu fuzzi data order fuzzi quotient critic path method cpm fuzzi data invest problem fuzzi data transport optim fuzzi data fuzzi step stone method gener view fuzzif model engin manag scienc appendic
94e2b74c4ff14698c05fdfee398c10d2e6de3263,The Internet as a Data Source for Advancement in Social Sciences,"This paper advocates the use of Internet data for social sciences with a special focus on human resources issues. It discusses the potentials and challenges of Internet data for social sciences and presents a selection of the relevant literature to establish the wide spectrum of topics, which can be reached. Such data represent a large and increasing part of everyday life, which cannot be measured otherwise. They are timely, perhaps even daily following the factual process, they typically involve large numbers of observations, and they allow for flexible conceptual forms and experimental settings. Internet data can successfully be applied to a very wide range of human resource issues including forecasting (e.g. of unemployment, consumption goods, tourism, festival winners and the like), nowcasting (obtaining relevant information much earlier than through traditional data collection techniques), detecting health issues and well-being (e.g. flu, malaise and ill-being during economic crises), documenting the matching process in various parts of individual life (e.g. jobs, partnership, shopping), and measuring complex processes where traditional data have known deficits (e.g. international migration, collective bargaining agreements in developing countries). Major problems in data analysis are still unsolved and more research on data reliability is needed. Current research is highly original but also exploratory and premature. Our article reviews the current attempts in the literature to incorporate Internet data into the mainstream of scholarly empirical research and guides the reader through this Special Issue. We provide some insights and a brief overview of the current state of research.",paper advoc use internet data social scienc special focu human resourc issu discuss potenti challeng internet data social scienc present select relev literatur establish wide spectrum topic reach data repres larg increas part everyday life cannot measur otherwis time perhap even daili follow factual process typic involv larg number observ allow flexibl conceptu form experiment set internet data success appli wide rang human resourc issu includ forecast eg unemploy consumpt good tourism festiv winner like nowcast obtain relev inform much earlier tradit data collect techniqu detect health issu wellb eg flu malais illb econom crise document match process variou part individu life eg job partnership shop measur complex process tradit data known deficit eg intern migrat collect bargain agreement develop countri major problem data analysi still unsolv research data reliabl need current research highli origin also exploratori prematur articl review current attempt literatur incorpor internet data mainstream scholarli empir research guid reader special issu provid insight brief overview current state research
3d9b385913f9d470e175051fc113eb2b8dc5981b,Big data and its epistemology,"The article considers whether Big Data, in the form of data‐driven science, will enable the discovery, or appraisal, of universal scientific theories, instrumentalist tools, or inductive inferences. It points out, initially, that such aspirations are similar to the now‐discredited inductivist approach to science. On the positive side, Big Data may permit larger sample sizes, cheaper and more extensive testing of theories, and the continuous assessment of theories. On the negative side, data‐driven science encourages passive data collection, as opposed to experimentation and testing, and hornswoggling (“unsound statistical fiddling”). The roles of theory and data in inductive algorithms, statistical modeling, and scientific discoveries are analyzed, and it is argued that theory is needed at every turn. Data‐driven science is a chimera.",articl consid whether big data form datadriven scienc enabl discoveri apprais univers scientif theori instrumentalist tool induct infer point initi aspir similar nowdiscredit inductivist approach scienc posit side big data may permit larger sampl size cheaper extens test theori continu assess theori neg side datadriven scienc encourag passiv data collect oppos experiment test hornswoggl unsound statist fiddl role theori data induct algorithm statist model scientif discoveri analyz argu theori need everi turn datadriven scienc chimera
74435e06c0726e36b3f41970645163258d87861f,CLAVIRE: e-Science infrastructure for data-driven computing,,nan
4e7c457b21d8ba062fdbe4cefa16c0f29a2576de,Compositional data analysis : theory and applications,"It is difficult to imagine that the statistical analysis of compositional data has been a major issue of concern for more than 100 years. It is even more difficult to realize that so many statisticians and users of statistics are unaware of the particular problems affecting compositional data, as well as their solutions. The issue of ``spurious correlation'', as the situation was phrased by Karl Pearson back in 1897, affects all data that measures parts of some whole, such as percentages, proportions, ppm and ppb. Such measurements are present in all fields of science, ranging from geology, biology, environmental sciences, forensic sciences, medicine and hydrology. This book presents the history and development of compositional data analysis along with Aitchison's log-ratio approach. Compositional Data Analysis describes the state of the art both in theoretical fields as well as applications in the different fields of science.",difficult imagin statist analysi composit data major issu concern year even difficult realiz mani statistician user statist unawar particular problem affect composit data well solut issu spuriou correl situat phrase karl pearson back affect data measur part whole percentag proport ppm ppb measur present field scienc rang geolog biolog environment scienc forens scienc medicin hydrolog book present histori develop composit data analysi along aitchison logratio approach composit data analysi describ state art theoret field well applic differ field scienc
5f0099070ab2ed282b52c15d1ccc4eb0cf1ac162,"Data sharing, small science and institutional repositories","Results are presented from the Data Curation Profiles project research, on who is willing to share what data with whom and when. Emerging from scientists’ discussions on sharing are several dimensions suggestive of the variation in both what it means ‘to share’ and how these processes are carried out. This research indicates that data curation services will need to accommodate a wide range of subdisciplinary data characteristics and sharing practices. As part of a larger set of strategies emerging across academic institutions, institutional repositories (IRs) will contribute to the stewardship and mobilization of scientific research data for e-Research and learning. There will be particular types of data that can be managed well in an IR context when characteristics and practices are well understood. Findings from this study elucidate scientists’ views on ‘sharable’ forms of data—the particular representation that they view as most valued for reuse by others within their own research areas—and the anticipated duration for such reuse. Reported sharing incidents that provide insights into barriers to sharing and related concerns on data misuse are included.",result present data curat profil project research will share data emerg scientist discuss share sever dimens suggest variat mean share process carri research indic data curat servic need accommod wide rang subdisciplinari data characterist share practic part larger set strategi emerg across academ institut institut repositori ir contribut stewardship mobil scientif research data eresearch learn particular type data manag well ir context characterist practic well understood find studi elucid scientist view sharabl form datath particular represent view valu reus other within research areasand anticip durat reus report share incid provid insight barrier share relat concern data misus includ
5eef24aac20bfed5a6c7702b13ae51a1f29c1b29,Clustering For Data Mining: A Data Recovery Approach (Chapman & Hall/Crc Computer Science),INTRODUCTION: HISTORICAL REMARKS WHAT IS CLUSTERING Exemplary Problems Bird's Eye View WHAT IS DATA Feature Characteristics Bivariate Analysis Feature Space and Data Scatter Preprocessing and Standardizing Mixed Data K-MEANS CLUSTERING Conventional K-Means Initialization of K-Means Intelligent K-Means Interpretation Aids Overall Assessment WARD HIERARCHICAL CLUSTERING Agglomeration: Ward Algorithm Divisive Clustering with Ward Criterion Conceptual Clustering Extensions of Ward Clustering Overall Assessment DATA RECOVERY MODELS Statistics Modeling as Data Recovery Data Recovery Model for K-Means Data Recovery Models for Ward Criterion Extensions to Other Data Types One-by-One Clustering Overall Assessment DIFFERENT CLUSTERING APPROACHES Extensions of K-Means Clustering Graph-Theoretic Approaches Conceptual Description of Clusters Overall Assessment GENERAL ISSUES Feature Selection and Extraction Data Pre-Processing and Standardization Similarity on Subsets and Partitions Dealing with Missing Data Validity and Reliability Overall Assessment CONCLUSION: Data Recovery Approach in Clustering BIBLIOGRAPHY Each chapter also contains a section of Base Words,introduct histor remark cluster exemplari problem bird eye view data featur characterist bivari analysi featur space data scatter preprocess standard mix data kmean cluster convent kmean initi kmean intellig kmean interpret aid overal assess ward hierarch cluster agglomer ward algorithm divis cluster ward criterion conceptu cluster extens ward cluster overal assess data recoveri model statist model data recoveri data recoveri model kmean data recoveri model ward criterion extens data type onebyon cluster overal assess differ cluster approach extens kmean cluster graphtheoret approach conceptu descript cluster overal assess gener issu featur select extract data preprocess standard similar subset partit deal miss data valid reliabl overal assess conclus data recoveri approach cluster bibliographi chapter also contain section base word
6309f94eebc515709cf7bbd455953efbfab4e5c2,"Science Aspirations, Capital, and Family Habitus","Low participation rates in the study of science, technology, engineering, and mathematics (STEM) post-16 are a matter of international concern. Existing evidence suggests children’s science aspirations are largely formed within the critical 10 to 14 age period. This article reports on survey data from over 9,000 elementary school children in England (age 10/11) and qualitative data from 160 semi-structured interviews (92 children aged 10/11 and 78 parents), collected as part of an ongoing 5-year longitudinal study in the United Kingdom tracking children from 10 to 14. Drawing on the conceptual framework of Bourdieu, the article explores how the interplay of family habitus and capital can make science aspirations more “thinkable” for some (notably middle-class) children than others. It is argued that while family habitus is not deterministic (there is no straightforward alignment between family habitus, capital, and a child’s science aspirations), social inequalities in the distribution of capital and differentially classed family habitus combine to produce uneven (classed, racialized) patterns in children’s science aspirations and potential future participation.",low particip rate studi scienc technolog engin mathemat stem post matter intern concern exist evid suggest children scienc aspir larg form within critic age period articl report survey data elementari school children england age qualit data semistructur interview children age parent collect part ongo year longitudin studi unit kingdom track children draw conceptu framework bourdieu articl explor interplay famili habitu capit make scienc aspir thinkabl notabl middleclass children other argu famili habitu determinist straightforward align famili habitu capit child scienc aspir social inequ distribut capit differenti class famili habitu combin produc uneven class racial pattern children scienc aspir potenti futur particip
01ac4f988ed6cb2e0afe7acc450ad2271bb4f207,Big data from small data: data-sharing in the 'long tail' of neuroscience,,nan
ffce6df6b54206f01e7a8eb515fbf716fa984215,Are Scientific Data Repositories Coping with Research Data Publishing?,"Research data publishing is intended as the release of research data to make it possible for practitioners to (re)use them according to “open science” dynamics. There are three main actors called to deal with research data publishing practices: researchers, publishers, and data repositories. This study analyses the solutions offered by generalist scientific data repositories, i.e., repositories supporting the deposition of any type of research data. These repositories cannot make any assumption on the application domain. They are actually called to face with the almost open ended typologies of data used in science. The current practices promoted by such repositories are analysed with respect to eight key aspects of data publishing, i.e., dataset formatting, documentation, licensing, publication costs, validation, availability, discovery and access, and citation. From this analysis it emerges that these repositories implement well consolidated practices and pragmatic solutions for literature repositories. These practices and solutions can not totally meet the needs of management and use of datasets resources, especially in a context where rapid technological changes continuously open new exploitation prospects.",research data publish intend releas research data make possibl practition reus accord open scienc dynam three main actor call deal research data publish practic research publish data repositori studi analys solut offer generalist scientif data repositori ie repositori support deposit type research data repositori cannot make assumpt applic domain actual call face almost open end typolog data use scienc current practic promot repositori analys respect eight key aspect data publish ie dataset format document licens public cost valid avail discoveri access citat analysi emerg repositori implement well consolid practic pragmat solut literatur repositori practic solut total meet need manag use dataset resourc especi context rapid technolog chang continu open new exploit prospect
cc0019f2ad728bac89ae1586062f27a8018f5763,Reproducibility in science,"Multiple sources can lead to issues with reproducibility and reliability in scientific data. The issue of reproducibility and reliability in science has come to the forefront in light of several high-profile studies that could not be reproduced. Whereas some errors in reliability can be attributed to the application of new techniques that have unappreciated caveats, some problems with reproducibility lie in the climate of intense pressure for funding and to publish faced by many researchers.",multipl sourc lead issu reproduc reliabl scientif data issu reproduc reliabl scienc come forefront light sever highprofil studi could reproduc wherea error reliabl attribut applic new techniqu unappreci caveat problem reproduc lie climat intens pressur fund publish face mani research
4470e53d2d28f93382de82f8f4365f7514b9f4cf,Data Scientist: The Engineer of the Future,,nan
c223ee2e2117a5d2119070177279950f58b706d2,"A conceptual framework for managing very diverse data for complex, interdisciplinary science","Much attention has been given to the challenges of handling massive data volumes in modern data-intensive science. This paper examines an equally daunting challenge – the diversity of interdisciplinary data, notably research data, and the need to interrelate these data to understand complex systemic problems such as environmental change and its impact. We use the experience of the International Polar Year 2007–8 (IPY) as a case study to examine data management approaches seeking to address issues around complex interdisciplinary science. We find that, while technology is a critical factor in addressing the interdisciplinary dimension of the data intensive science, the technologies developing for exa-scale data volumes differ from those that are needed for extremely distributed and heterogeneous data. Research data will continue to be highly heterogeneous and distributed and will require technologies to be much simpler and more flexible. More importantly, there is a need for both technical and cultural adaptation. We describe a vision of discoverable, open, linked, useful, and safe collections of data, organized and curated using the best principles and practices of information and library science. This vision provides a framework for our discussion and leads us to suggest several short- and long-term strategies to facilitate a socio-technical evolution in the overall science data ecosystem.",much attent given challeng handl massiv data volum modern dataintens scienc paper examin equal daunt challeng divers interdisciplinari data notabl research data need interrel data understand complex system problem environment chang impact use experi intern polar year ipi case studi examin data manag approach seek address issu around complex interdisciplinari scienc find technolog critic factor address interdisciplinari dimens data intens scienc technolog develop exascal data volum differ need extrem distribut heterogen data research data continu highli heterogen distribut requir technolog much simpler flexibl importantli need technic cultur adapt describ vision discover open link use safe collect data organ curat use best principl practic inform librari scienc vision provid framework discuss lead us suggest sever short longterm strategi facilit sociotechn evolut overal scienc data ecosystem
def0cdb0398081295dec0a6d913105f8d5d94cac,Toward a manifesto for the ‘public understanding of big data’,"In this article, we sketch a ‘manifesto’ for the ‘public understanding of big data’. On the one hand, this entails such public understanding of science and public engagement with science and technology–tinged questions as follows: How, when and where are people exposed to, or do they engage with, big data? Who are regarded as big data’s trustworthy sources, or credible commentators and critics? What are the mechanisms by which big data systems are opened to public scrutiny? On the other hand, big data generate many challenges for public understanding of science and public engagement with science and technology: How do we address publics that are simultaneously the informant, the informed and the information of big data? What counts as understanding of, or engagement with, big data, when big data themselves are multiplying, fluid and recursive? As part of our manifesto, we propose a range of empirical, conceptual and methodological exhortations. We also provide Appendix 1 that outlines three novel methods for addressing some of the issues raised in the article.",articl sketch manifesto public understand big data one hand entail public understand scienc public engag scienc technologyting question follow peopl expos engag big data regard big data trustworthi sourc credibl comment critic mechan big data system open public scrutini hand big data gener mani challeng public understand scienc public engag scienc technolog address public simultan inform inform inform big data count understand engag big data big data multipli fluid recurs part manifesto propos rang empir conceptu methodolog exhort also provid appendix outlin three novel method address issu rais articl
8be1068759a0a85e617e0dccbdaabc6047f9c62d,"Landolt-Börnstein, Numerical Data and Functional Relationships in Science and Technology",,nan
10a44b154d1d0db5bfcb3a8148728c26741f7ec0,Analysis of Multivariate Social Science Data,,nan
2c8a9f92a8d969d052f2960e5b349ebbdeac97f1,The (Big) Data-security assemblage: Knowledge and critique,"The Snowden revelations and the emergence of ‘Big Data’ have rekindled questions about how security practices are deployed in a digital age and with what political effects. While critical scholars have drawn attention to the social, political and legal challenges to these practices, the debates in computer and information science have received less analytical attention. This paper proposes to take seriously the critical knowledge developed in information and computer science and reinterpret their debates to develop a critical intervention into the public controversies concerning data-driven security and digital surveillance. The paper offers a two-pronged contribution: on the one hand, we challenge the credibility of security professionals’ discourses in light of the knowledge that they supposedly mobilize; on the other, we argue for a series of conceptual moves around data, human–computer relations, and algorithms to address some of the limitations of existing engagements with the Big Data-security assemblage.",snowden revel emerg big data rekindl question secur practic deploy digit age polit effect critic scholar drawn attent social polit legal challeng practic debat comput inform scienc receiv less analyt attent paper propos take serious critic knowledg develop inform comput scienc reinterpret debat develop critic intervent public controversi concern datadriven secur digit surveil paper offer twoprong contribut one hand challeng credibl secur profession discours light knowledg supposedli mobil argu seri conceptu move around data humancomput relat algorithm address limit exist engag big datasecur assemblag
6ebb3fb75e1a98dbc92945c76cb1d812004754c7,The Emerging Role of Libraries in Data Curation and E-science,"ABSTRACT The role of libraries is to collect, preserve, and disseminate the intellectual output of the society. This output includes books and serials as well as the digital versions of the same. Scientists, other scholars, and all of society are now producing, storing, and disseminating digital data that underpin the aforementioned documents in much larger volumes than the text. The survival of this data is in question since the data are not housed in long-lived institutions such as libraries. This situation threatens the underlying principles of scientific replicability since in many cases data cannot readily be collected again. Libraries are the institutions that could best manage this intellectual output.",abstract role librari collect preserv dissemin intellectu output societi output includ book serial well digit version scientist scholar societi produc store dissemin digit data underpin aforement document much larger volum text surviv data question sinc data hous longliv institut librari situat threaten underli principl scientif replic sinc mani case data cannot readili collect librari institut could best manag intellectu output
40ac2f8dee212766cf7908ceea432322bbf97cae,Numerical data and functional relationships in science and technology,,nan
f1933d47885d4854003ca1d134b399bfd5ac104e,Analyzing social science data,"PART ONE: HOW TO PREPARE DATA FOR ANALYSIS How to Code Data How to Code Questions with Multiple Answers Can the Respondent's Answers be Relied on? How to Check that the Right Thing is Being Measured TWO: HOW TO PREPARE VARIABLES FOR ANALYSIS How to Deal with Variables with Lots of Categories How to Identify and Change the Level of Measurement of Variables How to Deal with Questions that Fail to Identify Real Differences Between Cases How to Rearrange the Categories of a Variable What to do with Gaps in the Data What to do with People who 'Don't Know', 'Have no Opinion' or 'Can't Decide' How to Tell if the Distribution is Normal How to Tell if the Relationship is Linear How to Tell if Outlier Cases are a Problem What to do if the Required Variable is not Available How to Compare Apples with Oranges Comparing Scores on Different Variables PART THREE: HOW TO REDUCE THE AMOUNT OF DATA TO ANALYSE How to Work Out Which Variables to Use How to Combine Information from a Set of Variables into a Single Measure How to Build a Good Likert Scale How to Build a Scale Using Factor Analysis PART FOUR: HOW AND WHEN TO GENERALISE What Does it Mean to Generalize? How to Judge the Extent and Effect of Sample Bias How to Weight Samples to Adjust for Bias What are Tests of Significance? Should Tests of Significance be Used? What Factors Affect Significance Levels? Is the Sample Large Enough to Achieve Statistical Significance? Should Confidence Intervals be Used? PART FIVE: HOW TO ANALYSE A SINGLE VARIABLE How to Use Tables Effectively to Display the Distribution of a Single Variable How to Use Graphs for Single Variables Which Summary Statistics to Use to Describe a Single Variable Which Statistics to Use to Generalise about a Single Variable PART SIX: HOW TO ANALYSE TWO VARIABLES How and When to Use Crosstabulations Which Graph to Use How to Narrow down the Choice When Selecting Summary Statistics How to Interpret a Correlation Coefficient Which Correlation? How much Impact Does a Variable Have? How to Tell if Groups are Different Which Test of Significance? How are Confidence Intervals used in Bivariate Analysis? PART SEVEN: HOW TO CARRY OUT MULTIVARIATE ANALYSIS Understanding Bivariate Relationships The Logic of Elaboration Analysis Using Conditional Tables as a Method of Elaboration Analysis Using Conditional Correlations for Elaboration Analysis Using Partial Tables as a Method of Elaboration Analysis Using Partial Correlations for Elaboration Analysis What Type of Data are Needed for Multiple Regression? How to do a Multiple Regression How to Use Non-interval Variables in Multiple Regression What Does the Multiple Regression Output Mean? What Other Multivariate Methods are Availabe?",part one prepar data analysi code data code question multipl answer respond answer reli check right thing measur two prepar variabl analysi deal variabl lot categori identifi chang level measur variabl deal question fail identifi real differ case rearrang categori variabl gap data peopl dont know opinion cant decid tell distribut normal tell relationship linear tell outlier case problem requir variabl avail compar appl orang compar score differ variabl part three reduc amount data analys work variabl use combin inform set variabl singl measur build good likert scale build scale use factor analysi part four generalis mean gener judg extent effect sampl bia weight sampl adjust bia test signific test signific use factor affect signific level sampl larg enough achiev statist signific confid interv use part five analys singl variabl use tabl effect display distribut singl variabl use graph singl variabl summari statist use describ singl variabl statist use generalis singl variabl part six analys two variabl use crosstabul graph use narrow choic select summari statist interpret correl coeffici correl much impact variabl tell group differ test signific confid interv use bivari analysi part seven carri multivari analysi understand bivari relationship logic elabor analysi use condit tabl method elabor analysi use condit correl elabor analysi use partial tabl method elabor analysi use partial correl elabor analysi type data need multipl regress multipl regress use noninterv variabl multipl regress multipl regress output mean multivari method availab
d825b7ab9c0093c78a0d5c665815e0becc48cd9b,Dynamic changes in motivation in collaborative citizen-science projects,"Online citizen science projects engage volunteers in collecting, analyzing, and curating scientific data. Existing projects have demonstrated the value of using volunteers to collect data, but few projects have reached the full collaborative potential of scientists and volunteers. Understanding the shared and unique motivations of these two groups can help designers establish the technical and social infrastructures needed to promote effective partnerships. We present findings from a study of the motivational factors affecting participation in ecological citizen science projects. We show that volunteers are motivated by a complex framework of factors that dynamically change throughout their cycle of work on scientific projects; this motivational framework is strongly affected by personal interests as well as external factors such as attribution and acknowledgment. Identifying the pivotal points of motivational shift and addressing them in the design of citizen-science systems will facilitate improved collaboration between scientists and volunteers.",onlin citizen scienc project engag volunt collect analyz curat scientif data exist project demonstr valu use volunt collect data project reach full collabor potenti scientist volunt understand share uniqu motiv two group help design establish technic social infrastructur need promot effect partnership present find studi motiv factor affect particip ecolog citizen scienc project show volunt motiv complex framework factor dynam chang throughout cycl work scientif project motiv framework strongli affect person interest well extern factor attribut acknowledg identifi pivot point motiv shift address design citizensci system facilit improv collabor scientist volunt
49b56a85f4813dd4747b0bbb5584e7e6e7f54552,Handbook of Zeolite Science and Technology,"The Handbook of Zeolite Science and Technology offers effective analyses ofsalient cases selected expressly for their relevance to current and prospective research. Presenting the principal theoretical and experimental underpinnings of zeolites, this international effort is at once complete and forward-looking, combining fundamental concepts with the most sophisticated data for each scientific subtopic and budding technology. Supplying over 750 figures, and 350 display equations, this impressive achievement in zeolite science observes synthesis through the lens of MFI (ZSM-5 and silicalite). Chapters progress from conceptual building blocks to complex research presentations.",handbook zeolit scienc technolog offer effect analys ofsali case select expressli relev current prospect research present princip theoret experiment underpin zeolit intern effort complet forwardlook combin fundament concept sophist data scientif subtop bud technolog suppli figur display equat impress achiev zeolit scienc observ synthesi len mfi zsm silicalit chapter progress conceptu build block complex research present
effa683ec6111aaf4b4d29ab2fb26b832844d9e1,Networks: An Introduction,"The scientific study of networks, including computer networks, social networks, and biological networks, has received an enormous amount of interest in the last few years. The rise of the Internet and the wide availability of inexpensive computers have made it possible to gather and analyze network data on a large scale, and the development of a variety of new theoretical tools has allowed us to extract new knowledge from many different kinds of networks.The study of networks is broadly interdisciplinary and important developments have occurred in many fields, including mathematics, physics, computer and information sciences, biology, and the social sciences. This book brings together for the first time the most important breakthroughs in each of these fields and presents them in a coherent fashion, highlighting the strong interconnections between work in different areas. Subjects covered include the measurement and structure of networks in many branches of science, methods for analyzing network data, including methods developed in physics, statistics, and sociology, the fundamentals of graph theory, computer algorithms, and spectral methods, mathematical models of networks, including random graph models and generative models, and theories of dynamical processes taking place on networks.",scientif studi network includ comput network social network biolog network receiv enorm amount interest last year rise internet wide avail inexpens comput made possibl gather analyz network data larg scale develop varieti new theoret tool allow us extract new knowledg mani differ kind networksth studi network broadli interdisciplinari import develop occur mani field includ mathemat physic comput inform scienc biolog social scienc book bring togeth first time import breakthrough field present coher fashion highlight strong interconnect work differ area subject cover includ measur structur network mani branch scienc method analyz network data includ method develop physic statist sociolog fundament graph theori comput algorithm spectral method mathemat model network includ random graph model gener model theori dynam process take place network
a50fac59cf792546d79f027ad5c20d52506ae262,The nature of science and instructional practice: Making the unnatural natural,"The purpose of this study was to delineate the factors that mediate the translation of preservice teachers' conceptions of the nature of science (NOS) into instructional planning and classroom practice. Fourteen preservice secondary science teachers participated in the study. Prior to their student teaching, participants responded to an open-ended questionnaire designed to assess their conceptions of the NOS. Analysis of the questionnaires was postponed until after the completion of student teaching to avoid biasing the collection and/or analysis of other data sources. Throughout student teaching, participants' daily lesson plans, classroom videotapes, and portfolios, and supervisors' weekly clinical observation notes were collated. These data were searched for explicit references to the NOS. Following student teaching, participants were individually interviewed to validate their responses to the open-ended questionnaire and to identify the factors or constraints that mediate the translation of their conceptions of the NOS into their classroom teaching. Participants were found to possess adequate understandings of several important aspects of the NOS including the empirical and tentative nature of science, the distinction between observation and inference, and the role of subjectivity and creativity in science. Many claimed to have taught the NOS through science-based activities. However, data analyses revealed that explicit references to the NOS were rare in their planning and instruction. Participants articulated several factors for this lack of attention to the NOS. These included viewing the NOS as less significant than other instructional outcomes, preoccupation with classroom management and routine chores, discomfort with their own understandings of the NOS, the lack of resources and experience for teaching the NOS, cooperating teachers' imposed restraints, and the lack of planning time. In addition to these volunteered constraints, the data revealed others related to an intricate interaction between participants' perspectives on the NOS, pedagogy, and instructional outcomes. © 1998 John Wiley & Sons, Inc. Sci Ed82:417–436, 1998.",purpos studi delin factor mediat translat preservic teacher concept natur scienc no instruct plan classroom practic fourteen preservic secondari scienc teacher particip studi prior student teach particip respond openend questionnair design assess concept no analysi questionnair postpon complet student teach avoid bias collect andor analysi data sourc throughout student teach particip daili lesson plan classroom videotap portfolio supervisor weekli clinic observ note collat data search explicit refer no follow student teach particip individu interview valid respons openend questionnair identifi factor constraint mediat translat concept no classroom teach particip found possess adequ understand sever import aspect no includ empir tent natur scienc distinct observ infer role subject creativ scienc mani claim taught no sciencebas activ howev data analys reveal explicit refer no rare plan instruct particip articul sever factor lack attent no includ view no less signific instruct outcom preoccup classroom manag routin chore discomfort understand no lack resourc experi teach no cooper teacher impos restraint lack plan time addit volunt constraint data reveal other relat intric interact particip perspect no pedagogi instruct outcom john wiley son inc sci ed
9759ed3befc96caa5035b7176671efea99cd3493,A Brief Review on Leading Big Data Models,"Today, science is passing through an era of transformation, where the inundation of data, dubbed data deluge is influencing the decision making process. The science is driven by the data and is being termed as data science. In this internet age, the volume of the data has grown up to petabytes, and this large, complex, structured or unstructured, and heterogeneous data in the form of “Big Data” has gained significant attention. The rapid pace of data growth through various disparate sources, especially social media such as Facebook, has seriously challenged the data analytic capabilities of traditional relational databases. The velocity of the expansion of the amount of data gives rise to a complete paradigm shift in how new age data is processed. Confidence in the data engineering of the existing data processing systems is gradually fading whereas the capabilities of the new techniques for capturing, storing, visualizing, and analyzing data are evolving. In this review paper, we discuss some of the modern Big Data models that are leading contributors in the NoSQL era and claim to address Big Data challenges in reliable and efficient ways. Also, we take the potential of Big Data into consideration and try to reshape the original operationaloriented definition of “Big Science” (Furner, 2003) into a new data-driven definition and rephrase it as “The science that deals with Big Data is Big Science.”",today scienc pass era transform inund data dub data delug influenc decis make process scienc driven data term data scienc internet age volum data grown petabyt larg complex structur unstructur heterogen data form big data gain signific attent rapid pace data growth variou dispar sourc especi social media facebook serious challeng data analyt capabl tradit relat databas veloc expans amount data give rise complet paradigm shift new age data process confid data engin exist data process system gradual fade wherea capabl new techniqu captur store visual analyz data evolv review paper discuss modern big data model lead contributor nosql era claim address big data challeng reliabl effici way also take potenti big data consider tri reshap origin operationalori definit big scienc furner new datadriven definit rephras scienc deal big data big scienc
73504bdcc93ffdfc65f33929d8e8a328c79eb0c6,Amazon's Mechanical Turk,"Amazon’s Mechanical Turk (MTurk) is a relatively new website that contains the major elements required to conduct research: an integrated participant compensation system; a large participant pool; and a streamlined process of study design, participant recruitment, and data collection. In this article, we describe and evaluate the potential contributions of MTurk to psychology and other social sciences. Findings indicate that (a) MTurk participants are slightly more demographically diverse than are standard Internet samples and are significantly more diverse than typical American college samples; (b) participation is affected by compensation rate and task length, but participants can still be recruited rapidly and inexpensively; (c) realistic compensation rates do not affect data quality; and (d) the data obtained are at least as reliable as those obtained via traditional methods. Overall, MTurk can be used to obtain high-quality data inexpensively and rapidly.",amazon mechan turk mturk rel new websit contain major element requir conduct research integr particip compens system larg particip pool streamlin process studi design particip recruit data collect articl describ evalu potenti contribut mturk psycholog social scienc find indic mturk particip slightli demograph divers standard internet sampl significantli divers typic american colleg sampl b particip affect compens rate task length particip still recruit rapidli inexpens c realist compens rate affect data qualiti data obtain least reliabl obtain via tradit method overal mturk use obtain highqual data inexpens rapidli
22829b485a2fe75919f62c5c646dcc9ed051cfbd,Barriers and facilitators related to the implementation of a physiological track and trigger system: A systematic review of the qualitative evidence,"Purpose
To identify the barriers to, and facilitators of, the implementation of physiological track and trigger systems (PTTSs), perceived by healthcare workers, through a systematic review of the extant qualitative literature.


Data sources
Searches were performed in PUBMED, CINAHL, PsycInfo, Embase and Web of Science. The reference lists of included studies were also screened.


Study selection
The electronic searches yielded 2727 papers. After removing duplicates, and further screening, a total of 10 papers were determined to meet the inclusion criteria and were reviewed.


Data extraction
A deductive content analysis approach was taken to organizing and analysing the data. A framework consisting of two overarching dimensions ('User-related changes required to implement PTTSs effectively' and 'Factors that affect user-related changes'), 5 themes (staff perceptions of PTTSs and patient safety, workflow adjustment, PTTS, implementation process and local context) and 14 sub themes was used to classify the barriers and facilitators to the implementation of PTTSs.


Results of data synthesis
Successful implementation of a PTTS must address the social context in which it is to be implemented by ensuring that the users believe that the system is effective and benefits patient care. The users must feel invested in the PTTS and its use must be supported by training to ensure that all healthcare workers, senior and junior, understand their role in using the system.


Conclusion
PTTSs can improve patient safety and quality of care. However, there is a need for a robust implementation strategy or the benefits of PTTSs will not be realized.",purpos identifi barrier facilit implement physiolog track trigger system pttss perceiv healthcar worker systemat review extant qualit literatur data sourc search perform pubm cinahl psycinfo embas web scienc refer list includ studi also screen studi select electron search yield paper remov duplic screen total paper determin meet inclus criteria review data extract deduct content analysi approach taken organ analys data framework consist two overarch dimens userrel chang requir implement pttss effect factor affect userrel chang theme staff percept pttss patient safeti workflow adjust ptt implement process local context sub theme use classifi barrier facilit implement pttss result data synthesi success implement ptt must address social context implement ensur user believ system effect benefit patient care user must feel invest ptt use must support train ensur healthcar worker senior junior understand role use system conclus pttss improv patient safeti qualiti care howev need robust implement strategi benefit pttss realiz
c2eb2c7166b34c5eb8daaf8209a1a235a00c53d6,The Data Revolution and Economic Analysis,"Many believe that “big data” will transform business, government, and other aspects of the economy. In this article we discuss how new data may impact economic policy and economic research. Large-scale administrative data sets and proprietary private sector data can greatly improve the way we measure, track, and describe economic activity. They can also enable novel research designs that allow researchers to trace the consequences of different events or policies. We outline some of the challenges in accessing and making use of these data. We also consider whether the big data predictive modeling tools that have emerged in statistics and computer science may prove useful in economics.",mani believ big data transform busi govern aspect economi articl discuss new data may impact econom polici econom research largescal administr data set proprietari privat sector data greatli improv way measur track describ econom activ also enabl novel research design allow research trace consequ differ event polici outlin challeng access make use data also consid whether big data predict model tool emerg statist comput scienc may prove use econom
17141fb5e4630ddf1e9fb20757f439ae79ffc3f3,The ESA Climate Change Initiative: Satellite Data Records for Essential Climate Variables,"Observations of Earth from space have been made for over 40 years and have contributed to advances in many aspects of climate science. However, attempts to exploit this wealth of data are often hampered by a lack of homogeneity and continuity and by insufficient understanding of the products and their uncertainties. There is, therefore, a need to reassess and reprocess satellite datasets to maximize their usefulness for climate science. The European Space Agency has responded to this need by establishing the Climate Change Initiative (CCI). The CCI will create new climate data records for (currently) 13 essential climate variables (ECVs) and make these open and easily accessible to all. Each ECV project works closely with users to produce time series from the available satellite observations relevant to users' needs. A climate modeling users' group provides a climate system perspective and a forum to bring the data and modeling communities together. This paper presents the CCI program. It outlines its benefit and presents approaches and challenges for each ECV project, covering clouds, aerosols, ozone, greenhouse gases, sea surface temperature, ocean color, sea level, sea ice, land cover, fire, glaciers, soil moisture, and ice sheets. It also discusses how the CCI approach may contribute to defining and shaping future developments in Earth observation for climate science.",observ earth space made year contribut advanc mani aspect climat scienc howev attempt exploit wealth data often hamper lack homogen continu insuffici understand product uncertainti therefor need reassess reprocess satellit dataset maxim use climat scienc european space agenc respond need establish climat chang initi cci cci creat new climat data record current essenti climat variabl ecv make open easili access ecv project work close user produc time seri avail satellit observ relev user need climat model user group provid climat system perspect forum bring data model commun togeth paper present cci program outlin benefit present approach challeng ecv project cover cloud aerosol ozon greenhous gase sea surfac temperatur ocean color sea level sea ice land cover fire glacier soil moistur ice sheet also discuss cci approach may contribut defin shape futur develop earth observ climat scienc
07993804501ae4df9fe43cf8afb009ae38fe902e,A Mathematical Introduction to Compressive Sensing,,nan
1faa856958fd22125dff44c40d5fd7ba92e7cb3b,Clustering by fast search and find of density peaks,"Discerning clusters of data points Cluster analysis is used in many disciplines to group objects according to a defined measure of distance. Numerous algorithms exist, some based on the analysis of the local density of data points, and others on predefined probability distributions. Rodriguez and Laio devised a method in which the cluster centers are recognized as local density maxima that are far away from any points of higher density. The algorithm depends only on the relative densities rather than their absolute values. The authors tested the method on a series of data sets, and its performance compared favorably to that of established techniques. Science, this issue p. 1492 Local density of points is ranked and analyzed to categorize data. Cluster analysis is aimed at classifying elements into categories on the basis of their similarity. Its applications range from astronomy to bioinformatics, bibliometrics, and pattern recognition. We propose an approach based on the idea that cluster centers are characterized by a higher density than their neighbors and by a relatively large distance from points with higher densities. This idea forms the basis of a clustering procedure in which the number of clusters arises intuitively, outliers are automatically spotted and excluded from the analysis, and clusters are recognized regardless of their shape and of the dimensionality of the space in which they are embedded. We demonstrate the power of the algorithm on several test cases.",discern cluster data point cluster analysi use mani disciplin group object accord defin measur distanc numer algorithm exist base analysi local densiti data point other predefin probabl distribut rodriguez laio devis method cluster center recogn local densiti maxima far away point higher densiti algorithm depend rel densiti rather absolut valu author test method seri data set perform compar favor establish techniqu scienc issu p local densiti point rank analyz categor data cluster analysi aim classifi element categori basi similar applic rang astronomi bioinformat bibliometr pattern recognit propos approach base idea cluster center character higher densiti neighbor rel larg distanc point higher densiti idea form basi cluster procedur number cluster aris intuit outlier automat spot exclud analysi cluster recogn regardless shape dimension space embed demonstr power algorithm sever test case
c0a9c78988f0b264e27844d38ecf606efe37805e,The practice of social research,"Part I: AN INTRODUCTION TO INQUIRY. 1. Human Inquiry and Science. 2. Paradigms, Theory, and Social Research. 3. The Ethics and Politics of Social Research. Part II: THE STRUCTURING OF INQUIRY: QUANTITATIVE AND QUALITATIVE. 4. Research Design. 5. Conceptualization, Operationalization, and Measurement. 6. Indexes, Scales, and Typologies. 7. The Logic of Sampling. Part III: MODES OF OPERATION: QUANTITATIVE AND QUALITATIVE. 8. Experiments. 9. Survey Research. 10. Qualitative Field Research. 11. Unobtrusive Research. 12. Evaluation Research. Part IV: ANALYSIS OF DATA: QUANTITATIVE AND QUALITATIVE. 13. Qualitative Data Analysis. 14. Quantitative Data Analysis. 15. The Logic of Multivariate Analysis. 16. Statistical Analyses. 17. Reading and Writing Social Research. APPENDICES. A. Using the Library. B. GSS Household Enumeration Questionnaire. C. Random Numbers. D. Distribution of Chi Square. E. Normal Curve Areas. F. Estimated Sampling Error. Preface. Acknowledgments.",part introduct inquiri human inquiri scienc paradigm theori social research ethic polit social research part ii structur inquiri quantit qualit research design conceptu operation measur index scale typolog logic sampl part iii mode oper quantit qualit experi survey research qualit field research unobtrus research evalu research part iv analysi data quantit qualit qualit data analysi quantit data analysi logic multivari analysi statist analys read write social research appendic use librari b gss household enumer questionnair c random number distribut chi squar e normal curv area f estim sampl error prefac acknowledg
cae155b295abd5b0ab02fb26351720c40e969907,The Structure of Scientific Revolutions,"A good book may have the power to change the way we see the world, but a great book actually becomes part of our daily consciousness, pervading our thinking to the point that we take it for granted, and we forget how provocative and challenging its ideas once were-and still are. ""The Structure of Scientific Revolutions"" is that kind of book. When it was first published in 1962, it was a landmark event in the history and philosophy of science. And fifty years later, it still has many lessons to teach. With ""The Structure of Scientific Revolutions"", Kuhn challenged long-standing linear notions of scientific progress, arguing that transformative ideas don't arise from the day-to-day, gradual process of experimentation and data accumulation, but that revolutions in science, those breakthrough moments that disrupt accepted thinking and offer unanticipated ideas, occur outside of ""normal science,"" as he called it. Though Kuhn was writing when physics ruled the sciences, his ideas on how scientific revolutions bring order to the anomalies that amass over time in research experiments are still instructive in our biotech age. This new edition of Kuhn's essential work in the history of science includes an insightful introductory essay by Ian Hacking that clarifies terms popularized by Kuhn, including paradigm and incommensurability, and applies Kuhn's ideas to the science of today. Usefully keyed to the separate sections of the book, Hacking's essay provides important background information as well as a contemporary context. Newly designed, with an expanded index, this edition will be eagerly welcomed by the next generation of readers seeking to understand the history of our perspectives on science.",good book may power chang way see world great book actual becom part daili conscious pervad think point take grant forget provoc challeng idea wereand still structur scientif revolut kind book first publish landmark event histori philosophi scienc fifti year later still mani lesson teach structur scientif revolut kuhn challeng longstand linear notion scientif progress argu transform idea dont aris daytoday gradual process experiment data accumul revolut scienc breakthrough moment disrupt accept think offer unanticip idea occur outsid normal scienc call though kuhn write physic rule scienc idea scientif revolut bring order anomali amass time research experi still instruct biotech age new edit kuhn essenti work histori scienc includ insight introductori essay ian hack clarifi term popular kuhn includ paradigm incommensur appli kuhn idea scienc today use key separ section book hack essay provid import background inform well contemporari context newli design expand index edit eagerli welcom next gener reader seek understand histori perspect scienc
f0a3e1752e1146da927adc24ae07144ab2e744ec,Nonlinear dimensionality reduction by locally linear embedding.,"Many areas of science depend on exploratory data analysis and visualization. The need to analyze large amounts of multivariate data raises the fundamental problem of dimensionality reduction: how to discover compact representations of high-dimensional data. Here, we introduce locally linear embedding (LLE), an unsupervised learning algorithm that computes low-dimensional, neighborhood-preserving embeddings of high-dimensional inputs. Unlike clustering methods for local dimensionality reduction, LLE maps its inputs into a single global coordinate system of lower dimensionality, and its optimizations do not involve local minima. By exploiting the local symmetries of linear reconstructions, LLE is able to learn the global structure of nonlinear manifolds, such as those generated by images of faces or documents of text.",mani area scienc depend exploratori data analysi visual need analyz larg amount multivari data rais fundament problem dimension reduct discov compact represent highdimension data introduc local linear embed lle unsupervis learn algorithm comput lowdimension neighborhoodpreserv embed highdimension input unlik cluster method local dimension reduct lle map input singl global coordin system lower dimension optim involv local minima exploit local symmetri linear reconstruct lle abl learn global structur nonlinear manifold gener imag face document text
d91557927a1571efc5a1599a9c0889d7f1bff7a2,Applied Logistic Regression: Hosmer/Applied Logistic Regression,"""A new edition of the definitive guide to logistic regression modeling for health science and other applicationsThis thoroughly expanded Third Edition provides an easily accessible introduction to the logistic regression (LR) model and highlights the power of this model by examining the relationship between a dichotomous outcome and a set of covariables. Applied Logistic Regression, Third Edition emphasizes applications in the health sciences and handpicks topics that best suit the use of modern statistical software. The book provides readers with state-of-the-art techniques for building, interpreting, and assessing the performance of LR models. New and updated features include: A chapter on the analysis of correlated outcome data. A wealth of additional material for topics ranging from Bayesian methods to assessing model fit Rich data sets from real-world studies that demonstrate each method under discussion. Detailed examples and interpretation of the presented results as well as exercises throughout Applied Logistic Regression, Third Edition is a must-have guide for professionals and researchers who need to model nominal or ordinal scaled outcome variables in public health, medicine, and the social sciences as well as a wide range of other fields and disciplines""--",new edit definit guid logist regress model health scienc applicationsthi thoroughli expand third edit provid easili access introduct logist regress lr model highlight power model examin relationship dichotom outcom set covari appli logist regress third edit emphas applic health scienc handpick topic best suit use modern statist softwar book provid reader stateoftheart techniqu build interpret assess perform lr model new updat featur includ chapter analysi correl outcom data wealth addit materi topic rang bayesian method assess model fit rich data set realworld studi demonstr method discuss detail exampl interpret present result well exercis throughout appli logist regress third edit musthav guid profession research need model nomin ordin scale outcom variabl public health medicin social scienc well wide rang field disciplin
59bb17b27d7220e930ee6bebe1f94cf43ad42c2d,Model selection and multimodel inference : a practical information-theoretic approach,"The second edition of this book is unique in that it focuses on methods for making formal statistical inference from all the models in an a priori set (Multi-Model Inference). A philosophy is presented for model-based data analysis and a general strategy outlined for the analysis of empirical data. The book invites increased attention on a priori science hypotheses and modeling. Kullback-Leibler Information represents a fundamental quantity in science and is Hirotugu Akaike's basis for model selection. The maximized log-likelihood function can be bias-corrected as an estimator of expected, relative Kullback-Leibler information. This leads to Akaike's Information Criterion (AIC) and various extensions. These methods are relatively simple and easy to use in practice, but based on deep statistical theory. The information theoretic approaches provide a unified and rigorous theory, an extension of likelihood theory, an important application of information theory, and are objective and practical to employ across a very wide class of empirical problems. The book presents several new ways to incorporate model selection uncertainty into parameter estimates and estimates of precision. An array of challenging examples is given to illustrate various technical issues. This is an applied book written primarily for biologists and statisticians wanting to make inferences from multiple models and is suitable as a graduate text or as a reference for professional analysts.",second edit book uniqu focus method make formal statist infer model priori set multimodel infer philosophi present modelbas data analysi gener strategi outlin analysi empir data book invit increas attent priori scienc hypothes model kullbackleibl inform repres fundament quantiti scienc hirotugu akaik basi model select maxim loglikelihood function biascorrect estim expect rel kullbackleibl inform lead akaik inform criterion aic variou extens method rel simpl easi use practic base deep statist theori inform theoret approach provid unifi rigor theori extens likelihood theori import applic inform theori object practic employ across wide class empir problem book present sever new way incorpor model select uncertainti paramet estim estim precis array challeng exampl given illustr variou technic issu appli book written primarili biologist statistician want make infer multipl model suitabl graduat text refer profession analyst
f816c7407ee34eab3d40d87e286ff8e1608d3d19,KONECT: the Koblenz network collection,"We present the Koblenz Network Collection (KONECT), a project to collect network datasets in the areas of web science, network science and related areas, as well as provide tools for their analysis. In the cited areas, a surprisingly large number of very heterogeneous data can be modeled as networks and consequently, a unified representation of networks can be used to gain insight into many kinds of problems. Due to the emergence of the World Wide Web in the last decades many such datasets are now openly available. The KONECT project thus has the goal of collecting many diverse network datasets from the Web, and providing a way for their systematic study. The main parts of KONECT are (1) a collection of over 160 network datasets, consisting of directed, undirected, unipartite, bipartite, weighted, unweighted, signed and temporal networks collected from the Web, (2) a Matlab toolbox for network analysis and (3) a website giving a compact overview the various computed statistics and plots. In this paper, we describe KONECT's taxonomy of networks datasets, give an overview of the datasets included, review the supported statistics and plots, and briefly discuss KONECT's role in the area of web science and network science.",present koblenz network collect konect project collect network dataset area web scienc network scienc relat area well provid tool analysi cite area surprisingli larg number heterogen data model network consequ unifi represent network use gain insight mani kind problem due emerg world wide web last decad mani dataset openli avail konect project thu goal collect mani divers network dataset web provid way systemat studi main part konect collect network dataset consist direct undirect unipartit bipartit weight unweight sign tempor network collect web matlab toolbox network analysi websit give compact overview variou comput statist plot paper describ konect taxonomi network dataset give overview dataset includ review support statist plot briefli discuss konect role area web scienc network scienc
1eef1bbb11ca40e374216c918a7cf59e0d5ad299,Landolt-Bornstein: Numerical Data and Functional Relationships in Science and Technology,This book provides an up-to-date review of nanometer-scale magnetism and focuses on the investigation of the basic properties of magnetic nanostructures. It describes a wide range of physical aspects together with theoretical and experimental methods. A broad overview of the latest developments in this emerging and fascinating field of nanostructured materials is given with emphasis on the practical understanding and operation of submicron devices based on nanostructured magnetic materials.,book provid uptod review nanometerscal magnet focus investig basic properti magnet nanostructur describ wide rang physic aspect togeth theoret experiment method broad overview latest develop emerg fascin field nanostructur materi given emphasi practic understand oper submicron devic base nanostructur magnet materi
8d7f03c75bdb21d9a981cde8ae6a8359be2a67f8,Reproducing GW150914: The First Observation of Gravitational Waves From a Binary Black Hole Merger,"In 2016, LIGO and Virgo announced the first observation of gravitational waves from a binary black hole merger, known as GW150914. To establish the confidence of this detection, large-scale scientific workflows were used to measure the event’s statistical significance. They used code written by the LIGO/Virgo and were executed on the LIGO Data Grid. The codes are publicly available, but there has not yet been an attempt to directly reproduce the results, although several analyses have replicated the analysis, confirming the detection. We attempt to reproduce the result presented in the GW150914 discovery paper using publicly available code on the Open Science Grid. We show that we can reproduce the main result but we cannot exactly reproduce the LIGO analysis as the original dataset used is not public. We discuss the challenges we encountered and make recommendations for scientists who wish to make their work reproducible.",ligo virgo announc first observ gravit wave binari black hole merger known gw establish confid detect largescal scientif workflow use measur event statist signific use code written ligovirgo execut ligo data grid code publicli avail yet attempt directli reproduc result although sever analys replic analysi confirm detect attempt reproduc result present gw discoveri paper use publicli avail code open scienc grid show reproduc main result cannot exactli reproduc ligo analysi origin dataset use public discuss challeng encount make recommend scientist wish make work reproduc
f825b113bbb88ab40253169fc3480e13109348ec,The effect of human mobility and control measures on the COVID-19 epidemic in China,"Tracing infection from mobility data What sort of measures are required to contain the spread of severe acute respiratory syndrome–coronavirus 2 (SARS-CoV-2), which causes coronavirus disease 2019 (COVID-19)? The rich data from the Open COVID-19 Data Working Group include the dates when people first reported symptoms, not just a positive test date. Using these data and real-time travel data from the internet services company Baidu, Kraemer et al. found that mobility statistics offered a precise record of the spread of SARS-CoV-2 among the cities of China at the start of 2020. The frequency of introductions from Wuhan were predictive of the size of the epidemic sparked in other provinces. However, once the virus had escaped Wuhan, strict local control measures such as social isolation and hygiene, rather than long-distance travel restrictions, played the largest part in controlling SARS-CoV-2 spread. Science, this issue p. 493 Mobile phone data show that the spread of COVID-19 in China was driven by travel and mitigated substantially by local control measures. The ongoing coronavirus disease 2019 (COVID-19) outbreak expanded rapidly throughout China. Major behavioral, clinical, and state interventions were undertaken to mitigate the epidemic and prevent the persistence of the virus in human populations in China and worldwide. It remains unclear how these unprecedented interventions, including travel restrictions, affected COVID-19 spread in China. We used real-time mobility data from Wuhan and detailed case data including travel history to elucidate the role of case importation in transmission in cities across China and to ascertain the impact of control measures. Early on, the spatial distribution of COVID-19 cases in China was explained well by human mobility data. After the implementation of control measures, this correlation dropped and growth rates became negative in most locations, although shifts in the demographics of reported cases were still indicative of local chains of transmission outside of Wuhan. This study shows that the drastic control measures implemented in China substantially mitigated the spread of COVID-19.",trace infect mobil data sort measur requir contain spread sever acut respiratori syndromecoronaviru sarscov caus coronaviru diseas covid rich data open covid data work group includ date peopl first report symptom posit test date use data realtim travel data internet servic compani baidu kraemer et al found mobil statist offer precis record spread sarscov among citi china start frequenc introduct wuhan predict size epidem spark provinc howev viru escap wuhan strict local control measur social isol hygien rather longdist travel restrict play largest part control sarscov spread scienc issu p mobil phone data show spread covid china driven travel mitig substanti local control measur ongo coronaviru diseas covid outbreak expand rapidli throughout china major behavior clinic state intervent undertaken mitig epidem prevent persist viru human popul china worldwid remain unclear unpreced intervent includ travel restrict affect covid spread china use realtim mobil data wuhan detail case data includ travel histori elucid role case import transmiss citi across china ascertain impact control measur earli spatial distribut covid case china explain well human mobil data implement control measur correl drop growth rate becam neg locat although shift demograph report case still indic local chain transmiss outsid wuhan studi show drastic control measur implement china substanti mitig spread covid
da692ee969d9c33986196372c3f7cb87fa6b6f8f,Database resources of the National Center for Biotechnology Information,"Abstract The National Center for Biotechnology Information (NCBI) provides a large suite of online resources for biological information and data, including the GenBank® nucleic acid sequence database and the PubMed database of citations and abstracts for published life science journals. The Entrez system provides search and retrieval operations for most of these data from 39 distinct databases. The E-utilities serve as the programming interface for the Entrez system. Augmenting many of the Web applications are custom implementations of the BLAST program optimized to search specialized data sets. New resources released in the past year include PubMed Data Management, RefSeq Functional Elements, genome data download, variation services API, Magic-BLAST, QuickBLASTp, and Identical Protein Groups. Resources that were updated in the past year include the genome data viewer, a human genome resources page, Gene, virus variation, OSIRIS, and PubChem. All of these resources can be accessed through the NCBI home page at www.ncbi.nlm.nih.gov.",abstract nation center biotechnolog inform ncbi provid larg suit onlin resourc biolog inform data includ genbank nucleic acid sequenc databas pubm databas citat abstract publish life scienc journal entrez system provid search retriev oper data distinct databas eutil serv program interfac entrez system augment mani web applic custom implement blast program optim search special data set new resourc releas past year includ pubm data manag refseq function element genom data download variat servic api magicblast quickblastp ident protein group resourc updat past year includ genom data viewer human genom resourc page gene viru variat osiri pubchem resourc access ncbi home page wwwncbinlmnihgov
3efd851140aa28e95221b55fcc5659eea97b172d,The Graph Neural Network Model,"Many underlying relationships among data in several areas of science and engineering, e.g., computer vision, molecular chemistry, molecular biology, pattern recognition, and data mining, can be represented in terms of graphs. In this paper, we propose a new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains. This GNN model, which can directly process most of the practically useful types of graphs, e.g., acyclic, cyclic, directed, and undirected, implements a function tau(G,n) isin IRm that maps a graph G and one of its nodes n into an m-dimensional Euclidean space. A supervised learning algorithm is derived to estimate the parameters of the proposed GNN model. The computational cost of the proposed algorithm is also considered. Some experimental results are shown to validate the proposed learning algorithm, and to demonstrate its generalization capabilities.",mani underli relationship among data sever area scienc engin eg comput vision molecular chemistri molecular biolog pattern recognit data mine repres term graph paper propos new neural network model call graph neural network gnn model extend exist neural network method process data repres graph domain gnn model directli process practic use type graph eg acycl cyclic direct undirect implement function taugn isin irm map graph g one node n mdimension euclidean space supervis learn algorithm deriv estim paramet propos gnn model comput cost propos algorithm also consid experiment result shown valid propos learn algorithm demonstr gener capabl
3a24b6a70aa8c88192cb4b584bd5cd0ec631c0ca,Heart Disease and Stroke Statistics—2015 Update: A Report From the American Heart Association,"STRIDE (Stanford Translational Research Integrated Database Environment) is a research and development project at Stanford University to create a standards-based informatics platform supporting clinical and translational research. STRIDE consists of three integrated components: a clinical data warehouse, based on the HL7 Reference Information Model (RIM), containing clinical information on over 1.3 million pediatric and adult patients cared for at Stanford University Medical Center since 1995; an application development framework for building research data management applications on the STRIDE platform and a biospecimen data management system. STRIDE’s semantic model uses standardized terminologies, such as SNOMED, RxNorm, ICD and CPT, to represent important biomedical concepts and their relationships. The system is in daily use at Stanford and is an important component of Stanford University’s CTSA (Clinical and Translational Science Award) Informatics Program.",stride stanford translat research integr databas environ research develop project stanford univers creat standardsbas informat platform support clinic translat research stride consist three integr compon clinic data warehous base hl refer inform model rim contain clinic inform million pediatr adult patient care stanford univers medic center sinc applic develop framework build research data manag applic stride platform biospecimen data manag system stride semant model use standard terminolog snome rxnorm icd cpt repres import biomed concept relationship system daili use stanford import compon stanford univers ctsa clinic translat scienc award informat program
f04ae817e8a38f29188b47bc71d15213739eb6fb,The Solar Dynamics Observatory (SDO),,nan
136afcc7e8d0bb5c6b3dd68dcc0117c746c37d02,Qualitative Case Study Methodology: Study Design and Implementation for Novice Researchers,"Qualitative case study methodology provides tools for researchers to study complex phenomena within their contexts. When the approach is applied correctly, it becomes a valuable method for health science research to develop theory, evaluate programs, and develop interventions. The purpose of this paper is to guide the novice researcher in identifying the key elements for designing and implementing qualitative case study research projects. An overview of the types of case study designs is provided along with general recommendations for writing the research questions, developing propositions, determining the “case” under study, binding the case and a discussion of data sources and triangulation. To facilitate application of these principles, clear examples of research questions, study propositions and the different types of case study designs",qualit case studi methodolog provid tool research studi complex phenomena within context approach appli correctli becom valuabl method health scienc research develop theori evalu program develop intervent purpos paper guid novic research identifi key element design implement qualit case studi research project overview type case studi design provid along gener recommend write research question develop proposit determin case studi bind case discuss data sourc triangul facilit applic principl clear exampl research question studi proposit differ type case studi design
530cc7107d1043481d365af526720e93f5a27583,Citizens as sensors: the world of volunteered geography,,nan
fe096d8153c5a1f548b8016fff0a5fc650149329,The Protein Data Bank archive as an open data resource,,nan
1cf4a6954b419b5478c96119fc1e79aa90f87dea,The Cambridge Structural Database in retrospect and prospect.,"The Cambridge Crystallographic Data Centre (CCDC) was established in 1965 to record numerical, chemical and bibliographic data relating to published organic and metal-organic crystal structures. The Cambridge Structural Database (CSD) now stores data for nearly 700,000 structures and is a comprehensive and fully retrospective historical archive of small-molecule crystallography. Nearly 40,000 new structures are added each year. As X-ray crystallography celebrates its centenary as a subject, and the CCDC approaches its own 50th year, this article traces the origins of the CCDC as a publicly funded organization and its onward development into a self-financing charitable institution. Principally, however, we describe the growth of the CSD and its extensive associated software system, and summarize its impact and value as a basis for research in structural chemistry, materials science and the life sciences, including drug discovery and drug development. Finally, the article considers the CCDC's funding model in relation to open access and open data paradigms.",cambridg crystallograph data centr ccdc establish record numer chemic bibliograph data relat publish organ metalorgan crystal structur cambridg structur databas csd store data nearli structur comprehens fulli retrospect histor archiv smallmolecul crystallographi nearli new structur ad year xray crystallographi celebr centenari subject ccdc approach th year articl trace origin ccdc publicli fund organ onward develop selffinanc charit institut princip howev describ growth csd extens associ softwar system summar impact valu basi research structur chemistri materi scienc life scienc includ drug discoveri drug develop final articl consid ccdc fund model relat open access open data paradigm
0a97187e6a7e4064c05957103c3006b2bec80bf6,The Oswestry Disability Index.,"STUDY DESIGN
The Oswestry Disability Index (ODI) has become one of the principal condition-specific outcome measures used in the management of spinal disorders. This review is based on publications using the ODI identified from the authors' personal databases, the Science Citation Index, and hand searches of Spine and current textbooks of spinal disorders.


OBJECTIVES
To review the versions of this instrument, document methods by which it has been validated, collate data from scores found in normal and back pain populations, provide curves for power calculations in studies using the ODI, and maintain the ODI as a gold standard outcome measure.


SUMMARY OF BACKGROUND DATA
It has now been 20 years since its original publication. More than 200 citations exist in the Science Citation Index. The authors have a large correspondence file relating to the ODI, that is cited in most of the large textbooks related to spinal disorders.


METHODS
All the published versions of the questionnaire were identified. A systematic review of this literature was made. The various reports of validation were collated and related to a version.


RESULTS
Four versions of the ODI are available in English and nine in other languages. Some published versions contain misprints, and many omit the scoring system. At least 114 studies contain usable data. These data provide both validation and standards for other users and indicate the power of the instrument for detecting change in sample populations.


CONCLUSIONS
The ODI remains a valid and vigorous measure and has been a worthwhile outcome measure. The process of using the ODI is reviewed and should be the subject of further research. The receiver operating characteristics should be explored in a population with higher self-report disabilities. The behavior of the instrument is incompletely understood, particularly in sensitivity to real change.",studi design oswestri disabl index odi becom one princip conditionspecif outcom measur use manag spinal disord review base public use odi identifi author person databas scienc citat index hand search spine current textbook spinal disord object review version instrument document method valid collat data score found normal back pain popul provid curv power calcul studi use odi maintain odi gold standard outcom measur summari background data year sinc origin public citat exist scienc citat index author larg correspond file relat odi cite larg textbook relat spinal disord method publish version questionnair identifi systemat review literatur made variou report valid collat relat version result four version odi avail english nine languag publish version contain misprint mani omit score system least studi contain usabl data data provid valid standard user indic power instrument detect chang sampl popul conclus odi remain valid vigor measur worthwhil outcom measur process use odi review subject research receiv oper characterist explor popul higher selfreport disabl behavior instrument incomplet understood particularli sensit real chang
5f3d1106094be3017046d7953c2a71e7f4559124,Systematic Reviews in the Social Sciences: A Practical Guide,"Such diverse thinkers as Lao-Tze, Confucius, and U.S. Defense Secretary Donald Rumsfeld have all pointed out that we need to be able to tell the difference between real and assumed knowledge. The systematic review is a scientific tool that can help with this difficult task. It can help, for example, with appraising, summarising, and communicating the results and implications of otherwise unmanageable quantities of data. This is important because quite often there are so many studies, and their results are often so conflicting, that no policymaker or practitioner could possibly carry out this task themselves.Systematic review methods have been widely used in health care, and are becoming increasingly common in the social sciences (fostered, for example, by the work of the Campbell Collaboration). 
 
This book outlines the rationale and methods of systematic reviews, giving worked examples from social science and other fields. It requires no previous knowledge, but takes the reader through the process stage by stage. It draws on examples from such diverse fields as psychology, criminology, education, transport, social welfare, public health, and housing and urban policy, among others.The book includes detailed sections on assessing the quality of both quantitative, and qualitative research; searching for evidence in the social sciences;meta-analytic and other methods of evidence synthesis; publication bias; heterogeneity; and approaches to dissemination.",divers thinker laotz confuciu us defens secretari donald rumsfeld point need abl tell differ real assum knowledg systemat review scientif tool help difficult task help exampl apprais summaris commun result implic otherwis unmanag quantiti data import quit often mani studi result often conflict policymak practition could possibl carri task themselvessystemat review method wide use health care becom increasingli common social scienc foster exampl work campbel collabor book outlin rational method systemat review give work exampl social scienc field requir previou knowledg take reader process stage stage draw exampl divers field psycholog criminolog educ transport social welfar public health hous urban polici among othersth book includ detail section assess qualiti quantit qualit research search evid social sciencesmetaanalyt method evid synthesi public bia heterogen approach dissemin
d56c1e5d37f9e71bb1b6a08e0661ebb51a9ec9ab,Narrative Inquiry: Experience and Story in Qualitative Research,"'The literature on narrative inquiry has been, until now, widely scattered and theoretically incomplete. Clandinin and Connelly have created a major tour de force. This book is lucid, fluid, beautifully argued, and rich in examples. Students will find a wealth of arguments to support their research, and teaching faculty will find everything they need to teach narrative inquiry theory and methods' - Yvonna S. Lincoln, professor, Department of Educational Administration, Texas A&M University.Understanding experience as lived and told stories - also known as narrative inquiry - has gained popularity and credence in qualitative research. Unlike more traditional methods, narrative inquiry successfully captures personal and human dimensions that cannot be quantified into dry facts and numerical data. In this definitive guide, Jean Clandinin and Michael Connelly draw from more than twenty years of field experience to show how narrative inquiry can be used in educational and social science research. Tracing the origins of narrative inquiry in the social sciences, they offer new and practical ideas for conducting fieldwork, composing field notes, and conveying research results. Throughout the book, stories and examples reveal a wide range of narrative methods. Engaging and easy to read, ""Narrative Inquiry"" is a practical resource from experts who have long pioneered the use of narrative in qualitative research.",literatur narr inquiri wide scatter theoret incomplet clandinin connelli creat major tour de forc book lucid fluid beauti argu rich exampl student find wealth argument support research teach faculti find everyth need teach narr inquiri theori method yvonna lincoln professor depart educ administr texa universityunderstand experi live told stori also known narr inquiri gain popular credenc qualit research unlik tradit method narr inquiri success captur person human dimens cannot quantifi dri fact numer data definit guid jean clandinin michael connelli draw twenti year field experi show narr inquiri use educ social scienc research trace origin narr inquiri social scienc offer new practic idea conduct fieldwork compos field note convey research result throughout book stori exampl reveal wide rang narr method engag easi read narr inquiri practic resourc expert long pioneer use narr qualit research
c4e2a160c5a4c0de3036935e95cb266d00546762,"Applied Logistic Regression, Second Edition","""A new edition of the definitive guide to logistic regression modeling for health science and other applicationsThis thoroughly expanded Third Edition provides an easily accessible introduction to the logistic regression (LR) model and highlights the power of this model by examining the relationship between a dichotomous outcome and a set of covariables. Applied Logistic Regression, Third Edition emphasizes applications in the health sciences and handpicks topics that best suit the use of modern statistical software. The book provides readers with state-of-the-art techniques for building, interpreting, and assessing the performance of LR models. New and updated features include: A chapter on the analysis of correlated outcome data. A wealth of additional material for topics ranging from Bayesian methods to assessing model fit Rich data sets from real-world studies that demonstrate each method under discussion. Detailed examples and interpretation of the presented results as well as exercises throughout Applied Logistic Regression, Third Edition is a must-have guide for professionals and researchers who need to model nominal or ordinal scaled outcome variables in public health, medicine, and the social sciences as well as a wide range of other fields and disciplines""--",new edit definit guid logist regress model health scienc applicationsthi thoroughli expand third edit provid easili access introduct logist regress lr model highlight power model examin relationship dichotom outcom set covari appli logist regress third edit emphas applic health scienc handpick topic best suit use modern statist softwar book provid reader stateoftheart techniqu build interpret assess perform lr model new updat featur includ chapter analysi correl outcom data wealth addit materi topic rang bayesian method assess model fit rich data set realworld studi demonstr method discuss detail exampl interpret present result well exercis throughout appli logist regress third edit musthav guid profession research need model nomin ordin scale outcom variabl public health medicin social scienc well wide rang field disciplin
10a463bb00b44bdd3a8620f2bedb9e1564bfcf32,The Design and Analysis of Computer Algorithms,"From the Publisher: 
With this text, you gain an understanding of the fundamental concepts of algorithms, the very heart of computer science. It introduces the basic data structures and programming techniques often used in efficient algorithms. Covers use of lists, push-down stacks, queues, trees, and graphs. Later chapters go into sorting, searching and graphing algorithms, the string-matching algorithms, and the Schonhage-Strassen integer-multiplication algorithm. Provides numerous graded exercises at the end of each chapter. 
 
 
0201000296B04062001",publish text gain understand fundament concept algorithm heart comput scienc introduc basic data structur program techniqu often use effici algorithm cover use list pushdown stack queue tree graph later chapter go sort search graph algorithm stringmatch algorithm schonhagestrassen integermultipl algorithm provid numer grade exercis end chapter b
6da5d24defba21364de4842d65666118e46edf12,A New Product Growth for Model Consumer Durables,"(This article originally appeared in Management Science, January 1969, Volume 15, Number 5, pp. 215-227, published by The Institute of Management Sciences.) 
 
A growth model for the timing of initial purchase of new products is developed and tested empirically against data for eleven consumer durables. The basic assumption of the model is that the timing of a consumer's initial purchase is related to the number of previous buyers. A behavioral rationale for the model is offered in terms of innovative and imitative behavior. The model yields good predictions of the sales peak and the timing of the peak when applied to historical data. A long-range forecast is developed for the sales of color television sets.",articl origin appear manag scienc januari volum number pp publish institut manag scienc growth model time initi purchas new product develop test empir data eleven consum durabl basic assumpt model time consum initi purchas relat number previou buyer behavior rational model offer term innov imit behavior model yield good predict sale peak time peak appli histor data longrang forecast develop sale color televis set
944eb4fc8737f5dbe72f4a73f9db58418eec2758,The structure of scientific collaboration networks.,"The structure of scientific collaboration networks is investigated. Two scientists are considered connected if they have authored a paper together and explicit networks of such connections are constructed by using data drawn from a number of databases, including MEDLINE (biomedical research), the Los Alamos e-Print Archive (physics), and NCSTRL (computer science). I show that these collaboration networks form ""small worlds,"" in which randomly chosen pairs of scientists are typically separated by only a short path of intermediate acquaintances. I further give results for mean and distribution of numbers of collaborators of authors, demonstrate the presence of clustering in the networks, and highlight a number of apparent differences in the patterns of collaboration between the fields studied.",structur scientif collabor network investig two scientist consid connect author paper togeth explicit network connect construct use data drawn number databas includ medlin biomed research lo alamo eprint archiv physic ncstrl comput scienc show collabor network form small world randomli chosen pair scientist typic separ short path intermedi acquaint give result mean distribut number collabor author demonstr presenc cluster network highlight number appar differ pattern collabor field studi
85a8a97f614b2b6823e035bcc9abcb0f3d27be4d,An Introduction to the Bootstrap,"Statistics is the science of learning from experience, especially experience that arrives a little bit at a time. The earliest information 
science was statistics, originating in about 1650. This century has 
seen statistical techniques become the analytic methods of choice 
in biomedical science, psychology, education, economics, communications theory, sociology, genetic studies, epidemiology, and other 
areas. Recently, traditional sciences like geology, physics, and astronomy have begun to make increasing use of statistical methods 
as they focus on areas that demand informational efficiency, such as 
the study of rare and exotic particles or extremely distant galaxies. 
Most people are not natural-born statisticians. Left to our own 
devices we are not very good at picking out patterns from a sea 
of noisy data. To put it another way, we are all too good at picking out non-existent patterns that happen to suit our purposes. 
Statistical theory attacks the problem from both ends. It provides 
optimal methods for finding a real signal in a noisy background, 
and also provides strict checks against the overinterpretation of 
random patterns.",statist scienc learn experi especi experi arriv littl bit time earliest inform scienc statist origin centuri seen statist techniqu becom analyt method choic biomed scienc psycholog educ econom commun theori sociolog genet studi epidemiolog area recent tradit scienc like geolog physic astronomi begun make increas use statist method focu area demand inform effici studi rare exot particl extrem distant galaxi peopl naturalborn statistician left devic good pick pattern sea noisi data put anoth way good pick nonexist pattern happen suit purpos statist theori attack problem end provid optim method find real signal noisi background also provid strict check overinterpret random pattern
ccaf829bffd0b1a55a67a6958dcfb7af4cd16641,Formal Concept Analysis: Mathematical Foundations,"From the Publisher: 
This is the first textbook on formal concept analysis. It gives a systematic presentation of the mathematical foundations and their relation to applications in computer science, especially in data analysis and knowledge processing. Above all, it presents graphical methods for representing conceptual systems that have proved themselves in communicating knowledge. Theory and graphical representation are thus closely coupled together. The mathematical foundations are treated thoroughly and illuminated by means of numerous examples.",publish first textbook formal concept analysi give systemat present mathemat foundat relat applic comput scienc especi data analysi knowledg process present graphic method repres conceptu system prove commun knowledg theori graphic represent thu close coupl togeth mathemat foundat treat thoroughli illumin mean numer exampl
f338304435183c446671010b4e87fc505fba0ae7,Clickstream Data Yields High-Resolution Maps of Science,"Background Intricate maps of science have been created from citation data to visualize the structure of scientific activity. However, most scientific publications are now accessed online. Scholarly web portals record detailed log data at a scale that exceeds the number of all existing citations combined. Such log data is recorded immediately upon publication and keeps track of the sequences of user requests (clickstreams) that are issued by a variety of users across many different domains. Given these advantages of log datasets over citation data, we investigate whether they can produce high-resolution, more current maps of science. Methodology Over the course of 2007 and 2008, we collected nearly 1 billion user interactions recorded by the scholarly web portals of some of the most significant publishers, aggregators and institutional consortia. The resulting reference data set covers a significant part of world-wide use of scholarly web portals in 2006, and provides a balanced coverage of the humanities, social sciences, and natural sciences. A journal clickstream model, i.e. a first-order Markov chain, was extracted from the sequences of user interactions in the logs. The clickstream model was validated by comparing it to the Getty Research Institute's Architecture and Art Thesaurus. The resulting model was visualized as a journal network that outlines the relationships between various scientific domains and clarifies the connection of the social sciences and humanities to the natural sciences. Conclusions Maps of science resulting from large-scale clickstream data provide a detailed, contemporary view of scientific activity and correct the underrepresentation of the social sciences and humanities that is commonly found in citation data.",background intric map scienc creat citat data visual structur scientif activ howev scientif public access onlin scholarli web portal record detail log data scale exce number exist citat combin log data record immedi upon public keep track sequenc user request clickstream issu varieti user across mani differ domain given advantag log dataset citat data investig whether produc highresolut current map scienc methodolog cours collect nearli billion user interact record scholarli web portal signific publish aggreg institut consortia result refer data set cover signific part worldwid use scholarli web portal provid balanc coverag human social scienc natur scienc journal clickstream model ie firstord markov chain extract sequenc user interact log clickstream model valid compar getti research institut architectur art thesauru result model visual journal network outlin relationship variou scientif domain clarifi connect social scienc human natur scienc conclus map scienc result largescal clickstream data provid detail contemporari view scientif activ correct underrepresent social scienc human commonli found citat data
08b43d84e6747e370ef307e2ada50675b414514a,Survey of clustering algorithms,"Data analysis plays an indispensable role for understanding various phenomena. Cluster analysis, primitive exploration with little or no prior knowledge, consists of research developed across a wide variety of communities. The diversity, on one hand, equips us with many tools. On the other hand, the profusion of options causes confusion. We survey clustering algorithms for data sets appearing in statistics, computer science, and machine learning, and illustrate their applications in some benchmark data sets, the traveling salesman problem, and bioinformatics, a new field attracting intensive efforts. Several tightly related topics, proximity measure, and cluster validation, are also discussed.",data analysi play indispens role understand variou phenomena cluster analysi primit explor littl prior knowledg consist research develop across wide varieti commun divers one hand equip us mani tool hand profus option caus confus survey cluster algorithm data set appear statist comput scienc machin learn illustr applic benchmark data set travel salesman problem bioinformat new field attract intens effort sever tightli relat topic proxim measur cluster valid also discuss
444f7e9532a3985ecde11a1e253f717147c18dec,Status quo bias in decision making,,nan
7e4e5065f64fffe868640f05a9e7ed296cda4e0f,Social Vulnerability to Environmental Hazards,"County-level socioeconomic and demographic data were used to construct an index of social vulnerability to environmental hazards, called the Social Vulnerability Index (SoVI) for the United States based on 1990 data. Copyright (c) 2003 by the Southwestern Social Science Association.",countylevel socioeconom demograph data use construct index social vulner environment hazard call social vulner index sovi unit state base data copyright c southwestern social scienc associ
1996013872df1d43bca8c693786c3853e99aa9ff,"Research Design, Falsification, and the Qualitative–Quantitative Divide","R eceiving five serious reviews in this symposium is gratifying and confirms our belief that research design should be a priority for our discipline. We are pleased that our five distinguished reviewers appear to agree with our unified approach to the logic of inference in the social sciences, and with our fundamental point: that good quantitative and good qualitative research designs are based fundamentally on the same logic of inference. The reviewers also raised virtually no objections to the main practical contribution of our book-our many specific procedures for avoiding bias, getting the most out of qualitative data, and making reliable inferences. However, the reviews make clear that although our book may be the latest word on research design in political science, it is surely not the last. We are taxed for failing to include important issues in our analysis and for dealing inadequately with some of what we included. Before responding to the reviewers' most direct criticisms, let us explain what we emphasize in Designing Social Inquiry and how it relates to some of the points raised by the reviewers.",r eceiv five seriou review symposium gratifi confirm belief research design prioriti disciplin pleas five distinguish review appear agre unifi approach logic infer social scienc fundament point good quantit good qualit research design base fundament logic infer review also rais virtual object main practic contribut bookour mani specif procedur avoid bia get qualit data make reliabl infer howev review make clear although book may latest word research design polit scienc sure last tax fail includ import issu analysi deal inadequ includ respond review direct critic let us explain emphas design social inquiri relat point rais review
ef07defaf08123d5e1a8bd41ad6e2db5e5b225e3,The spread of true and false news online,"Lies spread faster than the truth There is worldwide concern over false news and the possibility that it can influence political, economic, and social well-being. To understand how false news spreads, Vosoughi et al. used a data set of rumor cascades on Twitter from 2006 to 2017. About 126,000 rumors were spread by ∼3 million people. False news reached more people than the truth; the top 1% of false news cascades diffused to between 1000 and 100,000 people, whereas the truth rarely diffused to more than 1000 people. Falsehood also diffused faster than the truth. The degree of novelty and the emotional reactions of recipients may be responsible for the differences observed. Science, this issue p. 1146 A large-scale analysis of tweets reveals that false rumors spread further and faster than the truth. We investigated the differential diffusion of all of the verified true and false news stories distributed on Twitter from 2006 to 2017. The data comprise ~126,000 stories tweeted by ~3 million people more than 4.5 million times. We classified news as true or false using information from six independent fact-checking organizations that exhibited 95 to 98% agreement on the classifications. Falsehood diffused significantly farther, faster, deeper, and more broadly than the truth in all categories of information, and the effects were more pronounced for false political news than for false news about terrorism, natural disasters, science, urban legends, or financial information. We found that false news was more novel than true news, which suggests that people were more likely to share novel information. Whereas false stories inspired fear, disgust, and surprise in replies, true stories inspired anticipation, sadness, joy, and trust. Contrary to conventional wisdom, robots accelerated the spread of true and false news at the same rate, implying that false news spreads more than the truth because humans, not robots, are more likely to spread it.",lie spread faster truth worldwid concern fals news possibl influenc polit econom social wellb understand fals news spread vosoughi et al use data set rumor cascad twitter rumor spread million peopl fals news reach peopl truth top fals news cascad diffus peopl wherea truth rare diffus peopl falsehood also diffus faster truth degre novelti emot reaction recipi may respons differ observ scienc issu p largescal analysi tweet reveal fals rumor spread faster truth investig differenti diffus verifi true fals news stori distribut twitter data compris stori tweet million peopl million time classifi news true fals use inform six independ factcheck organ exhibit agreement classif falsehood diffus significantli farther faster deeper broadli truth categori inform effect pronounc fals polit news fals news terror natur disast scienc urban legend financi inform found fals news novel true news suggest peopl like share novel inform wherea fals stori inspir fear disgust surpris repli true stori inspir anticip sad joy trust contrari convent wisdom robot acceler spread true fals news rate impli fals news spread truth human robot like spread
b9bb6963c8291a9a3b697d30d8e8979c25c51f02,Classical and modern regression with applications,"The author emphasizes applications with examples that illustrate nearly all the techniques discussed. Applications have been selected from physical sciences, engineering, biology, management science and economics. Emphasis is also placed on concepts with a blend between illustrations using real data sets and mathematical and conceptual development. Expanded coverage includes: simultaneous influence, maximum likelihood estimation of parameters, and the plotting of residuals, the use of the general linear hypothesis, indicator variables, the geometry of least squares, the relationship to ANOVA models, Box-Cox transformation with illustrations, categorical response, other nonnormal error situations, autocorrelated errors and logistic regression.",author emphas applic exampl illustr nearli techniqu discuss applic select physic scienc engin biolog manag scienc econom emphasi also place concept blend illustr use real data set mathemat conceptu develop expand coverag includ simultan influenc maximum likelihood estim paramet plot residu use gener linear hypothesi indic variabl geometri least squar relationship anova model boxcox transform illustr categor respons nonnorm error situat autocorrel error logist regress
e4fec57300d4033aa9372501a8b3a72c15a4384e,Applied statistics for the behavioral sciences,"This introductory text provides students with a conceptual understanding of basic statistical procedures, as well as the computational skills needed to complete them. The clear presentation, accessible language, and step-by-step instruction make it easy for students from a variety of social science disciplines to grasp the material. The scenarios presented in chapter exercises span the curriculum, from political science to marketing, so that students make a connection between their own area of interest and the study of statistics. Unique coverage focuses on concepts critical to understanding current statistical research such as power and sample size, multiple comparison tests, multiple regression, and analysis of covariance. Additional SPSS coverage throughout the text includes computer printouts and expanded discussion of their contents in interpreting the results of sample exercises. 1. Introduction. 2. Organizing and Graphing Data. 3. Describing Distributions: Individual Scores, Central Tendency, and Variation. 4. The Normal Distribution. 5. Correlation: A Measure of Relationship. 6. Linear Regression: Prediction. 7. Sampling, Probability, and Sampling Distributions. 8. Hypothesis Testing: One-Sample Case for the Mean. 9. Estimation: One-Sample Case for the Mean. 10. Hypothesis Testing: One-Sample Case for Other Statistics. 11. Hypothesis Testing: Two-Sample Case for the Mean. 12. Hypothesis Testing: Two-Sample Case for Other Statistics. 13. Determining Power and Sample Size. 14. Hypothesis Testing, K-Sample Case: Analysis of Variance, One-Way Classification. 15. Multiple-Comparison Procedures. 16. Analysis of Variance, Two-Way Classification. 17. Linear Regression: Estimation and Hypothesis Testing. 18. Multiple Linear Regression. 19. Analysis of Covariance. 20. Other Correlation Coefficients. 21. Chi-Square (X2) Tests for Frequencies. 22. Other Nonparametric Tests.",introductori text provid student conceptu understand basic statist procedur well comput skill need complet clear present access languag stepbystep instruct make easi student varieti social scienc disciplin grasp materi scenario present chapter exercis span curriculum polit scienc market student make connect area interest studi statist uniqu coverag focus concept critic understand current statist research power sampl size multipl comparison test multipl regress analysi covari addit spss coverag throughout text includ comput printout expand discuss content interpret result sampl exercis introduct organ graph data describ distribut individu score central tendenc variat normal distribut correl measur relationship linear regress predict sampl probabl sampl distribut hypothesi test onesampl case mean estim onesampl case mean hypothesi test onesampl case statist hypothesi test twosampl case mean hypothesi test twosampl case statist determin power sampl size hypothesi test ksampl case analysi varianc oneway classif multiplecomparison procedur analysi varianc twoway classif linear regress estim hypothesi test multipl linear regress analysi covari correl coeffici chisquar x test frequenc nonparametr test
d70e50a2cf1adb0a8de34e28de9cde267b931e26,The concepts of stress and stress system disorders. Overview of physical and behavioral homeostasis.,"OBJECTIVE
This article defines stress and related concepts and reviews their historical development. The notion of a stress system as the effector of the stress syndrome is suggested, and its physiologic and pathophysiologic manifestations are described. A new perspective on human disease states associated with dysregulation of the stress system is provided.


DATA SOURCES
Published original articles from human and animal studies and selected reviews. Literature was surveyed utilizing MEDLINE and the Index Medicus.


STUDY SELECTION
Original articles from the basic science and human literature consisted entirely of controlled studies based on verified methodologies and, with the exception of the most recent studies, replicated by more than one laboratory. Many of the basic science and clinical studies had been conducted in our own laboratories and clinical research units. Reviews cited were written by acknowledged leaders in the fields of neurobiology, endocrinology, and behavior.


DATA EXTRACTION
Independent extraction and cross-referencing by the authors.


DATA SYNTHESIS
Stress and related concepts can be traced as far back as written science and medicine. The stress system coordinates the generalized stress response, which takes place when a stressor of any kind exceeds a threshold. The main components of the stress system are the corticotropin-releasing hormone and locus ceruleus-norepinephrine/autonomic systems and their peripheral effectors, the pituitary-adrenal axis, and the limbs of the autonomic system. Activation of the stress system leads to behavioral and peripheral changes that improve the ability of the organism to adjust homeostasis and increase its chances for survival. There has been an exponential increase in knowledge regarding the interactions among the components of the stress system and between the stress system and other brain elements involved in the regulation of emotion, cognitive function, and behavior, as well as with the axes responsible for reproduction, growth, and immunity. This new knowledge has allowed association of stress system dysfunction, characterized by sustained hyperactivity and/or hypoactivity, to various pathophysiologic states that cut across the traditional boundaries of medical disciplines. These include a range of psychiatric, endocrine, and inflammatory disorders and/or susceptibility to such disorders.


CONCLUSIONS
We hope that knowledge from apparently disparate fields of science and medicine integrated into a working theoretical framework will allow generation and testing of new hypotheses on the pathophysiology and diagnosis of, and therapy for, a variety of human illnesses reflecting systematic alterations in the principal effectors of the generalized stress response. We predict that pharmacologic agents capable of altering the central apparatus that governs the stress response will be useful in the treatment of many of these illnesses.",object articl defin stress relat concept review histor develop notion stress system effector stress syndrom suggest physiolog pathophysiolog manifest describ new perspect human diseas state associ dysregul stress system provid data sourc publish origin articl human anim studi select review literatur survey util medlin index medicu studi select origin articl basic scienc human literatur consist entir control studi base verifi methodolog except recent studi replic one laboratori mani basic scienc clinic studi conduct laboratori clinic research unit review cite written acknowledg leader field neurobiolog endocrinolog behavior data extract independ extract crossreferenc author data synthesi stress relat concept trace far back written scienc medicin stress system coordin gener stress respons take place stressor kind exce threshold main compon stress system corticotropinreleas hormon locu ceruleusnorepinephrineautonom system peripher effector pituitaryadren axi limb autonom system activ stress system lead behavior peripher chang improv abil organ adjust homeostasi increas chanc surviv exponenti increas knowledg regard interact among compon stress system stress system brain element involv regul emot cognit function behavior well axe respons reproduct growth immun new knowledg allow associ stress system dysfunct character sustain hyperact andor hypoact variou pathophysiolog state cut across tradit boundari medic disciplin includ rang psychiatr endocrin inflammatori disord andor suscept disord conclus hope knowledg appar dispar field scienc medicin integr work theoret framework allow gener test new hypothes pathophysiolog diagnosi therapi varieti human ill reflect systemat alter princip effector gener stress respons predict pharmacolog agent capabl alter central apparatu govern stress respons use treatment mani ill
de96cb8ebe6119b28bb041bb3c57ccadc32a3997,An effect size primer: A guide for clinicians and researchers.,"Increasing emphasis has been placed on the use of effect size reporting in the analysis of social science data. Nonetheless, the use of effect size reporting remains inconsistent, and interpretation of effect size estimates continues to be confused. Researchers are presented with numerous effect sizes estimate options, not all of which are appropriate for every research question. Clinicians also may have little guidance in the interpretation of effect sizes relevant for clinical practice. The current article provides a primer of effect size estimates for the social sciences. Common effect sizes estimates, their use, and interpretations are presented as a guide for researchers.",increas emphasi place use effect size report analysi social scienc data nonetheless use effect size report remain inconsist interpret effect size estim continu confus research present numer effect size estim option appropri everi research question clinician also may littl guidanc interpret effect size relev clinic practic current articl provid primer effect size estim social scienc common effect size estim use interpret present guid research
54fd5a995a46f026860aede2aff6629fdae66a38,Requirements for Science Data Bases and SciDB,"For the past year, we have been assembling requirements from a collection of scientific data base users from astronomy, particle physics, fusion, remote sensing, oceanography, and biology. The intent has been to specify a common set of requirements for a new science data base system, which we call SciDB. In addition, we have discovered that very complex business analytics share most of the same requirements as “big science”. We have also constructed a partnership of companies to fund the development of SciDB, including eBay, the Large Synoptic Survey Telescope (LSST), Microsoft, the Stanford Linear Accelerator Center (SLAC) and Vertica. Lastly, we have identified two “lighthouse customers” (LSST and eBay) who will run the initial system, once it is constructed. In this paper, we report on the requirements we have identified and briefly sketch some of the SciDB design.",past year assembl requir collect scientif data base user astronomi particl physic fusion remot sens oceanographi biolog intent specifi common set requir new scienc data base system call scidb addit discov complex busi analyt share requir big scienc also construct partnership compani fund develop scidb includ ebay larg synopt survey telescop lsst microsoft stanford linear acceler center slac vertica lastli identifi two lighthous custom lsst ebay run initi system construct paper report requir identifi briefli sketch scidb design
964105343f08d1ca48f7b76bd7cb0cdcd24a4c8b,The Potential to Narrow Uncertainty in Regional Climate Predictions,"Abstract Faced by the realities of a changing climate, decision makers in a wide variety of organizations are increasingly seeking quantitative predictions of regional and local climate. An important issue for these decision makers, and for organizations that fund climate research, is what is the potential for climate science to deliver improvements—especially reductions in uncertainty—in such predictions? Uncertainty in climate predictions arises from three distinct sources: internal variability, model uncertainty, and scenario uncertainty. Using data from a suite of climate models, we separate and quantify these sources. For predictions of changes in surface air temperature on decadal timescales and regional spatial scales, we show that uncertainty for the next few decades is dominated by sources (model uncertainty and internal variability) that are potentially reducible through progress in climate science. Furthermore, we find that model uncertainty is of greater importance than internal variability. O...",abstract face realiti chang climat decis maker wide varieti organ increasingli seek quantit predict region local climat import issu decis maker organ fund climat research potenti climat scienc deliv improvementsespeci reduct uncertaintyin predict uncertainti climat predict aris three distinct sourc intern variabl model uncertainti scenario uncertainti use data suit climat model separ quantifi sourc predict chang surfac air temperatur decad timescal region spatial scale show uncertainti next decad domin sourc model uncertainti intern variabl potenti reduc progress climat scienc furthermor find model uncertainti greater import intern variabl
49594776b8a1dce89e976c846266ccefafa948b7,Stochastic Processes,"Stochastic processes are probabilistic models of data streams such as speech, audio and video signals, stock market prices, and measurements of physical phenomena by digital sensors such as medical instruments, GPS receivers, or seismographs. A solid understanding of the mathematical basis of these models is essential for understanding phenomena and processing information in many branches of science and engineering including physics, communications, signal processing, automation, and structural dynamics.",stochast process probabilist model data stream speech audio video signal stock market price measur physic phenomena digit sensor medic instrument gp receiv seismograph solid understand mathemat basi model essenti understand phenomena process inform mani branch scienc engin includ physic commun signal process autom structur dynam
164578a8d62985888e99d85154ff52dbea034a08,Data Mining Techniques,"Methods for knowledge discovery in data bases (KDD) have been studied for more than a decade. New methods are required owing to the size and complexity of data collections in administration, business and science. They include procedures for data query and extraction, for data cleaning, data analysis, and methods of knowledge representation. The part of KDD dealing with the analysis of the data has been termed data mining. Common data mining tasks include the induction of association rules, the discovery of functional relationships (classification and regression) and the exploration of groups of similar data objects in clustering. This review provides a discussion of and pointers to efficient algorithms for the common data mining tasks in a mathematical framework. Because of the size and complexity of the data sets, efficient algorithms and often crude approximations play an important role.",method knowledg discoveri data base kdd studi decad new method requir owe size complex data collect administr busi scienc includ procedur data queri extract data clean data analysi method knowledg represent part kdd deal analysi data term data mine common data mine task includ induct associ rule discoveri function relationship classif regress explor group similar data object cluster review provid discuss pointer effici algorithm common data mine task mathemat framework size complex data set effici algorithm often crude approxim play import role
2fa9691d984a857a1ec24240a2d72425b8614c87,Foundations of Qualitative Research: Interpretive and Critical Approaches,"Chapter 1: World Views, Paradigms, and the Practice of Social Science Research Case 1. Quantitative Research Case 2. Qualitative Research Thinking about the Foundations and Practice of Research What This Book Is and Is Not About. What Warrants Our Attention? The Traditional Canon Alternative Paradigms New Techniques or New Paradigms? Chapter 2: History and Context of Paradigm Development Positivism: A Response to Metaphysical and Magical Explanations Critical Theory: A Response to Inequities in Society Interpretivism: A Response to the Excesses of ""Scientific"" Social Science The Special Cases of Postmodernism and Feminism Chapter 3: Foundational Issues: Postpositivist and Critical Perspectives Social Science Research: The View from the Postpositivist Paradigm Social Science Research: The View from the Critical Theory Paradigm Chapter 4: History and Foundations of Interpretivist Research (1) Nature of Reality. (2) Purpose of Research. (3) Acceptable Methodology/Data. (4) The Meaning of Data (5) Relationship of Research to Practice. The Implications of an Interpretivist Approach What Sorts of Research are Worthwhile? Examples of Interpretive Research Chapter 5: Frameworks for Qualitative Research Postpositivist Research ""Moments"" of Qualitative Research Some General Frameworks for Qualitative Research Chapter 6: General Guidelines for Qualitative Research Guidelines for Qualitative Research Situated or Contextual Understanding, Not Truth, is the Purpose of Research Accept Multiple Sources of Influence Take A Foundational Rather Than Technique Perspective Practice Recursive (Iterative ) and Emergent Data Collection and Analysis Use Multiple Sources of Data Think of Research as a Reflective Process The Researcher is the Primary Tool for Data Collection and Analysis An Emphasis on Participatory versus Nonparticipatory Research. Adopt an Open Approach Deal With Bias Directly Select Natural Contexts for Research Research Should be Holistic, Not Atomistic Research Involves More Than Induction and Deduction: Analogical Reasoning, Abduction, and Family Resemblances Alternatives to Postpositivist Criteria for Believability: Validity and Reliability Alternative Approaches to Validity and Reliability: Triangulation and More Conclusions? Aren't They Generalizations? Chapter 7: Methods of Qualitative Research Case 1: Action Research on a Pediatric Surgical Ward Established Qualitative Research Methods Ethnography Case Studies: Another Form of Qualitative Observation Interview Research Historigraphy Historiography: The Research Methods of History Innovative Methods Participatory Qualitative Research Emancipatory Research Critical Emancipatory Action Research Chapter 8: Approaches to Data Analysis and Intepretation The Purpose of Research General Theory Objective Description Hermeneutic (Verstehen) Understanding Story telling/Narrative Data Analysis Families Eyeballing the Data Connoisseurship: A Global Perspective Hermeneutics as a Data Analysis Method Grounded Theory Analytic Induction A Final Topic: The Ethics of Research Chapter 9: 21st Century Social Science: Peering into the Future Will the Cacophony Continue? Why Can't Social Science Converge on The Answer? Competition Linearity Dialog as an Alternative to Competition Three Approaches to Knowing in Greek Thought Plato Aristotle The Humanities Choices 20th Century Social Science Made Suppose We Chose Badly Two Theories That May Help Us Build 21st Century Social Science Poetic Logic Chaos and Complexity Theory: Another Route to a Nonlinea Social Science",chapter world view paradigm practic social scienc research case quantit research case qualit research think foundat practic research book warrant attent tradit canon altern paradigm new techniqu new paradigm chapter histori context paradigm develop positiv respons metaphys magic explan critic theori respons inequ societi interpretiv respons excess scientif social scienc special case postmodern femin chapter foundat issu postpositivist critic perspect social scienc research view postpositivist paradigm social scienc research view critic theori paradigm chapter histori foundat interpretivist research natur realiti purpos research accept methodologydata mean data relationship research practic implic interpretivist approach sort research worthwhil exampl interpret research chapter framework qualit research postpositivist research moment qualit research gener framework qualit research chapter gener guidelin qualit research guidelin qualit research situat contextu understand truth purpos research accept multipl sourc influenc take foundat rather techniqu perspect practic recurs iter emerg data collect analysi use multipl sourc data think research reflect process research primari tool data collect analysi emphasi participatori versu nonparticipatori research adopt open approach deal bia directli select natur context research research holist atomist research involv induct deduct analog reason abduct famili resembl altern postpositivist criteria believ valid reliabl altern approach valid reliabl triangul conclus arent gener chapter method qualit research case action research pediatr surgic ward establish qualit research method ethnographi case studi anoth form qualit observ interview research historigraphi historiographi research method histori innov method participatori qualit research emancipatori research critic emancipatori action research chapter approach data analysi intepret purpos research gener theori object descript hermeneut verstehen understand stori tellingnarr data analysi famili eyebal data connoisseurship global perspect hermeneut data analysi method ground theori analyt induct final topic ethic research chapter st centuri social scienc peer futur cacophoni continu cant social scienc converg answer competit linear dialog altern competit three approach know greek thought plato aristotl human choic th centuri social scienc made suppos chose badli two theori may help us build st centuri social scienc poetic logic chao complex theori anoth rout nonlinea social scienc
31af4b8793e93fd35e89569ccd663ae8777f0072,The Netflix Prize,"Netflix released a dataset containing 100 million anonymous movie ratings and challenged the data mining, machine learning and computer science communities to develop systems that could beat the accuracy of its recommendation system, Cinematch. We briefly describe the challenge itself, review related work and efforts, and summarize visible progress to date. Other potential uses of the data are outlined, including its application to the KDD Cup 2007.",netflix releas dataset contain million anonym movi rate challeng data mine machin learn comput scienc commun develop system could beat accuraci recommend system cinematch briefli describ challeng review relat work effort summar visibl progress date potenti use data outlin includ applic kdd cup
8e4b30cfc46210ed439596d178ca0669946b5eb1,A Survey of Outlier Detection Methodologies,,nan
ca23dd4e9ab32bc29b79a4aa30f71ee6580a9f1c,Information visualization: perception for design by Colin Ware,"Most designers know that yellow text presented against a blue background reads clearly and easily, but how many can explain why, and what really are the best ways to help others and ourselves clearly see key patterns in a bunch of data? When we use software, access a website, or view business or scientific graphics, our understanding is greatly enhanced or impeded by the way the information is presented. 
 
This book explores the art and science of why we see objects the way we do. Based on the science of perception and vision, the author presents the key principles at work for a wide range of applications--resulting in visualization of improved clarity, utility, and persuasiveness. The book offers practical guidelines that can be applied by anyone: interaction designers, graphic designers of all kinds (including web designers), data miners, and financial analysts. 
 
 
 
Complete update of the recognized source in industry, research, and academic for applicable guidance on information visualizing. 
 
Includes the latest research and state of the art information on multimedia presentation. 
 
More than 160 explicit design guidelines based on vision science. 
 
A new final chapter that explains the process of visual thinking and how visualizations help us to think about problems. 
 
Packed with over 400 informative full color illustrations, which are key to understanding of the subject. 
 
Table of Contents 
 
 
Chapter 1. Foundations for an Applied Science of Data Visualization 
 
Chapter 2. The Environment, Optics, Resolution, and the Display 
 
Chapter 3. Lightness, Brightness, Contrast and Constancy 
 
Chapter 4. Color 
 
Chapter 5. Visual Salience and Finding Information 
 
Chapter 6. Static and Moving Patterns 
 
Chapter 7. Space Perception 
 
Chapter 8. Visual Objects and Data Objects 
 
Chapter 9. Images, Narrative, and Gestures for Explanation 
 
Chapter 10. Interacting with Visualizations 
 
Chapter 11. Visual Thinking Processes",design know yellow text present blue background read clearli easili mani explain realli best way help other clearli see key pattern bunch data use softwar access websit view busi scientif graphic understand greatli enhanc imped way inform present book explor art scienc see object way base scienc percept vision author present key principl work wide rang applicationsresult visual improv clariti util persuas book offer practic guidelin appli anyon interact design graphic design kind includ web design data miner financi analyst complet updat recogn sourc industri research academ applic guidanc inform visual includ latest research state art inform multimedia present explicit design guidelin base vision scienc new final chapter explain process visual think visual help us think problem pack inform full color illustr key understand subject tabl content chapter foundat appli scienc data visual chapter environ optic resolut display chapter light bright contrast constanc chapter color chapter visual salienc find inform chapter static move pattern chapter space percept chapter visual object data object chapter imag narr gestur explan chapter interact visual chapter visual think process
41dd19cc15a39191525b9886aa822f44a7856a4c,"""Doing"" Science versus ""Being"" a Scientist: Examining 10/11-Year-Old Schoolchildren's Constructions of Science through the Lens of Identity.","The concern about students' engagement with school science and the numbers pursuing the further study of science is an international phenomenon and a matter of considerable concern among policy makers. Research has demonstrated that the majority of young children have positive attitudes to science at age 10 but that this interest then declines sharply and by age 14, their attitude and interest in the study of science has been largely formed. This paper reports on data collected as part of a funded 5-year longitudinal study that seeks to determine how students' interest in science and scientific careers evolves. As an initial part of the study, six focus group discussions were undertaken with schoolchildren, age 10–11, to explore their attitudes toward science and interest in science, the findings of which are presented here. The children's responses are analyzed through the lens of identity, drawing on a theoretical framework that views identity as an embodied and a performed construction that is both produced by individuals and shaped by their specific structural locations. This work offers new insights into the manner in which students construct representations of science and scientists. © 2010 Wiley Periodicals, Inc. Sci Ed94:617–639, 2010",concern student engag school scienc number pursu studi scienc intern phenomenon matter consider concern among polici maker research demonstr major young children posit attitud scienc age interest declin sharpli age attitud interest studi scienc larg form paper report data collect part fund year longitudin studi seek determin student interest scienc scientif career evolv initi part studi six focu group discuss undertaken schoolchildren age explor attitud toward scienc interest scienc find present children respons analyz len ident draw theoret framework view ident embodi perform construct produc individu shape specif structur locat work offer new insight manner student construct represent scienc scientist wiley period inc sci ed
cd8055683caca2b2b4957621a09b575a708a98a6,The Hinode (Solar-B) Mission: An Overview,,nan
f2c7aba9255a14a8e438b7b12934442b5d4fa146,Vegetation Description and Analysis: A Practical Approach,"The Nature of Quantitative Plant Ecology and Vegetation Science. The Description of Vegetation in the Field. The Nature and Properties of Vegetation Data. Basic Statistical Analysis of Vegetation and Environmental Data. Ordination Methods I, 1950-1970. Ordination Methods II, 1970-1992. Phytosociology and the Zurick-Montpellier (Braun-Blanquet) School of Subjective Classification. Numerical Classification and Phytosociology. Computer Programs for Vegetation and Environmental Data Analysis. Quantitative Plant Ecology, Vegetation Science and the Future. References. Index.",natur quantit plant ecolog veget scienc descript veget field natur properti veget data basic statist analysi veget environment data ordin method ordin method ii phytosociolog zurickmontpelli braunblanquet school subject classif numer classif phytosociolog comput program veget environment data analysi quantit plant ecolog veget scienc futur refer index
831e6a3edba368604297f3164855146a376d33c9,Dynamic Version of the Economic Lot Size Model,"(This article originally appeared in Management Science, October 1958, Volume 5, Number 1, pp. 89-96, published by The Institute of Management Sciences.) 
 
A forward algorithm for a solution to the following dynamic version of the economic lot size model is given: allowing the possibility of demands for a single item, inventory holding charges, and setup costs to vary over N periods, we desire a minimum total cost inventory management scheme which satisfies known demand in every period. Disjoint planning horizons are shown to be possible which eliminate the necessity of having data for the full N periods.",articl origin appear manag scienc octob volum number pp publish institut manag scienc forward algorithm solut follow dynam version econom lot size model given allow possibl demand singl item inventori hold charg setup cost vari n period desir minimum total cost inventori manag scheme satisfi known demand everi period disjoint plan horizon shown possibl elimin necess data full n period
1e52db1f61a5f0083cbe87845c019ab351bfe6c9,Statistical learning theory,"A comprehensive look at learning and generalization theory. The statistical theory of learning and generalization concerns the problem of choosing desired functions on the basis of empirical data. Highly applicable to a variety of computer science and robotics fields, this book offers lucid coverage of the theory as a whole. Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more.",comprehens look learn gener theori statist theori learn gener concern problem choos desir function basi empir data highli applic varieti comput scienc robot field book offer lucid coverag theori whole present method determin necessari suffici condit consist learn process author cover function estim small data pool appli estim reallif problem much
7c4a9643c701c0c91ea50fd587038f79187a0a5e,Artificial Intelligence: A Guide to Intelligent Systems,"From the Publisher: 
Virtually all the literature on artificial intelligence is expressed in the jargon of commuter science, crowded with complex matrix algebra and differential equations. Unlike many other books on computer intelligence, this one demonstrates that most ideas behind intelligent systems are simple and straightforward. The book has evolved from lectures given to students with little knowledge of calculus, and the reader needs no prerequisites associated with knowledge of any programming language. The methods used in the book have been extensively tested through several courses given by the author. 
 
The book provides an introduction to the field of computer intelligence, covering 
 
rule-based expert systems, 
fuzzy expert systems, 
frame-based expert systems, 
artificail neural networks, 
evolutionary computation, 
hybrid intelligent systems, 
knowledge engineering, 
data mining. 
 
 
In a university setting the book can be used as an introductory course within computer science, information systems or engineering departments. The book is also suitable as a self-study guide for non-computer science professionals, giving access to the state of the art in knowledge-based systems and computational intelligence. Everyone who faces challenging problems and cannot solve them using traditional approaches can benefit",publish virtual literatur artifici intellig express jargon commut scienc crowd complex matrix algebra differenti equat unlik mani book comput intellig one demonstr idea behind intellig system simpl straightforward book evolv lectur given student littl knowledg calculu reader need prerequisit associ knowledg program languag method use book extens test sever cours given author book provid introduct field comput intellig cover rulebas expert system fuzzi expert system framebas expert system artificail neural network evolutionari comput hybrid intellig system knowledg engin data mine univers set book use introductori cours within comput scienc inform system engin depart book also suitabl selfstudi guid noncomput scienc profession give access state art knowledgebas system comput intellig everyon face challeng problem cannot solv use tradit approach benefit
6277dd84bd4ee42ab31a7afb3ef44e2b10f8d0dd,Establishing the norms of scientific argumentation in classrooms,"Basing its arguments in current perspectives on the nature of the scientific enterprise, which see argument and argumentative practice as a core activity of scientists, this article develops the case for the inclusion and central role of argument in science education. Beginning with a review of the nature of argument, it discusses the function and purpose of dialogic argument in the social construction of scientific knowledge and the interpretation of empirical data. The case is then advanced that any education about science, rather than education in science, must give the role of argument a high priority if it is to give a fair account of the social practice of science, and develop a knowledge and understanding of the evaluative criteria used to establish scientific theories. Such knowledge is essential to enhance the public understanding of science and improve scientific literacy. The existing literature, and work that has attempted to use argument within science education, is reviewed to show that classroom practice does provide the opportunity to develop young people's ability to construct argument. Furthermore, the case is advanced that the lack of opportunities for the practice of argument within science classrooms, and lack of teacher's pedagogical skills in organizing argumentative discourse within the classroom are significant impediments to progress in the field. © 2000 John Wiley & Sons, Inc. Sci Ed84:287–312, 2000.",base argument current perspect natur scientif enterpris see argument argument practic core activ scientist articl develop case inclus central role argument scienc educ begin review natur argument discuss function purpos dialog argument social construct scientif knowledg interpret empir data case advanc educ scienc rather educ scienc must give role argument high prioriti give fair account social practic scienc develop knowledg understand evalu criteria use establish scientif theori knowledg essenti enhanc public understand scienc improv scientif literaci exist literatur work attempt use argument within scienc educ review show classroom practic provid opportun develop young peopl abil construct argument furthermor case advanc lack opportun practic argument within scienc classroom lack teacher pedagog skill organ argument discours within classroom signific impedi progress field john wiley son inc sci ed
ef9b8640efb2f6a3f059a8a72fbac4d9e7da4251,A Continuous Satellite-Derived Measure of Global Terrestrial Primary Production,"Abstract Until recently, continuous monitoring of global vegetation productivity has not been possible because of technological limitations. This article introduces a new satellite-driven monitor of the global biosphere that regularly computes daily gross primary production (GPP) and annual net primary production (NPP) at 1-kilometer (km) resolution over 109,782,756 km2 of vegetated land surface. We summarize the history of global NPP science, as well as the derivation of this calculation, and current data production activity. The first data on NPP from the EOS (Earth Observing System) MODIS (Moderate Resolution Imaging Spectroradiometer) sensor are presented with different types of validation. We offer examples of how this new type of data set can serve ecological science, land management, and environmental policy. To enhance the use of these data by nonspecialists, we are now producing monthly anomaly maps for GPP and annual NPP that compare the current value with an 18-year average value for each pixel, clearly identifying regions where vegetation growth is higher or lower than normal.",abstract recent continu monitor global veget product possibl technolog limit articl introduc new satellitedriven monitor global biospher regularli comput daili gross primari product gpp annual net primari product npp kilomet km resolut km veget land surfac summar histori global npp scienc well deriv calcul current data product activ first data npp eo earth observ system modi moder resolut imag spectroradiomet sensor present differ type valid offer exampl new type data set serv ecolog scienc land manag environment polici enhanc use data nonspecialist produc monthli anomali map gpp annual npp compar current valu year averag valu pixel clearli identifi region veget growth higher lower normal
42bd119724bee894e0887bc1a27db26420e500ad,Approaches to social research,"Chapters 2-17 end with a Summary CHAPTER 1. INTRODUCTION Why Study Research Methods? Methodological Approaches to the Social World Conclusions I. THE SCIENTIFIC AND ETHICAL CONTEXTS OF SOCIAL RESEARCH CHAPTER 2. THE NATURE OF SCIENCE The Aim of Science Science as Product Science as Process Science: Ideal versus Reality CHAPTER 3. RESEARCH ETHICS Data Collection and Analysis Treatment of Human Subjects Making Ethical Decisions The Uses of Research: Science and Society II. RESEARCH DESIGN CHAPTER 4. ELEMENTS OF RESEARCH DESIGN Origins of Research Topics Units of Analysis Variables Relationships Formulating Questions and Hypotheses Research Purposes and Research Design Stages of Social Research CHAPTER 5. MEASUREMENT The Measurement Process Levels of Measurement Reliability and Validity Reliability Assessment Validity Assessment A Final Note on Reliability and Validity CHAPTER 6. SAMPLING Why Sample? Population Definition Sampling Designs Probability Sampling Nonprobability Sampling Other Sampling Designs Factors Affecting Choice of Sampling Design Factors Determining Sample Size Final Notes on Sampling Errors and Generalizability III. METHODS OF DATA COLLECTION CHAPTER 7. EXPERIMENTATION The Logic of Experimentation Staging Experiments The Experiment as a Social Occasion Experimentation Outside the Laboratory CHAPTER 8. EXPERIMENTAL DESIGNS Threats to Internal Validity Pre-experimental Designs True Experimental Designs Factorial Experimental Designs Quasi-experimental Designs CHAPTER 9. SURVEY RESEARCH General Features of Survey Research The Uses and Limitations of Surveys Survey Research Designs Steps in Survey Research: Planning Face-to-Face and Telephone Interviewing Paper-and-Pencil Mailed Questionnaires Computer-Assisted Interviews Mixed-Mode Surveys Field Administration CHAPTER 10. SURVEY INSTRUMENTATION The Survey as a Social Occasion Materials Available to the Survey Designer ""Sketches"" or Preliminaries Filling in the Sketch: Writing the Items Pretesting CHAPTER 11. FIELD RESEARCH The Potentials and Limitations of Field Research Research Design and Sampling Field Observation Field Interviewing Stages of Field Research CHAPTER 12. RESEARCH USING AVAILABLE DATA Sources of Available Data Advantages of Research Using Available Data General Methodological Issues in Available-Data Research Historical Analysis Content Analysis CHAPTER 13. MULTIPLE METHODS Triangulation Multiple Measures of Concepts within the Same Study Multiple Tests of Hypotheses across Different Studies A Comparison of the Four Basic Approaches to Social Research Meta-Analysis CHAPTER 14. EVALUATION RESEARCH Framework and Sample Studies Types of Evaluation Research Methodological Issues in Evaluation Research The Social and Political Context of Evaluation Research IV. DATA PROCESSING, ANALYSIS, AND INTERPRETATION CHAPTER 15. DATA PROCESSING AND ELEMENTARY DATA ANALYSIS Preview of Analysis Steps Data Processing Data Matrices and Documentation The Functions of Statistics in Social Research Inspecting and Modifying the Data Preliminary Hypothesis Testing CHAPTER 16. MULTIVARIATE ANALYSIS Modeling Relationships Elaboration: Tables and Beyond Multiple-Regression Analysis Other Modeling Techniques CHAPTER 17. WRITING RESEARCH REPORTS Searching the Literature Using the Internet Using the Library Outlining and Preparing to Write Major Headings Other Considerations Length",chapter end summari chapter introduct studi research method methodolog approach social world conclus scientif ethic context social research chapter natur scienc aim scienc scienc product scienc process scienc ideal versu realiti chapter research ethic data collect analysi treatment human subject make ethic decis use research scienc societi ii research design chapter element research design origin research topic unit analysi variabl relationship formul question hypothes research purpos research design stage social research chapter measur measur process level measur reliabl valid reliabl assess valid assess final note reliabl valid chapter sampl sampl popul definit sampl design probabl sampl nonprob sampl sampl design factor affect choic sampl design factor determin sampl size final note sampl error generaliz iii method data collect chapter experiment logic experiment stage experi experi social occas experiment outsid laboratori chapter experiment design threat intern valid preexperiment design true experiment design factori experiment design quasiexperiment design chapter survey research gener featur survey research use limit survey survey research design step survey research plan facetofac telephon interview paperandpencil mail questionnair computerassist interview mixedmod survey field administr chapter survey instrument survey social occas materi avail survey design sketch preliminari fill sketch write item pretest chapter field research potenti limit field research research design sampl field observ field interview stage field research chapter research use avail data sourc avail data advantag research use avail data gener methodolog issu availabledata research histor analysi content analysi chapter multipl method triangul multipl measur concept within studi multipl test hypothes across differ studi comparison four basic approach social research metaanalysi chapter evalu research framework sampl studi type evalu research methodolog issu evalu research social polit context evalu research iv data process analysi interpret chapter data process elementari data analysi preview analysi step data process data matric document function statist social research inspect modifi data preliminari hypothesi test chapter multivari analysi model relationship elabor tabl beyond multipleregress analysi model techniqu chapter write research report search literatur use internet use librari outlin prepar write major head consider length
7dcb61c32c9dcd4722037de73e9191d137504734,Reflexive Methodology: New Vistas for Qualitative Research,"Introduction: The Intellectualization of Method (Post-)Positivism, Social Constructionism, Critical Realism: Three Reference Points in the Philosophy of Science Data-Oriented Methods: Empiricist Techniques and Procedures Hermeneutics: Interpretation and Insight Critical Theory: The Political and Ideological Dimension Post-Structuralism and Postmodernism: Destabilizing Subject and Text Language/Gender/Power: Discourse Analysis, Feminism and Genealogy On Reflexive Interpretation: The Play of Interpretive Levels Applications of Reflexive Methodology: Strategies, Criteria, Varieties",introduct intellectu method postpositiv social construction critic realism three refer point philosophi scienc dataori method empiricist techniqu procedur hermeneut interpret insight critic theori polit ideolog dimens poststructur postmodern destabil subject text languagegenderpow discours analysi femin genealog reflex interpret play interpret level applic reflex methodolog strategi criteria varieti
887ad080fbf279dd3c096d8722114c98759ce183,Astronomical Data Analysis Software and Systems X,"The Astronomical Data Analysis Software and Systems—ADASS—Conference series is now in its 10th year and continues to highlight advances across a wide range of topical areas. This year’s focus areas included “Enabling Technologies for Astronomy,” “Software Development Technologies,” “Science Data Pipelines, “Sky Surveys,” “Outreach,” and “Software History.” In addition, “Birds-of-a-Feather” sessions were held concerning the National Virtual Observatory (NVO), CORBA, IRAF, AIPS , DS9, IDL, Linux, and FITS. As evidence for the wide and continuing interest in astronomical software issues, 304 participants attended the conference from 21 countries. The theme of “enabling technologies” was addressed by A. Szalay (reviewing the genesis, challenges, and opportunities of the virtual observatory), J. Spyromilio (commissioning the VLT), and J. Tarter and D. Werthimer (the science and technical challenges of the SETI project). S. Murray and R. Brissenden described the early scientific successes and operational systems for theChandra X-Ray Observatory, and B. Glendenning gave an overview of the software engineering challenges facing the ALMA telescope project. Key papers on software development technologies included J. Graybeal (CORBA), G. Filippi (software development methodologies employed at ESO), C. Kesselman (computational grids), J. Manuel Filgueira (distributed objects), and V. Yodaiken (real-time Linux). In the area of science data processing pipelines, R. Lupton described the image reduction pipeline for the Sloan Digital Sky Survey, and R. Cutri described the 2MASS project under the topic of sky surveys. K. Shortridge gave an insightful and amusing historical perspective of astronomical software development. The oral program also included a number of excellent contributed papers, and daily poster sessions (with over 120 posters presented in total) included presentations on all areas of software development and systems. Fourteen groups demonstrated their latest software systems and astronomical information services. Over the past decade the emphasis of the conference has gradually changed, from the “Data Analysis” to the “Systems” part of the title. This change reflects the fact that astronomical software development has entered into the age of very large projects, either in support of large, complex, forefront telescopes (Gemini, VLT, ALMA, and NGST for example) or in the support of massive surveys and the associated terabytescale databases (e.g., 2MASS, GSC-II, and SDSS). The soft-",astronom data analysi softwar systemsadassconfer seri th year continu highlight advanc across wide rang topic area year focu area includ enabl technolog astronomi softwar develop technolog scienc data pipelin sky survey outreach softwar histori addit birdsofafeath session held concern nation virtual observatori nvo corba iraf aip ds idl linux fit evid wide continu interest astronom softwar issu particip attend confer countri theme enabl technolog address szalay review genesi challeng opportun virtual observatori j spyromilio commiss vlt j tarter werthim scienc technic challeng seti project murray r brissenden describ earli scientif success oper system thechandra xray observatori b glenden gave overview softwar engin challeng face alma telescop project key paper softwar develop technolog includ j graybeal corba g filippi softwar develop methodolog employ eso c kesselman comput grid j manuel filgueira distribut object v yodaiken realtim linux area scienc data process pipelin r lupton describ imag reduct pipelin sloan digit sky survey r cutri describ mass project topic sky survey k shortridg gave insight amus histor perspect astronom softwar develop oral program also includ number excel contribut paper daili poster session poster present total includ present area softwar develop system fourteen group demonstr latest softwar system astronom inform servic past decad emphasi confer gradual chang data analysi system part titl chang reflect fact astronom softwar develop enter age larg project either support larg complex forefront telescop gemini vlt alma ngst exampl support massiv survey associ terabytescal databas eg mass gscii sdss soft
4169f14a9b39da5cfec5e5dfb24ad2f140cf3e23,Effect Size,,nan
50f1415d55e99276d21966771a09ac8d13ee78da,Big data challenge: a data management perspective,,nan
33780e4aba639a97f9fb7f7e773853f74dd494b7,The Bioperl toolkit: Perl modules for the life sciences.,"The Bioperl project is an international open-source collaboration of biologists, bioinformaticians, and computer scientists that has evolved over the past 7 yr into the most comprehensive library of Perl modules available for managing and manipulating life-science information. Bioperl provides an easy-to-use, stable, and consistent programming interface for bioinformatics application programmers. The Bioperl modules have been successfully and repeatedly used to reduce otherwise complex tasks to only a few lines of code. The Bioperl object model has been proven to be flexible enough to support enterprise-level applications such as EnsEMBL, while maintaining an easy learning curve for novice Perl programmers. Bioperl is capable of executing analyses and processing results from programs such as BLAST, ClustalW, or the EMBOSS suite. Interoperation with modules written in Python and Java is supported through the evolving BioCORBA bridge. Bioperl provides access to data stores such as GenBank and SwissProt via a flexible series of sequence input/output modules, and to the emerging common sequence data storage format of the Open Bioinformatics Database Access project. This study describes the overall architecture of the toolkit, the problem domains that it addresses, and gives specific examples of how the toolkit can be used to solve common life-sciences problems. We conclude with a discussion of how the open-source nature of the project has contributed to the development effort.",bioperl project intern opensourc collabor biologist bioinformatician comput scientist evolv past yr comprehens librari perl modul avail manag manipul lifesci inform bioperl provid easytous stabl consist program interfac bioinformat applic programm bioperl modul success repeatedli use reduc otherwis complex task line code bioperl object model proven flexibl enough support enterpriselevel applic ensembl maintain easi learn curv novic perl programm bioperl capabl execut analys process result program blast clustalw emboss suit interoper modul written python java support evolv biocorba bridg bioperl provid access data store genbank swissprot via flexibl seri sequenc inputoutput modul emerg common sequenc data storag format open bioinformat databas access project studi describ overal architectur toolkit problem domain address give specif exampl toolkit use solv common lifesci problem conclud discuss opensourc natur project contribut develop effort
4f7a5761adee85ba731ab547255111c284022d0b,Digital Soil Mapping,"Digital soil mapping (DSM),as one of the sub -disciplines of soil science, was first introduced in McBratny et al. in 2003. It has since then witnessed many developments and has had a lot of scientific contributions at the global level. DSM aims to create and populate spatial soil information collected through field and laboratory observations that are coupled through quantitative relationships with environmental data. The output involves raster maps of predictions and uncertainties. The enhanced availability of spatial data, such as digital elevation models and satellite images; the increasing computation power to process data; the development of data-mining tools and GIS; and increasing global demand for spatial data including uncertainty assessments are some of the factors that have led to the success of field.This paper reviews the development of digital soil mapping through time, the covariates, some modeling examples,and the DSM studies so far carried out in Iran.",digit soil map dsma one sub disciplin soil scienc first introduc mcbratni et al sinc wit mani develop lot scientif contribut global level dsm aim creat popul spatial soil inform collect field laboratori observ coupl quantit relationship environment data output involv raster map predict uncertainti enhanc avail spatial data digit elev model satellit imag increas comput power process data develop datamin tool gi increas global demand spatial data includ uncertainti assess factor led success fieldthi paper review develop digit soil map time covari model examplesand dsm studi far carri iran
df296559baaceb4a5efdb9fb7d6fbaf637fd9ccb,The cost of doing science on the cloud: The Montage example,"Utility grids such as the Amazon EC2 cloud and Amazon S3 offer computational and storage resources that can be used on-demand for a fee by compute and data-intensive applications. The cost of running an application on such a cloud depends on the compute, storage and communication resources it will provision and consume. Different execution plans of the same application may result in significantly different costs. Using the Amazon cloud fee structure and a real-life astronomy application, we study via simulation the cost performance tradeoffs of different execution and resource provisioning plans. We also study these trade-offs in the context of the storage and communication fees of Amazon S3 when used for long-term application data archival. Our results show that by provisioning the right amount of storage and compute resources, cost can be significantly reduced with no significant impact on application performance.",util grid amazon ec cloud amazon offer comput storag resourc use ondemand fee comput dataintens applic cost run applic cloud depend comput storag commun resourc provis consum differ execut plan applic may result significantli differ cost use amazon cloud fee structur reallif astronomi applic studi via simul cost perform tradeoff differ execut resourc provis plan also studi tradeoff context storag commun fee amazon use longterm applic data archiv result show provis right amount storag comput resourc cost significantli reduc signific impact applic perform
bf245b7c072d3cd3f45ed9f9b9f80fb417395d47,The INTEGRAL Science Data Centre (ISDC),The INTEGRAL Science Data Centre (ISDC) provides the INTEGRAL data and means to analyse them to the scientific community. The ISDC runs a gamma ray burst alert system that provides the position of gamma ray bursts on the sky within seconds to the community. It operates a quick-look analysis of the data within few hours that detects new and unexpected sources as well as it monitors the instruments. The ISDC processes the data through a standard analysis the results of which are provided to the observers together with their data.,integr scienc data centr isdc provid integr data mean analys scientif commun isdc run gamma ray burst alert system provid posit gamma ray burst sky within second commun oper quicklook analysi data within hour detect new unexpect sourc well monitor instrument isdc process data standard analysi result provid observ togeth data
db22407602c7406015cd278773ec80aace490e69,Data Analysis in Forensic Science A Bayesian Decision Perspective,"If you really want to be smarter, reading can be one of the lots ways to evoke and realize. Many people who like reading will have more knowledge and experiences. Reading can be a way to gain information from economics, politics, science, fiction, literature, religion, and many others. As one of the part of book categories, data analysis in forensic science a bayesian decision perspective always becomes the most wanted book. Many people are absolutely searching for this book. It means that many love to read this kind of book.",realli want smarter read one lot way evok realiz mani peopl like read knowledg experi read way gain inform econom polit scienc fiction literatur religion mani other one part book categori data analysi forens scienc bayesian decis perspect alway becom want book mani peopl absolut search book mean mani love read kind book
47c6cac68d034066e1f05e909863f5cce62fcb2b,Mapping the backbone of science,,nan
497d3e9006db04242649672eb5fd9ca41f95b89a,Consultative Committee For Space Data Systems,"The major space agencies of the world recognize that there are benefits in using standard techniques for handling space data and that, by cooperatively developing these techniques, future data system interoperability will be enhanced. In order to assure that work towards standardization of space-related information technologies provides the maximum benefi t for 
the interested agencies, both individually and collectively, an international Consultative Committee for Space Data Systems (CCSDS) was established in 1982 as a forum for international cooperation in the development of data handling techniques supporting space research, including space science and 
applications. In 1991, the committee was incorporated as a subcommittee of the International Organization for Standardization (ISO). 
The article describs the work of CCSDS till its beginning in the 80s till today (2009).",major space agenc world recogn benefit use standard techniqu handl space data cooper develop techniqu futur data system interoper enhanc order assur work toward standard spacerel inform technolog provid maximum benefi interest agenc individu collect intern consult committe space data system ccsd establish forum intern cooper develop data handl techniqu support space research includ space scienc applic committe incorpor subcommitte intern organ standard iso articl describ work ccsd till begin till today
a9bf700aa5b6ebaa4d8a8f575d9ecb4a8f67627d,Gaming for (Citizen) Science: Exploring Motivation and Data Quality in the Context of Crowdsourced Science through the Design and Evaluation of a Social-Computational System,"Citizen Sort, currently under development, is a web-based social-computational system designed to support a citizen science task, the taxonomic classification of various insect, animal, and plant species. In addition to supporting this natural science objective, the Citizen Sort platform will also support information science research goals on motivation for participation in social-computation and citizen science. In particular, this research program addresses the use of games to motivate participation in social-computational citizen science, and explores the effects of system design on motivation and data quality. A design science approach, where IT artifacts are developed to solve problems and answer research questions is described. Research questions, progress on Citizen Sort planning and implementation, and key challenges are discussed.",citizen sort current develop webbas socialcomput system design support citizen scienc task taxonom classif variou insect anim plant speci addit support natur scienc object citizen sort platform also support inform scienc research goal motiv particip socialcomput citizen scienc particular research program address use game motiv particip socialcomput citizen scienc explor effect system design motiv data qualiti design scienc approach artifact develop solv problem answer research question describ research question progress citizen sort plan implement key challeng discuss
22158fa7321ef520c13f50c32b50feccfc1d5aa9,The Science of Real-Time Data Capture: Self-Reports in Health Research,"PART I: THE SCIENCE AND THEORY OF REAL-TIME DATA CAPTURE: A FOCUS ON ECOLOGICAL MOMENTARY ASSESSMENT (EMA) 1. Historical Roots and Rationale of Ecological Momentary Assessment (EMA) 2. Retrospective and Concurrent Self-Reports: The Rationale for Real-Time Data Capture 3. Designing Protocols for Ecological Momentary Assessment 4. Special Methodological Challenges and Opportunities in Ecological Momentary Assessment 5. The Analysis of Real-Time Momentary Data: A Practical Guide PART II: APPLICATION OF REAL-TIME DATA CAPTURE: EXEMPLARS OF REAL-TIME DATA RESEARCH 6. Real-Time Data Capture and Adolescent Cigarette Smoking: Moods and Smoking 7. Ecological Momentary Assessment of Physical Activity in Hispanics/Latinos Using Pedometers and Diaries 8. Dietary Assessment and Monitoring in Real-Time 9. Real-Time Data Capture: Ecological Momentary Assessment of Behavioral Symptoms Associated with Eating Disorders 10. Ecological Momentary Assessment for Alcohol Consumption 11. Assessing the Impact of Fibromyalgia Syndrome in Real-Time 12. Evaluating Fatigue of Ovarian Cancer Patients Using Ecological Momentary Assessment 13. Personality, Mood States, and Daily Health 14. Ecological Momentary Assessment as a Resource for Social Epidemiology PART III: FUTURE DEVELOPMENTS IN REAL-TIME DATA CAPTURE 15. Momentary Health Interventions: Where are we and where are we going? 16. Technological Innovations Enabling Automatic, Context-Sensitive Ecological Momentary Assessment 17. Statistical Issues in Intensive Longitudinal Data Analysis 18. Thoughts on the Present State of Real-Tmie Data Capture",part scienc theori realtim data captur focu ecolog momentari assess ema histor root rational ecolog momentari assess ema retrospect concurr selfreport rational realtim data captur design protocol ecolog momentari assess special methodolog challeng opportun ecolog momentari assess analysi realtim momentari data practic guid part ii applic realtim data captur exemplar realtim data research realtim data captur adolesc cigarett smoke mood smoke ecolog momentari assess physic activ hispanicslatino use pedomet diari dietari assess monitor realtim realtim data captur ecolog momentari assess behavior symptom associ eat disord ecolog momentari assess alcohol consumpt assess impact fibromyalgia syndrom realtim evalu fatigu ovarian cancer patient use ecolog momentari assess person mood state daili health ecolog momentari assess resourc social epidemiolog part iii futur develop realtim data captur momentari health intervent go technolog innov enabl automat contextsensit ecolog momentari assess statist issu intens longitudin data analysi thought present state realtmi data captur
966b08ae8efc07838c02fb5005bcc173f978b51d,A Comprehensive Survey of Clustering Algorithms,,nan
136a7a91676a7f812ab941372e4c1e006deeeddd,CODATA Recommended Values of the Fundamental Physical Constants: 2010 | NIST,"This paper gives the 2010 self-consistent set of values of the basic constants and conversion factors of physics and chemistry recommended by the Committee on Data for Science and Technology (CODATA) for international use. The 2010 adjustment takes into account the data considered in the 2006 adjustment as well as the data that became available from 1 January 2007, after the closing date of that adjustment, until 31 December 2010, the closing date of the new adjustment. Further, it describes in detail the adjustment of the values of the constants, including the selection of the final set of input data based on the results of least-squares analyses. The 2010 set replaces the previously recommended 2006 CODATA set and may also be found on the World Wide Web at physics.nist.gov/constants.",paper give selfconsist set valu basic constant convers factor physic chemistri recommend committe data scienc technolog codata intern use adjust take account data consid adjust well data becam avail januari close date adjust decemb close date new adjust describ detail adjust valu constant includ select final set input data base result leastsquar analys set replac previous recommend codata set may also found world wide web physicsnistgovconst
b22de434b462558a127f327f29e2b0c673c0d7ab,"Latent Dirichlet allocation (LDA) and topic modeling: models, applications, a survey",,nan
81da5bd490672b1fbf64826a11888e6c59a6f61e,Evaluating replicability of laboratory experiments in economics,"Another social science looks at itself Experimental economists have joined the reproducibility discussion by replicating selected published experiments from two top-tier journals in economics. Camerer et al. found that two-thirds of the 18 studies examined yielded replicable estimates of effect size and direction. This proportion is somewhat lower than unaffiliated experts were willing to bet in an associated prediction market, but roughly in line with expectations from sample sizes and P values. Science, this issue p. 1433 By several metrics, economics experiments do replicate, although not as often as predicted. The replicability of some scientific findings has recently been called into question. To contribute data about replicability in economics, we replicated 18 studies published in the American Economic Review and the Quarterly Journal of Economics between 2011 and 2014. All of these replications followed predefined analysis plans that were made publicly available beforehand, and they all have a statistical power of at least 90% to detect the original effect size at the 5% significance level. We found a significant effect in the same direction as in the original study for 11 replications (61%); on average, the replicated effect size is 66% of the original. The replicability rate varies between 67% and 78% for four additional replicability indicators, including a prediction market measure of peer beliefs.",anoth social scienc look experiment economist join reproduc discuss replic select publish experi two toptier journal econom camer et al found twothird studi examin yield replic estim effect size direct proport somewhat lower unaffili expert will bet associ predict market roughli line expect sampl size p valu scienc issu p sever metric econom experi replic although often predict replic scientif find recent call question contribut data replic econom replic studi publish american econom review quarterli journal econom replic follow predefin analysi plan made publicli avail beforehand statist power least detect origin effect size signific level found signific effect direct origin studi replic averag replic effect size origin replic rate vari four addit replic indic includ predict market measur peer belief
1c2bf15547506de420fb14a412c82506ab880975,Planck 2015 results. I. Overview of products and scientific results,"The European Space Agency's Planck satellite, dedicated to studying the early Universe and its subsequent evolution, was launched 14{\textasciitilde}May 2009and scanned the microwave and submillimetre sky continuously between12{\textasciitilde}August 2009 and 23{\textasciitilde}October 2013. In February{\textasciitilde}2015, ESA and the PlanckCollaboration released the second set of cosmology products based ondata from the entire Planck mission, including both temperature andpolarization, along with a set of scientific and technical papers and aweb-based explanatory supplement. This paper gives an overview of themain characteristics of the data and the data products in the release,as well as the associated cosmological and astrophysical science resultsand papers. The science products include maps of the cosmic microwavebackground (CMB), the thermal Sunyaev-Zeldovich effect, and diffuseforegrounds in temperature and polarization, catalogues of compactGalactic and extragalactic sources (including separate catalogues ofSunyaev-Zeldovich clusters and Galactic cold clumps), and extensivesimulations of signals and noise used in assessing the performance ofthe analysis methods and assessment of uncertainties. The likelihoodcode used to assess cosmological models against the Planck data aredescribed, as well as a CMB lensing likelihood. Scientific resultsinclude cosmological parameters deriving from CMB power spectra,gravitational lensing, and cluster counts, as well as constraints oninflation, non-Gaussianity, primordial magnetic fields, dark energy, andmodified gravity.",european space agenc planck satellit dedic studi earli univers subsequ evolut launch textasciitildemay scan microwav submillimetr sky continu betweentextasciitildeaugust textasciitildeoctob februarytextasciitild esa planckcollabor releas second set cosmolog product base ondata entir planck mission includ temperatur andpolar along set scientif technic paper awebbas explanatori supplement paper give overview themain characterist data data product releasea well associ cosmolog astrophys scienc resultsand paper scienc product includ map cosmic microwavebackground cmb thermal sunyaevzeldovich effect diffuseforeground temperatur polar catalogu compactgalact extragalact sourc includ separ catalogu ofsunyaevzeldovich cluster galact cold clump extensivesimul signal nois use assess perform ofth analysi method assess uncertainti likelihoodcod use assess cosmolog model planck data aredescrib well cmb lens likelihood scientif resultsinclud cosmolog paramet deriv cmb power spectragravit lens cluster count well constraint oninfl nongaussian primordi magnet field dark energi andmodifi graviti
622dc72bc883dd96a3538f45ba16491e39bd53cf,"The impacts of an invasive species citizen science training program on participant attitudes, behavior, and science literacy","Citizen science can make major contributions to informal science education by targeting participants’ attitudes and knowledge about science while changing human behavior towards the environment. We examined how training associated with an invasive species citizen science program affected participants in these areas. We found no changes in science literacy or overall attitudes between tests administered just before and after a one-day training program, matching results from other studies. However, we found improvements in science literacy and knowledge using context-specific measures and in self-reported intention to engage in pro-environmental activities. While we noted modest change in knowledge and attitudes, we found comparison and interpretation of these data difficult in the absence of other studies using similar measures. We suggest that alternative survey instruments are needed and should be calibrated appropriately to the pre-existing attitudes, behavior, and levels of knowledge in these relatively sophisticated target groups.",citizen scienc make major contribut inform scienc educ target particip attitud knowledg scienc chang human behavior toward environ examin train associ invas speci citizen scienc program affect particip area found chang scienc literaci overal attitud test administ oneday train program match result studi howev found improv scienc literaci knowledg use contextspecif measur selfreport intent engag proenvironment activ note modest chang knowledg attitud found comparison interpret data difficult absenc studi use similar measur suggest altern survey instrument need calibr appropri preexist attitud behavior level knowledg rel sophist target group
60e801e3dfc9812e294ed9de6d579e0293d61643,Probabilistic machine learning and artificial intelligence,,nan
54fc2d014bb417fbc13dbda61577d896195a7ce5,Sex and Science: How Professor Gender Perpetuates the Gender Gap,"Why aren't there more women in science? This paper begins to shed light on this question by exploiting data from the U.S. Air Force Academy, where students are randomly assigned to professors for a wide variety of mandatory standardized courses.We focus on the role of professor gender. Our results suggest that although professor gender has little impact on male students, it has a powerful effect on female students' performance in math and science classes, and high-performing female students' likelihood of taking future math and science courses, and graduating with a STEM degree. The estimates are largest for students whose SAT math scores are in the top 5% of the national distribution. The gender gap in course grades and STEM majors is eradicated when high-performing female students are assigned to female professors in mandatory introductory math and science coursework.",arent women scienc paper begin shed light question exploit data us air forc academi student randomli assign professor wide varieti mandatori standard coursesw focu role professor gender result suggest although professor gender littl impact male student power effect femal student perform math scienc class highperform femal student likelihood take futur math scienc cours graduat stem degre estim largest student whose sat math score top nation distribut gender gap cours grade stem major erad highperform femal student assign femal professor mandatori introductori math scienc coursework
621e8b30252ba4b6370382915a0586b437b82aca,Statistical Methods for Categorical Data Analysis,"This book provides a comprehensive introduction to methods and models for categorical data analysis and their applications in social science research. Companion website also available, at https://webspace.utexas.edu/dpowers/www/",book provid comprehens introduct method model categor data analysi applic social scienc research companion websit also avail httpswebspaceutexasedudpowerswww
f27b8071b1bb9168a4237c370980e5562c709dd7,"Big-Data Computing: Creating revolutionary breakthroughs in commerce, science, and society","Advances in digital sensors, communications, computation, and storage have created huge collections of data, capturing information of value to business, science, government, and society. For example, search engine companies such as Google, Yahoo!, and Microsoft have created an entirely new business by capturing the information freely available on the World Wide Web and providing it to people in useful ways. These companies collect trillions of bytes of data every day and continually add new services such as satellite images, driving directions, and image retrieval. The societal benefits of these services are immeasurable, having transformed how people find and make use of information on a daily basis.",advanc digit sensor commun comput storag creat huge collect data captur inform valu busi scienc govern societi exampl search engin compani googl yahoo microsoft creat entir new busi captur inform freeli avail world wide web provid peopl use way compani collect trillion byte data everi day continu add new servic satellit imag drive direct imag retriev societ benefit servic immeasur transform peopl find make use inform daili basi
d7c535ae48cc29f5e87f0a64c43a0c728080241e,Epistemologically Authentic Inquiry in Schools: A Theoretical Framework for Evaluating Inquiry Tasks,"A main goal of science education is to help students learn to reason scien- tifically. A main way to facilitate learning is to engage students in inquiry activities such as conducting experiments. This article presents a theoretical framework for evaluating inquiry tasks in terms of how similar they are to authentic science. The framework helps identify the respects in which these reasoning tasks are similar to and different from real scientific research. The framework is based on a recent theory of reasoning, models-of-data theory. We argue that inquiry tasks commonly used in schools evoke reasoning processes that are qualitatively different from the processes employed in real scientific inquiry. More- over, school reasoning tasks appear to be based on an epistemology that differs from the epistemology of authentic science. Inquiry tasks developed by researchers have increas- ingly captured features of authentic science, but further improvement is still possible. We conclude with a discussion of the implications of our analysis for research, assessment, and instruction. C",main goal scienc educ help student learn reason scien tific main way facilit learn engag student inquiri activ conduct experi articl present theoret framework evalu inquiri task term similar authent scienc framework help identifi respect reason task similar differ real scientif research framework base recent theori reason modelsofdata theori argu inquiri task commonli use school evok reason process qualit differ process employ real scientif inquiri school reason task appear base epistemolog differ epistemolog authent scienc inquiri task develop research increa ingli captur featur authent scienc improv still possibl conclud discuss implic analysi research assess instruct c
451ce6775150a829c0513a7e4fc86a1ec8095bf0,From Big Data to Knowledge in the Social Sciences,"One of the challenges associated with high-volume, diverse datasets is whether synthesis of open data streams can translate into actionable knowledge. Recognizing that challenge and other issues related to these types of data, the National Institutes of Health developed the Big Data to Knowledge or BD2K initiative. The concept of translating “big data to knowledge” is important to the social and behavioral sciences in several respects. First, a general shift to data-intensive science will exert an influence on all scientific disciplines, but particularly on the behavioral and social sciences given the wealth of behavior and related constructs captured by big data sources. Second, science is itself a social enterprise; by applying principles from the social sciences to the conduct of research, it should be possible to ameliorate some of the systemic problems that plague the scientific enterprise in the age of big data. We explore the feasibility of recalibrating the basic mechanisms of the scientific enterprise so that they are more transparent and cumulative; more integrative and cohesive; and more rapid, relevant, and responsive.",one challeng associ highvolum divers dataset whether synthesi open data stream translat action knowledg recogn challeng issu relat type data nation institut health develop big data knowledg bdk initi concept translat big data knowledg import social behavior scienc sever respect first gener shift dataintens scienc exert influenc scientif disciplin particularli behavior social scienc given wealth behavior relat construct captur big data sourc second scienc social enterpris appli principl social scienc conduct research possibl amelior system problem plagu scientif enterpris age big data explor feasibl recalibr basic mechan scientif enterpris transpar cumul integr cohes rapid relev respons
63aa61cd896ccab41cf55f4eabf57269705e917c,Numerical Data and Functional Relationships in Science and Technology - New Series.,,nan
71cb78088052d49bc93032636ef9e56bc7274e09,Statistics: The Art and Science of Learning from Data,"Part 1: Gathering and Exploring Data 1. Statistics: The Art and Science of Learning from Data 1.1 Using Data to Answer Statistical Questions 1.2 Sample Versus Population 1.3 Using Calculators and Computers Chapter Summary Chapter Problems 2. Exploring Data with Graphs and Numerical Summaries 2.1 Different Types of Data 2.2 Graphical Summaries of Data 2.3 Measuring the Center of Quantitative Data 2.4 Measuring the Variability of Quantitative Data 2.5 Using Measures of Position to Describe Variability 2.6 Recognizing and Avoiding Misuses of Graphical Summaries Chapter Summary Chapter Problems 3. Association: Contingency, Correlation, and Regression 3.1 The Association Between Two Categorical Variables 3.2 The Association Between Two Quantitative Variables 3.3 Predicting the Outcome of a Variable 3.4 Cautions in Analyzing Associations Chapter Summary Chapter Problems 4. Gathering Data 4.1 Experimental and Observational Studies 4.2 Good and Poor Ways to Sample 4.3 Good and Poor Ways to Experiment 4.4 Other Ways to Conduct Experimental and Nonexperimental Studies Chapter Summary Chapter Problems Part 1 Review Part 1 Questions Part 1 Exercises Part 2: Probability, Probability Distributions, and Sampling Distributions 5. Probability in Our Daily Lives 5.1 How Probability Quantifies Randomness 5.2 Finding Probabilities 5.3 Conditional Probability: The Probability of A Given B 5.4 Applying the Probability Rules Chapter Summary Chapter Problems 6. Probability Distributions 6.1 Summarizing Possible Outcomes and Their Probabilities 6.2 Probabilities for Bell-Shaped Distributions 6.3 Probabilities When Each Observation Has Two Possible Outcomes Chapter Summary Chapter Problems 7. Sampling Distributions 7.1 How Sample Proportions Vary Around the Population Proportion 7.2 How Sample Means Vary Around the Population Mean 7.3 The Binomial Distribution Is a Sampling Distribution (Optional) Chapter Summary Chapter Problems Part 2 Review Part 2 Questions Part 2 Exercises Part 3: Inferential Statistics 8. Statistical Inference: Confidence Intervals 8.1 Point and Interval Estimates of Population Parameters 8.2 Constructing a Confidence Interval to Estimate a Population Proportion 8.3 Constructing a Confidence Interval to Estimate a Population Mean 8.4 Choosing the Sample Size for a Study 8.5 Using Computers to Make New Estimation Methods Possible Chapter Summary Chapter Problems 9. Statistical Inference: Significance Tests about Hypotheses 9.1 Steps for Performing a Significance Test 9.2 Significance Tests about Proportions 9.3 Significance Tests about Means 9.4 Decisions and Types of Errors in Significance Tests 9.5 Limitations of Significance Tests 9.6 The Likelihood of a Type II Error (Not Rejecting H0, Even Though It's False) Chapter Summary Chapter Problems 10. Comparing Two Groups 10.1 Categorical Response: Comparing Two Proportions 10.2 Quantitative Response: Comparing Two Means 10.3 Other Ways of Comparing Means and Comparing Proportions 10.4 Analyzing Dependent Samples 10.5 Adjusting for the Effects of Other Variables Chapter Summary Chapter Problems Part 3 Review Part 3 Questions Part 3 Exercises Part 4: Analyzing Association and Extended Statistical Methods 11. Analyzing the Association Between Categorical Variables 11.1 Independence and Association 11.2 Testing Categorical Variables for Independence 11.3 Determining the Strength of the Association 11.4 Using Residuals to Reveal the Pattern of Association 11.5 Small Sample Sizes: Fisher's Exact Test Chapter Summary Chapter Problems 12. Analyzing the Association Between Quantitative Variables: Regression Analysis 12.1 Model How Two Variables Are Related 12.2 Describe Strength of Association 12.3 Make Inference About the Association 12.4How the Data Vary Around the Regression Line 12.5 Exponential Regression: A Model for Nonlinearity Chapter Summary Chapter Problems 13. Multiple Regression 13.1 Using Several Variables to Predict a Response 13.2 Extending the Correlation and R-squared for Multiple Regression 13.3 Using Multiple Regression to Make Inferences 13.4 Checking a Regression Model Using Residual Plots 13.5 Regression and Categorical Predictors 13.6 Modeling a Categorical Response Chapter Summary Chapter Problems 14. Comparing Groups: Analysis of Variance Methods 14.1 One-Way ANOVA: Comparing Several Means 14.2 Estimating Differences in Groups for a Single Factor 14.3 Two-Way ANOVA Chapter Summary Chapter Problems 15. Nonparametric Statistics 15.1 Compare Two Groups by Ranking 15.2 Nonparametric Methods For Several Groups and for Matched Pairs Chapter Summary Chapter Problems PART 4 Review Part 4 Questions Part 4 Exercises Tables Answers Index Index of Applications Photo Credits",part gather explor data statist art scienc learn data use data answer statist question sampl versu popul use calcul comput chapter summari chapter problem explor data graph numer summari differ type data graphic summari data measur center quantit data measur variabl quantit data use measur posit describ variabl recogn avoid misus graphic summari chapter summari chapter problem associ conting correl regress associ two categor variabl associ two quantit variabl predict outcom variabl caution analyz associ chapter summari chapter problem gather data experiment observ studi good poor way sampl good poor way experi way conduct experiment nonexperiment studi chapter summari chapter problem part review part question part exercis part probabl probabl distribut sampl distribut probabl daili live probabl quantifi random find probabl condit probabl probabl given b appli probabl rule chapter summari chapter problem probabl distribut summar possibl outcom probabl probabl bellshap distribut probabl observ two possibl outcom chapter summari chapter problem sampl distribut sampl proport vari around popul proport sampl mean vari around popul mean binomi distribut sampl distribut option chapter summari chapter problem part review part question part exercis part inferenti statist statist infer confid interv point interv estim popul paramet construct confid interv estim popul proport construct confid interv estim popul mean choos sampl size studi use comput make new estim method possibl chapter summari chapter problem statist infer signific test hypothes step perform signific test signific test proport signific test mean decis type error signific test limit signific test likelihood type ii error reject h even though fals chapter summari chapter problem compar two group categor respons compar two proport quantit respons compar two mean way compar mean compar proport analyz depend sampl adjust effect variabl chapter summari chapter problem part review part question part exercis part analyz associ extend statist method analyz associ categor variabl independ associ test categor variabl independ determin strength associ use residu reveal pattern associ small sampl size fisher exact test chapter summari chapter problem analyz associ quantit variabl regress analysi model two variabl relat describ strength associ make infer associ data vari around regress line exponenti regress model nonlinear chapter summari chapter problem multipl regress use sever variabl predict respons extend correl rsquar multipl regress use multipl regress make infer check regress model use residu plot regress categor predictor model categor respons chapter summari chapter problem compar group analysi varianc method oneway anova compar sever mean estim differ group singl factor twoway anova chapter summari chapter problem nonparametr statist compar two group rank nonparametr method sever group match pair chapter summari chapter problem part review part question part exercis tabl answer index index applic photo credit
1110eb8dadaa11b15a5b5e7f31d67d9edea4de1f,An empirical test of a taxonomy of responses to anomalous data in science.,"The purpose of this study was to test a taxonomy of seven proposed responses to anomalous data. Our results generally supported the taxonomy but indicated that one additional type of response should be added to the taxonomy. We conclude that there are eight possible responses to anomalous data: (a) ignoring the data, (b) rejecting the data, (c) professing uncertainty about the validity of the data, (d) excluding the data from the domain of the current theory, (e) holding the data in abeyance, (f) reinter- preting the data, (g) accepting the data and making peripheral changes to the current theory, and (h) ac- cepting the data and changing theories. We suggest that this taxonomy could help science teachers in two ways. First, science teachers could use the taxonomy to try to anticipate how students might react to anom- alous data so as to make theory change more likely. Second, science teachers could use the taxonomy as a framework to guide classroom discussion about the nature of scientific rationality. In addition, the tax- onomy suggests directions for future research. © 1998 John Wiley & Sons, Inc. J Res Sci Teach 35: 623-654, 1998.",purpos studi test taxonomi seven propos respons anomal data result gener support taxonomi indic one addit type respons ad taxonomi conclud eight possibl respons anomal data ignor data b reject data c profess uncertainti valid data exclud data domain current theori e hold data abey f reinter prete data g accept data make peripher chang current theori h ac cept data chang theori suggest taxonomi could help scienc teacher two way first scienc teacher could use taxonomi tri anticip student might react anom alou data make theori chang like second scienc teacher could use taxonomi framework guid classroom discuss natur scientif ration addit tax onomi suggest direct futur research john wiley son inc j re sci teach
80e1b3691efb64233fa7c5e39f15f1eff7f14110,The elements of graphing data,,nan
a6a3ba5fd69fb8d4b5618cff865fed5870772eea,Enhancing the Quality and Trust of Citizen Science Data,"The Internet, Web 2.0 and Social Networking technologies are enabling citizens to actively participate in “citizen science” projects by contributing data to scientific programs. However, the limited expertise of contributors can lead to poor quality or misleading data being submitted. Subsequently, the scientific community often perceive citizen science data as not worthy of being used in serious scientific research. In this paper, we describe a technological framework that combines data quality improvements and trust metrics to enhance the reliability of citizen science data. We describe how trust models provide a simple and effective mechanism for measuring the reliability of community-generated data. We also describe filtering services that remove untrustworthy data, and enable confident re-use of the data. The resulting services are evaluated in the context of the Coral Watch project which uses volunteers to collect data on coral reef bleaching.",internet web social network technolog enabl citizen activ particip citizen scienc project contribut data scientif program howev limit expertis contributor lead poor qualiti mislead data submit subsequ scientif commun often perceiv citizen scienc data worthi use seriou scientif research paper describ technolog framework combin data qualiti improv trust metric enhanc reliabl citizen scienc data describ trust model provid simpl effect mechan measur reliabl communitygener data also describ filter servic remov untrustworthi data enabl confid reus data result servic evalu context coral watch project use volunt collect data coral reef bleach
3cc66978dd00260c94ad8d99cfeec4821846565f,Managing and Mining Graph Data,,nan
3627e71e8ca6d87b10699ed5432424afd921d3fa,Landolt-Börnstein: Numerical Data and Functional Relationships in Science and Technology - New Series,"This book provides an introduction to Quantum Field Theory (QFT) at an elementary level—with only special relativity, electromagnetism and quantum mechanics as prerequisites. For this fresh approach to teaching QFT, based on numerous lectures and courses given by the authors, a representative sample of topics has been selected containing some of the more innovative, challenging or subtle concepts. They are presented with a minimum of technical details, the discussion of the main ideas being more important than the presentation of the typically very technical mathematical details necessary to obtain the final results.",book provid introduct quantum field theori qft elementari levelwith special rel electromagnet quantum mechan prerequisit fresh approach teach qft base numer lectur cours given author repres sampl topic select contain innov challeng subtl concept present minimum technic detail discuss main idea import present typic technic mathemat detail necessari obtain final result
0d10f2efad55f6669376058b17bf00017e704aa4,Math and science motivation: A longitudinal examination of the links between choices and beliefs.,"This study addresses the longitudinal associations between youths' out-of-school activities, expectancies-values, and high school course enrollment in the domains of math and science. Data were collected on 227 youth who reported on their activity participation in 5th grade, expectancies-values in 6th and 10th grade, and courses taken throughout high school. Math and science course grades at 5th and 10th grade were gathered through school record data. Results indicated youths' math and science activity participation predicted their expectancies and values, which, in turn, predicted the number of high school courses above the predictive power of grades. Although there were mean-level differences between boys and girls on some of these indicators, relations among indicators did not significantly differ by gender.",studi address longitudin associ youth outofschool activ expectanciesvalu high school cours enrol domain math scienc data collect youth report activ particip th grade expectanciesvalu th th grade cours taken throughout high school math scienc cours grade th th grade gather school record data result indic youth math scienc activ particip predict expect valu turn predict number high school cours predict power grade although meanlevel differ boy girl indic relat among indic significantli differ gender
c51f841b17cbb5b521f0a6709597c5dd86127ff7,"Nonseparable, Stationary Covariance Functions for Space–Time Data","Geostatistical approaches to spatiotemporal prediction in environmental science, climatology, meteorology, and related fields rely on appropriate covariance models. This article proposes general classes of nonseparable, stationary covariance functions for spatiotemporal random processes. The constructions are directly in the space–time domain and do not depend on closed-form Fourier inversions. The model parameters can be associated with the data's spatial and temporal structures, respectively; and a covariance model with a readily interpretable space–time interaction parameter is fitted to wind data from Ireland.",geostatist approach spatiotempor predict environment scienc climatolog meteorolog relat field reli appropri covari model articl propos gener class nonsepar stationari covari function spatiotempor random process construct directli spacetim domain depend closedform fourier invers model paramet associ data spatial tempor structur respect covari model readili interpret spacetim interact paramet fit wind data ireland
060dc033e1959be59eb483bb2d7aa4ce209f1a76,Sublime frequencies:  The construction of sublime listening experiences in the sonification of scientific data,"In the past two decades, the sonification of scientific data – an auditory equivalent of data visualization in which data are turned into sounds – has become increasingly widespread, particularly as an artistic practice and as a means of popularizing science. Sonification is thus part of the recent trend, discussed in public understanding of science literature, towards increased emphasis on ‘interactivity’ and ‘crossovers’ between science and art as a response to the perceived crisis in the relationship between the sciences and their publics. However, sonification can also be understood as the latest iteration in a long tradition of theorizing the relations between nature, science and human experience. This article analyses the recent public fascination with sonification and argues that sonification grips public imaginations through the promise of sublime experiences. I show how the ‘auditory sublime’ is constructed through varying combinations of technological, musical and rhetorical strategies. Rather than maintain a singular conception of the auditory sublime, practitioners draw on many scientific and artistic repertoires. However, sound is often situated as an immersive and emotional medium in contrast to the supposedly more detached sense of vision. The public sonification discourse leaves intact this dichotomy, reinforcing the idea that sound has no place in specialist science.",past two decad sonif scientif data auditori equival data visual data turn sound becom increasingli widespread particularli artist practic mean popular scienc sonif thu part recent trend discuss public understand scienc literatur toward increas emphasi interact crossov scienc art respons perceiv crisi relationship scienc public howev sonif also understood latest iter long tradit theoriz relat natur scienc human experi articl analys recent public fascin sonif argu sonif grip public imagin promis sublim experi show auditori sublim construct vari combin technolog music rhetor strategi rather maintain singular concept auditori sublim practition draw mani scientif artist repertoir howev sound often situat immers emot medium contrast supposedli detach sens vision public sonif discours leav intact dichotomi reinforc idea sound place specialist scienc
cab9848f517e2b328f4e338120423260909579d4,ROC Curves for Continuous Data,"Bringing together all the relevant material to impart a clear understanding of how to analyze ROC curves, this book covers the fundamental theory as well as various special topics. It provides illustrative examples of the major methodological developments and includes as much of the mathematical theory as necessary without making the treatment too dense. The authors survey the uses made of the methodology across a range of different areas, from atmospheric science and geoscience to experimental psychology and sociology. They also list a number of websites from which software implementing the various techniques can be downloaded.",bring togeth relev materi impart clear understand analyz roc curv book cover fundament theori well variou special topic provid illustr exampl major methodolog develop includ much mathemat theori necessari without make treatment dens author survey use made methodolog across rang differ area atmospher scienc geoscienc experiment psycholog sociolog also list number websit softwar implement variou techniqu download
12747823c0346f027da877a0d98509f6984fee2c,Does Practical Work Really Work? A study of the effectiveness of practical work as a teaching and learning method in school science,"Many within the science education community and beyond see practical work carried out by students as an essential feature of science education. Questions have, however, been raised by some science educators about its effectiveness as a teaching and learning strategy. This study explored the effectiveness of practical work by analysing a sample of 25 ‘typical’ science lessons involving practical work in English secondary schools. Data took the form of observational field notes and tape‐recorded interviews with teachers and students. The analysis used a model of effectiveness based on the work of Millar et al. and Tiberghien. The teachers’ focus in these lessons was predominantly on developing students’ substantive scientific knowledge, rather than on developing understanding of scientific enquiry procedures. Practical work was generally effective in getting students to do what is intended with physical objects, but much less effective in getting them to use the intended scientific ideas to guide their actions and reflect upon the data they collect. There was little evidence that the cognitive challenge of linking observables to ideas is recognized by those who design practical activities for science lessons. Tasks rarely incorporated explicit strategies to help students to make such links, or were presented in class in ways that reflected the size of the learning demand. The analytical framework used in this study offers a means of assessing the learning demand of practical tasks, and identifying those that require specific support for students’ thinking and learning in order to be effective.",mani within scienc educ commun beyond see practic work carri student essenti featur scienc educ question howev rais scienc educ effect teach learn strategi studi explor effect practic work analys sampl typic scienc lesson involv practic work english secondari school data took form observ field note taperecord interview teacher student analysi use model effect base work millar et al tiberghien teacher focu lesson predominantli develop student substant scientif knowledg rather develop understand scientif enquiri procedur practic work gener effect get student intend physic object much less effect get use intend scientif idea guid action reflect upon data collect littl evid cognit challeng link observ idea recogn design practic activ scienc lesson task rare incorpor explicit strategi help student make link present class way reflect size learn demand analyt framework use studi offer mean assess learn demand practic task identifi requir specif support student think learn order effect
c51f841b17cbb5b521f0a6709597c5dd86127ff7,"Nonseparable, Stationary Covariance Functions for Space–Time Data","Geostatistical approaches to spatiotemporal prediction in environmental science, climatology, meteorology, and related fields rely on appropriate covariance models. This article proposes general classes of nonseparable, stationary covariance functions for spatiotemporal random processes. The constructions are directly in the space–time domain and do not depend on closed-form Fourier inversions. The model parameters can be associated with the data's spatial and temporal structures, respectively; and a covariance model with a readily interpretable space–time interaction parameter is fitted to wind data from Ireland.",geostatist approach spatiotempor predict environment scienc climatolog meteorolog relat field reli appropri covari model articl propos gener class nonsepar stationari covari function spatiotempor random process construct directli spacetim domain depend closedform fourier invers model paramet associ data spatial tempor structur respect covari model readili interpret spacetim interact paramet fit wind data ireland
060dc033e1959be59eb483bb2d7aa4ce209f1a76,Sublime frequencies:  The construction of sublime listening experiences in the sonification of scientific data,"In the past two decades, the sonification of scientific data – an auditory equivalent of data visualization in which data are turned into sounds – has become increasingly widespread, particularly as an artistic practice and as a means of popularizing science. Sonification is thus part of the recent trend, discussed in public understanding of science literature, towards increased emphasis on ‘interactivity’ and ‘crossovers’ between science and art as a response to the perceived crisis in the relationship between the sciences and their publics. However, sonification can also be understood as the latest iteration in a long tradition of theorizing the relations between nature, science and human experience. This article analyses the recent public fascination with sonification and argues that sonification grips public imaginations through the promise of sublime experiences. I show how the ‘auditory sublime’ is constructed through varying combinations of technological, musical and rhetorical strategies. Rather than maintain a singular conception of the auditory sublime, practitioners draw on many scientific and artistic repertoires. However, sound is often situated as an immersive and emotional medium in contrast to the supposedly more detached sense of vision. The public sonification discourse leaves intact this dichotomy, reinforcing the idea that sound has no place in specialist science.",past two decad sonif scientif data auditori equival data visual data turn sound becom increasingli widespread particularli artist practic mean popular scienc sonif thu part recent trend discuss public understand scienc literatur toward increas emphasi interact crossov scienc art respons perceiv crisi relationship scienc public howev sonif also understood latest iter long tradit theoriz relat natur scienc human experi articl analys recent public fascin sonif argu sonif grip public imagin promis sublim experi show auditori sublim construct vari combin technolog music rhetor strategi rather maintain singular concept auditori sublim practition draw mani scientif artist repertoir howev sound often situat immers emot medium contrast supposedli detach sens vision public sonif discours leav intact dichotomi reinforc idea sound place specialist scienc
cab9848f517e2b328f4e338120423260909579d4,ROC Curves for Continuous Data,"Bringing together all the relevant material to impart a clear understanding of how to analyze ROC curves, this book covers the fundamental theory as well as various special topics. It provides illustrative examples of the major methodological developments and includes as much of the mathematical theory as necessary without making the treatment too dense. The authors survey the uses made of the methodology across a range of different areas, from atmospheric science and geoscience to experimental psychology and sociology. They also list a number of websites from which software implementing the various techniques can be downloaded.",bring togeth relev materi impart clear understand analyz roc curv book cover fundament theori well variou special topic provid illustr exampl major methodolog develop includ much mathemat theori necessari without make treatment dens author survey use made methodolog across rang differ area atmospher scienc geoscienc experiment psycholog sociolog also list number websit softwar implement variou techniqu download
12747823c0346f027da877a0d98509f6984fee2c,Does Practical Work Really Work? A study of the effectiveness of practical work as a teaching and learning method in school science,"Many within the science education community and beyond see practical work carried out by students as an essential feature of science education. Questions have, however, been raised by some science educators about its effectiveness as a teaching and learning strategy. This study explored the effectiveness of practical work by analysing a sample of 25 ‘typical’ science lessons involving practical work in English secondary schools. Data took the form of observational field notes and tape‐recorded interviews with teachers and students. The analysis used a model of effectiveness based on the work of Millar et al. and Tiberghien. The teachers’ focus in these lessons was predominantly on developing students’ substantive scientific knowledge, rather than on developing understanding of scientific enquiry procedures. Practical work was generally effective in getting students to do what is intended with physical objects, but much less effective in getting them to use the intended scientific ideas to guide their actions and reflect upon the data they collect. There was little evidence that the cognitive challenge of linking observables to ideas is recognized by those who design practical activities for science lessons. Tasks rarely incorporated explicit strategies to help students to make such links, or were presented in class in ways that reflected the size of the learning demand. The analytical framework used in this study offers a means of assessing the learning demand of practical tasks, and identifying those that require specific support for students’ thinking and learning in order to be effective.",mani within scienc educ commun beyond see practic work carri student essenti featur scienc educ question howev rais scienc educ effect teach learn strategi studi explor effect practic work analys sampl typic scienc lesson involv practic work english secondari school data took form observ field note taperecord interview teacher student analysi use model effect base work millar et al tiberghien teacher focu lesson predominantli develop student substant scientif knowledg rather develop understand scientif enquiri procedur practic work gener effect get student intend physic object much less effect get use intend scientif idea guid action reflect upon data collect littl evid cognit challeng link observ idea recogn design practic activ scienc lesson task rare incorpor explicit strategi help student make link present class way reflect size learn demand analyt framework use studi offer mean assess learn demand practic task identifi requir specif support student think learn order effect
3e40ed4ba57a911d5780610ca31a358084669f11,"Analysis of Multivariate Social Science Data, Second Edition","When four of the leading researchers in the field of quantitative social sciences team up to write a book together, you can expect nothing less than a brilliant work. That is what the first edition of “Analysis of Multivariate Social Science Data” from 2002 was, and that’s what the current second edition is. This new edition contains additional chapters on regression analysis, confirmatory factor analysis including structural equation models, and multilevel models.",four lead research field quantit social scienc team write book togeth expect noth less brilliant work first edit analysi multivari social scienc data that current second edit new edit contain addit chapter regress analysi confirmatori factor analysi includ structur equat model multilevel model
6e42ed47688746c1a81b6e79ca562d6c9d0be12e,Big data: How do your data grow?,,nan
83bda2860fb4005b0316e8d5850f68100e3cdeb7,Lab Experiments Are a Major Source of Knowledge in the Social Sciences,"Experimental Economics The disciplines of social science, with the notable exception of psychology, have traditionally steered clear of laboratory. The field of economics, and in particular econometrics, has amassed an imposing arsenal of quantitative and statistical methods for analyzing observational data in assessing economic theory and in making causal inferences. More recently, laboratory experiments carried out under controlled conditions and randomized field experiments carried out under natural conditions have gained some currency as complementary approaches. Falk and Heckman (p. 535) review the strengths and shortfalls of these recent developments. Laboratory experiments are a widely used methodology for advancing causal knowledge in the physical and life sciences. With the exception of psychology, the adoption of laboratory experiments has been much slower in the social sciences, although during the past two decades the use of lab experiments has accelerated. Nonetheless, there remains considerable resistance among social scientists who argue that lab experiments lack “realism” and generalizability. In this article, we discuss the advantages and limitations of laboratory social science experiments by comparing them to research based on nonexperimental data and to field experiments. We argue that many recent objections against lab experiments are misguided and that even more lab experiments should be conducted.",experiment econom disciplin social scienc notabl except psycholog tradit steer clear laboratori field econom particular econometr amass impos arsen quantit statist method analyz observ data assess econom theori make causal infer recent laboratori experi carri control condit random field experi carri natur condit gain currenc complementari approach falk heckman p review strength shortfal recent develop laboratori experi wide use methodolog advanc causal knowledg physic life scienc except psycholog adopt laboratori experi much slower social scienc although past two decad use lab experi acceler nonetheless remain consider resist among social scientist argu lab experi lack realism generaliz articl discuss advantag limit laboratori social scienc experi compar research base nonexperiment data field experi argu mani recent object lab experi misguid even lab experi conduct
9849ff80a6e3d0ede2f726940901c70a88cb7116,An online algorithm for segmenting time series,"In recent years, there has been an explosion of interest in mining time-series databases. As with most computer science problems, representation of the data is the key to efficient and effective solutions. One of the most commonly used representations is piecewise linear approximation. This representation has been used by various researchers to support clustering, classification, indexing and association rule mining of time-series data. A variety of algorithms have been proposed to obtain this representation, with several algorithms having been independently rediscovered several times. In this paper, we undertake the first extensive review and empirical comparison of all proposed techniques. We show that all these algorithms have fatal flaws from a data-mining perspective. We introduce a novel algorithm that we empirically show to be superior to all others in the literature.",recent year explos interest mine timeseri databas comput scienc problem represent data key effici effect solut one commonli use represent piecewis linear approxim represent use variou research support cluster classif index associ rule mine timeseri data varieti algorithm propos obtain represent sever algorithm independ rediscov sever time paper undertak first extens review empir comparison propos techniqu show algorithm fatal flaw datamin perspect introduc novel algorithm empir show superior other literatur
104ddf3dbb59096999ae310eea6771dcd3d7f252,Data Mining with Decision Trees: Theory and Applications,"Decision trees have become one of the most powerful and popular approaches in knowledge discovery and data mining; it is the science of exploring large and complex bodies of data in order to discover useful patterns. Decision tree learning continues to evolve over time. Existing methods are constantly being improved and new methods introduced. This 2nd Edition is dedicated entirely to the field of decision trees in data mining; to cover all aspects of this important technique, as well as improved or new methods and techniques developed after the publication of our first edition. In this new edition, all chapters have been revised and new topics brought in. New topics include Cost-Sensitive Active Learning, Learning with Uncertain and Imbalanced Data, Using Decision Trees beyond Classification Tasks, Privacy Preserving Decision Tree Learning, Lessons Learned from Comparative Studies, and Learning Decision Trees for Big Data. A walk-through guide to existing open-source data mining software is also included in this edition. This book invites readers to explore the many benefits in data mining that decision trees offer: Self-explanatory and easy to follow when compacted Able to handle a variety of input data: nominal, numeric and textual Scales well to big data Able to process datasets that may have errors or missing values High predictive performance for a relatively small computational effort Available in many open source data mining packages over a variety of platforms Useful for various tasks, such as classification, regression, clustering and feature selection Readership: Researchers, graduate and undergraduate students in information systems, engineering, computer science, statistics and management.",decis tree becom one power popular approach knowledg discoveri data mine scienc explor larg complex bodi data order discov use pattern decis tree learn continu evolv time exist method constantli improv new method introduc nd edit dedic entir field decis tree data mine cover aspect import techniqu well improv new method techniqu develop public first edit new edit chapter revis new topic brought new topic includ costsensit activ learn learn uncertain imbalanc data use decis tree beyond classif task privaci preserv decis tree learn lesson learn compar studi learn decis tree big data walkthrough guid exist opensourc data mine softwar also includ edit book invit reader explor mani benefit data mine decis tree offer selfexplanatori easi follow compact abl handl varieti input data nomin numer textual scale well big data abl process dataset may error miss valu high predict perform rel small comput effort avail mani open sourc data mine packag varieti platform use variou task classif regress cluster featur select readership research graduat undergradu student inform system engin comput scienc statist manag
128c49a834e06409af15001de12c351fcacbf74b,Information Sciences,"The information sciences provide tools for deductive reasoning to supplement the classifications made by the data sciences and the explanations made by explanatory models. Formal ontologies provide a unifying framework for organizing definitions, research findings, and theories. One of the primary purposes of a formal ontology is to use deductive reasoning to answer questions submitted to computer. A general or upper oncology is required to integrate more specialized domain ontologies. The Suggested Upper Merged Ontology is particularly helpful because it consists of 20,000 concepts with connections to both WordNet and FrameNet. WordNet is an electronic dictionary while FrameNet captures co-occurrences of words to provide a thematic context in which words occur. Together, WordNet, FrameNet, and the Suggested Upper Merged Ontology provide an integration of three major information science tools.",inform scienc provid tool deduct reason supplement classif made data scienc explan made explanatori model formal ontolog provid unifi framework organ definit research find theori one primari purpos formal ontolog use deduct reason answer question submit comput gener upper oncolog requir integr special domain ontolog suggest upper merg ontolog particularli help consist concept connect wordnet framenet wordnet electron dictionari framenet captur cooccurr word provid themat context word occur togeth wordnet framenet suggest upper merg ontolog provid integr three major inform scienc tool
16c9a99680bda420806a6df5e34ede696868db94,Privacy-Preserving Data Mining: Models and Algorithms,"Advances in hardware technology have increased the capability to store and record personal data about consumers and individuals, causing concerns that personal data may be used for a variety of intrusive or malicious purposes. Privacy-Preserving Data Mining: Models and Algorithms proposes a number of techniques to perform the data mining tasks in a privacy-preserving way. These techniques generally fall into the following categories: data modification techniques, cryptographic methods and protocols for data sharing, statistical techniques for disclosure and inference control, query auditing methods, randomization and perturbation-based techniques. This edited volume contains surveys by distinguished researchers in the privacy field. Each survey includes the key research content as well as future research directions. Privacy-Preserving Data Mining: Models and Algorithms is designed for researchers, professors, and advanced-level students in computer science, and is also suitable for industry practitioners.",advanc hardwar technolog increas capabl store record person data consum individu caus concern person data may use varieti intrus malici purpos privacypreserv data mine model algorithm propos number techniqu perform data mine task privacypreserv way techniqu gener fall follow categori data modif techniqu cryptograph method protocol data share statist techniqu disclosur infer control queri audit method random perturbationbas techniqu edit volum contain survey distinguish research privaci field survey includ key research content well futur research direct privacypreserv data mine model algorithm design research professor advancedlevel student comput scienc also suitabl industri practition
de6fcef4febe3d8acd6f7ecc272baeee41355640,Beyond the Data Deluge,The demands of data-intensive science represent a challenge for diverse scientific communities.,demand dataintens scienc repres challeng divers scientif commun
991b6e7ada8f6538cde1debb3b890c614b9bdbc5,"Big Data, data integrity, and the fracturing of the control zone","Despite all the attention to Big Data and the claims that it represents a “paradigm shift” in science, we lack understanding about what are the qualities of Big Data that may contribute to this revolutionary impact. In this paper, we look beyond the quantitative aspects of Big Data (i.e. lots of data) and examine it from a sociotechnical perspective. We argue that a key factor that distinguishes “Big Data” from “lots of data” lies in changes to the traditional, well-established “control zones” that facilitated clear provenance of scientific data, thereby ensuring data integrity and providing the foundation for credible science. The breakdown of these control zones is a consequence of the manner in which our network technology and culture enable and encourage open, anonymous sharing of information, participation regardless of expertise, and collaboration across geographic, disciplinary, and institutional barriers. We are left with the conundrum—how to reap the benefits of Big Data while re-creating a trust fabric and an accountable chain of responsibility that make credible science possible.",despit attent big data claim repres paradigm shift scienc lack understand qualiti big data may contribut revolutionari impact paper look beyond quantit aspect big data ie lot data examin sociotechn perspect argu key factor distinguish big data lot data lie chang tradit wellestablish control zone facilit clear proven scientif data therebi ensur data integr provid foundat credibl scienc breakdown control zone consequ manner network technolog cultur enabl encourag open anonym share inform particip regardless expertis collabor across geograph disciplinari institut barrier left conundrumhow reap benefit big data recreat trust fabric account chain respons make credibl scienc possibl
e8556def981f064bfafafa98f3bd36a9aa32b044,Citation analysis as a tool in journal evaluation.,"As a communications system, the network of journals that play a paramount role in the exchange of scientific and technical information is little understood. Periodically since 1927, when Gross and Gross published their study (1) of references in 1 year’s issues of the Journal of the American Chemical Socie/y, pieces of the network have been illuminated by the work of Bradford (2), Allen (3), Gross and Woodford (4), Hooker (5), Henkle (6), Fussier (7), Brown (8), and others (9). Nevertheless, there is still no map of the journal network as a whok. To date, studies of the network and of the interrelation of its components have been limited in the number of journak, the areas of scientific study, and the periods of time their authors were able to consider, Such shortcomings have not been due to any lack of purpose, insight, or energy on the part of investigators, but to the practical difficulty of compiling and manipulating manually the enormous amount of necessary data. A solution to this problem of data is available in the data base used to produce the Science Citation Index ( SCI ) (10). The coverage of the SCI is international and multidisciplinary; it has grown from 600 journals in 1964 to 2400 journals in 1972, and now includes the world’s most important scientific and technical journals in mow disciplines. The SCI is published quarterly and is cumulated annually and quinquennially, but the data base from which the volumes are compiled is maintained on magnetic tape and is updated weekly. At the end of 1971, this data base contained more than 27 mi[tion references to about 10 million different published items. These references appeared over the past decade in the footnotes and bibliographies of more than 2 million journal articles, communications, letters, and so on. The data base is, thus, not only multidisciplinary, it covers a substantial period of time and, being in machine-readable form, is amenable to extensive manipulation by computer. In 1971, the Institute for Scientfic Information (1S1) decided to undertake a systematic analysis of journal citation patterns across the whole of science and technology. It began by extracting from the data base all references pobIished during the last quarter of 1969 in the 2200 journals then covered by the SCL The resultant sample was about 1 million citations of journals, books, reports, theses, and so forth. To test whether this 3-month sample was representative of the year as a whole, it was matched against another sample made by selecting every 27th reference from the approximately 4 million references collected over the entire year. The two samples were similar enough in scope (number of diflerent items cited) and detail (relative frequency of their citation by different journals) to",commun system network journal play paramount role exchang scientif technic inform littl understood period sinc gross gross publish studi refer year issu journal american chemic sociey piec network illumin work bradford allen gross woodford hooker henkl fussier brown other nevertheless still map journal network whok date studi network interrel compon limit number journak area scientif studi period time author abl consid shortcom due lack purpos insight energi part investig practic difficulti compil manipul manual enorm amount necessari data solut problem data avail data base use produc scienc citat index sci coverag sci intern multidisciplinari grown journal journal includ world import scientif technic journal mow disciplin sci publish quarterli cumul annual quinquenni data base volum compil maintain magnet tape updat weekli end data base contain mition refer million differ publish item refer appear past decad footnot bibliographi million journal articl commun letter data base thu multidisciplinari cover substanti period time machineread form amen extens manipul comput institut scientfic inform decid undertak systemat analysi journal citat pattern across whole scienc technolog began extract data base refer pobiish last quarter journal cover scl result sampl million citat journal book report these forth test whether month sampl repres year whole match anoth sampl made select everi th refer approxim million refer collect entir year two sampl similar enough scope number difler item cite detail rel frequenc citat differ journal
7484ddebd54457816d916f7c016b549a24f2b0e6,Mastering Data Mining: The Art and Science of Customer Relationship Management,"From the Publisher: 
""Berry and Linoff lead the reader down an enlightened path of best practices."" -Dr. Jim Goodnight, President and Cofounder, SAS Institute Inc.""This is a great book, and it will be in my stack of four or five essential resources for my professional work."" -Ralph Kimball, Author of The Data Warehouse Lifecycle ToolkitMastering Data MiningIn this follow-up to their successful first book, Data Mining Techniques, Michael J. A. Berry and Gordon S. Linoff offer a case study-based guide to best practices in commercial data mining. Their first book acquainted you with the new generation of data mining tools and techniques and showed you how to use them to make better business decisions. Mastering Data Mining shifts the focus from understanding data mining techniques to achieving business results, placing particular emphasis on customer relationship management.In this book, you'll learn how to apply data mining techniques to solve practical business problems. After providing the fundamental principles of data mining and customer relationship management, Berry and Linoff share the lessons they have learned through a series of warts-and-all case studies drawn from their experience in a variety of industries, including e-commerce, banking, cataloging, retailing, and telecommunications.Through the cases, you will learn how to formulate the business problem, analyze the data, evaluate the results, and utilize this information for similar business problems in different industries.Berry and Linoff show you how to use data mining to:* Retain customer loyalty* Target the right prospects* Identify new markets for products and services* Recognize cross-selling opportunities on and off the Web. Thecompanion Web site features:* Updated information on data mining products and service providers* Information on data mining conferences, courses, and other sources of information* Full-color versions of the illustrations used in the book",publish berri linoff lead reader enlighten path best practic dr jim goodnight presid cofound sa institut incthi great book stack four five essenti resourc profession work ralph kimbal author data warehous lifecycl toolkitmast data miningin followup success first book data mine techniqu michael j berri gordon linoff offer case studybas guid best practic commerci data mine first book acquaint new gener data mine tool techniqu show use make better busi decis master data mine shift focu understand data mine techniqu achiev busi result place particular emphasi custom relationship managementin book youll learn appli data mine techniqu solv practic busi problem provid fundament principl data mine custom relationship manag berri linoff share lesson learn seri wartsandal case studi drawn experi varieti industri includ ecommerc bank catalog retail telecommunicationsthrough case learn formul busi problem analyz data evalu result util inform similar busi problem differ industriesberri linoff show use data mine retain custom loyalti target right prospect identifi new market product servic recogn crosssel opportun web thecompanion web site featur updat inform data mine product servic provid inform data mine confer cours sourc inform fullcolor version illustr use book
215be270e66623e0320c8f3d0893a5500b2bc52e,The high-throughput highway to computational materials design.,,nan
da559bd90f2490f58ad91f7d43bab26823239f2c,A rational analysis of the selection task as optimal data selection.,"Human reasoning in hypothesis-testing tasks like P. C. Wason's (1968) selection task has been depicted as prone to systematic biases. However, performance on this task has been assessed against a now outmoded falsificationist philosophy of science. Therefore, the experimental data is reassessed in the light of a Bayesian model of optimal data selection in inductive hypothesis testing. The model provides a rational analysis (J. R. Anderson, 1990) of the selection task that fits well with people's performance on both abstract and thematic versions of the task. The model suggests that reasoning in these tasks may be rational rather than subject to systematic bias.",human reason hypothesistest task like p c wason select task depict prone systemat bias howev perform task assess outmod falsificationist philosophi scienc therefor experiment data reassess light bayesian model optim data select induct hypothesi test model provid ration analysi j r anderson select task fit well peopl perform abstract themat version task model suggest reason task may ration rather subject systemat bia
80c5d486c73bc43fcbbfcfbbb1971c1a72a8f27b,Artificial Intelligence in Human Resources Management: Challenges and a Path Forward,"There is a substantial gap between the promise and reality of artificial intelligence in human resource (HR) management. This article identifies four challenges in using data science techniques for HR tasks: complexity of HR phenomena, constraints imposed by small data sets, accountability questions associated with fairness and other ethical and legal constraints, and possible adverse employee reactions to management decisions via data-based algorithms. It then proposes practical responses to these challenges based on three overlapping principles—causal reasoning, randomization and experiments, and employee contribution—that would be both economically efficient and socially appropriate for using data science in the management of employees.",substanti gap promis realiti artifici intellig human resourc hr manag articl identifi four challeng use data scienc techniqu hr task complex hr phenomena constraint impos small data set account question associ fair ethic legal constraint possibl advers employe reaction manag decis via databas algorithm propos practic respons challeng base three overlap principlescaus reason random experi employe contributionthat would econom effici social appropri use data scienc manag employe
100d5c0e10af860e734c61ca70222cf2fc6ec125,"Conceptual approaches for defining data, information, and knowledge","The field of Information Science is constantly changing. Therefore, information scientists are required to regularly review-and if necessary-redefine its fundamental building blocks. This article is one of a group of four articles, which resulted from a Critical Delphi study conducted in 2003-2005. The study, ""Knowledge Map of Information Science,"" was aimed at exploring the foundations of information science. The international panel was composed of 57 leading scholars from 16 countries, who represent (almost) all the major subfields and important aspects of the field. This particular article documents 130 definitions of data, information, and knowledge formulated by 45 scholars, and maps the major conceptual approaches for defining these three key concepts.",field inform scienc constantli chang therefor inform scientist requir regularli reviewand necessaryredefin fundament build block articl one group four articl result critic delphi studi conduct studi knowledg map inform scienc aim explor foundat inform scienc intern panel compos lead scholar countri repres almost major subfield import aspect field particular articl document definit data inform knowledg formul scholar map major conceptu approach defin three key concept
113a347b4d0682067d14685500a1689cdccb50e3,Analysis of Multivariate Social Science Data,"Preface Setting the Scene Structure of the book Our limited use of mathematics Variables The geometry of multivariate analysis Use of examples Data inspection, transformations, and missing data Cluster Analysis Classification in social sciences Some methods of cluster analysis Graphical presentation of results Derivation of the distance matrix Example on English dialects Comparisons Clustering variables Further examples and suggestions for further work Multidimensional Scaling Introduction Examples Classical, ordinal, and metrical multidimensional scaling Comments on computational procedures Assessing fit and choosing the number of dimensions A worked example: dimensions of color vision Further examples and suggestions for further work Correspondence Analysis Aims of correspondence analysis Carrying out a correspondence analysis: a simple numerical example Carrying out a correspondence analysis: the general method The biplot Interpretation of dimensions Choosing the number of dimensions Example: confidence in purchasing from European Community countries Correspondence analysis of multiway tables Further examples and suggestions for further work Principal Components Analysis Introduction Some potential applications Illustration of PCA for two variables An outline of PCA Examples Component scores The link between PCA and multidimensional scaling and between PCA and correspondence analysis Using principal component scores to replace the original variables Further examples and suggestions for further work NEW! Regression Analysis Basic ideas Simple linear regression A probability model for simple linear regression Inference for the simple linear regression model Checking the assumptions Multiple regression Examples of multiple regression Estimation and inference about the parameters Interpretation of the regression coefficients Selection of regressor variables Transformations and interactions Logistic regression Path analysis Further examples and suggestions for further work Factor Analysis Introduction to latent variable models The linear single-factor model The general linear factor model Interpretation Adequacy of the model and choice of the number of factors Rotation Factor scores A worked example: the test anxiety inventory How rotation helps interpretation A comparison of factor analysis and principal components analysis Further examples and suggestions for further work Software Factor Analysis for Binary Data Latent trait models Why is the factor analysis model for metrical variables invalid for binary responses? Factor model for binary data using the item response theory approach Goodness-of-fit Factor scores Rotation Underlying variable approach Example: sexual attitudes Further examples and suggestions for further work Software Factor Analysis for Ordered Categorical Variables The practical background Two approaches to modeling ordered categorical data Item response function approach Examples The underlying variable approach Unordered and partially ordered observed variables Further examples and suggestions for further work Software Latent Class Analysis for Binary Data Introduction The latent class model for binary data Example: attitude to science and technology data How can we distinguish the latent class model from the latent trait model? Latent class analysis, cluster analysis, and latent profile analysis Further examples and suggestions for further work Software NEW! Confirmatory Factor Analysis and Structural Equation Models Introduction Path diagram Measurement models Adequacy of the model Introduction to structural equation models with latent variables The linear structural equation model A worked example Extensions Further examples Software NEW! Multilevel Modeling Introduction Some potential applications Comparing groups using multilevel modeling Random intercept model Random slope model Contextual effects Multilevel multivariate regression Multilevel factor analysis Further examples and suggestions for further work Further topics Estimation procedures and software References Index Further reading sections appear at the end of each chapter.",prefac set scene structur book limit use mathemat variabl geometri multivari analysi use exampl data inspect transform miss data cluster analysi classif social scienc method cluster analysi graphic present result deriv distanc matrix exampl english dialect comparison cluster variabl exampl suggest work multidimension scale introduct exampl classic ordin metric multidimension scale comment comput procedur assess fit choos number dimens work exampl dimens color vision exampl suggest work correspond analysi aim correspond analysi carri correspond analysi simpl numer exampl carri correspond analysi gener method biplot interpret dimens choos number dimens exampl confid purchas european commun countri correspond analysi multiway tabl exampl suggest work princip compon analysi introduct potenti applic illustr pca two variabl outlin pca exampl compon score link pca multidimension scale pca correspond analysi use princip compon score replac origin variabl exampl suggest work new regress analysi basic idea simpl linear regress probabl model simpl linear regress infer simpl linear regress model check assumpt multipl regress exampl multipl regress estim infer paramet interpret regress coeffici select regressor variabl transform interact logist regress path analysi exampl suggest work factor analysi introduct latent variabl model linear singlefactor model gener linear factor model interpret adequaci model choic number factor rotat factor score work exampl test anxieti inventori rotat help interpret comparison factor analysi princip compon analysi exampl suggest work softwar factor analysi binari data latent trait model factor analysi model metric variabl invalid binari respons factor model binari data use item respons theori approach goodnessoffit factor score rotat underli variabl approach exampl sexual attitud exampl suggest work softwar factor analysi order categor variabl practic background two approach model order categor data item respons function approach exampl underli variabl approach unord partial order observ variabl exampl suggest work softwar latent class analysi binari data introduct latent class model binari data exampl attitud scienc technolog data distinguish latent class model latent trait model latent class analysi cluster analysi latent profil analysi exampl suggest work softwar new confirmatori factor analysi structur equat model introduct path diagram measur model adequaci model introduct structur equat model latent variabl linear structur equat model work exampl extens exampl softwar new multilevel model introduct potenti applic compar group use multilevel model random intercept model random slope model contextu effect multilevel multivari regress multilevel factor analysi exampl suggest work topic estim procedur softwar refer index read section appear end chapter
0888bb211901eaac37b19a7e4a5096006349c4d5,Manifesto of computational social science,,nan
d9aa7f330b5e790ca4817a8dcd9a8acf85149b8c,Qualitative Research Methods for Science Education,,nan
bcce25437e5e259bde08b32d7764d50cbebf0406,Ensuring the Data-Rich Future of the Social Sciences,"Massive increases in the availability of informative social science data are making dramatic progress possible in analyzing, understanding, and addressing many major societal problems. Yet the same forces pose severe challenges to the scientific infrastructure supporting data sharing, data management, informatics, statistical methodology, and research ethics and policy, and these are collectively holding back progress. I address these changes and challenges and suggest what can be done.",massiv increas avail inform social scienc data make dramat progress possibl analyz understand address mani major societ problem yet forc pose sever challeng scientif infrastructur support data share data manag informat statist methodolog research ethic polici collect hold back progress address chang challeng suggest done
2c2142a28eab7569c1c75a93c185d3c8c5152e51,Where's the evidence that active learning works?,"Calls for reforms in the ways we teach science at all levels, and in all disciplines, are wide spread. The effectiveness of the changes being called for, employment of student-centered, active learning pedagogy, is now well supported by evidence. The relevant data have come from a number of different disciplines that include the learning sciences, cognitive psychology, and educational psychology. There is a growing body of research within specific scientific teaching communities that supports and validates the new approaches to teaching that have been adopted. These data are reviewed, and their applicability to physiology education is discussed. Some of the inherent limitations of research about teaching and learning are also discussed.",call reform way teach scienc level disciplin wide spread effect chang call employ studentcent activ learn pedagogi well support evid relev data come number differ disciplin includ learn scienc cognit psycholog educ psycholog grow bodi research within specif scientif teach commun support valid new approach teach adopt data review applic physiolog educ discuss inher limit research teach learn also discuss
27b1cc9aeae9e5868dbbfa34f5a79cd561c523d8,"Sowing the seeds of ROSE : background, rationale, questionnaire development and data collection for ROSE (The Relevance of Science Education) : a comparative study of students’ views of science and science education",,nan
1bcdf65d707f7111dbe0f7c89545871e6523066b,Vegetation Description and Data Analysis: A Practical Approach,"Preface to the second edition ix Acknowledgements xi Safety in the field xiii Chapter 1 The nature of quantitative plant ecology and vegetation science 1 Chapter 2 Environmental gradients, plant communities and vegetation dynamics 23 Chapter 3 The description of vegetation in the field 49 Chapter 4 The nature and properties of vegetation data 101 Chapter 5 Basic statistical methods for understanding multivariate analysis 139 Chapter 6 Ordination methods 171 Chapter 7 Phytosociology and the Zurich-Montpellier (Braun-Blanquet) School of subjective classification 273 Chapter 8 Numerical classification, cluster analysis and phytosociology 307 Chapter 9 Computer software for the analysis of vegetation and environmental/biotic data 359 Chapter 10 Future developments in vegetation science and quantitative plant ecology 369 References 371 Index 403",prefac second edit ix acknowledg xi safeti field xiii chapter natur quantit plant ecolog veget scienc chapter environment gradient plant commun veget dynam chapter descript veget field chapter natur properti veget data chapter basic statist method understand multivari analysi chapter ordin method chapter phytosociolog zurichmontpelli braunblanquet school subject classif chapter numer classif cluster analysi phytosociolog chapter comput softwar analysi veget environmentalbiot data chapter futur develop veget scienc quantit plant ecolog refer index
55d7e9ebeaaef53110c4370d8a2530122f7d02af,"The use of terrestrial LiDAR technology in forest science: application fields, benefits and challenges",,nan
4f2e84f1c5ea7a0d5d8ebfa12a78a869f13d7b59,Deep learning for neural networks,"Machine learning algorithms are designed to improve as they encounter more data, making them a versatile technology for understanding large sets of photos such as those accessible from Google Images. Elizabeth Holm, professor of materials science and engineering at Carnegie Mellon University, is leveraging this technology to better understand the enormous number of research images accumulated in the field of materials science. [13]",machin learn algorithm design improv encount data make versatil technolog understand larg set photo access googl imag elizabeth holm professor materi scienc engin carnegi mellon univers leverag technolog better understand enorm number research imag accumul field materi scienc
014183ead7f85c417f15e806cac00027b1580e02,Model Selection,,nan
475bbf493d8246031a5152c8005a5c567231307c,Basis Set Exchange: A Community Database for Computational Sciences,"Basis sets are some of the most important input data for computational models in the chemistry, materials, biology, and other science domains that utilize computational quantum mechanics methods. Providing a shared, Web-accessible environment where researchers can not only download basis sets in their required format but browse the data, contribute new basis sets, and ultimately curate and manage the data as a community will facilitate growth of this resource and encourage sharing both data and knowledge. We describe the Basis Set Exchange (BSE), a Web portal that provides advanced browsing and download capabilities, facilities for contributing basis set data, and an environment that incorporates tools to foster development and interaction of communities. The BSE leverages and enables continued development of the basis set library originally assembled at the Environmental Molecular Sciences Laboratory.",basi set import input data comput model chemistri materi biolog scienc domain util comput quantum mechan method provid share webaccess environ research download basi set requir format brows data contribut new basi set ultim curat manag data commun facilit growth resourc encourag share data knowledg describ basi set exchang bse web portal provid advanc brows download capabl facil contribut basi set data environ incorpor tool foster develop interact commun bse leverag enabl continu develop basi set librari origin assembl environment molecular scienc laboratori
8570541f188469198e377ad6405b63e21e064f11,"Little science confronts the data deluge: habitat ecology, embedded sensor networks, and digital libraries",,nan
0476ddfada4efc840f38a71588afb6a88874e5dc,Data at work: supporting sharing in science and engineering,"Data are a fundamental component of science and engineering work, and the ability to share data is critical to the validation and progress of science. Data sharing and reuse in some fields, however, has proven to be a difficult problem. This paper argues that the development of effective CSCW systems to support data sharing in work groups requires a better understanding of the use of data in practice. Drawing on our work with three scientific disciplines, we show that data play two general roles in scientific communities: 1) they serve as evidence to support scientific inquiry, and 2) they make a social contribution to the establishment and maintenance of communities of practice. A clearer consideration and understanding of these roles can contribute to the design of more effective data sharing systems. We suggest that this can be achieved through supporting social interaction around data abstractions, reaching beyond current metadata models, and supporting the social roles of data.",data fundament compon scienc engin work abil share data critic valid progress scienc data share reus field howev proven difficult problem paper argu develop effect cscw system support data share work group requir better understand use data practic draw work three scientif disciplin show data play two gener role scientif commun serv evid support scientif inquiri make social contribut establish mainten commun practic clearer consider understand role contribut design effect data share system suggest achiev support social interact around data abstract reach beyond current metadata model support social role data
e53a4e19d7329965de877d0dfde5872f5cb007c7,Reasoning from data: How students collect and interpret data in science investigations,"This study explored the understandings of data and measurement that school students draw upon, and the ways that they reason from data, when carrying out a practical science inquiry task. The two practical tasks used in the study each involved investigations of the relationships between two independent variables (IVs) and a dependent variable (DV); in both tasks, one IV covaried with the DV, whereas the other did not. Each was undertaken by 10 students, aged 10, 12, and 14 years (total n = 60 students), working individually. Their actions were video-recorded for analysis. In a subsequent interview, each student was asked to discuss and interpret data collected by two other students, undertaking a similar (but different) practical task, shown on a video-recording. An analysis of the sample students' performance on the practical tasks and their interview responses showed few differences across task contexts, or with age, in students' reasoning, but significant differences in performance when investigating situations of covariation and non-covariation. Few students in the sample displayed sufficient understanding of measurement error to deal effectively with the latter. Investigations of non-covariation cases revealed, much more clearly than investigations of covariation cases, the students' ideas about data and measurement, and their ways of reasoning from data. Such investigations therefore provide particularly valuable contexts for teaching and research.",studi explor understand data measur school student draw upon way reason data carri practic scienc inquiri task two practic task use studi involv investig relationship two independ variabl iv depend variabl dv task one iv covari dv wherea undertaken student age year total n student work individu action videorecord analysi subsequ interview student ask discuss interpret data collect two student undertak similar differ practic task shown videorecord analysi sampl student perform practic task interview respons show differ across task context age student reason signific differ perform investig situat covari noncovari student sampl display suffici understand measur error deal effect latter investig noncovari case reveal much clearli investig covari case student idea data measur way reason data investig therefor provid particularli valuabl context teach research
c2c548403f0478b44fb007d0b0d2acbac313aeb3,CODATA key values for thermodynamics,"The Committee on Data for Science and Technology (CODATA) has conducted a project to establish internationally agreed values for the thermodynamic properties of key chemical substances. This table presents the final results of the project. Use of these recommended, internally consistent values is encouraged in the analysis of thermodynamic measurements, data reduction, and preparation of other thermodynamic tables. The table includes the standard enthalpy of formation at 298.15 K, the entropy at 298.15 K, and the quantity H ° (298.15 K)-H ° (0). A value of 0 in theD",committe data scienc technolog codata conduct project establish intern agre valu thermodynam properti key chemic substanc tabl present final result project use recommend intern consist valu encourag analysi thermodynam measur data reduct prepar thermodynam tabl tabl includ standard enthalpi format k entropi k quantiti h kh valu thed
e6e7bd03b1fca6e11e19c1c03fad0880c35d385f,Irena: tool suite for modeling and analysis of small‐angle scattering,"Irena, a tool suite for analysis of both X-ray and neutron small-angle scattering (SAS) data within the commercial Igor Pro application, brings together a comprehensive suite of tools useful for investigations in materials science, physics, chemistry, polymer science and other fields. In addition to Guinier and Porod fits, the suite combines a variety of advanced SAS data evaluation tools for the modeling of size distribution in the dilute limit using maximum entropy and other methods, dilute limit small-angle scattering from multiple non-interacting populations of scatterers, the pair-distance distribution function, a unified fit, the Debye–Bueche model, the reflectivity (X-ray and neutron) using Parratt's formalism, and small-angle diffraction. There are also a number of support tools, such as a data import/export tool supporting a broad sampling of common data formats, a data modification tool, a presentation-quality graphics tool optimized for small-angle scattering data, and a neutron and X-ray scattering contrast calculator. These tools are brought together into one suite with consistent interfaces and functionality. The suite allows robust automated note recording and saving of parameters during export.",irena tool suit analysi xray neutron smallangl scatter sa data within commerci igor pro applic bring togeth comprehens suit tool use investig materi scienc physic chemistri polym scienc field addit guinier porod fit suit combin varieti advanc sa data evalu tool model size distribut dilut limit use maximum entropi method dilut limit smallangl scatter multipl noninteract popul scatter pairdist distribut function unifi fit debyebuech model reflect xray neutron use parratt formal smallangl diffract also number support tool data importexport tool support broad sampl common data format data modif tool presentationqu graphic tool optim smallangl scatter data neutron xray scatter contrast calcul tool brought togeth one suit consist interfac function suit allow robust autom note record save paramet export
3b59a9cbe019062c5afb2f7b0dfe19828f593853,THE USE OF CITATION DATA IN WRITING THE HISTORY OF SCIENCE,"Abstract : A study is reported which tested the hypothesis that citation indexes are useful heuristic tools for the historian. In this approach, the history of science is regarded as a chronological sequence of events in which each new discovery is dependent upon earlier discoveries. Models of history were constructed consisting of chronological maps or topological network diagrams. Two such models were used here. The first is based on the events in the history of DNA as described by Dr. Isaac Asimov in the Genetic Code. The second is based on the bibliographic citation data contained in the documents which are the original published studies of events represented in the Asimov book. The interdependencies of linkages among 40 major events (nodes) included in both network diagrams were mapped and compared. The study confirmed 65% (28 of 43) of the historical dependencies in the Asimov network by corresponding linkages established by citations. In addition, 31 citation connections were found which did not correspond to any historical dependencies noted in The Genetic Code.",abstract studi report test hypothesi citat index use heurist tool historian approach histori scienc regard chronolog sequenc event new discoveri depend upon earlier discoveri model histori construct consist chronolog map topolog network diagram two model use first base event histori dna describ dr isaac asimov genet code second base bibliograph citat data contain document origin publish studi event repres asimov book interdepend linkag among major event node includ network diagram map compar studi confirm histor depend asimov network correspond linkag establish citat addit citat connect found correspond histor depend note genet code
d751a404697db6de97c364092598e385c9e63c72,Data Mining: Data Mining Concepts and Techniques,Data mining is a field of intersection of computer science and statistics used to discover patterns in the information bank. The main aim of the data mining process is to extract the useful information from the dossier of data and mold it into an understandable structure for future use. There are different process and techniques used to carry out data mining successfully.,data mine field intersect comput scienc statist use discov pattern inform bank main aim data mine process extract use inform dossier data mold understand structur futur use differ process techniqu use carri data mine success
3d45e1d46928827f61b1841f9b2420f922abb92e,The Appearance of Data,"This paper explores conditions that allow data to appear, to come into being, in both conventional and more radical approaches in empirical social science research. Conventional qualitative inquiry that uses a positivist ontology—even when it claims to be interpretive—treats qualitative data, words, as brute, existing independent of an interpretive frame, waiting to be “collected” by a human. However, a Deleuzo-Guattarian ontology that does not assume the subject/object binary might not think the concept data at all. The author resists recuperating data in the collapse of the old empiricism and is content to pause in the curious possibilities of a normative ontology that imagines a superior, affirmative, and experimental empiricism in which all concepts, including data, must be re-thought.",paper explor condit allow data appear come convent radic approach empir social scienc research convent qualit inquiri use positivist ontologyeven claim interpretivetreat qualit data word brute exist independ interpret frame wait collect human howev deleuzoguattarian ontolog assum subjectobject binari might think concept data author resist recuper data collaps old empiric content paus curiou possibl norm ontolog imagin superior affirm experiment empiric concept includ data must rethought
20d8a8600a8eacd3ebc163145a841eb72f94c1f8,Single subject research methodology in behavioral sciences,"1. Applied Research in Education and Behavioral Science, David L. Gast 2. Scientific Research in Educational and Clinical Settings, David L. Gast and James W. Tawney 3. Ethical Principles and Practices, Linda Mechling and David L. Gast 4. Writing Tasks: Literature Reviews, Research Proposals, and Finals Reports, Mark Wolery and Kathleen Lynne Lane 5. General Factors in Measurement and Evaluation, David L. Gast 6. Replication, David L. Gast 7. Dependent Measures and Measurement Procedures, Kevin Ayres and David L. Gast 8. Visual Representation of Data, Amy D. Spriggs and David L. Gast 9. Visual Analysis of Graphic Data, David L. Gast and Amy D. Spriggs 10. Withdrawal and Reversal Designs, David L. Gast and Diana Hammond 11. Multiple Baseline and Multiple Probe Designs, David L. Gast and Jennifer Ledford 12. Comparative Intervention Designs, Mark Wolery, David L. Gast, and Diana Hammond 13. Variations of Multiple Baseline Designs and Combination Designs, David L. Gast and Jennifer Ledford 14. Statistics and Single Subject Research Methodology, Jonathan M. Campbell and Caitlin V. Herzinger",appli research educ behavior scienc david l gast scientif research educ clinic set david l gast jame w tawney ethic principl practic linda mechl david l gast write task literatur review research propos final report mark woleri kathleen lynn lane gener factor measur evalu david l gast replic david l gast depend measur measur procedur kevin ayr david l gast visual represent data ami sprigg david l gast visual analysi graphic data david l gast ami sprigg withdraw revers design david l gast diana hammond multipl baselin multipl probe design david l gast jennif ledford compar intervent design mark woleri david l gast diana hammond variat multipl baselin design combin design david l gast jennif ledford statist singl subject research methodolog jonathan campbel caitlin v herzing
876c700036e6282690f84e75626044c27bc56f65,Numerical data and functional relationships in science and technology,,nan
21da991da90631cdfaaede7a24dd719d3fcd1adf,Information as thing,"Three meanings of “information” are distinguished: “Information‐as‐process”; “information‐as‐knowledge”; and “information‐as‐thing,” the attributive use of “information” to denote things regarded as informative. The nature and characteristics of “information‐as‐thing” are discussed, using an indirect approach (“What things are informative?”). Varieties of “information‐as‐thing” include data, text, documents, objects, and events. On this view “information” includes but extends beyond communication. Whatever information storage and retrieval systems store and retrieve is necessarily “information‐as‐thing.” These three meanings of “information,” along with “information processing,” offer a basis for classifying disparate information‐related activities (e.g., rhetoric, bibliographic retrieval, statistical analysis) and, thereby, suggest a topography for “information science.” © 1991 John Wiley & Sons, Inc.",three mean inform distinguish informationasprocess informationasknowledg informationasth attribut use inform denot thing regard inform natur characterist informationasth discuss use indirect approach thing inform varieti informationasth includ data text document object event view inform includ extend beyond commun whatev inform storag retriev system store retriev necessarili informationasth three mean inform along inform process offer basi classifi dispar informationrel activ eg rhetor bibliograph retriev statist analysi therebi suggest topographi inform scienc john wiley son inc
d441ac8a4da15b1ebd9321f33c914647d99b780d,Lack of group-to-individual generalizability is a threat to human subjects research,"Significance The current study quantified the degree to which group data are able to describe individual participants. We utilized intensive repeated-measures data—data that have been collected many times, across many individuals—to compare the distributions of bivariate correlations calculated within subjects vs. those calculated between subjects. Because the vast majority of social and medical science research aggregates across subjects, we aimed to assess how closely such aggregations reflect their constituent individuals. We provide evidence that conclusions drawn from aggregated data may be worryingly imprecise. Specifically, the variance in individuals is up to four times larger than in groups. These data call for a focus on idiography and open science that may substantially alter best-practice guidelines in the medical and behavioral sciences. Only for ergodic processes will inferences based on group-level data generalize to individual experience or behavior. Because human social and psychological processes typically have an individually variable and time-varying nature, they are unlikely to be ergodic. In this paper, six studies with a repeated-measure design were used for symmetric comparisons of interindividual and intraindividual variation. Our results delineate the potential scope and impact of nonergodic data in human subjects research. Analyses across six samples (with 87–94 participants and an equal number of assessments per participant) showed some degree of agreement in central tendency estimates (mean) between groups and individuals across constructs and data collection paradigms. However, the variance around the expected value was two to four times larger within individuals than within groups. This suggests that literatures in social and medical sciences may overestimate the accuracy of aggregated statistical estimates. This observation could have serious consequences for how we understand the consistency between group and individual correlations, and the generalizability of conclusions between domains. Researchers should explicitly test for equivalence of processes at the individual and group level across the social and medical sciences.",signific current studi quantifi degre group data abl describ individu particip util intens repeatedmeasur datadata collect mani time across mani individualsto compar distribut bivari correl calcul within subject vs calcul subject vast major social medic scienc research aggreg across subject aim assess close aggreg reflect constitu individu provid evid conclus drawn aggreg data may worryingli imprecis specif varianc individu four time larger group data call focu idiographi open scienc may substanti alter bestpractic guidelin medic behavior scienc ergod process infer base grouplevel data gener individu experi behavior human social psycholog process typic individu variabl timevari natur unlik ergod paper six studi repeatedmeasur design use symmetr comparison interindividu intraindividu variat result delin potenti scope impact nonergod data human subject research analys across six sampl particip equal number assess per particip show degre agreement central tendenc estim mean group individu across construct data collect paradigm howev varianc around expect valu two four time larger within individu within group suggest literatur social medic scienc may overestim accuraci aggreg statist estim observ could seriou consequ understand consist group individu correl generaliz conclus domain research explicitli test equival process individu group level across social medic scienc
145a3a9c25fcbd31d19de928170a92bde5c64c10,What accounts for international differences in student performance? A re-examination using PISA data,,nan
922e397a4f37ed5e4b0cdde100f733472b3fb390,Geographical information science,Abstract. Research papers at conferences such as EGIS and the International Symposia on Spatial Data Handling address a set of intellectual and scientific questions which go well beyond the limited technical capabilities of current technology in geographical information systems. This paper reviews the topics which might be included in a science of geographical information. Research on these fundamental issues is a better prospect for long-term survival and acceptance in the academy than the development of technical capabilities. This paper reviews the current state of research in a series of key areas and speculates on why progress has been so uneven. The final section of the paper looks to the future and to new areas of significant potential in this area of research.,abstract research paper confer egi intern symposia spatial data handl address set intellectu scientif question go well beyond limit technic capabl current technolog geograph inform system paper review topic might includ scienc geograph inform research fundament issu better prospect longterm surviv accept academi develop technic capabl paper review current state research seri key area specul progress uneven final section paper look futur new area signific potenti area research
64bf542854f74a24bd68e264267bc0af664de995,Open Data in Science,"Abstract Open Data (OD) is an emerging term in the process of defining how scientific data may be published and re-used without price or permission barriers. Scientists generally see published data as belonging to the scientific community, but many publishers claim copyright over data and will not allow its re-use without permission. This is a major impediment to the progress of scholarship in the digital age. This article reviews the need for Open Data, shows examples of why Open Data are valuable, and summarizes some early initiatives in formalizing the right of access to and re-use of scientific data.",abstract open data od emerg term process defin scientif data may publish reus without price permiss barrier scientist gener see publish data belong scientif commun mani publish claim copyright data allow reus without permiss major impedi progress scholarship digit age articl review need open data show exampl open data valuabl summar earli initi formal right access reus scientif data
904e54b9143d51afe343ca9af9457316c42cd6c9,High-Resolution Scanning X-ray Diffraction Microscopy,"Coherent diffractive imaging (CDI) and scanning transmission x-ray microscopy (STXM) are two popular microscopy techniques that have evolved quite independently. CDI promises to reach resolutions below 10 nanometers, but the reconstruction procedures put stringent requirements on data quality and sample preparation. In contrast, STXM features straightforward data analysis, but its resolution is limited by the spot size on the specimen. We demonstrate a ptychographic imaging method that bridges the gap between CDI and STXM by measuring complete diffraction patterns at each point of a STXM scan. The high penetration power of x-rays in combination with the high spatial resolution will allow investigation of a wide range of complex mesoscopic life and material science specimens, such as embedded semiconductor devices or cellular networks.",coher diffract imag cdi scan transmiss xray microscopi stxm two popular microscopi techniqu evolv quit independ cdi promis reach resolut nanomet reconstruct procedur put stringent requir data qualiti sampl prepar contrast stxm featur straightforward data analysi resolut limit spot size specimen demonstr ptychograph imag method bridg gap cdi stxm measur complet diffract pattern point stxm scan high penetr power xray combin high spatial resolut allow investig wide rang complex mesoscop life materi scienc specimen embed semiconductor devic cellular network
6b82497a15d7c66e2227de3973d38c65b50385f1,Estimating Dynamic Panel Data Models in Political Science,"Panel data are a very valuable resource for finding empirical solutions to political science puzzles. Yet numerous published studies in political science that use panel data to estimate models with dynamics have failed to take into account important estimation issues, which calls into question the inferences we can make from these analyses. The failure to account explicitly for unobserved individual effects in dynamic panel data induces bias and inconsistency in cross-sectional estimators. The purpose of this paper is to review dynamic panel data estimators that eliminate these problems. I first show how the problems with cross-sectional estimators arise in dynamic models for panel data. I then show how to correct for these problems using generalized method of moments estimators. Finally, I demonstrate the usefulness of these methods with replications of analyses in the debate over the dynamics of party identification.",panel data valuabl resourc find empir solut polit scienc puzzl yet numer publish studi polit scienc use panel data estim model dynam fail take account import estim issu call question infer make analys failur account explicitli unobserv individu effect dynam panel data induc bia inconsist crosssect estim purpos paper review dynam panel data estim elimin problem first show problem crosssect estim aris dynam model panel data show correct problem use gener method moment estim final demonstr use method replic analys debat dynam parti identif
4f0d47b625c09a0206511f425256b7dc1aa09922,Statistical Procedures and the Justification of Knowledge in Psychological Science,"Justification, in the vernacular language of philosophy of science, refers to the evaluation, defense, and confirmation of claims of truth. In this article, we examine some aspects of the rhetoric of justification, which in part draws on statistical data analysis to shore up facts and inductive inferences. There are a number of problems of methodological spirit and substance that in the past have been resistant to attempts to correct them. The major problems are discussed, and readers are reminded of ways to clear away these obstacles to justification.",justif vernacular languag philosophi scienc refer evalu defens confirm claim truth articl examin aspect rhetor justif part draw statist data analysi shore fact induct infer number problem methodolog spirit substanc past resist attempt correct major problem discuss reader remind way clear away obstacl justif
c473f93e6b5729bbb21c0eb061c8af1f03d539be,Interpretation and Method : Empirical Research Methods and the Interpretive Turn,"This book demonstrates the relevance, rigor, and creativity of interpretive research methodologies for the social and human sciences. The book situates methods questions within the context of broader methodological questions--specifically, the character of social realities and their ""know-ability."" Exceptionally clear and well-written chapters provide engaging discussions of the methods of accessing, generating, and analyzing social science data, using methods ranging from reflexive historical analysis to critical ethnography. Reflecting on their own research experiences, the contributors offer an inside, applied perspective on how research topics, evidence, and methods intertwine to produce knowledge in the social sciences.",book demonstr relev rigor creativ interpret research methodolog social human scienc book situat method question within context broader methodolog questionsspecif charact social realiti knowabl except clear wellwritten chapter provid engag discuss method access gener analyz social scienc data use method rang reflex histor analysi critic ethnographi reflect research experi contributor offer insid appli perspect research topic evid method intertwin produc knowledg social scienc
aa449c6b6614387fbf783f0d490c466ab2044109,Data-Driven Modeling & Scientific Computation: Methods for Complex Systems & Big Data,"The burgeoning field of data analysis is expanding at an incredible pace due to the proliferation of data collection in almost every area of science. The enormous data sets now routinely encountered in the sciences provide an incentive to develop mathematical techniques and computational algorithms that help synthesize, interpret and give meaning to the data in the context of its scientific setting. A specific aim of this book is to integrate standard scientific computing methods with data analysis. By doing so, it brings together, in a self-consistent fashion, the key ideas from:DT statistics,DT time-frequency analysis, and DT low-dimensional reductions The blend of these ideas provides meaningful insight into the data sets one is faced with in every scientific subject today, including those generated from complex dynamical systems. This is a particularly exciting field and much of the final part of the book is driven by intuitive examples from it, showing how the three areas can be used in combination to give critical insight into the fundamental workings of various problems.Data-Driven Modeling and Scientific Computation is a survey of practical numerical solution techniques for ordinary and partial differential equations as well as algorithms for data manipulation and analysis. Emphasis is on the implementation of numerical schemes to practical problems in the engineering, biological and physical sciences. An accessible introductory-to-advanced text, this book fully integrates MATLAB and its versatile and high-level programming functionality, while bringing together computational and data skills for both undergraduate and graduate students in scientific computing.",burgeon field data analysi expand incred pace due prolifer data collect almost everi area scienc enorm data set routin encount scienc provid incent develop mathemat techniqu comput algorithm help synthes interpret give mean data context scientif set specif aim book integr standard scientif comput method data analysi bring togeth selfconsist fashion key idea fromdt statisticsdt timefrequ analysi dt lowdimension reduct blend idea provid meaning insight data set one face everi scientif subject today includ gener complex dynam system particularli excit field much final part book driven intuit exampl show three area use combin give critic insight fundament work variou problemsdatadriven model scientif comput survey practic numer solut techniqu ordinari partial differenti equat well algorithm data manipul analysi emphasi implement numer scheme practic problem engin biolog physic scienc access introductorytoadvanc text book fulli integr matlab versatil highlevel program function bring togeth comput data skill undergradu graduat student scientif comput
c2d3a1661a97f10ad29d2ea56e09981e4cb758e1,A Data Repository for the EDM Community: The PSLC DataShop,"In recent years, educational data mining has emerged as a burgeoning new area for scientific investigation. One reason for the emerging excitement about educational data mining is the increasing availability of fine-grained, extensive, and longitudinal data on student learning. These data come from many sources, including standardized tests combined with student demographic data (for instance, www.icpsr.umich.edu/IAED), and videos of classroom interactions [22]. Extensive new data sources have been transformational in science [5] and business (being a major part of the success of key businesses such as Google, FedEx, and WalMart).",recent year educ data mine emerg burgeon new area scientif investig one reason emerg excit educ data mine increas avail finegrain extens longitudin data student learn data come mani sourc includ standard test combin student demograph data instanc wwwicpsrumicheduia video classroom interact extens new data sourc transform scienc busi major part success key busi googl fedex walmart
428922e0d2bf4b2f90dea64b7ea3b88645985d19,"New Politics and Class Politics in the Context of Austerity and Globalization: Welfare State Regress in 18 Countries, 1975–95","The relevance of socioeconomic class and of class-related parties for policymaking is a recurring issue in the social sciences. The “new politics” perspective holds that in the present era of austerity, class-based parties once driving welfare state expansion have been superseded by powerful new interest groups of welfare-state clients capable of largely resisting retrenchment pressures emanating from postindustrial forces. We argue that retrenchment can fruitfully be analyzed as distributive conflict involving a remaking of the early postwar social contract based on the full employment welfare state, a conflict in which partisan politics and welfare-state institutions are likely to matter. Pointing to problems of conceptualization and measurement of the dependent variable in previous research, we bring in new data on the extent of retrenchment in social citizenship rights and show that the long increase in social rights has been turned into a decline and that significant retrenchment has taken place in several countries. Our analyses demonstrate that partisan politics remains significant for retrenchment also when we take account of contextual indictors, such as constitutional veto points, economic factors, and globalization.Author names are in alphabetical order and they share equal responsibility for the manuscript. Early versions of this paper were presented at annual meetings of the Nordic Political Science Association in Aalborg, 2002, and the American Political Science Association in San Francisco, 2001, the International Sociological Association RC 28 meeting in Mannheim, 2001, the International Sociological Association RC 19 meeting in Tilburg 2000, and the American Sociological Association in Washington, DC, 2000, as well as at various seminars. For constructive comments on different versions of the manuscript we thank Rainer Lepsius, Anders Lindbom, Ingalill Montanari, John Myles, Michael Shalev, Sheila Shaver, and Robin Stryker, as well as other participants in these meetings. We want to thank Olof Bäckman, Stefan Englund, Ingrid Esser, Helena Höög, and Annita Näsström for very valuable help and Dennis Quinn for providing us his data on international financial deregulation. Our thanks are also due to three anonymous referees for careful reading. This research has been supported by grants from the Bank of Sweden Tercentennial Foundation and the Swedish Council for Social Research.",relev socioeconom class classrel parti policymak recur issu social scienc new polit perspect hold present era auster classbas parti drive welfar state expans supersed power new interest group welfarest client capabl larg resist retrench pressur eman postindustri forc argu retrench fruit analyz distribut conflict involv remak earli postwar social contract base full employ welfar state conflict partisan polit welfarest institut like matter point problem conceptu measur depend variabl previou research bring new data extent retrench social citizenship right show long increas social right turn declin signific retrench taken place sever countri analys demonstr partisan polit remain signific retrench also take account contextu indictor constitut veto point econom factor globalizationauthor name alphabet order share equal respons manuscript earli version paper present annual meet nordic polit scienc associ aalborg american polit scienc associ san francisco intern sociolog associ rc meet mannheim intern sociolog associ rc meet tilburg american sociolog associ washington dc well variou seminar construct comment differ version manuscript thank rainer lepsiu ander lindbom ingalil montanari john myle michael shalev sheila shaver robin stryker well particip meet want thank olof bäckman stefan englund ingrid esser helena höög annita näsström valuabl help denni quinn provid us data intern financi deregul thank also due three anonym refere care read research support grant bank sweden tercentenni foundat swedish council social research
6765332ea2813d8b0c744fe20fb02269c23bfec8,Registered Reports A Method to Increase the Credibility of Published Results,"Ignoring replications and negative results is bad for science. This special issue presents a novel publishing format – Registered Reports – as a partial solution. Peer review occurs prior to data collection, design and analysis plans are preregistered, and results are reported regardless of outcome. Fourteen Registered Reports of replications of important published results in social psychology are reported with strong confirmatory tests. Further, the articles demonstrate open science practices such as open data, open materials, and disclosure of research process, conflicts of interest, and contributions. The credibility of published science will increase with cultural shifts that accept replications and negative results as viable research outcomes, and when transparency and reproducibility are part of standard research practice.",ignor replic neg result bad scienc special issu present novel publish format regist report partial solut peer review occur prior data collect design analysi plan preregist result report regardless outcom fourteen regist report replic import publish result social psycholog report strong confirmatori test articl demonstr open scienc practic open data open materi disclosur research process conflict interest contribut credibl publish scienc increas cultur shift accept replic neg result viabl research outcom transpar reproduc part standard research practic
e31f0c56082f1887844dc8d8f80993c4fbcf6919,Open Data for Global Science,"he digital revolution has transformed the accumulation of properly curated public research data into an essential upstream resource whose value increases with use. The potential contributions of such data to the creation of new knowledge and downstream economic and social goods can in many cases be multiplied exponentially when the data are made openly available on digital networks. Most developed countries spend large amounts of public resources on research and related scientific facilities and instruments that generate massive amounts of data. Yet precious little of that investment is devoted to promoting the value of the resulting data by preserving and making them broadly available. The largely ad hoc approach to managing such data, however, is now beginning to be understood as inadequate to meet the exigencies of the national and international research enterprise. The time has thus come for the research community to establish explicit responsibilities for these digital resources. This article reviews the opportunities and challenges to the global science system associated with establishing an open data policy.",digit revolut transform accumul properli curat public research data essenti upstream resourc whose valu increas use potenti contribut data creation new knowledg downstream econom social good mani case multipli exponenti data made openli avail digit network develop countri spend larg amount public resourc research relat scientif facil instrument gener massiv amount data yet preciou littl invest devot promot valu result data preserv make broadli avail larg ad hoc approach manag data howev begin understood inadequ meet exig nation intern research enterpris time thu come research commun establish explicit respons digit resourc articl review opportun challeng global scienc system associ establish open data polici
19e65a2421be24bb7b4d2205f2ff5cec0b22e11f,Textual Data Mining to Support Science and Technology Management,,nan
16bc829d2e64017cb5c018fe190b3208829bd634,Extended guidelines for mtDNA typing of population data in forensic science.,,nan
c730acd465ab5ab22b3e3033eb8503a3128aaf05,Selected climatic data for a global set of standard stations for vegetation science,,nan
6a04847a2e6875142d594abfd0c977fa42a5a95a,Data curation + process curation=data integration + science,"In bioinformatics, we are familiar with the idea of curated data as a prerequisite for data integration. We neglect, often to our cost, the curation and cataloguing of the processes that we use to integrate and analyse our data. Programmatic access to services, for data and processes, means that compositions of services can be made that represent the in silico experiments or processes that bioinformaticians perform. Data integration through workflows depends on being able to know what services exist and where to find those services. The large number of services and the operations they perform, their arbitrary naming and lack of documentation, however, mean that they can be difficult to use. The workflows themselves are composite processes that could be pooled and reused but only if they too can be found and understood. Thus appropriate curation, including semantic mark-up, would enable processes to be found, maintained and consequently used more easily. This broader view on semantic annotation is vital for full data integration that is necessary for the modern scientific analyses in biology. This article will brief the community on the current state of the art and the current challenges for process curation, both within and without the Life Sciences.",bioinformat familiar idea curat data prerequisit data integr neglect often cost curat catalogu process use integr analys data programmat access servic data process mean composit servic made repres silico experi process bioinformatician perform data integr workflow depend abl know servic exist find servic larg number servic oper perform arbitrari name lack document howev mean difficult use workflow composit process could pool reus found understood thu appropri curat includ semant markup would enabl process found maintain consequ use easili broader view semant annot vital full data integr necessari modern scientif analys biolog articl brief commun current state art current challeng process curat within without life scienc
5211b7741e9eea049d2d9139e683cbb18ee9d8ac,A future for models and data in environmental science.,,nan
0166d107c091e2ea0c0d2ea172f48ab010677e4f,Anatomy of STEM teaching in North American universities,"Lecture is prominent, but practices vary A large body of evidence demonstrates that strategies that promote student interactions and cognitively engage students with content (1) lead to gains in learning and attitudinal outcomes for students in science, technology, engineering, and mathematics (STEM) courses (1, 2). Many educational and governmental bodies have called for and supported adoption of these student-centered strategies throughout the undergraduate STEM curriculum. But to the extent that we have pictures of the STEM undergraduate instructional landscape, it has mostly been provided through self-report surveys of faculty members, within a particular STEM discipline [e.g., (3–6)]. Such surveys are prone to reliability threats and can underestimate the complexity of classroom environments, and few are implemented nationally to provide valid and reliable data (7). Reflecting the limited state of these data, a report from the U.S. National Academies of Sciences, Engineering, and Medicine called for improved data collection to understand the use of evidence-based instructional practices (8). We report here a major step toward a characterization of STEM teaching practices in North American universities based on classroom observations from over 2000 classes taught by more than 500 STEM faculty members across 25 institutions.",lectur promin practic vari larg bodi evid demonstr strategi promot student interact cognit engag student content lead gain learn attitudin outcom student scienc technolog engin mathemat stem cours mani educ government bodi call support adopt studentcent strategi throughout undergradu stem curriculum extent pictur stem undergradu instruct landscap mostli provid selfreport survey faculti member within particular stem disciplin eg survey prone reliabl threat underestim complex classroom environ implement nation provid valid reliabl data reflect limit state data report us nation academi scienc engin medicin call improv data collect understand use evidencebas instruct practic report major step toward character stem teach practic north american univers base classroom observ class taught stem faculti member across institut
29421664e97c275cfc3711228b22a05a3bfb3835,Science fraud: from patchwork mouse to patchwork data,"Summerlin pulled two white mice from the container. While they wriggled and squeaked in protest, he inspected the sites of the black skin grafts. Impulsively, Summerlin took his felttipped pen out of the breast pocket of his white coat and applied it briefly to the grafted patches on the two white animals. The ink made them look darker. Then he replaced the mice in the bin and strode out . . . From The Patchwork Mouse, an account of William T. Summerlin's 1974 false claim of skin transplantation without immunosuppression (1).",summerlin pull two white mice contain wriggl squeak protest inspect site black skin graft impuls summerlin took felttip pen breast pocket white coat appli briefli graft patch two white anim ink made look darker replac mice bin strode patchwork mous account william summerlin fals claim skin transplant without immunosuppress
ea11efe27e029e391ea52609468353f98d9f946b,Machine learning on Big Data,"Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities. The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research.",statist machin learn undergon phase transit pure academ endeavor one main driver modern commerc scienc even recent result terascal learn larg neural network suggest scale import ingredi qualiti model tutori introduc current applic techniqu system aim crossfertil research databas machin learn commun tutori cover current larg scale applic machin learn comput model workflow behind build base foundat present current stateoftheart system support bulk tutori also identifi critic gap stateoftheart lead close seminar introduc two set open research question better system support alreadi establish use case machin learn support recent advanc machin learn research
fd6a95e22826991d995edd2190006c6d08056cf1,Nuclear Data for Science and Technology,,nan
05547c1b970ce193d0756004881a4bcd1ac7e4d4,Earth science: Microseismicity data forecast rupture area,,nan
d1ed3cf4fe0e4612448c9564214cf1019cdc58a0,Earth System Science Workbench: a data management infrastructure for earth science products,"The Earth System Science Workbench (ESSW) is a non-intrusive data management infrastructure for researchers who are also data publishers. An implementation of ESSW to track the processing of locally received satellite imagery is presented, demonstrating the Workbench's transparent and robust support for archiving and publishing data products. ESSW features a Lab Notebook metadata service, an ND-WORM (No Duplicate-Write Once Read Many) storage service, and Web user interface tools. The Lab Notebook logs processes (experiments) and their relationships via a custom API to XML documents stored in a relational database. The ND-WORM provides a managed storage archive for the Lab Notebook by keeping unique file digests and name-space meta-data, also in a relational database. ESSW Notebook tools allow project searching and ordering, and file and meta-data management.",earth system scienc workbench essw nonintrus data manag infrastructur research also data publish implement essw track process local receiv satellit imageri present demonstr workbench transpar robust support archiv publish data product essw featur lab notebook metadata servic ndworm duplicatewrit read mani storag servic web user interfac tool lab notebook log process experi relationship via custom api xml document store relat databas ndworm provid manag storag archiv lab notebook keep uniqu file digest namespac metadata also relat databas essw notebook tool allow project search order file metadata manag
2f2a2e5bf046cfe076a62a102117b74cae0e788e,Visualizing Science by Citation Mapping,"Science mapping is discussed in the general context of information visualization. Attempts to construct maps of science using citation data are reviewed, focusing on the use of co-citation clusters. New work is reported on a dataset of about 36,000 documents using simplified methods for ordination, and nesting maps hierarchically. An overall map of the dataset shows the multidisciplinary breadth of the document sample, and submaps allow drilling down to the document level. An effort to visualize these data using advanced virtual reality software is described, and the creation of document pathways through the map is seen as a realization of Bush's (1945) associative trails.",scienc map discuss gener context inform visual attempt construct map scienc use citat data review focus use cocit cluster new work report dataset document use simplifi method ordin nest map hierarch overal map dataset show multidisciplinari breadth document sampl submap allow drill document level effort visual data use advanc virtual realiti softwar describ creation document pathway map seen realiz bush associ trail
26089e831948b18123615e697eb6b1adab9f2111,Nuclear Data for Science and Technology,,nan
fd958e368103a84dcd0be53f9c3dae8cd7ac131b,Science knowledge and attitudes across cultures: a meta-analysis,"The correlation between knowledge and attitudes has been the source of controversy in research on the public understanding of science (PUS). Although many studies, both quantitative and qualitative, have examined this issue, the results are at best diverse and at worst contradictory. In this paper, we review the evidence on the relationship between public attitudes and public knowledge about science across 40 countries using a meta-analytic approach. We fit multilevel models to data from 193 nationally representative surveys on PUS carried out since 1989. We find a small positive correlation between general attitudes towards science and general knowledge of scientific facts, after controlling for a range of possible confounding variables. This general relationship varies little across cultures but more substantially between different domains of science and technology. Our results suggest that PUS research needs to focus on understanding the mechanisms that underlie the clear association that exists between knowledge and attitudes about science.",correl knowledg attitud sourc controversi research public understand scienc pu although mani studi quantit qualit examin issu result best divers worst contradictori paper review evid relationship public attitud public knowledg scienc across countri use metaanalyt approach fit multilevel model data nation repres survey pu carri sinc find small posit correl gener attitud toward scienc gener knowledg scientif fact control rang possibl confound variabl gener relationship vari littl across cultur substanti differ domain scienc technolog result suggest pu research need focu understand mechan underli clear associ exist knowledg attitud scienc
c10f0d2d0bb5bc92dc33276fc6c8a8a68cff7eda,"Badges to Acknowledge Open Practices: A Simple, Low-Cost, Effective Method for Increasing Transparency","Beginning January 2014, Psychological Science gave authors the opportunity to signal open data and materials if they qualified for badges that accompanied published articles. Before badges, less than 3% of Psychological Science articles reported open data. After badges, 23% reported open data, with an accelerating trend; 39% reported open data in the first half of 2015, an increase of more than an order of magnitude from baseline. There was no change over time in the low rates of data sharing among comparison journals. Moreover, reporting openness does not guarantee openness. When badges were earned, reportedly available data were more likely to be actually available, correct, usable, and complete than when badges were not earned. Open materials also increased to a weaker degree, and there was more variability among comparison journals. Badges are simple, effective signals to promote open practices and improve preservation of data and materials by using independent repositories.",begin januari psycholog scienc gave author opportun signal open data materi qualifi badg accompani publish articl badg less psycholog scienc articl report open data badg report open data acceler trend report open data first half increas order magnitud baselin chang time low rate data share among comparison journal moreov report open guarante open badg earn reportedli avail data like actual avail correct usabl complet badg earn open materi also increas weaker degre variabl among comparison journal badg simpl effect signal promot open practic improv preserv data materi use independ repositori
7c8a32b586757a982abd90d9e5f32be5d6351b41,Model Based Inference in the Life Sciences: A Primer on Evidence,,nan
1d0588ab31f2e29c6029cfa0762bad255c30d94a,"An Evaluation of Amazon’s Mechanical Turk, Its Rapid Rise, and Its Effective Use","Over the past 2 decades, many social scientists have expanded their data-collection capabilities by using various online research tools. In the 2011 article “Amazon’s Mechanical Turk: A new source of inexpensive, yet high-quality, data?” in Perspectives on Psychological Science, Buhrmester, Kwang, and Gosling introduced researchers to what was then considered to be a promising but nascent research platform. Since then, thousands of social scientists from seemingly every field have conducted research using the platform. Here, we reflect on the impact of Mechanical Turk on the social sciences and our article’s role in its rise, provide the newest data-driven recommendations to help researchers effectively use the platform, and highlight other online research platforms worth consideration.",past decad mani social scientist expand datacollect capabl use variou onlin research tool articl amazon mechan turk new sourc inexpens yet highqual data perspect psycholog scienc buhrmest kwang gosl introduc research consid promis nascent research platform sinc thousand social scientist seemingli everi field conduct research use platform reflect impact mechan turk social scienc articl role rise provid newest datadriven recommend help research effect use platform highlight onlin research platform worth consider
40a8bd9fdcfa5ae1d7b91894719d37ea861f2c2d,Influencing student understanding of the nature of science: Data from a case of curriculum development,"The purpose of this study was to investigate the effects of the first-year field test BSCS middle school science program on student understanding of the creative, developmental, testable, and unified nature of science. The experimental group, which was exposed to the BSCS program, and the control group, which was taught using a more traditional middle school science curriculum, were administered a pretest and posttest using the Modified Nature of Scientific Knowledge Scale (MNSKS). Analyses of the results showed that the understanding of students who experienced the BSCS science program decreased significantly in regard to the developmental and testable nature of science. The understanding of students who experienced the control-group science program decreased significantly in regard to the creative nature of science. Analyses of covariance indicated that students in the control group possessed a significantly better understanding of the testable nature of science than did students who used the BSCS science program. Implications of these results are related to the constructivist view of learning, the development of curricula designed to facilitate scientific literacy, and future research endeavors.",purpos studi investig effect firstyear field test bsc middl school scienc program student understand creativ development testabl unifi natur scienc experiment group expos bsc program control group taught use tradit middl school scienc curriculum administ pretest posttest use modifi natur scientif knowledg scale mnsk analys result show understand student experienc bsc scienc program decreas significantli regard development testabl natur scienc understand student experienc controlgroup scienc program decreas significantli regard creativ natur scienc analys covari indic student control group possess significantli better understand testabl natur scienc student use bsc scienc program implic result relat constructivist view learn develop curricula design facilit scientif literaci futur research endeavor
4cc445dfc181101552971c2342a06a24bc4bbc88,"Student performances on the science processes of recording data, analyzing data, drawing conclusions, and providing evidence","The National Committee on Science Education Standards and Assessment (1994 draft) viewed several science processes as important to an understanding of science as inquiry: formulating usable questions, planning experiments, conducting systematic observations, interpreting and analyzing data, drawing conclusions, communicating, and coordinating and implementing a full investigation. This study is one of three undertaken to develop research rubrics for a performance assessment of science processes and to evaluate seventh-grade science students' ability to perform them. Specifically, this article focuses on the processes of recording data, analyzing data, drawing conclusions, and providing evidence. A total of 364 students field tested the Alternative Assessment of Science Process Skills. Their responses were used to develop a research rubric, and then this rubric was used to determine response patterns that could inform both instruction and assessment of science process skills. Only 61% of students performed the activity and recorded data successfully. Sixty-nine percent of students did not attend to the hypothesis in drawing their conclusions. Eighty-one percent did not provide specific evidence for their conclusions. These results were discussed in light of relevant theories and models as well as their implications for instruction and assessment. © 1996 John Wiley & Sons, Inc.",nation committe scienc educ standard assess draft view sever scienc process import understand scienc inquiri formul usabl question plan experi conduct systemat observ interpret analyz data draw conclus commun coordin implement full investig studi one three undertaken develop research rubric perform assess scienc process evalu seventhgrad scienc student abil perform specif articl focus process record data analyz data draw conclus provid evid total student field test altern assess scienc process skill respons use develop research rubric rubric use determin respons pattern could inform instruct assess scienc process skill student perform activ record data success sixtynin percent student attend hypothesi draw conclus eightyon percent provid specif evid conclus result discuss light relev theori model well implic instruct assess john wiley son inc
f26b402b75675c4aec5e9b932c6622cdc7407e25,KDD for Science Data Analysis: Issues and Examples,"The analysis of the massive data sets collected by scientific instruments demands automation as a prerequisite to analysis. There is an urgent need to create an intermediate level at which scientists can operate effectively; isolating them from the massive sizes and harnessing human analysis capabilities to focus on tasks in which machines do not even remotely approach humans—namely, creative data analysis, theory and hypothesis formation, and drawing insights into underlying phenomena. We give an overview of the main issues in the exploitation of scientific datasets, present five case studies where KDD tools play important and enabling roles, and conclude with future challenges for data mining and KDD techniques in science data analysis.",analysi massiv data set collect scientif instrument demand autom prerequisit analysi urgent need creat intermedi level scientist oper effect isol massiv size har human analysi capabl focu task machin even remot approach humansnam creativ data analysi theori hypothesi format draw insight underli phenomena give overview main issu exploit scientif dataset present five case studi kdd tool play import enabl role conclud futur challeng data mine kdd techniqu scienc data analysi
adc47a50258fa843316ddb315d214a86b77419ae,On the Application of Formal Principles to Life Science Data: a Case Study in the Gene Ontology,,nan
2eedbe2dc1f90d30d2330ad97fef65cc5da35931,Statistics of Earth Science Data,,nan
164b662718402f9b9dc158748fd20ab92c429cc4,Multivariate analysis of data in sensory science,,nan
e8a400b157f0419f1c5d12eecd41cb516c1b6477,"Which h-index? — A comparison of WoS, Scopus and Google Scholar",,nan
4ebeeda4f692e16e7f0588193b4c3dbe9f823cf2,Big Data and Their Epistemological Challenge,,nan
bf5a13c1a5096e86eaa316b97ff43df0078a2042,Probability Theory: The Logic of Science,"This book goes beyond the conventional mathematics of probability theory, viewing the subject in a wider context. Now results are discussed, along with the application of probability theory to a wide variety of problems in physics, mathematics, economics, chemistry and biology. It contains many exercises and problems, and is suitable for use as a textbook on graduate level courses involving data analysis. The material is aimed at readers who are already familiar with applied mathematics at an advanced undergraduate level or higher. The book is not restricted to one particular discipline but rather will be of interest to scientists working in any area where inference from incomplete information is necessary.",book goe beyond convent mathemat probabl theori view subject wider context result discuss along applic probabl theori wide varieti problem physic mathemat econom chemistri biolog contain mani exercis problem suitabl use textbook graduat level cours involv data analysi materi aim reader alreadi familiar appli mathemat advanc undergradu level higher book restrict one particular disciplin rather interest scientist work area infer incomplet inform necessari
d01378408cc72d65ec6fd0c912b7f6dba44c6288,Developing a science of land change: challenges and methodological issues.,"Land-change science has emerged as a foundational element of global environment change and sustainability science. It seeks to understand the human and environment dynamics that give rise to changed land uses and covers, not only in terms of their type and magnitude but their location as well. This focus requires the integration of social, natural, and geographical information sciences. Each of these broad research communities has developed different ways to enter the land-change problem, each with different means of treating the locational specificity of the critical variables, such as linking the land manager to the parcel being managed. The resulting integration encounters various data, methodological, and analytical problems, especially those concerning aggregation and inference, land-use pixel links, data and measurement, and remote sensing analysis. Here, these integration problems, which hinder comprehensive understanding and theory development, are addressed. Their recognition and resolution are required for the sustained development of land-change science.",landchang scienc emerg foundat element global environ chang sustain scienc seek understand human environ dynam give rise chang land use cover term type magnitud locat well focu requir integr social natur geograph inform scienc broad research commun develop differ way enter landchang problem differ mean treat locat specif critic variabl link land manag parcel manag result integr encount variou data methodolog analyt problem especi concern aggreg infer landus pixel link data measur remot sens analysi integr problem hinder comprehens understand theori develop address recognit resolut requir sustain develop landchang scienc
5ee1b885d5cec839291ca67009dbf1caa546da24,The Economic Logic of “Open Science” and the Balance between Private Property Rights and the Public Domain in Scientific Data and Information: A Primer,,nan
caf174b2da16efaff0be53a1f5e8bb27453c2efa,Data-intensive e-science frontier research,"Large-scale e-science, including high-energy and nuclear physics, biomedical informatics, and Earth science, depend on an increasingly integrated, distributed cyberinfrastructure serving virtual organizations on a global scale.",largescal escienc includ highenergi nuclear physic biomed informat earth scienc depend increasingli integr distribut cyberinfrastructur serv virtual organ global scale
fafb3674d408810811224468b49a2fb6ae5b8e3c,A call for mtDNA data quality control in forensic science.,,nan
7c37727568c324cb2b613a457eca9a31d49604a4,Technical note: Application of the Box-Cox data transformation to animal science experiments.,"In the use of ANOVA for hypothesis testing in animal science experiments, the assumption of homogeneity of errors often is violated because of scale effects and the nature of the measurements. We demonstrate a method for transforming data so that the assumptions of ANOVA are met (or violated to a lesser degree) and apply it in analysis of data from a physiology experiment. Our study examined whether melatonin implantation would affect progesterone secretion in cycling pony mares. Overall treatment variances were greater in the melatonin-treated group, and several common transformation procedures failed. Application of the Box-Cox transformation algorithm reduced the heterogeneity of error and permitted the assumption of equal variance to be met.",use anova hypothesi test anim scienc experi assumpt homogen error often violat scale effect natur measur demonstr method transform data assumpt anova met violat lesser degre appli analysi data physiolog experi studi examin whether melatonin implant would affect progesteron secret cycl poni mare overal treatment varianc greater melatonintr group sever common transform procedur fail applic boxcox transform algorithm reduc heterogen error permit assumpt equal varianc met
07975bba7a9f710c3ce23d90953d180faa323d60,Modern analytical ultracentrifugation in protein science: A tutorial review,"Analytical ultracentrifugation (AU) is reemerging as a versatile tool for the study of proteins. Monitoring the sedimentation of macromolecules in the centrifugal field allows their hydrodynamic and thermodynamic characterization in solution, without interaction with any matrix or surface. The combination of new instrumentation and powerful computational software for data analysis has led to major advances in the characterization of proteins and protein complexes. The pace of new advancements makes it difficult for protein scientists to gain sufficient expertise to apply modern AU to their research problems. To address this problem, this review builds from the basic concepts to advanced approaches for the characterization of protein systems, and key computational and internet resources are provided. We will first explore the characterization of proteins by sedimentation velocity (SV). Determination of sedimentation coefficients allows for the modeling of the hydrodynamic shape of proteins and protein complexes. The computational treatment of SV data to resolve sedimenting components has been achieved. Hence, SV can be very useful in the identification of the oligomeric state and the stoichiometry of heterogeneous interactions. The second major part of the review covers sedimentation equilibrium (SE) of proteins, including membrane proteins and glycoproteins. This is the method of choice for molar mass determinations and the study of self‐association and heterogeneous interactions, such as protein–protein, protein–nucleic acid, and protein–small molecule binding.",analyt ultracentrifug au reemerg versatil tool studi protein monitor sediment macromolecul centrifug field allow hydrodynam thermodynam character solut without interact matrix surfac combin new instrument power comput softwar data analysi led major advanc character protein protein complex pace new advanc make difficult protein scientist gain suffici expertis appli modern au research problem address problem review build basic concept advanc approach character protein system key comput internet resourc provid first explor character protein sediment veloc sv determin sediment coeffici allow model hydrodynam shape protein protein complex comput treatment sv data resolv sediment compon achiev henc sv use identif oligomer state stoichiometri heterogen interact second major part review cover sediment equilibrium se protein includ membran protein glycoprotein method choic molar mass determin studi selfassoci heterogen interact proteinprotein proteinnucl acid proteinsmal molecul bind
374c8ef7124c6d60b313574ceb5562c65e0b79be,The properties of high-dimensional data spaces: implications for exploring gene and protein expression data,,nan
10c39539ed74cf239cf6f7f4eea7d4a57e947aad,Young People's Images of Science,"This book should be of interest to all science educators, whether they teach students, advise or inspect or are involved in planning a science curriculum. The content is essentially an account of a research project undertaken to find out and to report the range and nature of school students' understanding of the nature of science. The authors designed a cross-age study, giving the same task to samples of pupils of three different ages: 9, 12 and 16 years. The collected data were analysed to see the ways in which understanding seemed to change with age and experience. The researchers' interest in students' ideas about science has grown from their observation that learners' responses to observations and ideas are constrained and limited in significant ways by their perception of the nature of scientific work and of scientific knowledge. The result is that students often misinterpret information and experiences presented in the classroom and laboratory. The authors hope that, by knowing more about these misperceptions, we may understand better the processes of science content learning and hence achieve more effective teaching. The book is divided into three sections. In the first 70 pages the authors set out the arguments for giving the nature of science a more prominent place in the curriculum. Next they present an overview of the major schools of thought about science and scientific knowledge, followed by a summary of previous research on students' ideas about the nature of science. The section concludes with the questions, methods and tools used in the research. In the next 60 pages the main findings of the study are presented and discussed. In the final chapter the authors bring together the theoretical arguments for the place of teaching about the nature of science with the results of the research study and consider the possible implications for science teaching in schools, discussing ways in which the curriculum could be adapted to assist students to become better citizens in a modern technological world. The book is well laid out, carefully planned and argued at every stage, with excellent clear headings and summaries. It is possible to read it on a superficial level, dwelling more on the conclusions, or to select sections for closer study using either the index or section headings. There are several appendices, one of which contains the 174 references to other publications quoted in the text. There is considerable food for thought and/or discussion or debate, not only for new teachers but as timely reminders to those who have been in the classroom, laboratory or management for many years, about their aims and objectives and whether they are being realized. This is a volume which should find its way into the resource library of every science teaching department.",book interest scienc educ whether teach student advis inspect involv plan scienc curriculum content essenti account research project undertaken find report rang natur school student understand natur scienc author design crossag studi give task sampl pupil three differ age year collect data analys see way understand seem chang age experi research interest student idea scienc grown observ learner respons observ idea constrain limit signific way percept natur scientif work scientif knowledg result student often misinterpret inform experi present classroom laboratori author hope know mispercept may understand better process scienc content learn henc achiev effect teach book divid three section first page author set argument give natur scienc promin place curriculum next present overview major school thought scienc scientif knowledg follow summari previou research student idea natur scienc section conclud question method tool use research next page main find studi present discuss final chapter author bring togeth theoret argument place teach natur scienc result research studi consid possibl implic scienc teach school discuss way curriculum could adapt assist student becom better citizen modern technolog world book well laid care plan argu everi stage excel clear head summari possibl read superfici level dwell conclus select section closer studi use either index section head sever appendic one contain refer public quot text consider food thought andor discuss debat new teacher time remind classroom laboratori manag mani year aim object whether realiz volum find way resourc librari everi scienc teach depart
655b232d4dc0b73f36944d42b40922b8220f5c5b,Why Linked Data is Not Enough for Scientists,"Scientific data stands to represent a significant portion of the linked open data cloud and science itself stands to benefit from the data fusion capability that this will afford. However, simply publishing linked data into the cloud does not necessarily meet the requirements of reuse. Publishing has requirements of provenance, quality, credit, attribution, methods in order to provide the \emph{reproducibility} that allows validation of results. In this paper we make the case for a scientific data publication model on top of linked data and introduce the notion of \emph{Research Objects} as first class citizens for sharing and publishing.",scientif data stand repres signific portion link open data cloud scienc stand benefit data fusion capabl afford howev simpli publish link data cloud necessarili meet requir reus publish requir proven qualiti credit attribut method order provid emphreproduc allow valid result paper make case scientif data public model top link data introduc notion emphresearch object first class citizen share publish
f650deee6a7f2b5b5c1643ddb9e56f2e2dd8294d,The contribution of data mining to information science,"The information explosion is a serious challenge for current information institutions. On the other hand, data mining, which is the search for valuable information in large volumes of data, is one of the solutions to face this challenge. In the past several years, data mining has made a significant contribution to the field of information science. This paper examines the impact of data mining by reviewing existing applications, including personalized environments, electronic commerce, and search engines. For these three types of application, how data mining can enhance their functions is discussed. The reader of this paper is expected to get an overview of the state of the art research associated with these applications. Furthermore, we identify the limitations of current work and raise several directions for future research.",inform explos seriou challeng current inform institut hand data mine search valuabl inform larg volum data one solut face challeng past sever year data mine made signific contribut field inform scienc paper examin impact data mine review exist applic includ person environ electron commerc search engin three type applic data mine enhanc function discuss reader paper expect get overview state art research associ applic furthermor identifi limit current work rais sever direct futur research
5d1b6b28cd0dafcf73d80419eb9ffdf54e546bf4,Statistics and the Evaluation of Evidence for Forensic Scientists,Preface to the first edition. Preface to the second edition. Uncertainty in forensic science. Variation. The evaluation of evidence. Historical review. Bayesian inference. Sampling. Interpretation. Transfer evidence. Discrete data. Continuous data. Multivariate analysis. Fibres. DNA profiling. Bayesian networks. References. Notation. Cases.,prefac first edit prefac second edit uncertainti forens scienc variat evalu evid histor review bayesian infer sampl interpret transfer evid discret data continu data multivari analysi fibr dna profil bayesian network refer notat case
890d7f077bb5dce137aa41e784c4aea22e899027,When Do Scientists Become Entrepreneurs? The Social Structural Antecedents of Commercial Activity in the Academic Life Sciences1,"The authors examine the conditions prompting university‐employed life scientists to become entrepreneurs, defined to occur when a scientist (1) founds a biotechnology company, or (2) joins the scientific advisory board of a new biotechnology firm. This study draws on theories of social influence, socialization, and status dynamics to examine how proximity to colleagues in commercial science influences individuals’ propensity to transition to entrepreneurship. To expose the mechanisms at work, this study also assesses how proximity effects change over time as for‐profit science diffuses through the academy. Using adjusted proportional hazards models to analyze case‐cohort data, the authors find evidence that the orientation toward commercial science of individuals’ colleagues and coauthors, as well as a number of other workplace attributes, significantly influences scientists’ hazards of transitioning to for‐profit science.",author examin condit prompt universityemploy life scientist becom entrepreneur defin occur scientist found biotechnolog compani join scientif advisori board new biotechnolog firm studi draw theori social influenc social statu dynam examin proxim colleagu commerci scienc influenc individu propens transit entrepreneurship expos mechan work studi also assess proxim effect chang time forprofit scienc diffus academi use adjust proport hazard model analyz casecohort data author find evid orient toward commerci scienc individu colleagu coauthor well number workplac attribut significantli influenc scientist hazard transit forprofit scienc
ba552db747386562f0f054e9ade71f2fbb7db947,The resolution of multipeak data in fibre science,"A computer program based on a procedure discussed by Powell has been developed for the resolution of overlapping peaks in data output from x-ray diffraction, ion-exchange chromatography with spectroscopic detection, and infrared spectroscopy. A polynomial background is also fitted to the data so that recourse to arbitrary graphical methods for separating peaks and background is no longer necessary.",comput program base procedur discuss powel develop resolut overlap peak data output xray diffract ionexchang chromatographi spectroscop detect infrar spectroscopi polynomi background also fit data recours arbitrari graphic method separ peak background longer necessari
041dc0af3c468ce803d948ab37aea63cfdb033f6,Phenology: An Integrative Environmental Science,,nan
24a25e012c15706947294e93ec4a4b82475dd8a4,Buckets of Resistance: Standards and the Effectiveness of Citizen Science,"In light of arguments that citizen science has the potential to make environmental knowledge and policy more robust and democratic, this article inquires into the factors that shape the ability of citizen science to actually influence scientists and decision makers. Using the case of community-based air toxics monitoring with ‘‘buckets,’’ it argues that citizen science’s effectiveness is significantly influenced by standards and standardized practices. It demonstrates that, on one hand, standards serve a boundary-bridging function that affords bucket monitoring data a crucial measure of legitimacy among experts. On the other hand, standards simultaneously serve a boundary-policing function, allowing experts to dismiss bucket data as irrelevant to the central project of air quality assessment. The article thus calls attention to standard setting as an important site of intervention for citizen science-based efforts to democratize science and policy.",light argument citizen scienc potenti make environment knowledg polici robust democrat articl inquir factor shape abil citizen scienc actual influenc scientist decis maker use case communitybas air toxic monitor bucket argu citizen scienc effect significantli influenc standard standard practic demonstr one hand standard serv boundarybridg function afford bucket monitor data crucial measur legitimaci among expert hand standard simultan serv boundarypol function allow expert dismiss bucket data irrelev central project air qualiti assess articl thu call attent standard set import site intervent citizen sciencebas effort democrat scienc polici
2c5895c47012b9c42fad64e103f0a80fdacfd635,"The Magnitude, Destinations, and Determinants of Mathematics and Science Teacher Turnover","This study examines the magnitude, destinations, and determinants of mathematics and science teacher turnover. The data are from the nationally representative Schools and Staffing Survey and the Teacher Follow-Up Survey. Over the past two decades, rates of mathematics and science teacher turnover have increased but, contrary to conventional wisdom, have not been consistently different than those of other teachers. Also, contrary to conventional wisdom, mathematics and science teachers were also no more likely than other teachers to take noneducation jobs, such as in technological fields or to be working for private business or industry. The data also show there are large school-to-school differences in mathematics and science turnover; high-poverty, high-minority, and urban public schools have among the highest rates. In the case of cross-school migration, the data show there is an annual asymmetric reshuffling of a significant portion of the mathematics and science teaching force from poor to not-poor schools, from high-minority to low-minority schools, and from urban to suburban schools. A number of key organizational characteristics and conditions of schools accounted for these school differences. The strongest factor for mathematics teachers was the degree of individual classroom autonomy held by teachers. Net of other factors such as salaries, schools with less classroom autonomy lose math teachers at a far higher rate than other teachers. In contrast, for science teachers salary was the strongest factor, while classroom autonomy was not strongly related to their turnover.",studi examin magnitud destin determin mathemat scienc teacher turnov data nation repres school staf survey teacher followup survey past two decad rate mathemat scienc teacher turnov increas contrari convent wisdom consist differ teacher also contrari convent wisdom mathemat scienc teacher also like teacher take noneduc job technolog field work privat busi industri data also show larg schooltoschool differ mathemat scienc turnov highpoverti highminor urban public school among highest rate case crossschool migrat data show annual asymmetr reshuffl signific portion mathemat scienc teach forc poor notpoor school highminor lowminor school urban suburban school number key organiz characterist condit school account school differ strongest factor mathemat teacher degre individu classroom autonomi held teacher net factor salari school less classroom autonomi lose math teacher far higher rate teacher contrast scienc teacher salari strongest factor classroom autonomi strongli relat turnov
bb8d94b70e3db414406265406491d30e92cf9f70,Citation data as science indicators,"Attempts to appraise the condition of science as intellectual activity or social institution have involved data compilation—reports on amounts of money spent on scientific research, magnitudes of scientific manpower, number ot students enrolled as science majors at universities, and number of scientific papers produced or number of patents issued. For avariety of reasons, these all fail to indicate the “condition” of science. Perhaps the problem is that such data are compiled and presented without regard toa specific set of questions or set of hypotheses; thus a coherent framework for estimating the social or intellectual condition of science is missing. Science Indicators 1972 (.S/-72) is an improvement over mere data compilation, and it should be applauded as a step, however preliminary and tentative, in the right direction. The purpose of this paper is to suggest further indicators relevant for measuring scientific activity, in the hope that this will lead to a better estimate of the condition of science. At the Institute for Scientific Information (1S1), we operate on the fundamental as-",attempt apprais condit scienc intellectu activ social institut involv data compilationreport amount money spent scientif research magnitud scientif manpow number ot student enrol scienc major univers number scientif paper produc number patent issu avarieti reason fail indic condit scienc perhap problem data compil present without regard toa specif set question set hypothes thu coher framework estim social intellectu condit scienc miss scienc indic improv mere data compil applaud step howev preliminari tent right direct purpos paper suggest indic relev measur scientif activ hope lead better estim condit scienc institut scientif inform oper fundament
f27f06a64a90128f2bf17705540bea7431dd5a0a,The Office of Science Data-Management Challenge,"Science--like business, national security, and even everyday life--is becoming more and more data intensive. In some sciences the data-management challenge already exceeds the compute-power challenge in its needed resources. Leadership in applying computing to science will necessarily require both world-class computing and world-class data management. The Office of Science program needs a leadership-class capability in scientific data management. Currently two-thirds of Office of Science research and development in data management is left to the individual scientific programs. About $18M/year is spent by the programs on data-management research and development targeted at their most urgent needs. This is to be compared with the $9M/year spent on data management by DOE computer science. This highly mission-directed approach has been effective, but only in meeting just the highest-priority needs of individual programs. A coherent, leadership-class, program of data management is clearly warranted by the scale and nature of the Office of Science programs. More directly, much of the Office of Science portfolio is in desperate need of such a program; without it, data management could easily become the primary bottleneck to scientific progress within the next five years. When grouped into simulation-intensive science, experiment/observation-intensive science, and information-intensive science, the Office of Science programs show striking commonalities in their data-management needs. Not just research and development but also packaging and hardening as well as maintenance and support are required. Meeting these needs is a medium- to long-term effort requiring a well-planned program of evolving investment. We propose an Office of Science Data-Management Program at an initial scale of $32M/year of new funding. The program should be managed by a Director charged with creating and maintaining a forward-looking approach to multiscience data-management challenges. The program should favor collaborative proposals involving computer science and application science or, ideally, multiple application sciences. Proposals bringing substantial application science funding should be especially favored. The proposed program has many similarities to the DOE SciDAC program. SciDAC already has a modest data-management component. The SciDAC program partially addresses many issues relevant to data management, and has fostered close collaboration between computer science and application sciences. Serious consideration should be given to integrating the management of the new Office of Science Data-Management Program and that of SciDAC or the successor to SciDAC.",sciencelik busi nation secur even everyday lifei becom data intens scienc datamanag challeng alreadi exce computepow challeng need resourc leadership appli comput scienc necessarili requir worldclass comput worldclass data manag offic scienc program need leadershipclass capabl scientif data manag current twothird offic scienc research develop data manag left individu scientif program myear spent program datamanag research develop target urgent need compar myear spent data manag doe comput scienc highli missiondirect approach effect meet highestprior need individu program coher leadershipclass program data manag clearli warrant scale natur offic scienc program directli much offic scienc portfolio desper need program without data manag could easili becom primari bottleneck scientif progress within next five year group simulationintens scienc experimentobservationintens scienc informationintens scienc offic scienc program show strike common datamanag need research develop also packag harden well mainten support requir meet need medium longterm effort requir wellplan program evolv invest propos offic scienc datamanag program initi scale myear new fund program manag director charg creat maintain forwardlook approach multisci datamanag challeng program favor collabor propos involv comput scienc applic scienc ideal multipl applic scienc propos bring substanti applic scienc fund especi favor propos program mani similar doe scidac program scidac alreadi modest datamanag compon scidac program partial address mani issu relev data manag foster close collabor comput scienc applic scienc seriou consider given integr manag new offic scienc datamanag program scidac successor scidac
654b16fc452219c1b681d75ed045cf905855bd5e,Hyperlinks as a data source for science mapping,"Hyperlinks between academic web sites, like citations, can potentially be used to map disciplinary structures and identify evidence of connections between disciplines. In this paper we classified a sample of links originating in three different disciplines: maths, physics and sociology. Links within a discipline were found to be different in character to links between pages in different disciplines. There were also disciplinary differences in both types of link. As a consequence, we argue that interpretations of web science maps covering multiple disciplines will need to be sensitive to the contexts of the links mapped.",hyperlink academ web site like citat potenti use map disciplinari structur identifi evid connect disciplin paper classifi sampl link origin three differ disciplin math physic sociolog link within disciplin found differ charact link page differ disciplin also disciplinari differ type link consequ argu interpret web scienc map cover multipl disciplin need sensit context link map
99cb2f3dabf276c43f840ea09099b57ddc4199aa,Discovering and Maintaining Links on the Web of Data,,nan
bc5337b0a9c8e82ad3490409adf423a56863dc66,The Protein Data Bank: a historical perspective.,"The Protein Data Bank began as a grassroots effort in 1971. It has grown from a small archive containing a dozen structures to a major international resource for structural biology containing more than 40000 entries. The interplay of science, technology and attitudes about data sharing have all played a role in the growth of this resource.",protein data bank began grassroot effort grown small archiv contain dozen structur major intern resourc structur biolog contain entri interplay scienc technolog attitud data share play role growth resourc
41e2f85dd49bc997396bc27b630f8d10e24b4235,Addressing Big Data challenges for Scientific Data Infrastructure,"This paper discusses the challenges that are imposed by Big Data Science on the modern and future Scientific Data Infrastructure (SDI). The paper refers to different scientific communities to define requirements on data management, access control and security. The paper introduces the Scientific Data Lifecycle Management (SDLM) model that includes all the major stages and reflects specifics in data management in modern e-Science. The paper proposes the SDI generic architecture model that provides a basis for building interoperable data or project centric SDI using modern technologies and best practices. The paper explains how the proposed models SDLM and SDI can be naturally implemented using modern cloud based infrastructure services provisioning model.",paper discuss challeng impos big data scienc modern futur scientif data infrastructur sdi paper refer differ scientif commun defin requir data manag access control secur paper introduc scientif data lifecycl manag sdlm model includ major stage reflect specif data manag modern escienc paper propos sdi gener architectur model provid basi build interoper data project centric sdi use modern technolog best practic paper explain propos model sdlm sdi natur implement use modern cloud base infrastructur servic provis model
f9edcd99423749b9936d3a749d47db52005cde8d,What Kind of a Girl Does Science? The Construction of School Science Identities,"A view of science as a culturally-mediated way of thinking and knowing suggests that learning can be defined as engagement with scientific practices. How students engage in school science is influenced by whether and how students view themselves and whether or not they are the kind of person who engages in science. It is therefore crucial to understand students' identities and how they do or do not overlap with school science identities. In this paper, we describe four middle school African American girls' engagement with science. They were selected in the 7th grade because they expressed a fondness for science in school or because they had science-related hobbies outside of school. The data were collected from the following sources: interviews of students, their parents and their teachers; observations in science classes; journal writing; and focus groups. These girls' stories provide us with a better understanding of the variety of ways girls choose to engage in science and how this engagement is shaped by their views of what kind of girl they are. © 2000 John Wiley & Sons, Inc. J Res Sci Teach 37: 441–458, 2000.",view scienc culturallymedi way think know suggest learn defin engag scientif practic student engag school scienc influenc whether student view whether kind person engag scienc therefor crucial understand student ident overlap school scienc ident paper describ four middl school african american girl engag scienc select th grade express fond scienc school sciencerel hobbi outsid school data collect follow sourc interview student parent teacher observ scienc class journal write focu group girl stori provid us better understand varieti way girl choos engag scienc engag shape view kind girl john wiley son inc j re sci teach
7e0960d5a68ed9be5ad1ada6dab29aed17637aa1,Stereotypic images of the scientist: The draw‐a‐scientist test,"The present work intends to present the analysis of representations referring science and scientist of children who are part of a Junior Scientific Initiation project. The instruments used for the data collection were questionnaires and drawings, in which the analysis of this study were carried out from the Content Analysis the Laurence Bardin. With the results it was observed that the three students involved in the research have some stereotyped representations both in relation to the knowledge identified as science and in relation to the profile of scientist. It is expected, with the study, it is hoped that teachers will reflect on the information and activities they propose to students in science classes, being of great importance the previous knowledge of the students on these representations. Besides that, should teachers consider the fundamental Scientific Initiation Junior so that the students can express and extend their representations in relation to science and scientist, it is necessary that the school context modifies the ways of approaching subjects related to science and to scientists",present work intend present analysi represent refer scienc scientist children part junior scientif initi project instrument use data collect questionnair draw analysi studi carri content analysi laurenc bardin result observ three student involv research stereotyp represent relat knowledg identifi scienc relat profil scientist expect studi hope teacher reflect inform activ propos student scienc class great import previou knowledg student represent besid teacher consid fundament scientif initi junior student express extend represent relat scienc scientist necessari school context modifi way approach subject relat scienc scientist
46fb3c0ea7f91aa10d0794c0c26284deedb44695,Impact of bibliometrics upon the science system: Inadvertent consequences?,,nan
52c9e15facda9999e54b8876d8ad5f2edd885d9f,A Bayesian Truth Serum for Subjective Data,"Subjective judgments, an essential information source for science and policy, are problematic because there are no public criteria for assessing judgmental truthfulness. I present a scoring method for eliciting truthful subjective data in situations where objective truth is unknowable. The method assigns high scores not to the most common answers but to the answers that are more common than collectively predicted, with predictions drawn from the same population. This simple adjustment in the scoring criterion removes all bias in favor of consensus: Truthful answers maximize expected score even for respondents who believe that their answer represents a minority view.",subject judgment essenti inform sourc scienc polici problemat public criteria assess judgment truth present score method elicit truth subject data situat object truth unknow method assign high score common answer answer common collect predict predict drawn popul simpl adjust score criterion remov bia favor consensu truth answer maxim expect score even respond believ answer repres minor view
1fd799775cc90b4bf04424eb4d7352c10cd1ffb0,Database Paper - The IRI Marketing Data Set,"This paper describes a new data set available to academic researchers at the following website: http://mktsci.pubs.informs.org . These data are comprised of store sales and consumer panel data for 30 product categories. The store sales data contain 5 years of product sales, pricing, and promotion data for all items sold in 47 U.S. markets. In two U.S. markets, the store level data are supplemented with panel-level purchase data and cover the entire population of stores. Further information is available regarding store characteristics in these markets. We address several potential applications of these data, as well as the access protocol. 
 
The data set described in this paper is maintained by IRI. Any fees charged by IRI for the distribution of the data set will be used for the continual maintenance and updating of the data. Scholarships to cover IRI's fees for those who need it are available through the INFORMS Society for Marketing Science ISMS. Please see the website above for further details.",paper describ new data set avail academ research follow websit httpmktscipubsinformsorg data compris store sale consum panel data product categori store sale data contain year product sale price promot data item sold us market two us market store level data supplement panellevel purchas data cover entir popul store inform avail regard store characterist market address sever potenti applic data well access protocol data set describ paper maintain iri fee charg iri distribut data set use continu mainten updat data scholarship cover iri fee need avail inform societi market scienc ism pleas see websit detail
4b2b0821d9d6c9535f4f1aaf80b1e6be79a3ca3e,Networks,"The study of networks, including computer networks, social networks, and biological networks, has attracted enormous interest in recent years. The rise of the Internet and the wide availability of inexpensive computers have made it possible to gather and analyse network data on an unprecendented scale, and the development of new theoretical tools has allowed us to extract knowledge from networks of many different kinds. The study of networks is broadly interdisciplinary and developments have occurred in many fields, including mathematics, physics, computer and information sciences, biology, and the social science. This book brings together the most important breakthroughts in each of these fields and presents them in a unified fashion, highlighting the strong interconnections between work in different areas. Topics covered include the measurement of networks; methods for analysing network data, including methods developed in physics, statistics, and sociology; fundamentals of graph theory; computer algorithms, including spectral algorithms and community detection; mathematical models of networks such as random graph models and generative models; and models of processes taking place on networks.",studi network includ comput network social network biolog network attract enorm interest recent year rise internet wide avail inexpens comput made possibl gather analys network data unprecend scale develop new theoret tool allow us extract knowledg network mani differ kind studi network broadli interdisciplinari develop occur mani field includ mathemat physic comput inform scienc biolog social scienc book bring togeth import breakthrought field present unifi fashion highlight strong interconnect work differ area topic cover includ measur network method analys network data includ method develop physic statist sociolog fundament graph theori comput algorithm includ spectral algorithm commun detect mathemat model network random graph model gener model model process take place network
e346b6781fcd1ce694befddd4fd063da87db2d06,Statistics for Sensory and Consumer Science,"Preface. Acknowledgements. 1 Introduction. 1.1 The Distinction between Trained Sensory Panels and Consumer Panels. 1.2 The Need for Statistics in Experimental Planning and Analysis. 1.3 Scales and Data Types. 1.4 Organisation of the Book. 2 Important Data Collection Techniques for Sensory and Consumer Studies. 2.1 Sensory Panel Methodologies. 2.2 Consumer Tests. PART I PROBLEM DRIVEN. 3 Quality Control of Sensory Profile Data. 3.1 General Introduction. 3.2 Visual Inspection of Raw Data. 3.3 Mixed Model ANOVA for Assessing the Importance of the Sensory Attributes. 3.4 Overall Assessment of Assessor Differences Using All Variables Simultaneously. 3.5 Methods for Detecting Differences in Use of the Scale. 3.6 Comparing the Assessors Ability to Detect Differences between the Products. 3.7 Relations between Individual Assessor Ratings and the Panel Average. 3.8 Individual Line Plots for Detailed Inspection of Assessors. 3.9 Miscellaneous Methods.- 4 Correction Methods and Other Remedies for Improving Sensory Profile Data. 4.1 Introduction. 4.2 Correcting for Different Use of the Scale. 4.3 Computing Improved Panel Averages. 4.4 Pre-processing of Data for Three-Way Analysis. 5 Detecting and Studying Sensory Differences and Similarities between Products. 5.1 Introduction. 5.2 Analysing Sensory Profile Data: Univariate Case. 5.3 Analysing Sensory Profile Data: Multivariate Case. 6 Relating Sensory Data to Other Measurements. 6.1 Introduction. 6.2 Estimating Relations between Consensus Profiles and External Data. 6.3 Estimating Relations between Individual Sensory Profiles and External Data. 7 Discrimination and Similarity Testing. 7.1 Introduction. 7.2 Analysis of Data from Basic Sensory Discrimination Tests. 7.3 Examples of Basic Discrimination Testing. 7.4 Power Calculations in Discrimination Tests. 7.5 Thurstonian Modelling: What Is It Really? 7.6 Similarity versus Difference Testing. 7.7 Replications: What to Do? 7.8 Designed Experiments, Extended Analysis and Other Test Protocols. 8 Investigating Important Factors Influencing Food Acceptance and Choice. 8.1 Introduction. 8.2 Preliminary Analysis of Consumer Data Sets (Raw Data Overview). 8.3 Experimental Designs for Rating Based Consumer Studies. 8.4 Analysis of Categorical Effect Variables. 8.5 Incorporating Additional Information about Consumers. 8.6 Modelling of Factors as Continuous Variables. 8.7 Reliability/Validity Testing for Rating Based Methods. 8.8 Rank Based Methodology. 8.9 Choice Based Conjoint Analysis. 8.10 Market Share Simulation. 9 Preference Mapping for Understanding Relations between Sensory Product Attributes and Consumer Acceptance. 9.1 Introduction. 9.2 External and Internal Preference Mapping. 9.3 Examples of Linear Preference Mapping. 9.4 Ideal Point Preference Mapping. 9.5 Selecting Samples for Preference Mapping. 9.6 Incorporating Additional Consumer Attributes. 9.7 Combining Preference Mapping with Additional Information about the Samples. 10 Segmentation of Consumer Data. 10.1 Introduction. 10.2 Segmentation of Rating Data. 10.3 Relating Segments to Consumer Attributes. PART II METHOD ORIENTED. 11 Basic Statistics. 11.1 Basic Concepts and Principles. 11.2 Histogram, Frequency and Probability. 11.3 Some Basic Properties of a Distribution (Mean, Variance and Standard Deviation). 11.4 Hypothesis Testing and Confidence Intervals for the Mean . 11.5 Statistical Process Control. 11.6 Relationships between Two or More Variables. 11.7 Simple Linear Regression. 11.8 Binomial Distribution and Tests. 11.9 Contingency Tables and Homogeneity Testing. 12 Design of Experiments for Sensory and Consumer Data. 12.1 Introduction. 12.2 Important Concepts and Distinctions. 12.3 Full Factorial Designs. 12.4 Fractional Factorial Designs: Screening Designs. 12.5 Randomised Blocks and Incomplete Block Designs. 12.6 Split-Plot and Nested Designs. 12.7 Power of Experiments. 13 ANOVA for Sensory and Consumer Data. 13.1 Introduction. 13.2 One-Way ANOVA. 13.3 Single Replicate Two-Way ANOVA. 13.4 Two-Way ANOVA with Randomised Replications. 13.5 Multi-Way ANOVA. 13.6 ANOVA for Fractional Factorial Designs. 13.7 Fixed and Random Effects in ANOVA: Mixed Models. 13.8 Nested and Split-Plot Models. 13.9 Post Hoc Testing. 14 Principal Component Analysis. 14.1 Interpretation of Complex Data Sets by PCA. 14.2 Data Structures for the PCA. 14.3 PCA: Description of the Method. 14.4 Projections and Linear Combinations. 14.5 The Scores and Loadings Plots. 14.6 Correlation Loadings Plot. 14.7 Standardisation. 14.8 Calculations and Missing Values. 14.9 Validation. 14.10 Outlier Diagnostics. 14.11 Tucker-1. 14.12 The Relation between PCA and Factor Analysis (FA). 15 Multiple Regression, Principal Components Regression and Partial Least Squares Regression. 15.1 Introduction. 15.2 Multivariate Linear Regression. 15.3 The Relation between ANOVA and Regression Analysis. 15.4 Linear Regression Used for Estimating Polynomial Models. 15.5 Combining Continuous and Categorical Variables. 15.6 Variable Selection for Multiple Linear Regression. 15.7 Principal Components Regression (PCR). 15.8 Partial Least Squares (PLS) Regression. 15.9 Model Validation: Prediction Performance. 15.10 Model Diagnostics and Outlier Detection. 15.11 Discriminant Analysis. 15.12 Generalised Linear Models, Logistic Regression and Multinomial Regression. 16 Cluster Analysis: Unsupervised Classification. 16.1 Introduction. 16.2 Hierarchical Clustering. 16.3 Partitioning Methods. 16.4 Cluster Analysis for Matrices. 17 Miscellaneous Methodologies. 17.1 Three-Way Analysis of Sensory Data. 17.2 Relating Three-Way Data to Two-Way Data. 17.3 Path Modelling. 17.4 MDS-Multidimensional Scaling. 17.5 Analysing Rank Data. 17.6 The L-PLS Method. 17.7 Missing Value Estimation. Nomenclature, Symbols and Abbreviations. Index.",prefac acknowledg introduct distinct train sensori panel consum panel need statist experiment plan analysi scale data type organis book import data collect techniqu sensori consum studi sensori panel methodolog consum test part problem driven qualiti control sensori profil data gener introduct visual inspect raw data mix model anova assess import sensori attribut overal assess assessor differ use variabl simultan method detect differ use scale compar assessor abil detect differ product relat individu assessor rate panel averag individu line plot detail inspect assessor miscellan method correct method remedi improv sensori profil data introduct correct differ use scale comput improv panel averag preprocess data threeway analysi detect studi sensori differ similar product introduct analys sensori profil data univari case analys sensori profil data multivari case relat sensori data measur introduct estim relat consensu profil extern data estim relat individu sensori profil extern data discrimin similar test introduct analysi data basic sensori discrimin test exampl basic discrimin test power calcul discrimin test thurstonian model realli similar versu differ test replic design experi extend analysi test protocol investig import factor influenc food accept choic introduct preliminari analysi consum data set raw data overview experiment design rate base consum studi analysi categor effect variabl incorpor addit inform consum model factor continu variabl reliabilityvalid test rate base method rank base methodolog choic base conjoint analysi market share simul prefer map understand relat sensori product attribut consum accept introduct extern intern prefer map exampl linear prefer map ideal point prefer map select sampl prefer map incorpor addit consum attribut combin prefer map addit inform sampl segment consum data introduct segment rate data relat segment consum attribut part ii method orient basic statist basic concept principl histogram frequenc probabl basic properti distribut mean varianc standard deviat hypothesi test confid interv mean statist process control relationship two variabl simpl linear regress binomi distribut test conting tabl homogen test design experi sensori consum data introduct import concept distinct full factori design fraction factori design screen design randomis block incomplet block design splitplot nest design power experi anova sensori consum data introduct oneway anova singl replic twoway anova twoway anova randomis replic multiway anova anova fraction factori design fix random effect anova mix model nest splitplot model post hoc test princip compon analysi interpret complex data set pca data structur pca pca descript method project linear combin score load plot correl load plot standardis calcul miss valu valid outlier diagnost tucker relat pca factor analysi fa multipl regress princip compon regress partial least squar regress introduct multivari linear regress relat anova regress analysi linear regress use estim polynomi model combin continu categor variabl variabl select multipl linear regress princip compon regress pcr partial least squar pl regress model valid predict perform model diagnost outlier detect discrimin analysi generalis linear model logist regress multinomi regress cluster analysi unsupervis classif introduct hierarch cluster partit method cluster analysi matric miscellan methodolog threeway analysi sensori data relat threeway data twoway data path model mdsmultidimension scale analys rank data lpl method miss valu estim nomenclatur symbol abbrevi index
89227d150b531658bbcd23a5b02c8d147b96ed10,"Geometric representation of high dimension, low sample size data","Summary.  High dimension, low sample size data are emerging in various areas of science. We find a common structure underlying many such data sets by using a non‐standard type of asymptotics: the dimension tends to ∞ while the sample size is fixed. Our analysis shows a tendency for the data to lie deterministically at the vertices of a regular simplex. Essentially all the randomness in the data appears only as a random rotation of this simplex. This geometric representation is used to obtain several new statistical insights.",summari high dimens low sampl size data emerg variou area scienc find common structur underli mani data set use nonstandard type asymptot dimens tend sampl size fix analysi show tendenc data lie determinist vertic regular simplex essenti random data appear random rotat simplex geometr represent use obtain sever new statist insight
689178ea158205d3bd47549031e4a277926d14ac,The application of Principal Component Analysis to materials science data,"The relationship between apparently disparate sets of data is a critical component of interpreting materials' behavior, especially in terms of assessing the impact of the microscopic characteristics of materials on their macroscopic or engineering behavior. In this paper we demonstrate the value of principal component analysis of property data associated with high temperature superconductivity to examine the statistical impact of the materials' intrinsic characteristics on high temperature superconducting behavior",relationship appar dispar set data critic compon interpret materi behavior especi term assess impact microscop characterist materi macroscop engin behavior paper demonstr valu princip compon analysi properti data associ high temperatur superconduct examin statist impact materi intrins characterist high temperatur superconduct behavior
938d8e55a4262a611e8b5979ae92e1f4b01074b4,Road Traffic Data: Collection Methods and Applications,The mission of the IPTS is to provide customer-driven support to the EU policy-making process by researching science-based responses to policy challenges that have both a socioeconomic and a scientific or technological dimension. Legal Notice Neither the European Commission nor any person acting on behalf of the Commission is responsible for the use which might be made of this publication. (*) Certain mobile telephone operators do not allow access to 00 800 numbers or these calls may be billed.,mission ipt provid customerdriven support eu policymak process research sciencebas respons polici challeng socioeconom scientif technolog dimens legal notic neither european commiss person act behalf commiss respons use might made public certain mobil telephon oper allow access number call may bill
3c123bf62763d45c2c55fc06365dc2142103a729,Inductive Risk and Values in Science,"Although epistemic values have become widely accepted as part of scientific reasoning, non-epistemic values have been largely relegated to the ""external"" parts of science (the selection of hypotheses, restrictions on methodologies, and the use of scientific technologies). I argue that because of inductive risk, or the risk of error, non-epistemic values are required in science wherever non-epistemic consequences of error should be considered. I use examples from dioxin studies to illustrate how non-epistemic consequences of error can and should be considered in the internal stages of science: choice of methodology, characterization of data, and interpretation of results.",although epistem valu becom wide accept part scientif reason nonepistem valu larg releg extern part scienc select hypothes restrict methodolog use scientif technolog argu induct risk risk error nonepistem valu requir scienc wherev nonepistem consequ error consid use exampl dioxin studi illustr nonepistem consequ error consid intern stage scienc choic methodolog character data interpret result
62cd3123ddd65dff935c6c03d90788d71bec90a9,Predictive Data Mining: A Practical Guide,1 What is Data Mining? 2 Statistical Evaluation for Big Data 3 Preparing the Data 4 Data Reduction 5 Looking for Solutions 6 What's Best for Data Reduction and Mining? 7 Art or Science? Case Studies in Data Mining,data mine statist evalu big data prepar data data reduct look solut what best data reduct mine art scienc case studi data mine
4bd0c123f3d77a10cec974533263d5e0da20ab4a,A Stratosphere-Troposphere Data Assimilation System,"Abstract A data assimilation system has been developed at the UK Meteorological Office to analyze the mix of observations available in the troposphere and stratosphere. The data assimilation system is based on the analysis correction scheme used at the UK Meteorological Office for operational weather forecasting. The assimilation system is currently being used to supply near real-time analyses of meteorological fields from the troposphere and stratosphere to the Upper Atmosphere Research Satellite (UARS) Science Team. At this stage, these analyses are based on a similar set of observations to the operational analyses, so they provide an independent check of the UARS observations. In the stratosphere they are largely based on soundings from the National Oceanic and Atmospheric Administration polar orbiters. Some results from the assimilation system are presented for periods in January and August 1992. They are compared with equivalent products from the National Meteorological Center. A particular study is ...",abstract data assimil system develop uk meteorolog offic analyz mix observ avail tropospher stratospher data assimil system base analysi correct scheme use uk meteorolog offic oper weather forecast assimil system current use suppli near realtim analys meteorolog field tropospher stratospher upper atmospher research satellit uar scienc team stage analys base similar set observ oper analys provid independ check uar observ stratospher larg base sound nation ocean atmospher administr polar orbit result assimil system present period januari august compar equival product nation meteorolog center particular studi
9c01c4ec48dcfe0d15629264b1e6adc52d0a5764,Integrating vessel monitoring systems (VMS) data with daily catch data from logbooks to explore the spatial distribution of catch and effort at high resolution,"This is a pre-copy-editing, author-produced PDF of an article accepted for publication in ICES Journal of Marine Science following peer review. The definitive publisher-authenticated version “Gerritsen H., Lordan C., Integrating vessel monitoring systems (VMS) data with daily catch data from logbooks to explore the spatial distribution of catch and effort at high resolution. (2011) ICES Journal of Marine Science, 68 (1): 245-252” is available online at: http://icesjms.oxfordjournals.org/content/68/1/245",precopyedit authorproduc pdf articl accept public ice journal marin scienc follow peer review definit publisherauthent version gerritsen h lordan c integr vessel monitor system vm data daili catch data logbook explor spatial distribut catch effort high resolut ice journal marin scienc avail onlin httpicesjmsoxfordjournalsorgcont
b0c5efdf2f90322784283290a052797eb073b554,The World Ocean Database,"The World Ocean Database (WOD) is the most comprehensive global ocean profile-plankton database available internationally without restriction. All data are in one well-documented format and are available both on DVDs for a minimal charge and on-line without charge. The latest DVD version of the WOD is the World Ocean Database 2009 (WOD09). All data in the WOD are associated with as much metadata as possible, and every ocean data value has a quality control flag associated with it. The WOD is a product of the U.S. National Oceanographic Data Center and its co-located World Data Center for Oceanography. However, the WOD exists because of the international oceanographic data exchange that has occurred under the auspices of the Intergovernmental Oceanographic Commission (IOC) and the International Council of Science (ICSU) World Data Center (WDC) system. World Data Centers are part of the ICSU World Data System.",world ocean databas wod comprehens global ocean profileplankton databas avail intern without restrict data one welldocu format avail dvd minim charg onlin without charg latest dvd version wod world ocean databas wod data wod associ much metadata possibl everi ocean data valu qualiti control flag associ wod product us nation oceanograph data center coloc world data center oceanographi howev wod exist intern oceanograph data exchang occur auspic intergovernment oceanograph commiss ioc intern council scienc icsu world data center wdc system world data center part icsu world data system
b8691ae58baa4019e8fac7b59e5c129b3cc4aa84,Towards FAIR principles for research software,"The FAIR Guiding Principles, published in 2016, aim to improve the findability, accessibility,
interoperability and reusability of digital research objects for both humans and machines.
The FAIR principles are also directly relevant to research software. In this position paper
“Towards FAIR principles for research software”, we summarised and developed a basis for
community discussion. At the start, we discussed what makes software different from data
concerning the application of the FAIR principles, and which desired characteristics of
research software go beyond FAIR. Then, we presented an analysis of where the existing
principles can directly apply to software, and where they need to be adapted or
reinterpreted. Our next step after the position paper is to prompt for community-agreed
identifiers for FAIR research software.Acknowledgments
To all the authors of Towards FAIR principles for research software
https://doi.org/10.3233/DS-190026, and the numerous people who contributed to the
discussions around FAIR research software at different occasions preceding the work on this
paper. References
Lamprecht, Anna-Lena, et al. (2019) Towards FAIR principles for research software. Data
Science. https://doi.org/10.3233/DS-190026 ABOUT THE AUTHOR(S) Dr Paula Andrea Martinez is leading the National Training Program for the Characterisation
Community in Australia since 2019. She works for the National Image Facility (NIF). Last year
she worked at ELIXIR Europe coordinating the Bioinformatics and Data Science training
program in Belgium and collaborated with multiple ELIXIR nodes in the development of
Software best practices. Her career, spanning Sweden, Australia and Belgium nurtured her
experience in Bioinformatics and Research Software development for complex and dataintensive science. She started a career in Computer Science, later on, interested in research
methods development and now outreach and advocacy in data and software best practices",fair guid principl publish aim improv findabl access interoper reusabl digit research object human machin fair principl also directli relev research softwar posit paper toward fair principl research softwar summaris develop basi commun discuss start discuss make softwar differ data concern applic fair principl desir characterist research softwar go beyond fair present analysi exist principl directli appli softwar need adapt reinterpret next step posit paper prompt communityagre identifi fair research softwareacknowledg author toward fair principl research softwar httpsdoiorgd numer peopl contribut discuss around fair research softwar differ occas preced work paper refer lamprecht annalena et al toward fair principl research softwar data scienc httpsdoiorgd author dr paula andrea martinez lead nation train program characteris commun australia sinc work nation imag facil nif last year work elixir europ coordin bioinformat data scienc train program belgium collabor multipl elixir node develop softwar best practic career span sweden australia belgium nurtur experi bioinformat research softwar develop complex dataintens scienc start career comput scienc later interest research method develop outreach advocaci data softwar best practic
94b295e711ec744583597432c19749a5cd61038e,"Multicategory Support Vector Machines , Theory , and Application to the Classification of Microarray Data and Satellite Radiance Data","2002 Ph.D. in Statistics, University of Wisconsin-Madison Dissertation: Multicategory Support Vector Machines, Theory, and Application to the Classification of Microarray Data and Satellite Radiance Data Advisor: Grace Wahba, Ph.D. (Co-advisor: Yi Lin, Ph.D.) 1996 M.Sc. in Statistics, Seoul National University, Korea Thesis: Image Data Analysis by Markov Random Field Models Advisor: Jong Woo Jeon, Ph.D. 1994 B.Sc. in Computer Science and Statistics, Seoul National University, Korea",phd statist univers wisconsinmadison dissert multicategori support vector machin theori applic classif microarray data satellit radianc data advisor grace wahba phd coadvisor yi lin phd msc statist seoul nation univers korea thesi imag data analysi markov random field model advisor jong woo jeon phd bsc comput scienc statist seoul nation univers korea
dc994a4ca68c4ce94bb1c5e601bc51054f4556f1,Measuring Resemblance in Sequence Data: An Optimal Matching Analysis of Musicians' Careers,"This article introduces a method that measures resemblance between sequences using a simple metric based on the insertions, deletions, and substitutions required to transform one sequence into another. The method, called optimal matching, is widely used in natural science. The article reviews the literature on sequence analysis, then discusses the optimal matching algorithm in some detail. Applying this technique to a data set detailing careers of musicians active in Germany in the 18th century demonstrates the practical steps involved in the application of the technique and develops a set of typical careers that successfully categorize most of the actual careers studied by the authors.",articl introduc method measur resembl sequenc use simpl metric base insert delet substitut requir transform one sequenc anoth method call optim match wide use natur scienc articl review literatur sequenc analysi discuss optim match algorithm detail appli techniqu data set detail career musician activ germani th centuri demonstr practic step involv applic techniqu develop set typic career success categor actual career studi author
56125ef1ea46916f3155d0fbe3968bca344fd818,Strategies for analyzing ecological momentary assessment data.,"Studies incorporating repeated observations of momentary phenomena are becoming more common in behavioral and medical science. Analysis of such data requires the use of statistical techniques that are unfamiliar to many investigators. Some common ways of analyzing momentary data are reviewed--aggregation strategies, repeated measures analysis of variance, pooled within-person regression, and two-stage estimation procedures for multilevel models--and are found to be usually suboptimal, possibly leading to incorrect inferences. A broad class of statistical models for multilevel data that can address many research questions typically asked of momentary data are then described. Analytic issues that merit careful consideration include the scaling of momentary variables, allowance for serial autocorrelation of residuals, and the treatment of coefficients that vary across individuals as fixed versus random effects.",studi incorpor repeat observ momentari phenomena becom common behavior medic scienc analysi data requir use statist techniqu unfamiliar mani investig common way analyz momentari data reviewedaggreg strategi repeat measur analysi varianc pool withinperson regress twostag estim procedur multilevel modelsand found usual suboptim possibl lead incorrect infer broad class statist model multilevel data address mani research question typic ask momentari data describ analyt issu merit care consider includ scale momentari variabl allow serial autocorrel residu treatment coeffici vari across individu fix versu random effect
db59c6111788c9d4fa40c9de3daf7cf2625e4bc7,On the economics of information,"On November 11, 1971, the Special Interest Group of the American Society for Information Science on Behavioral and Social Sciences held a panel discussion a t the annual meeting in Denver. The audience found the ideas generated of sufficient importance to request that the highlights be published and disseminated to policy makers and other key people. In this paper, Robin Crickman' has summarized the statements of the five panelists. The primary message from these and other comments made during the panel discussion was the need to probe more deeply into the utility of knowledge for decision-making, to shift priorities toward making data more usable to policy-makers than to collectors and disseminators.",novemb special interest group american societi inform scienc behavior social scienc held panel discuss annual meet denver audienc found idea gener suffici import request highlight publish dissemin polici maker key peopl paper robin crickman summar statement five panelist primari messag comment made panel discuss need probe deepli util knowledg decisionmak shift prioriti toward make data usabl policymak collector dissemin
3646a27c7271bc02164cbc6512607e5e9f20b223,Data quality and quality control of a population-based cancer registry. Experience in Finland.,"Cancer registries should pay great attention to the quality of their data, both in terms of completeness (all cancer patients in the population are registered) and accuracy (data on individual cancer patients must be correct). In addition to technical measures in the data processing, different types of checks and comparisons should be routine practice. Active research policy and ambitious, research-oriented staff with competence in medicine, biostatistics and computer science are essential in terms of maintaining good data quality.",cancer registri pay great attent qualiti data term complet cancer patient popul regist accuraci data individu cancer patient must correct addit technic measur data process differ type check comparison routin practic activ research polici ambiti researchori staff compet medicin biostatist comput scienc essenti term maintain good data qualiti
61b045ccaf872af79d2d7baccb61fd768c8a71a6,The iPlant Collaborative: Cyberinfrastructure for Plant Biology,"The iPlant Collaborative (iPlant) is a United States National Science Foundation (NSF) funded project that aims to create an innovative, comprehensive, and foundational cyberinfrastructure in support of plant biology research (PSCIC, 2006). iPlant is developing cyberinfrastructure that uniquely enables scientists throughout the diverse fields that comprise plant biology to address Grand Challenges in new ways, to stimulate and facilitate cross-disciplinary research, to promote biology and computer science research interactions, and to train the next generation of scientists on the use of cyberinfrastructure in research and education. Meeting humanity's projected demands for agricultural and forest products and the expectation that natural ecosystems be managed sustainably will require synergies from the application of information technologies. The iPlant cyberinfrastructure design is based on an unprecedented period of research community input, and leverages developments in high-performance computing, data storage, and cyberinfrastructure for the physical sciences. iPlant is an open-source project with application programming interfaces that allow the community to extend the infrastructure to meet its needs. iPlant is sponsoring community-driven workshops addressing specific scientific questions via analysis tool integration and hypothesis testing. These workshops teach researchers how to add bioinformatics tools and/or datasets into the iPlant cyberinfrastructure enabling plant scientists to perform complex analyses on large datasets without the need to master the command-line or high-performance computational services.",iplant collabor iplant unit state nation scienc foundat nsf fund project aim creat innov comprehens foundat cyberinfrastructur support plant biolog research pscic iplant develop cyberinfrastructur uniqu enabl scientist throughout divers field compris plant biolog address grand challeng new way stimul facilit crossdisciplinari research promot biolog comput scienc research interact train next gener scientist use cyberinfrastructur research educ meet human project demand agricultur forest product expect natur ecosystem manag sustain requir synergi applic inform technolog iplant cyberinfrastructur design base unpreced period research commun input leverag develop highperform comput data storag cyberinfrastructur physic scienc iplant opensourc project applic program interfac allow commun extend infrastructur meet need iplant sponsor communitydriven workshop address specif scientif question via analysi tool integr hypothesi test workshop teach research add bioinformat tool andor dataset iplant cyberinfrastructur enabl plant scientist perform complex analys larg dataset without need master commandlin highperform comput servic
9e7a7c605264f886bee1e0b53909f825ed6e20e6,Making Data Maximally Available,"Science is driven by data. New technologies have vastly increased the ease of data collection and consequently the amount of data collected, while also enabling data to be independently mined and reanalyzed by others. And society now relies on scientific data of diverse kinds; for example, in responding to disease outbreaks, managing resources, responding to climate change, and improving transportation. It is obvious that making data widely available is an essential element of scientific research. The scientific community strives to meet its basic responsibilities toward transparency, standardization, and data archiving. Yet, as pointed out in a special section of this issue (pp. 692–729), scientists are struggling with the huge amount, complexity, and variety of the data that are now being produced.",scienc driven data new technolog vastli increas eas data collect consequ amount data collect also enabl data independ mine reanalyz other societi reli scientif data divers kind exampl respond diseas outbreak manag resourc respond climat chang improv transport obviou make data wide avail essenti element scientif research scientif commun strive meet basic respons toward transpar standard data archiv yet point special section issu pp scientist struggl huge amount complex varieti data produc
cab479743ab6c15bc7a6245296c5b9f11ae8acfa,Making Social Science Work Across Space and Time: A Critical Reflection on Robert Putnam's Making Democracy Work,"Political scientists are becoming more self-conscious about how they connect quantitative and qualitative data in social science and about the role of systematic country studies in comparative research. As the most striking example of both practices in recent years, Robert Putnam and his collaborators' Making Democracy Work deserves more serious criticism than it has received. While Putnam's original project aimed at a precise goal—studying how a new administrative reform is institutionalized—his ultimate project aimed at nothing less than examining how differently democracy works in different sociopolitical contexts, operationalized cross-sectionally in southern and northern Italy. The sources of these differences he found in the two regions' histories, which led him to employ the quantitative interregional data he had collected for one purpose to support a model of historical development of North and South. This historical reconstruction rests largely on qualitative data; but it also rests on a set of comparative inferences about individual values and community cohesiveness in the two regions that is of questionable historical validity and innocent of structural grounding. This article applauds Putnam's joining qualitative and quantitative data but attacks his reconstruction of Italian history to fit his model of social capital.",polit scientist becom selfconsci connect quantit qualit data social scienc role systemat countri studi compar research strike exampl practic recent year robert putnam collabor make democraci work deserv seriou critic receiv putnam origin project aim precis goalstudi new administr reform institutionalizedhi ultim project aim noth less examin differ democraci work differ sociopolit context operation crosssect southern northern itali sourc differ found two region histori led employ quantit interregion data collect one purpos support model histor develop north south histor reconstruct rest larg qualit data also rest set compar infer individu valu commun cohes two region question histor valid innoc structur ground articl applaud putnam join qualit quantit data attack reconstruct italian histori fit model social capit
85705ada0f98731a51b76ce8a49441b6f3785046,"Data, Relativism and Archaeological Science",Discussion du mode de production des donnees : le modele ethnographique de production des donnees n'est pas adapte a l'archeologie et conduit a des erreurs d'appreciation du passe,discuss du mode de product de donne le model ethnographiqu de product de donne nest pa adapt larcheologi et conduit de erreur dappreci du pass
90faebb8c0e629202ab8a33ba44c78c68c312ba0,Student conceptualizations of the nature of science in response to a socioscientific issue,"This study investigates student conceptualizations of the nature of science (NOS) and how students interpret and evaluate conflicting evidence regarding a socioscientific issue. Eighty‐four high school students participated in the study by reading contradictory reports about the status of global warming and responding to questions designed to elicit ideas pertinent to the research goals. A subsample of 30 students was interviewed in order to triangulate data from the written responses. Data were analyzed using a qualitative methodological approach. The participants displayed a range of views on three distinct aspects of NOS: empiricism, tentativeness, and social embeddedness. Findings indicate that interpretation and evaluation of conflicting evidence in a socioscientific context is influenced by a variety of factors related to NOS such as data interpretation and social interactions including individuals' own articulation of personal beliefs and scientific knowledge. Implications for science teaching and learning are discussed.",studi investig student conceptu natur scienc no student interpret evalu conflict evid regard socioscientif issu eightyfour high school student particip studi read contradictori report statu global warm respond question design elicit idea pertin research goal subsampl student interview order triangul data written respons data analyz use qualit methodolog approach particip display rang view three distinct aspect no empiric tent social embedded find indic interpret evalu conflict evid socioscientif context influenc varieti factor relat no data interpret social interact includ individu articul person belief scientif knowledg implic scienc teach learn discuss
6cadb82f9cd0daf03c39155fccc0435c55e690b0,State of the art of graph-based data mining,The need for mining structured data has increased in the past few years. One of the best studied data structures in computer science and discrete mathematics are graphs. It can therefore be no surprise that graph based data mining has become quite popular in the last few years.This article introduces the theoretical basis of graph based data mining and surveys the state of the art of graph-based data mining. Brief descriptions of some representative approaches are provided as well.,need mine structur data increas past year one best studi data structur comput scienc discret mathemat graph therefor surpris graph base data mine becom quit popular last yearsthi articl introduc theoret basi graph base data mine survey state art graphbas data mine brief descript repres approach provid well
d6722587872877b8cb6edf67675185c0ae48bf0d,Teaching objects-first in introductory computer science,"An objects-first strategy for teaching introductory computer science courses is receiving increased attention from CS educators. In this paper, we discuss the challenge of the objects-first strategy and present a new approach that attempts to meet this challenge. The new approach is centered on the visualization of objects and their behaviors using a 3D animation environment. Statistical data as well as informal observations are summarized to show evidence of student performance as a result of this approach. A comparison is made of the pedagogical aspects of this new approach with that of other relevant work.",objectsfirst strategi teach introductori comput scienc cours receiv increas attent cs educ paper discuss challeng objectsfirst strategi present new approach attempt meet challeng new approach center visual object behavior use anim environ statist data well inform observ summar show evid student perform result approach comparison made pedagog aspect new approach relev work
07ecb2b8de1cd5f61936c60b9fdc52c31d4b3f22,Unraveling the Complexities of Life Sciences Data,"The life sciences have entered into the realm of big data and data-enabled science, where data can either empower or overwhelm. These data bring the challenges of the 5 Vs of big data: volume, veracity, velocity, variety, and value. Both independently and through our involvement with DELSA Global (Data-Enabled Life Sciences Alliance, DELSAglobal.org), the Kolker Lab ( kolkerlab.org ) is creating partnerships that identify data challenges and solve community needs. We specialize in solutions to complex biological data challenges, as exemplified by the community resource of MOPED (Model Organism Protein Expression Database, MOPED.proteinspire.org ) and the analysis pipeline of SPIRE (Systematic Protein Investigative Research Environment, PROTEINSPIRE.org ). Our collaborative work extends into the computationally intensive tasks of analysis and visualization of millions of protein sequences through innovative implementations of sequence alignment algorithms and creation of the Protein Sequence Universe tool (PSU). Pushing into the future together with our collaborators, our lab is pursuing integration of multi-omics data and exploration of biological pathways, as well as assigning function to proteins and porting solutions to the cloud. Big data have come to the life sciences; discovering the knowledge in the data will bring breakthroughs and benefits.",life scienc enter realm big data dataen scienc data either empow overwhelm data bring challeng vs big data volum verac veloc varieti valu independ involv delsa global dataen life scienc allianc delsaglobalorg kolker lab kolkerlaborg creat partnership identifi data challeng solv commun need special solut complex biolog data challeng exemplifi commun resourc mope model organ protein express databas mopedproteinspireorg analysi pipelin spire systemat protein investig research environ proteinspireorg collabor work extend comput intens task analysi visual million protein sequenc innov implement sequenc align algorithm creation protein sequenc univers tool psu push futur togeth collabor lab pursu integr multiom data explor biolog pathway well assign function protein port solut cloud big data come life scienc discov knowledg data bring breakthrough benefit
da1b6a6d102724fdccd9a3c57a41554fccf40092,Managing and Mining Uncertain Data,,nan
d09f846b76d78a3d5439b0c7ecfa446fbecdddd2,"Framing Experience: Concept Maps, Mind Maps, and Data Collection in Qualitative Research","Traditionally, qualitative data collection has focused on observation, interviews, and document or artifact review. Building on earlier work on concept mapping in the social sciences, the authors describe its use in an exploratory pilot study on the perceptions of four Canadians who worked abroad on a criminal justice reform project. Drawing on this study, the authors argue that traditional definitions of concept mapping should be expanded to include more flexible approaches to the collection of graphic representations of experience. In this way, user-generated maps can assist participants to better frame their experience and can help qualitative researchers in the design and development of additional data collection strategies. Whether one calls these data collection tools concept maps or mind maps, for a generation of visually oriented social science researchers they offer a graphic and participant-centric means to ground data within theory.",tradit qualit data collect focus observ interview document artifact review build earlier work concept map social scienc author describ use exploratori pilot studi percept four canadian work abroad crimin justic reform project draw studi author argu tradit definit concept map expand includ flexibl approach collect graphic represent experi way usergener map assist particip better frame experi help qualit research design develop addit data collect strategi whether one call data collect tool concept map mind map gener visual orient social scienc research offer graphic participantcentr mean ground data within theori
f67dad4e1fc000cb8ebb2cb6a8c3f7183d0efe86,Rebooting MOOC Research,"Improve assessment, data sharing, and experimental design The chief executive officer of edX, Anant Agarwal, declared that Massive Open Online Courses (MOOCs) should serve as “particle accelerator for learning” (1). MOOCs provide new sources of data and opportunities for large-scale experiments that can advance the science of learning. In the years since MOOCs first attracted widespread attention, new lines of research have begun, but findings from these efforts have had few implications for teaching and learning. Big data sets do not, by virtue of their size, inherently possess answers to interesting questions. For MOOC research to advance the science of learning, researchers, course developers, and other stakeholders must advance the field along three trajectories: from studies of engagement to research about learning, from investigations of individual courses to comparisons across contexts, and from a reliance on post hoc analyses to greater use of multidisciplinary, experimental design.",improv assess data share experiment design chief execut offic edx anant agarw declar massiv open onlin cours mooc serv particl acceler learn mooc provid new sourc data opportun largescal experi advanc scienc learn year sinc mooc first attract widespread attent new line research begun find effort implic teach learn big data set virtu size inher possess answer interest question mooc research advanc scienc learn research cours develop stakehold must advanc field along three trajectori studi engag research learn investig individu cours comparison across context relianc post hoc analys greater use multidisciplinari experiment design
c9144c907de1cd5096d1496058782aa7a05ae52e,Suggestions for presenting the results of data analyses,"We give suggestions for the presentation of research results from frequentist, information-theoretic, and Bayesian analysis paradigms, followed by several general suggestions. The information-theoretic and Bayesian methods offer alternative approaches to data analysis and inference compared to traditionally used methods. Guidance is lacking on the presentation of results under these alternative procedures and on nontesting aspects of classical frequentist methods of statistical analysis. Null hypothesis testing has come under intense criticism. We recommend less reporting of the results of statistical tests of null hypotheses in cases where the null is surely false anyway, or where the null hypothesis is of little interest to science or management.",give suggest present research result frequentist informationtheoret bayesian analysi paradigm follow sever gener suggest informationtheoret bayesian method offer altern approach data analysi infer compar tradit use method guidanc lack present result altern procedur nontest aspect classic frequentist method statist analysi null hypothesi test come intens critic recommend less report result statist test null hypothes case null sure fals anyway null hypothesi littl interest scienc manag
d9c38786fc70eb9a135405cc5ac76f05b778e66c,Dynamic Data Driven Applications Systems: A New Paradigm for Application Simulations and Measurements,,nan
34d0f17694eb50bd8365e13dde6d93cd82dd9881,An overview of MODIS capabilities for ocean science observations,"The Moderate Resolution Imaging Spectroradiometer (MODIS) will add a significant new capability for investigating the 70% of the Earth's surface that is covered by oceans, in addition to contributing to the continuation of a decadal scale time series necessary for climate change assessment in the oceans. Sensor capabilities of particular importance for improving the accuracy of ocean products include high SNR and high stability for narrow or spectral bands, improved onboard radiometric calibration and stability monitoring, and improved science data product algorithms. Spectral bands for resolving solar-stimulated chlorophyll fluorescence and a split window in the 4-/spl mu/m region for SST will result in important new global ocean science products for biology and physics. MODIS will return full global data at 1-km resolution. The complete suite of Levels 2 and 3 ocean products is reviewed, and many areas where MODIS data are expected to make significant, new contributions to the enhanced understanding of the oceans' role in understanding climate change are discussed. In providing a highly complementary and consistent set of observations of terrestrial, atmospheric, and ocean observations, MODIS data will provide important new information on the interactions between Earth's major components.",moder resolut imag spectroradiomet modi add signific new capabl investig earth surfac cover ocean addit contribut continu decad scale time seri necessari climat chang assess ocean sensor capabl particular import improv accuraci ocean product includ high snr high stabil narrow spectral band improv onboard radiometr calibr stabil monitor improv scienc data product algorithm spectral band resolv solarstimul chlorophyl fluoresc split window spl mum region sst result import new global ocean scienc product biolog physic modi return full global data km resolut complet suit level ocean product review mani area modi data expect make signific new contribut enhanc understand ocean role understand climat chang discuss provid highli complementari consist set observ terrestri atmospher ocean observ modi data provid import new inform interact earth major compon
9b41e7559902658b5a6a85c2d06bdc8dd3d8806e,The Open Science Grid,"The U.S. LHC Tier-1 and Tier-2 laboratories and universities are developing production Grids to support LHC applications running across a worldwide Grid computing system. Together with partners in computer science, physics grid projects and (active experiments, we will build a common national production grid infrastructure which is open in its architecture, implementation and use. The Open Science Grid (OSG) model builds upon the successful approach of last year's joint Grid2003 project. The Grid3 shared infrastructure has for over eight months provided significant computational resources and throughput to a range of applications, including ATLAS and CMS data challenges, SDSS, LIGO, and biology analyses, and computer science demonstrators and experiments. To move towards LHC-scale data management, access and analysis capabilities, we must increase the scale, services, and sustainability of the current infrastructure by an order of magnitude or more. Thus, we must achieve a significant upgrade in its functionalities and technologies. The initial OSG partners will build upon a fully usable, sustainable and robust grid. Initial partners include the US LHC collaborations, DOE & NSF Laboratories and Universities & Trillium Grid projects. The approach is to federate with other application communities in the U.S. to build a shared infrastructure open to other sciences and capable of being modified and improved to respond to needs of other applications, including CDF, D0, BaBar, and RHIC experiments. We describe the application-driven, engineered services of the OSG, short term plans and status, and the roadmap for a consortium, its partnerships and national focus. The partners in the Open Science Grid Consortium have come together to build a sustainable national production Grid infrastructure in the United States that will be open to scientific collaborations. The Consortium will build on and evolve the existing Grid3 [2] common shared infrastructure together with the distributed computing facilities at the Laboratories and Universities, including the Fermilab SAMGrid [3] system. The Open Science Grid Consortium will act to integrate, deploy, maintain and operate a shared common infrastructure to the benefit of all its users. To meet the long-term needs of the experimental physics community in the US, existing grid infrastructures must evolve by an order of magnitude or more in size, performance, and capabilities. The Consortium plans to evolve the grid infrastructure to meet both these needs and computational needs of other science partners. Our vision is to make a significant step forward in cooperative development and Grid interoperation on a global …",us lhc tier tier laboratori univers develop product grid support lhc applic run across worldwid grid comput system togeth partner comput scienc physic grid project activ experi build common nation product grid infrastructur open architectur implement use open scienc grid osg model build upon success approach last year joint grid project grid share infrastructur eight month provid signific comput resourc throughput rang applic includ atla cm data challeng sdss ligo biolog analys comput scienc demonstr experi move toward lhcscale data manag access analysi capabl must increas scale servic sustain current infrastructur order magnitud thu must achiev signific upgrad function technolog initi osg partner build upon fulli usabl sustain robust grid initi partner includ us lhc collabor doe nsf laboratori univers trillium grid project approach feder applic commun us build share infrastructur open scienc capabl modifi improv respond need applic includ cdf babar rhic experi describ applicationdriven engin servic osg short term plan statu roadmap consortium partnership nation focu partner open scienc grid consortium come togeth build sustain nation product grid infrastructur unit state open scientif collabor consortium build evolv exist grid common share infrastructur togeth distribut comput facil laboratori univers includ fermilab samgrid system open scienc grid consortium act integr deploy maintain oper share common infrastructur benefit user meet longterm need experiment physic commun us exist grid infrastructur must evolv order magnitud size perform capabl consortium plan evolv grid infrastructur meet need comput need scienc partner vision make signific step forward cooper develop grid interoper global
7f54287fa97b1b0e1b6780e684312c0384fee675,The Quality of Students' Use of Evidence in Written Scientific Explanations,"Drawing on sociological and philosophical studies of science, science educators have begun to view argumentation as a central scientific practice that students should learn. In this article, we extend recent work to understand the structure of students' arguments to include judgments about their quality through content analyses of high school students' written explanations for 2 problems of natural selection. In these analyses, we aim to explicate the relations between students' conceptual understanding of specific domains and their epistemic understanding of scientific practices of argumentation as they try to learn science through inquiry. We present a method that assesses the warrant of explanatory claims, the sufficiency of the evidence explicitly cited for claims, and students' rhetorical use of specific inscriptions in their arguments. Students were attentive to the need to cite data, yet they often failed to cite sufficient evidence for claims. Students' references to specific inscriptions in their arguments often failed to articulate how specific data related to particular claims. We discuss these patterns of data citation in terms of what they suggest about students' epistemological ideas about explanation and consequent implications for inquiry-oriented, science education reforms.",draw sociolog philosoph studi scienc scienc educ begun view argument central scientif practic student learn articl extend recent work understand structur student argument includ judgment qualiti content analys high school student written explan problem natur select analys aim explic relat student conceptu understand specif domain epistem understand scientif practic argument tri learn scienc inquiri present method assess warrant explanatori claim suffici evid explicitli cite claim student rhetor use specif inscript argument student attent need cite data yet often fail cite suffici evid claim student refer specif inscript argument often fail articul specif data relat particular claim discuss pattern data citat term suggest student epistemolog idea explan consequ implic inquiryori scienc educ reform
d78511778677a0826f097ebc274563b242f7e761,The Open Science Grid,"The Open Science Grid (OSG) provides a distributed facility where the Consortium members provide guaranteed and opportunistic access to shared computing and storage resources. OSG provides support for and evolution of the infrastructure through activities that cover operations, security, software, troubleshooting, addition of new capabilities, and support for existing and engagement with new communities. The OSG SciDAC-2 project provides specific activities to manage and evolve the distributed infrastructure and support its use. The innovative aspects of the project are the maintenance and performance of a collaborative (shared & common) petascale national facility over tens of autonomous computing sites, for many hundreds of users, transferring terabytes of data a day, executing tens of thousands of jobs a day, and providing robust and usable resources for scientific groups of all types and sizes. More information can be found at the OSG web site: www.opensciencegrid.org.",open scienc grid osg provid distribut facil consortium member provid guarante opportunist access share comput storag resourc osg provid support evolut infrastructur activ cover oper secur softwar troubleshoot addit new capabl support exist engag new commun osg scidac project provid specif activ manag evolv distribut infrastructur support use innov aspect project mainten perform collabor share common petascal nation facil ten autonom comput site mani hundr user transfer terabyt data day execut ten thousand job day provid robust usabl resourc scientif group type size inform found osg web site wwwopensciencegridorg
ef6b6d214289d19f98dc38cdb9406001b921edd9,Qualitative Research for the Social Sciences,"PART I. CONCEPTUAL AND HISTORICAL CONTEXT Chapter 1. Introduction Chapter 2. Qualitative Research-A Reflexive Stance Chapter 3. Ethical Issues in Qualitative Research Chapter 4. Conceptualizing Research Approaches Chapter 5. A Detailed Examination of Common Approaches Chapter 6. A Review of Additional Research Approaches PART II. THE QUALITATIVE RESEARCH PROCESS Chapter 7. Planning and Conceptualizing a Qualitative Research Study Chapter 8. Social Media, the Internet, and Technology Chapter 9. A Review of Research Literature Chapter 10. Interviewing Chapter 11. Additional Methods of Gathering Data PART III. THE FINAL PRODUCT Chapter 12. Drawing Meaning from the Data Chapter 13. Communicating Your Ideas Chapter 14. Judging the Research Process and Product Epilogue: Social Science and the Future of Qualitative Research Glossary",part conceptu histor context chapter introduct chapter qualit researcha reflex stanc chapter ethic issu qualit research chapter conceptu research approach chapter detail examin common approach chapter review addit research approach part ii qualit research process chapter plan conceptu qualit research studi chapter social media internet technolog chapter review research literatur chapter interview chapter addit method gather data part iii final product chapter draw mean data chapter commun idea chapter judg research process product epilogu social scienc futur qualit research glossari
057fd4df2816fdc5c19c0c26ca80921324c98123,"Interpretation of Inaccurate, Insufficient and Inconsistent Data","Sumntary Many problems in physical science involve the estimation of a number of unknown parameters which bear a linear or quasi-linear relationship to a set of experimental data. The data may be contaminated by random errors, insufficient to determine the unknowns, redundant, or all of the above. This paper presents a method of optimizing the conclusions from such a data set. The problem is formulated as an ill-posed matrix equation, and general criteria are established for constructing an ‘ inverse ’ matrix. The ‘ solution ’ to the problem is defined in terms of a set of generalized eigenvectors of the matrix, and may be chosen to optimize the resolution provided by the data, the expected error in the solution, the fit to the data, the proximity of the solution to an arbitrary function, or any combination of the above. The classical ‘ least-squares ’ solution is discussed as a special case.",sumntari mani problem physic scienc involv estim number unknown paramet bear linear quasilinear relationship set experiment data data may contamin random error insuffici determin unknown redund paper present method optim conclus data set problem formul illpos matrix equat gener criteria establish construct invers matrix solut problem defin term set gener eigenvector matrix may chosen optim resolut provid data expect error solut fit data proxim solut arbitrari function combin classic leastsquar solut discuss special case
621398d6fc7b7f98191695ae427f58f52abba5c2,OECD Principles and Guidelines for Access to Research Data from Public Funding,"Ministers of science and technology asked the OECD in January 2004 to develop international guidelines on access to research data from public funding. The resulting Principles and Guidelines for Access to Research Data from Public Funding were recently approved by OECD governments and are discussed below. They are intended to promote data access and sharing among researchers, research institutions, and national research agencies. OECD member countries have committed to taking these principles and guidelines into account in developing their own national laws and research policies, taking account of differences in their respective national context.",minist scienc technolog ask oecd januari develop intern guidelin access research data public fund result principl guidelin access research data public fund recent approv oecd govern discuss intend promot data access share among research research institut nation research agenc oecd member countri commit take principl guidelin account develop nation law research polici take account differ respect nation context
c152c6358d89e4a0a64a876d1d54e1a6b9291b4a,Mixed method data collection strategies,"Social scientists have long relied on a wide range of tools to collect information about the social world, but as individual fields have become more specialised, researchers are trained to use a narrow range of the possible data collection methods. This book, first published in 2006, draws on a broad range of available social data collection methods to formulate a set of data collection approaches. The approaches described here are ideal for social science researchers who plan to collect new data about people, organisations, or social processes. Axinn and Pearce present methods designed to create a comprehensive empirical description of the subject being studied, with an emphasis on accumulating the information needed to understand what causes what with a minimum of error. In addition to providing methodological motivation and underlying principles, the book is filled with detailed instructions and concrete examples for those who wish to apply the methods to their research.",social scientist long reli wide rang tool collect inform social world individu field becom specialis research train use narrow rang possibl data collect method book first publish draw broad rang avail social data collect method formul set data collect approach approach describ ideal social scienc research plan collect new data peopl organis social process axinn pearc present method design creat comprehens empir descript subject studi emphasi accumul inform need understand caus minimum error addit provid methodolog motiv underli principl book fill detail instruct concret exampl wish appli method research
ea5c82d066cc20a9cf90fb5921071c7f501e4337,Handling Data Skew in MapReduce,"MapReduce systems have become popular for processing large data sets and are increasingly being used in e-science applications. In contrast to simple application scenarios like word count, e-science applications involve complex computations which pose new challenges to MapReduce systems. In particular, (a) the runtime complexity of the reducer task is typically high, and (b) scientific data is often skewed. This leads to highly varying execution times for the reducers. Varying execution times result in low resource utilisation and high overall execution time since the next MapReduce cycle can only start after all reducers are done. In this paper we address the problem of efficiently processing MapReduce jobs with complex reducer tasks over skewed data. We define a new cost model that takes into account non-linear reducer tasks and we provide an algorithm to estimate the cost in a distributed environment. We propose two load balancing approaches, fine partitioning and dynamic fragmentation, that are based on our cost model and can deal with both skewed data and complex reduce tasks. Fine partitioning produces a fixed number of data partitions, dynamic fragmentation dynamically splits large partitions into smaller portions and replicates data if necessary. Our approaches can be seamlessly integrated into existing MapReduce systems like Hadoop. We empirically evaluate our solution on both synthetic data and real data from an e-science application.",mapreduc system becom popular process larg data set increasingli use escienc applic contrast simpl applic scenario like word count escienc applic involv complex comput pose new challeng mapreduc system particular runtim complex reduc task typic high b scientif data often skew lead highli vari execut time reduc vari execut time result low resourc utilis high overal execut time sinc next mapreduc cycl start reduc done paper address problem effici process mapreduc job complex reduc task skew data defin new cost model take account nonlinear reduc task provid algorithm estim cost distribut environ propos two load balanc approach fine partit dynam fragment base cost model deal skew data complex reduc task fine partit produc fix number data partit dynam fragment dynam split larg partit smaller portion replic data necessari approach seamlessli integr exist mapreduc system like hadoop empir evalu solut synthet data real data escienc applic
7b73e8701e94899a99d25741079d0dff554f3ab2,Service-Oriented Science,"New information architectures enable new approaches to publishing and accessing valuable data and programs. So-called service-oriented architectures define standard interfaces and protocols that allow developers to encapsulate information tools as services that clients can access without knowledge of, or control over, their internal workings. Thus, tools formerly accessible only to the specialist can be made available to all; previously manual data-processing and analysis tasks can be automated by having services access services. Such service-oriented approaches to science are already being applied successfully, in some cases at substantial scales, but much more effort is required before these approaches are applied routinely across many disciplines. Grid technologies can accelerate the development and adoption of service-oriented science by enabling a separation of concerns between discipline-specific content and domain-independent software and hardware infrastructure.",new inform architectur enabl new approach publish access valuabl data program socal serviceori architectur defin standard interfac protocol allow develop encapsul inform tool servic client access without knowledg control intern work thu tool formerli access specialist made avail previous manual dataprocess analysi task autom servic access servic serviceori approach scienc alreadi appli success case substanti scale much effort requir approach appli routin across mani disciplin grid technolog acceler develop adopt serviceori scienc enabl separ concern disciplinespecif content domainindepend softwar hardwar infrastructur
12ec8bc371e72fc2613829daf26b25b2c001c30a,Comparative Welfare States Data Set,"The data contained in this data set were collected by a project entitled ""Comparative Welfare States in the 21 Century"" directed by David Brady, Evelyne Huber, and John D. Stephens. The project was supported in 2011-13 by grants from the National Science Foundation (""Collaborative Research: Comparative Welfare States: A Public Use Archival Dataset,” SES 1059959 and 1061007). Additional support was provided by the Morehead Alumni Distinguished Professorship and the Margaret and Paul A. Johnston Professorships (funding the Gerhard E. Lenski, Jr. Distinguished Professorship) in the College of Arts and Sciences at the University of North Carolina at Chapel Hill. Some further support was provided by Duke University and the WZB Berlin Social Science Center. An earlier version of this dataset was assembled by Evelyne Huber, Charles Ragin, and John Stephens in the 1990s. That project was supported in 1990-92 by a grant from the National Science Foundation (Grant # SES 9108716). Please direct correspondence to David Brady at david.brady@ucr.edu.",data contain data set collect project entitl compar welfar state centuri direct david bradi evelyn huber john stephen project support grant nation scienc foundat collabor research compar welfar state public use archiv dataset se addit support provid morehead alumni distinguish professorship margaret paul johnston professorship fund gerhard e lenski jr distinguish professorship colleg art scienc univers north carolina chapel hill support provid duke univers wzb berlin social scienc center earlier version dataset assembl evelyn huber charl ragin john stephen project support grant nation scienc foundat grant se pleas direct correspond david bradi davidbradyucredu
642e65252035e32ea1dd2e3ced3ae7f62b754cd8,Principles of research in behavioral science,"1. THE SCIENCE OF PSYCHOLOGY: THEORY, RESEARCH, AND APPLICATION Science / Theories / Research / Theory, Research, and Application2. RESEARCH STRATEGIES: AN OVERVIEW Purposes of Research / Quantitative and Qualitative Research / Research Strategies / Time Perspectives: Short-Term versus Long-Term / Research Settings: Laboratory versus Field / Research as a Set of Tradeoffs3. THE ETHICAL TREATMENT OF RESEARCH PARTICIPANTS Responsibility for Ethical Research / Ethical Considerations in Planning Research / Ethical Considerations During Data Collection / Ethical Considerations Following Data Collection4. FORMULATING A RESEARCH QUESTION Formulating Research Hypotheses / Replication Research / Designing Research for Utilization / Bias in the Formulation of Research Questions5. DEVELOPING A MEASUREMENT STRATEGY Reliability and Validity / Modalities of Measurement / Evaluating and Selecting Measures 6. THE INTERNAL VALIDITY OF RESEARCH Confounds / Threats to Internal Validity / Reactivity / Demand Characteristics / Experimenter Expectancies7. THE EXPERIMENTAL RESEARCH STRATEGY A Note on Statistics / Manipulating the Independent Variable / Controlling Extraneous Variance / Multiple-Group Designs / Factorial Designs8. THE CORRELATIONAL (PASSIVE) RESEARCH STRATEGY The Nature of Correlational Research / Simple and Partial Correlation Analysis / Multiple Regression Analysis (MRA) / Some Other Correlational Techniques / Testing Mediational Hypotheses / Factor Analysis9. THE SINGLE-CASE RESEARCH STRATEGY The Role of Single-Case Research in Psychology / Validity Criteria in Single-Case Research / Case Study Research / Single-Case Experiments / Data Analysis in Single-Case Research10. RESEARCH IN NATURAL SETTINGS The Problem of Control in Natural Settings / Field Experiments / Natural Experiments and Quasi-Experiments / Naturalistic Observation / Interviews / Archival Data / Coding Open-Ended Data11. SURVEY RESEARCH Asking Questions / Obtaining Answers / Multi-Item Scales / Response Biases / Questionnaire Design / Questionnaire Administration / Survey Data Archives12. DATA COLLECTION Research Participants / Research Procedures / Using the Internet to Collect Data13. INTERPRETING RESEARCH RESULTS Describing Results / Interpreting the Results / Fitting Results into the Big Picture14. THE EXTERNAL VALIDITY OF RESEARCH The Concept of External Validity / The Structural Component of External Validity / The Functional and Conceptual Components of External Validity / Assessing External Validity / Laboratory Research, Natural-Setting Research, and External Validity15. EVALUATION RESEARCH Goal Definition / Program Monitoring / Impact Assessment / Efficiency Analysis / Information Utilization / Measuring Change16. INTEGRATIVE LITERATURE REVIEWING Defining the Research Question / Data Collection / Data Evaluation / Data Analysis / Data Interpretation / A Sample Meta-Analysis17. WRITING RESEARCH REPORTS The Research Report / Journal Articles and Convention Presentations / Ethical Issues in Publication18. THE PROFESSIONAL AND SOCIAL RESPONSIBILITIES OF SCIENTISTS Malpractice in Research / Mistakes and Error in Research / Using the Results of Research / Research and the Common Good",scienc psycholog theori research applic scienc theori research theori research applic research strategi overview purpos research quantit qualit research research strategi time perspect shortterm versu longterm research set laboratori versu field research set tradeoff ethic treatment research particip respons ethic research ethic consider plan research ethic consider data collect ethic consider follow data collect formul research question formul research hypothes replic research design research util bia formul research question develop measur strategi reliabl valid modal measur evalu select measur intern valid research confound threat intern valid reactiv demand characterist experiment expect experiment research strategi note statist manipul independ variabl control extran varianc multiplegroup design factori design correl passiv research strategi natur correl research simpl partial correl analysi multipl regress analysi mra correl techniqu test mediat hypothes factor analysi singlecas research strategi role singlecas research psycholog valid criteria singlecas research case studi research singlecas experi data analysi singlecas research research natur set problem control natur set field experi natur experi quasiexperi naturalist observ interview archiv data code openend data survey research ask question obtain answer multiitem scale respons bias questionnair design questionnair administr survey data archiv data collect research particip research procedur use internet collect data interpret research result describ result interpret result fit result big pictur extern valid research concept extern valid structur compon extern valid function conceptu compon extern valid assess extern valid laboratori research naturalset research extern valid evalu research goal definit program monitor impact assess effici analysi inform util measur chang integr literatur review defin research question data collect data evalu data analysi data interpret sampl metaanalysi write research report research report journal articl convent present ethic issu public profession social respons scientist malpractic research mistak error research use result research research common good
469c93bd8a79c6a400405437cbb97cbfa3a27abe,Data Streams: Models and Algorithms (Advances in Database Systems),"This book primarily discusses issues related to the mining aspects of data streams and it is unique in its primary focus on the subject. This volume covers mining aspects of data streams comprehensively: each contributed chapter contains a survey on the topic, the key ideas in the field for that particular topic, and future research directions. The book is intended for a professional audience composed of researchers and practitioners in industry. This book is also appropriate for advanced-level students in computer science.",book primarili discuss issu relat mine aspect data stream uniqu primari focu subject volum cover mine aspect data stream comprehens contribut chapter contain survey topic key idea field particular topic futur research direct book intend profession audienc compos research practition industri book also appropri advancedlevel student comput scienc
fd2e8585481501c2fc5871d0dd60d9b758bfdba6,Important but not for me: students’ attitudes towards secondary school science in England,"This article presents some of the results of the questionnaire‐based Relevance of Science Education Project (ROSE) carried out in England in the latter half of 2003 as part of a wider international comparative study based at the University of Oslo. Data, drawn from 1277 students, most of whom were 14 or 15 years old, indicate their views about their school science education, their choice of careers and what they would most like to learn about in their science lessons. The findings are placed in the context of other accounts of the ‘student voice’ in science education and their implications for policy and science curriculum reform are discussed.",articl present result questionnairebas relev scienc educ project rose carri england latter half part wider intern compar studi base univers oslo data drawn student year old indic view school scienc educ choic career would like learn scienc lesson find place context account student voic scienc educ implic polici scienc curriculum reform discuss
fa23c195b5ac15e571d386f37da3afe912d42f88,Longitudinal and Panel Data,"This focuses on models and data that arise from repeated observations of a cross-section of individuals, households or companies. These models have found important applications within business, economics, education, political science and other social science disciplines. The author introduces the foundations of longitudinal and panel data analysis at a level suitable for quantitatively oriented graduate social science students as well as individual researchers. He emphasizes mathematical and statistical fundamentals but also describes substantive applications from across the social sciences, showing the breadth and scope that these models enjoy. The applications are enhanced by real-world data sets and software programs in SAS and Stata.",focus model data aris repeat observ crosssect individu household compani model found import applic within busi econom educ polit scienc social scienc disciplin author introduc foundat longitudin panel data analysi level suitabl quantit orient graduat social scienc student well individu research emphas mathemat statist fundament also describ substant applic across social scienc show breadth scope model enjoy applic enhanc realworld data set softwar program sa stata
937287b0c249add46f61718c170542294b226ccf,Astronomical Data Analysis Software and Systems Xv,"Until 23 Nov 2003, no total solar eclipse (TSE) had ever been observed from the Antarctic. Yet, interest in securing observations of that event, visible only from the Antarctic, was extremely high and provided the impetus for breaking that paradigm of elusivity in the historical record of science and exploration. The execution of a lunar shadow intercept and the conduction of an observing program from a Boeing 747-400 ER aircraft over the Antarctic interior permitted the previously unobtainable to be accomplished. The unique computational and navigational requirements for this flight are discussed from the enabling perspective of control and data acquisition S/W specifically developed for this task.",nov total solar eclips tse ever observ antarct yet interest secur observ event visibl antarct extrem high provid impetu break paradigm elus histor record scienc explor execut lunar shadow intercept conduct observ program boe er aircraft antarct interior permit previous unobtain accomplish uniqu comput navig requir flight discuss enabl perspect control data acquisit sw specif develop task
716899800f8c04722603ef3bcee557f401e0ca10,Statistical Methods for Communication Science,Contents: Preface. Statistics and Communication Science. Fundamentals of Measurement. Sampling. Data Description and Visualization. Fundamentals of Probability. Assessing and Quantifying Reliability. Parameter Estimation. Hypothesis Testing Concepts. Testing a Hypothesis About a Single Mean. Comparing Two Independent Groups. Some Tests for Categorical Variables. Simple Linear Regression. Multiple Linear Regression. Single Factor Analysis of Variance. Analysis of Covariance: ANOVA With Statistical Controls. Interaction. Appendices.,content prefac statist commun scienc fundament measur sampl data descript visual fundament probabl assess quantifi reliabl paramet estim hypothesi test concept test hypothesi singl mean compar two independ group test categor variabl simpl linear regress multipl linear regress singl factor analysi varianc analysi covari anova statist control interact appendic
24a2ccdf4629f85f23ea39e39ea96f763ccd34e8,The WFCAM Science Archive,"We describe the WFCAM Science Archive, which is the primary point of access for users of data from the wide-field infrared camera WFCAM on the United Kingdom Infrared Telescope (UKIRT), especially science catalogue products from the UKIRT Infrared Deep Sky Survey. We describe the database design with emphasis on those aspects of the system that enable users to fully exploit the survey data sets in a variety of different ways. We give details of the database-driven curation applications that take data from the standard nightly pipeline-processed and calibrated files for the production of science-ready survey data sets. We describe the fundamentals of querying relational databases with a set of astronomy usage examples, and illustrate the results.",describ wfcam scienc archiv primari point access user data widefield infrar camera wfcam unit kingdom infrar telescop ukirt especi scienc catalogu product ukirt infrar deep sky survey describ databas design emphasi aspect system enabl user fulli exploit survey data set varieti differ way give detail databasedriven curat applic take data standard nightli pipelineprocess calibr file product sciencereadi survey data set describ fundament queri relat databas set astronomi usag exampl illustr result
22f9e174bf51476efcf9cd8b14a674b1da5c2b92,The Data Avalanche is Here: Shouldn’t We Be Digging?,"We have access to an unprecedented amount of fine-grained data on cities, transportation, economies, and societies, much of these data referenced in geo-space and time. There is a tremendous opportunity to discover new knowledge about spatial economies that can inform theory and modeling in regional science. However, there is little evidence of computational methods for discovering knowledge from databases in the regional science literature. This paper addresses this gap by clarifying the geospatial knowledge discovery process, its relation to scientific knowledge construction, and identifying challenges to a greater role in regional science.",access unpreced amount finegrain data citi transport economi societi much data referenc geospac time tremend opportun discov new knowledg spatial economi inform theori model region scienc howev littl evid comput method discov knowledg databas region scienc literatur paper address gap clarifi geospati knowledg discoveri process relat scientif knowledg construct identifi challeng greater role region scienc
e0ffacf66497c7dfc4e5c58a49f2af77ab3c24cf,An assimilated dataset for Earth science applications,"The Data Assimilation Office at NASA's Goddard Space Flight Center is currently producing a multiyear gridded global atmospheric dataset for use in climate research, including tropospheric chemistry applications. The data, which are being made available to the scientific community, are well suited for climate research since they are produced by a fixed assimilation system designed to minimize the spinup in the hydrological cycle. By using a nonvarying system, the variability due to algorithm change is eliminated and geophysical variability can be more confidently isolated. The analysis incorporates rawinsonde reports, satellite retrievals of geopotential thickness, cloud-motion winds, and aircraft, ship, and rocketsonde reports. At the lower boundary, the assimilating atmospheric general circulation model is constrained by the observed sea surface temperature and soil moisture derived from observed surface air temperature and precipitation fields. The available output data include all prognostic variables...",data assimil offic nasa goddard space flight center current produc multiyear grid global atmospher dataset use climat research includ tropospher chemistri applic data made avail scientif commun well suit climat research sinc produc fix assimil system design minim spinup hydrolog cycl use nonvari system variabl due algorithm chang elimin geophys variabl confid isol analysi incorpor rawinsond report satellit retriev geopotenti thick cloudmot wind aircraft ship rocketsond report lower boundari assimil atmospher gener circul model constrain observ sea surfac temperatur soil moistur deriv observ surfac air temperatur precipit field avail output data includ prognost variabl
ea5e1f456870cb6352799f604e3e7717b5ddbc46,Statistics for engineering and the sciences,"CHAPTER 1: INTRODUCTION 1.1 Statistics: The Science of Data 1.2 Fundamental Elements of Statistics 1.3 Types of Data 1.4 The Role of Statistics in Critical Thinking 1.5 A Guide to Statistical Methods Presented in this Text Statistics in Action: Contamination of Fish in the Tennessee River Collecting theData CHAPTER 2: DESCRIPTIVE STATISTICS 2.1 Graphical and Numerical Methods for Describing Qualitative Data 2.2 Graphical Methods for Describing Quantitative Data 2.3 Numerical Methods for Describing Quantitative Data 2.4 Measures of Central Tendency 2.5 Measures of Variation 2.6 Measures of Relative Standing 2.7 Methods for Detecting Outliers 2.8 Distorting the Truth with Descriptive Statistics Statistics in Action: Characteristics of Contaminated Fish in the Tennessee River CHAPTER 3: PROBABILITY 3.1 The Role of Probability in Statistics 3.2 Events, Sample Spaces, and Probability 3.3 Compound Events 3.4 Complementary Events 3.5 Conditional Probability 3.6 Probability Rules for Unions and Intersections 3.7 Bayes' Rule (Optional) 3.8 Some Counting Rules 3.9 Probability and Statistics: An Example 3.10 Random Sampling Statistics in Action: Assessing Predictors of Software Defects CHAPTER 4: DISCRETE RANDOM VARIABLES 4.1 Discrete Random Variables 4.2 The Probability Distribution for a Discrete Random Variable 4.3 Expected Values for Random Variables 4.4 Some Useful Expectation Theorems 4.5 Bernoulli Trials 4.6 The Binomial Probability Distribution 4.7 The Multinomial Probability Distribution 4.8 The Negative Binomial and the Geometric Probability Distributions 4.9 The Hypergeometric Probability Distribution 4.10 The Poisson Probability Distribution 4.11 Moments and Moment Generating Functions (Optional) Statistics in Action: The Reliability of a ""One-Shot"" Device CHAPTER 5: CONTINUOUS RANDOM VARIABLES 5.1 Continuous Random Variables 5.2 The Density Function for a Continuous Random Variable 5.3 Expected Values for Continuous Random Variables 5.4 The Uniform Probability Distribution 5.5 The Normal Probability Distribution 5.6 Descriptive Methods for Assessing Normality 5.7 Gamma-Type Probability Distributions 5.8 The Weibull Probability Distriibution 5.9 Beta-Type Probability Distributions 5.10 Moments and Moment Generating Functions (Optional) Statistics in Action: Super Weapons Development: Optimizing the Hit Ratio CHAPTER 6: JOINT PROBABILITY DISTRIBUTIONS AND SAMPLING DISTRIBUTIONS 6.1 Bivariate Probability Distributions for Discrete Random Variables 6.2 Bivariate Probability Distributions for Continuous Random Variables 6.3 The Expected Value of Functions of Two Random Variables 6.4 Independence 6.5 The Covariance and Correlation of Two Random Variables 6.6 Probability Distributions and Expected Values of Functions of Random Variables (Optional) 6.7 Sampling Distributions 6.8 Approximating a Sampling Distribution by Monte Carlo Simulation 6.9 The Sampling Distributions of Means and Sums 6.10 Normal Approximation to the Binomial Distribution 6.11 Sampling Distributions Related to the Normal Distribution Statistics in Action: Availability of an Up/Down System CHAPTER 7: ESTIMATION USING CONFIDENCE INTERVALS 7.1 Point Estimators and their Properties 7.2 Finding Point Estimators: Classical Methods of Estimation 7.3 Finding Interval Estimators: The Pivotal Method 7.4 Estimation of Population Mean 7.5 Estimation of the Difference Between Two Population Means: Independent Samples 7.6 Estimation of the Difference Between Two Population Means: Matched Pairs 7.7 Estimation of a Poulation Proportion 7.8 Estimation of the Difference Between Two Population Proportions 7.9 Estimation of a Population Variance 7.10 Estimation of the Ratio of Two Population Variances 7.11 Choosing the Sample Size 7.12 Alternative Estimation Methods: Bootstrapping and Bayesian Methods (Optional) Statistics in Action: Bursting Strength of PET Beverage Bottles CHAPTER 8: TESTS OF HYPOTHESES 8.1 The Relationship Between Statistical Tests of Hypotheses and Confidence Intervals 8.2 Elements and Properties of a Statistical Test 8.3 Finding Statistical Tests: Classical Methods 8.4 Choosing the Null and Alternative Hypotheses 8.5 Testing a Population Mean 8.6 The Observed Significance Level for a Test 8.7 Testing the Difference Between Two Population Means: Independent Samples 8.8 Testing the Difference Between Two Population Means: Independent Samples 8.9 Testing a Population Proportion 8.10 Testing the Difference Between Two Population Proportions 8.11 Testing a Population Variance 8.12 Testing the Ration of Two Population Variances 8.13 Alternative Testing Procedures: Bootstrapping and Bayesian Methods (Optional) Statistics in Action: Comparing Methods for Dissolving Drug Tablets - Dissolution Method Equivalence Testing CHAPTER 9: CATEGORICAL DATA ANALYSIS 9.1 Categorical Data and Multinomial Probabilities 9.2 Estimating Category Probabilities in a One-Way Table 9.3 Testing Category Probabilities in a One-Way Table 9.4 Inferences About Category Probabilities in a Two-Way (Contingency) Table 9.5 Contingency Tables with Fixed Marginal Totals 9.6 Exact Tests for Independence in a Contingency Table Analysis (Optional) Statistics in Action: The Public's Perception of Engineers and Engineering CHAPTER 10: SIMPLE LINEAR REGRESSION 10.1 Regression Models 10.2 Model Assumptions 10.3 Estimating ss0 and ss1: The Method of Least Squares 10.4 Properties of the Least Squares Estimators 10.5 An Estimator of d2 10.6 Assessing the Utility of the Model: Making Inferences About the Slope ss1 10.7 The Coefficient of Correlation 10.8 The Coefficient of Determination 10.9 Using the Model for Estimation and Pediction 10.10 A Complete Example 10.11 A Summary of the Steps to Follow in Simple Linear Regression Statistics in Action: Can Dowser's Really Detect Water? CHAPTER 11: MULTIPLE REGRESSION ANALYSIS 11.1 General Form of a Multiple Regression Model 11.2 Model Assumptions 11.3 Fitting the Model: The Method of Least Squares 11.4 Computations using Matrix Algebra Estimating and Making Inferences about the ss Parameters 11.5 Assessing Overall Model Adequacy 11.6 A Confidence Interval for E(y) and a prediction interval for a Future Value of y 11.7 A First-Order Model with Quantitative Predictors 11.8 An Interaction Model with Quantitative Predictors 11.9 A Quadratic (Second-Order) Model with a Quantitative Predictor 11.10 Checking Assumptions: Residual Analysis 11.11 Some Pitfalls: Estimability, Multicollinearity, and Extrapolation 11.12 A Summary of the Steps to Follow in a Multiple Regression Analysis Statistics in Action: Bid-Rigging in the Highway Construction Industry CHAPTER 12: MODEL BUILDING 12.1 Introduction: Why Model Building is Important 12.2 The Two Types of Independent Variables: Quantitative and Qualitative 12.3 Models with a Single Quantitative Independent Variable 12.4 Models with Two Quantitative Independent Variables 12.5 Coding Quantitative Independent Variables (Optional) 12.6 Models with One Qualitative Independent Variable 12.7 Models with Both Quantitative and Qualitative Independent Variables 12.8 Tests for Comparing Nested Models 12.9 External Model Validation (Optional) 12.10 Stepwise Regression Statistics in Action: Deregulation of the Intrastate Trucking Industry CHAPTER 13: PRINCIPLES OF EXPERIMENTAL DESIGN 13.1 Introduction 13.2 Experimental Design Terminology 13.3 Controlling the Information in an Experiment 13.4 Noise-Reducing Designs 13.5 Volume-Increasing Designs 13.6 Selecting the Sample Size 13.7 The Importance of Randomization Statistics in Action: Anti-Corrosive Behavior of Epoxy Coatings Augmented with Zinc CHAPTER 14: ANALYSIS OF VARIANCE FOR DESIGNED EXPERIMENTS 14.1 Introduction 14.2 The Logic Behind an Analysis of Variance 14.3 One-Factor Completely Randomized Designs 14.4 Randomized Block Designs 14.5 Two-Factor Factorial Experiments 14.6 More Complex Factorial Designs (Optional) 14.7 Nested Sampling Designs (Optional) 14.8 Multiple Comparisons of Teatment Means 14.9 Checking ANOVA Assumptions Statistics in Action: On the Trail of the Cockroach CHAPTER 15: NONPARAMETRIC STATISTICS 15.1 Introduction: Distribution-Free Tests 15.2 Testing for Location of a Single Population 15.3 Comparing Two Populations: Independent Random Samples 15.4 Comparing Two Populations: Matched-Pair Design 15.5 Comparing Three or More Populations: Completely Randomized Design 15.6 Comparing Three or More Populations: Randomized Block Design 15.7 Nonparametric Regression Statistics in Action: Agent Orange and Vietnam Vets CHAPTER 16: STATISTICAL PROCESS AND QUALITY CONTROL 16.1 Total Quality Management 16.2 Variable Control Charts 16.3 Control Chart for Means: x-Chart 16.4 Control Chart for Process Variation: R-Chart 16.5 Detecting Trends in a Control Chart: Runs Analysis 16.6 Control Chart for Percent Defective: p-Chart 16.7 Control Chart for number of Defectives per item: c-Chart 16.8 Tolerance Limits 16.9 Capability Analysis (Optional) 16.10 Acceptance Sampling for Defectives 16.11 Other Sampling Plans (Optional) 16.12 Evolutionary Operations (Optional) Statistics in Action: Testing Jet Fuel Additive for Safety CHAPTER 17: PRODUCT AND SYSTEM RELIABILITY 17.1 Introduction 17.2 Failure Time Distributions 17.3 Hazard Rates 17.4 Life Testing: Censored Sampling 17.5 Estimating the Parameters of an Exponential Failure Time Distribution 17.6 Estimating the Parameters of a Weibull Failure Time Distribution 17.7 System Reliability Statistics in Action: Modeling the Hazard Rate of Reinforced Concrete Bridge Deck Deterioration APPENDIX A: MATRIX ALGEBRA APPENDIX B: USEFUL STATISTICAL TABLES APPENDIX C: SAS FOR WINDOWS TUTORIAL APPENDIX D: MINITAB FOR WINDOWS TUTORIAL APPENDIX E: SPSS FOR WINDOWS TUTORIAL ANSWERS TO SELECTED EXERCISES INDEX",chapter introduct statist scienc data fundament element statist type data role statist critic think guid statist method present text statist action contamin fish tennesse river collect thedata chapter descript statist graphic numer method describ qualit data graphic method describ quantit data numer method describ quantit data measur central tendenc measur variat measur rel stand method detect outlier distort truth descript statist statist action characterist contamin fish tennesse river chapter probabl role probabl statist event sampl space probabl compound event complementari event condit probabl probabl rule union intersect bay rule option count rule probabl statist exampl random sampl statist action assess predictor softwar defect chapter discret random variabl discret random variabl probabl distribut discret random variabl expect valu random variabl use expect theorem bernoulli trial binomi probabl distribut multinomi probabl distribut neg binomi geometr probabl distribut hypergeometr probabl distribut poisson probabl distribut moment moment gener function option statist action reliabl oneshot devic chapter continu random variabl continu random variabl densiti function continu random variabl expect valu continu random variabl uniform probabl distribut normal probabl distribut descript method assess normal gammatyp probabl distribut weibul probabl distriibut betatyp probabl distribut moment moment gener function option statist action super weapon develop optim hit ratio chapter joint probabl distribut sampl distribut bivari probabl distribut discret random variabl bivari probabl distribut continu random variabl expect valu function two random variabl independ covari correl two random variabl probabl distribut expect valu function random variabl option sampl distribut approxim sampl distribut mont carlo simul sampl distribut mean sum normal approxim binomi distribut sampl distribut relat normal distribut statist action avail updown system chapter estim use confid interv point estim properti find point estim classic method estim find interv estim pivot method estim popul mean estim differ two popul mean independ sampl estim differ two popul mean match pair estim poulat proport estim differ two popul proport estim popul varianc estim ratio two popul varianc choos sampl size altern estim method bootstrap bayesian method option statist action burst strength pet beverag bottl chapter test hypothes relationship statist test hypothes confid interv element properti statist test find statist test classic method choos null altern hypothes test popul mean observ signific level test test differ two popul mean independ sampl test differ two popul mean independ sampl test popul proport test differ two popul proport test popul varianc test ration two popul varianc altern test procedur bootstrap bayesian method option statist action compar method dissolv drug tablet dissolut method equival test chapter categor data analysi categor data multinomi probabl estim categori probabl oneway tabl test categori probabl oneway tabl infer categori probabl twoway conting tabl conting tabl fix margin total exact test independ conting tabl analysi option statist action public percept engin engin chapter simpl linear regress regress model model assumpt estim ss ss method least squar properti least squar estim estim assess util model make infer slope ss coeffici correl coeffici determin use model estim pedict complet exampl summari step follow simpl linear regress statist action dowser realli detect water chapter multipl regress analysi gener form multipl regress model model assumpt fit model method least squar comput use matrix algebra estim make infer ss paramet assess overal model adequaci confid interv ey predict interv futur valu firstord model quantit predictor interact model quantit predictor quadrat secondord model quantit predictor check assumpt residu analysi pitfal estim multicollinear extrapol summari step follow multipl regress analysi statist action bidrig highway construct industri chapter model build introduct model build import two type independ variabl quantit qualit model singl quantit independ variabl model two quantit independ variabl code quantit independ variabl option model one qualit independ variabl model quantit qualit independ variabl test compar nest model extern model valid option stepwis regress statist action deregul intrast truck industri chapter principl experiment design introduct experiment design terminolog control inform experi noisereduc design volumeincreas design select sampl size import random statist action anticorros behavior epoxi coat augment zinc chapter analysi varianc design experi introduct logic behind analysi varianc onefactor complet random design random block design twofactor factori experi complex factori design option nest sampl design option multipl comparison teatment mean check anova assumpt statist action trail cockroach chapter nonparametr statist introduct distributionfre test test locat singl popul compar two popul independ random sampl compar two popul matchedpair design compar three popul complet random design compar three popul random block design nonparametr regress statist action agent orang vietnam vet chapter statist process qualiti control total qualiti manag variabl control chart control chart mean xchart control chart process variat rchart detect trend control chart run analysi control chart percent defect pchart control chart number defect per item cchart toler limit capabl analysi option accept sampl defect sampl plan option evolutionari oper option statist action test jet fuel addit safeti chapter product system reliabl introduct failur time distribut hazard rate life test censor sampl estim paramet exponenti failur time distribut estim paramet weibul failur time distribut system reliabl statist action model hazard rate reinforc concret bridg deck deterior appendix matrix algebra appendix b use statist tabl appendix c sa window tutori appendix minitab window tutori appendix e spss window tutori answer select exercis index
e5cfb20df1a1abb9b425fb85a4529855017714db,The Analysis and Interpretation of Multivariate Data for Social Scientists,"Based on a longtime course for master's level students at the London School of Economics and Politics, where the authors are based, this text concentrates on the multivariate methods so useful to social science problems involving correlational rather than causal relationships. Chapters with application examples and further readings cover data preliminaries, cluster analysis, multidimensional scaling, correspondence analysis, principal components analysis, factor analysis, and latent variable methods. While mathematical demands are minimal, these methods require use of a computer software package; an auxiliary website supplies data sets and code for use with SPSS.",base longtim cours master level student london school econom polit author base text concentr multivari method use social scienc problem involv correl rather causal relationship chapter applic exampl read cover data preliminari cluster analysi multidimension scale correspond analysi princip compon analysi factor analysi latent variabl method mathemat demand minim method requir use comput softwar packag auxiliari websit suppli data set code use spss
afcae65c578d36201cc5a691ab8a5d83eeae16b5,“Paradigms Lost”: On Theory and Method in Research in Marketing,"Only recently have marketing scientists become concerned with issues in the philosophy of science. This paper points to one neglected area—the implications of a theoretical tradition for the selection of research methods (design, data collection, and data analysis). It is argued that marketing has been relying primarily on only one theoretical tradition. The dominance of this philosophy has led to marketing science growing more rapidly in the area of hypothesis testing than in the development of new, rich explanatory theories. Several suggestions are made to achieve a balance in theory construction and testing, with implications for reducing methods bias by a process of triangulating methodologies.",recent market scientist becom concern issu philosophi scienc paper point one neglect areath implic theoret tradit select research method design data collect data analysi argu market reli primarili one theoret tradit domin philosophi led market scienc grow rapidli area hypothesi test develop new rich explanatori theori sever suggest made achiev balanc theori construct test implic reduc method bia process triangul methodolog
bbeb0f3ce758b1301231f11ed9656a0278cbd987,Data sharing in the sciences,"ion, resolving file/element naming and data protection issues, and resource allocation. The cloud provides technology as a service; the two major services are Software-as-a-Service (SaaS) and Infrastructureas-a-Service (IaaS) both of which can simplify data sharing. Software-asa-Service provides access to a suite of software tools, either as a monthly or per-use cost for commercial software, or at no cost for non-commercial software. This enables a computing environment with no capital investment, few set-up costs, and no maintenance. Infrastructure-as-a-Service provides on-demand computing cycles and data storage via a virtual machine that can be configured to execute requests. The impact of the cloud is not fully understood and the future is unclear. Although Geambasu and colleagues argue that the cloud infrastructure will eliminate the need for traditional data centers within organizations, Arms and colleagues (2009) argue that local systems operations help to diffuse expertise across an organization and thus will continue to be valuable. Access and Discovery Metadata, Ontologies, and Vocabularies Access to and discovery of data resources require sufficient, targeted description of the resources themselves. This description is generally accomplished with metadata, ontologies, and vocabularies. The words metadata and ontologies have been used in multiple ways, but it is worth defining them briefly for our purposes. Ontologies are hierarchical, formal representations of the objects that constitute a specific area of interest (Gruber, 1995). In general, metadata has been used in information science to mean information about a particular representation of data (a document or set of documents, a dataset, images, or similar digital objects) (Duval, Hodgins, Sutton, & Weibel, 2002). A vocabulary consists of the properties that characterize the particular metadataset. For example, Dublin Core, which may be the most common metadata vocabulary, is applied to data to describe them for resource discovery and content management. It includes thirteen properties—such as title, author, and publication data—that characterize a particular digital resource. Metadata can be informal or maintained and created in a more structured way as part of the dataset itself. Metadata can be as straightforward as the date a particular dataset was generated, the creators/ custodians of the data, and the experimental or observational procedures that generated the data, to much more complex information about potential uses, geographic location of the data, its quality, or its state of completeness. Some metadata are also used to describe the kinds of web services that generated and maintain the dataset, associated tasks, and previous uses by others. Metadata can be human-generated or automatically generated and can be intended either for human use or for use by automated processes. Scientific communities, national scientific bodies, and international scientific organizations have all created metadata 268 Annual Review of Information Science and Technology",ion resolv fileel name data protect issu resourc alloc cloud provid technolog servic two major servic softwareasaservic saa infrastructureasaservic iaa simplifi data share softwareasaservic provid access suit softwar tool either monthli perus cost commerci softwar cost noncommerci softwar enabl comput environ capit invest setup cost mainten infrastructureasaservic provid ondemand comput cycl data storag via virtual machin configur execut request impact cloud fulli understood futur unclear although geambasu colleagu argu cloud infrastructur elimin need tradit data center within organ arm colleagu argu local system oper help diffus expertis across organ thu continu valuabl access discoveri metadata ontolog vocabulari access discoveri data resourc requir suffici target descript resourc descript gener accomplish metadata ontolog vocabulari word metadata ontolog use multipl way worth defin briefli purpos ontolog hierarch formal represent object constitut specif area interest gruber gener metadata use inform scienc mean inform particular represent data document set document dataset imag similar digit object duval hodgin sutton weibel vocabulari consist properti character particular metadataset exampl dublin core may common metadata vocabulari appli data describ resourc discoveri content manag includ thirteen propertiessuch titl author public datathat character particular digit resourc metadata inform maintain creat structur way part dataset metadata straightforward date particular dataset gener creator custodian data experiment observ procedur gener data much complex inform potenti use geograph locat data qualiti state complet metadata also use describ kind web servic gener maintain dataset associ task previou use other metadata humangener automat gener intend either human use use autom process scientif commun nation scientif bodi intern scientif organ creat metadata annual review inform scienc technolog
922e773e471430f637d07af4f17b72461ede8b7c,Reusing Scientific Data: How Earthquake Engineering Researchers Assess the Reusability of Colleagues’ Data,,nan
75974013b5abee21298e7119964cf4e8965f16de,A twenty-first century science,,nan
46fd40358f55f062ca37ec05f3f74dd08d88499b,Some Methodological Issues in Cohort Analysis of Archival Data,"Walton, John 1966a ""Substance and artifact: the current status of research on community power structure."" American Journal of Sociology 71 (January) :430-8. 1966b ""Discipline, method and community power: a note on the sociology of knowledge."" American Sociological Review 31 (October): 684-99. 1967 ""The vertical axis of community organization and the structure of power."" Southwestern Social Science Quarterly 48 (December) :353-68. Wolfinger, Raymond E. 1962 ""Reputation and reality in the study of community power."" American Sociological Review 25 (October) :636-44.",walton john substanc artifact current statu research commun power structur american journal sociolog januari b disciplin method commun power note sociolog knowledg american sociolog review octob vertic axi commun organ structur power southwestern social scienc quarterli decemb wolfing raymond e reput realiti studi commun power american sociolog review octob
2c46c17fedb951e6321c8c31b09d01861c8142a9,"Declarative Data Cleaning: Language, Model, and Algorithms","The problem of data cleaning, which consists of emoving inconsistencies and errors from original data sets, is well known in the area of decision support systems and data warehouses. However, for non-conventional applications, such as the migration of largely unstructured data into structured one, or the integration of heterogeneous scientific data sets in inter-discipl- inary fields (e.g., in environmental science), existing ETL (Extraction Transformation Loading) and data cleaning tools for writing data cleaning programs are insufficient. The main challenge with them is the design of a data flow graph that effectively generates clean data, and can perform efficiently on large sets of input data. The difficulty with them comes from (i) a lack of clear separation between the logical specification of data transformations and their physical implementation and (ii) the lack of explanation of cleaning results and user interaction facilities to tune a data cleaning program. This paper addresses these two problems and presents a language, an execution model and algorithms that enable users to express data cleaning specifications declaratively and perform the cleaning efficiently. We use as an example a set of bibliographic references used to construct the Citeseer Web site. The underlying data integration problem is to derive structured and clean textual records so that meaningful queries can be performed. Experimental results report on the assessement of the proposed framework for data cleaning.",problem data clean consist emov inconsist error origin data set well known area decis support system data warehous howev nonconvent applic migrat larg unstructur data structur one integr heterogen scientif data set interdiscipl inari field eg environment scienc exist etl extract transform load data clean tool write data clean program insuffici main challeng design data flow graph effect gener clean data perform effici larg set input data difficulti come lack clear separ logic specif data transform physic implement ii lack explan clean result user interact facil tune data clean program paper address two problem present languag execut model algorithm enabl user express data clean specif declar perform clean effici use exampl set bibliograph refer use construct cites web site underli data integr problem deriv structur clean textual record meaning queri perform experiment result report assess propos framework data clean
221da285b72f6272c2d7332a547d1e034a60e154,Data modelling versus ontology engineering,"Ontologies in current computer science parlance are computer based resources that represent agreed domain semantics. Unlike data models, the fundamental asset of ontologies is their relative independence of particular applications, i.e. an ontology consists of relatively generic knowledge that can be reused by different kinds of applications/tasks. The first part of this paper concerns some aspects that help to understand the differences and similarities between ontologies and data models. In the second part we present an ontology engineering framework that supports and favours the genericity of an ontology. We introduce the DOGMA ontology engineering approach that separates ""atomic"" conceptual relations from ""predicative"" domain rules. A DOGMA ontology consists of an ontology base that holds sets of intuitive context-specific conceptual relations and a layer of ""relatively generic"" ontological commitments that hold the domain rules. This constitutes what we shall call the double articulation of a DOGMA ontology 1.",ontolog current comput scienc parlanc comput base resourc repres agre domain semant unlik data model fundament asset ontolog rel independ particular applic ie ontolog consist rel gener knowledg reus differ kind applicationstask first part paper concern aspect help understand differ similar ontolog data model second part present ontolog engin framework support favour gener ontolog introduc dogma ontolog engin approach separ atom conceptu relat predic domain rule dogma ontolog consist ontolog base hold set intuit contextspecif conceptu relat layer rel gener ontolog commit hold domain rule constitut shall call doubl articul dogma ontolog
cfc1ab5e9effeac607a1760c08daaefeffb1d1a5,MapReduce in the Clouds for Science,"The utility computing model introduced by cloud computing combined with the rich set of cloud infrastructure services offers a very viable alternative to traditional servers and computing clusters. MapReduce distributed data processing architecture has become the weapon of choice for data-intensive analyses in the clouds and in commodity clusters due to its excellent fault tolerance features, scalability and the ease of use. Currently, there are several options for using MapReduce in cloud environments, such as using MapReduce as a service, setting up one’s own MapReduce cluster on cloud instances, or using specialized cloud MapReduce runtimes that take advantage of cloud infrastructure services. In this paper, we introduce Azure MapReduce, a novel MapReduce runtime built using the Microsoft Azure cloud infrastructure services. Azure MapReduce architecture successfully leverages the high latency, eventually consistent, yet highly scalable Azure infrastructure services to provide an efficient, on demand alternative to traditional MapReduce clusters. Further we evaluate the use and performance of MapReduce frameworks, including Azure MapReduce, in cloud environments for scientific applications using sequence assembly and sequence alignment as use cases.",util comput model introduc cloud comput combin rich set cloud infrastructur servic offer viabl altern tradit server comput cluster mapreduc distribut data process architectur becom weapon choic dataintens analys cloud commod cluster due excel fault toler featur scalabl eas use current sever option use mapreduc cloud environ use mapreduc servic set one mapreduc cluster cloud instanc use special cloud mapreduc runtim take advantag cloud infrastructur servic paper introduc azur mapreduc novel mapreduc runtim built use microsoft azur cloud infrastructur servic azur mapreduc architectur success leverag high latenc eventu consist yet highli scalabl azur infrastructur servic provid effici demand altern tradit mapreduc cluster evalu use perform mapreduc framework includ azur mapreduc cloud environ scientif applic use sequenc assembl sequenc align use case
7467866259be9bcad9a9f03a21c9a0c594b828c0,Biostatistics for animal science,Presenting and summarizing data Probability Random variables and their distributions Population and sample Hypotheses testing Correlation Two independent variables Concepts of experimental design Blocking Split-plot design Analysis of covariance Repeated measures Lack of fit,present summar data probabl random variabl distribut popul sampl hypothes test correl two independ variabl concept experiment design block splitplot design analysi covari repeat measur lack fit
cee6a6d139c4dce2db0ff4db8f67a9d27b2bba5c,Statistical Databases,,nan
d944ebc2103355b8fddd9c05e5cc8a9eccee875b,Open Access and Global Participation in Science,"Previous investigations into the impact of open-access journals on subsequent citations confounded open and electronic access and failed to track availability over time. With new data, we separated these effects. We demonstrate that a journal receives a modest increase in citations when it comes online freely, but the jump is larger when it first comes online through commercial sources. This effect reverses for poor countries where free-access articles are much more likely to be cited. Together, findings suggest that free Internet access widens the circle of those who read and make use of scientists' investigations.",previou investig impact openaccess journal subsequ citat confound open electron access fail track avail time new data separ effect demonstr journal receiv modest increas citat come onlin freeli jump larger first come onlin commerci sourc effect revers poor countri freeaccess articl much like cite togeth find suggest free internet access widen circl read make use scientist investig
907e0a1242aa0ab1415b57c5154884ba74a099c4,Environmental Science : A Global Concern,"This book is intended for use in a one- or two-semester course in environmental science, human ecology, or environmental studies at the college or advanced placement high school level. Because most students who will use this book are freshman or sophomore nonscience majors, the authors have tried to make the text readable and accessible without technical jargon or a presumption of prior science background. At the same time, enough data and depth are presented to make this book suitable for many upper-division classes and a valuable resource for students who will keep it in their personal libraries after their formal studies are completed. The goal of this book is to provide an up-to-date, introductory view of essential themes in environmental science along with emphasis on details and case studies that will help students process and retain the general principles.",book intend use one twosemest cours environment scienc human ecolog environment studi colleg advanc placement high school level student use book freshman sophomor nonscienc major author tri make text readabl access without technic jargon presumpt prior scienc background time enough data depth present make book suitabl mani upperdivis class valuabl resourc student keep person librari formal studi complet goal book provid uptod introductori view essenti theme environment scienc along emphasi detail case studi help student process retain gener principl
ec75210474282a9f42f97f4fb94d519290082df4,The Herschel Data Processing System - HIPE and Pipelines - Up and Running Since the Start of the Mission,"The Herschel Space Observatory is the fourth cornerstone mission in the ESA science programme and performs photometry and spectroscopy in the 55 - 672 micron range. The development of the Herschel Data Processing System started in 2002 to support the data analysis for Instrument Level Tests. The Herschel Data Processing System was used for the pre-flight characterisation of the instruments, and during various ground segment test campaigns. Following the successful launch of Herschel 14th of May 2009 the Herschel Data Processing System demonstrated its maturity when the first PACS preview observation of M51 was processed within 30 minutes of reception of the first science data after launch. Also the first HIFI observations on DR21 were successfully reduced to high quality spectra, followed by SPIRE observations on M66 and M74. A fast turn-around cycle between data retrieval and the production of science-ready products was demonstrated during the Herschel Science Demonstration Phase Initial Results Workshop held 7 months after launch, which is a clear proof that the system has reached a good level of maturity. We will summarise the scope, the management and development methodology of the Herschel Data Processing system, present some key software elements and give an overview about the current status and future development milestones.",herschel space observatori fourth cornerston mission esa scienc programm perform photometri spectroscopi micron rang develop herschel data process system start support data analysi instrument level test herschel data process system use preflight characteris instrument variou ground segment test campaign follow success launch herschel th may herschel data process system demonstr matur first pac preview observ process within minut recept first scienc data launch also first hifi observ dr success reduc high qualiti spectra follow spire observ fast turnaround cycl data retriev product sciencereadi product demonstr herschel scienc demonstr phase initi result workshop held month launch clear proof system reach good level matur summaris scope manag develop methodolog herschel data process system present key softwar element give overview current statu futur develop mileston
b79b8703a9807ab19ab993d309c650859c171ba7,Administrative Science as Socially Constructed Truth.,"(?) 1985 by Cornell University. 0001 -8392/85/3004-0497/$1 .00. This paper argues that the body of knowledge that constitutes administrative science is a socially constructed product. Because empirical observations are inevitably mediated by theoretical preconceptions, our knowledge of organizations is fundamentally shaped by the subjective world views through which we perceive data. Truth is defined in terms of the theoretical constructs and conceptual vocabulary that guide research and mediate access to organizational phenomena. The chief product of research is, consequently, theoretical language, rather than objective data. The knowledge of administrative science is not built from objective truths but is, instead, an artifact-the product of social definition. Institutional mechanisms reinforce these social definitions of truth by investing them with the stamp of scientific authenticity.",cornel univers paper argu bodi knowledg constitut administr scienc social construct product empir observ inevit mediat theoret preconcept knowledg organ fundament shape subject world view perceiv data truth defin term theoret construct conceptu vocabulari guid research mediat access organiz phenomena chief product research consequ theoret languag rather object data knowledg administr scienc built object truth instead artifactth product social definit institut mechan reinforc social definit truth invest stamp scientif authent
11dbcc3b66789b2791b1d1a780692df32c5fc120,Data Visualization : Principles and Practice,"The goal of data visualization is to use images to improve our understanding of a dataset, drawing on techniques from mathematics, computer science, cognitive and perception science, and physics. In this introductory text, the author provides a compact introduction to the field that allows readers to learn about visualization techniques. The material focuses on those techniques and methods that have a broad applicability in visualization applications, occur in most practical problems in various guises, and do not demand a specialized background to be understood. However, the author has also included a number of less mainstream visualization techniques. With these methods, the book gives the reader an idea of the large variety of applications of data visualizations, illustrates the wide range of problems that can be tackled by such methods, and emphasizes the strong connections between visualization and related disciplines such as imaging and computer graphics.",goal data visual use imag improv understand dataset draw techniqu mathemat comput scienc cognit percept scienc physic introductori text author provid compact introduct field allow reader learn visual techniqu materi focus techniqu method broad applic visual applic occur practic problem variou guis demand special background understood howev author also includ number less mainstream visual techniqu method book give reader idea larg varieti applic data visual illustr wide rang problem tackl method emphas strong connect visual relat disciplin imag comput graphic
7a649ce3304aa787b91d2c59a09c5dc8ad1a3e96,Computational science and engineering,"Computational Science and Engineering (CSE) is the multi-disciplinary field of computer-based modelling and simulation for studying scientific phenomena and engineering designs. Modelling and simulation helps to validate theory, and makes it possible to analyse scenarios that would otherwise be too time-consuming, expensive, or dangerous to study by experiment. Data exploration helps to turn numbers into insight which is especially challenging in times of Big Data.",comput scienc engin cse multidisciplinari field computerbas model simul studi scientif phenomena engin design model simul help valid theori make possibl analys scenario would otherwis timeconsum expens danger studi experi data explor help turn number insight especi challeng time big data
25732139300e03b2dd2ad07e2500b356b061ae43,User-friendly web mapping: lessons from a citizen science website,"Citizen science websites are emerging as a common way for volunteers to collect and report geographic ecological data. Engaging the public in citizen science is challenging and, when involving online participation, data entry, and map use, becomes even more daunting. Given these new challenges, citizen science websites must be easy to use, result in positive overall satisfaction for many different users, support many different tasks, and ensure data quality. To begin reaching these goals, we built a geospatially enabled citizen science website, evaluated its usability, and gained experience by working with and listening to citizens using the website. We sought to determine general perceptions, discover potential problems, and iteratively improve website features. Although the website was rated positively overall, map-based tasks identified a wide range of problems. Given our results, we redesigned the website, improved the content, enhanced the ease of use, simplified the map interface, and added features. We discuss citizen science websites in relation to online Public Participation Geographic Information Systems, examine the role(s) websites may play in the citizen science research model, discuss how citizen science research advances GIScience, and offer guidelines to improve citizen-based web mapping applications.",citizen scienc websit emerg common way volunt collect report geograph ecolog data engag public citizen scienc challeng involv onlin particip data entri map use becom even daunt given new challeng citizen scienc websit must easi use result posit overal satisfact mani differ user support mani differ task ensur data qualiti begin reach goal built geospati enabl citizen scienc websit evalu usabl gain experi work listen citizen use websit sought determin gener percept discov potenti problem iter improv websit featur although websit rate posit overal mapbas task identifi wide rang problem given result redesign websit improv content enhanc eas use simplifi map interfac ad featur discuss citizen scienc websit relat onlin public particip geograph inform system examin role websit may play citizen scienc research model discuss citizen scienc research advanc giscienc offer guidelin improv citizenbas web map applic
99275cf0d56914361636d7c16c5101b8de5ecc44,"Validity of the Computer Science and Applications, Inc. (CSA) activity monitor.","The validity of the Computer Science and Applications, Inc. (CSA) accelerometer in assessing physical activity was assessed during treadmill walking and running at three different grades. Energy expenditure (EE) served as the criterion measure. CSA data were compared to data collected with the Caltrac accelerometer. Both accelerometers were sensitive to changes in treadmill speed, but neither discriminated changes in treadmill grade. Caltrac and CSA activity counts were significantly and similarly correlated with EE (r = 0.66-0.82), relative VO2 (r = 0.77-0.89), heart rate (r = 0.66-0.80), treadmill speed (r = 0.82-0.92), and with each other (r = 0.77-0.82). CSA data were used to develop models to predict EE (kcal.min-1). Cross-validation resulted in a mean difference between actual and predicted EE of 0.02 kcal.min-1 (SEE = 0.85 kcal.min-1). The range of individual differences in the validation group was large for both the CSA model (-2.86 to +3.86 kcal.min-1) and Caltrac (-4.17 to +2.04 kcal.min-1). It is concluded that the CSA and Caltrac accelerometers have similar validity and that either instrument can be used to estimate EE of groups.",valid comput scienc applic inc csa acceleromet assess physic activ assess treadmil walk run three differ grade energi expenditur ee serv criterion measur csa data compar data collect caltrac acceleromet acceleromet sensit chang treadmil speed neither discrimin chang treadmil grade caltrac csa activ count significantli similarli correl ee r rel vo r heart rate r treadmil speed r r csa data use develop model predict ee kcalmin crossvalid result mean differ actual predict ee kcalmin see kcalmin rang individu differ valid group larg csa model kcalmin caltrac kcalmin conclud csa caltrac acceleromet similar valid either instrument use estim ee group
74baf17147c7d88db9198cfa3b5f87a0f8b89503,Guide to Intelligent Data Analysis - How to Intelligently Make Sense of Real Data,,nan
49a966258dfd23b8a398209d50a7773bb81b7b9f,Using the science writing heuristic as a tool for learning from laboratory investigations in secondary science,"This article presents and discusses preliminary research on a new heuristic tool for learning from laboratory activities in secondary science. The tool, called the science writing heuristic, can be used by teachers as a framework from which to design classroom activities. Theoretically, the science writing heuristic represents a bridge between traditional laboratory reports and types of writing that promote personal construction of meaning. Two eighth-grade classes participated in using the science writing heuristic during an 8-week stream study. The teacher and one of the researchers collaboratively developed activities based on the science writing heuristic that the teacher implemented. Nineteen target students were studied in depth. Characteristics of report writing and students' understanding of the nature of science were investigated, using interpretive techniques. There is evidence that use of the science writing heuristic facilitated students to generate meaning from data, make connections among procedures, data, evidence, and claims, and engage in metacognition. Students' vague understandings of the nature of science at the beginning of the study were modified to more complex, rich, and specific understandings. The implications of the study for writing in science classrooms is discussed. © 1999 John Wiley & Sons, Inc. J Res Sci Teach 36: 1065–1084, 1999",articl present discuss preliminari research new heurist tool learn laboratori activ secondari scienc tool call scienc write heurist use teacher framework design classroom activ theoret scienc write heurist repres bridg tradit laboratori report type write promot person construct mean two eighthgrad class particip use scienc write heurist week stream studi teacher one research collabor develop activ base scienc write heurist teacher implement nineteen target student studi depth characterist report write student understand natur scienc investig use interpret techniqu evid use scienc write heurist facilit student gener mean data make connect among procedur data evid claim engag metacognit student vagu understand natur scienc begin studi modifi complex rich specif understand implic studi write scienc classroom discuss john wiley son inc j re sci teach
2ec0540c7c7b8d2e4a2d958c745da2a46b4f558a,Data archiving,,nan
58400ccf99214b17c6a9b6d460515293adc88fec,A data set for color research,"We present an extensive data set for color research that has been made available online (www.cs. sfu.ca/∼colour/data). The data are especially germane to research into computational color constancy, but we have also aimed to make the data as general as possible, and we anticipate a wide range of benefits to research into computational color science and computer vision. Because data are useful only in context, we provide the details of the collection process, including the camera characterization, and the data used to determine that characterization. The most significant part of the data is 743 images of scenes taken under a carefully chosen set of 11 illuminants. The data set also has several standardized sets of spectra for synthetic data experiments, including some data for fluorescent surfaces. © 2002 Wiley Periodicals, Inc. Col Res Appl, 27, 147–151, 2002; Published online in Wiley InterScience (www.interscience.wiley.com). DOI 10.1002/col.10049",present extens data set color research made avail onlin wwwc sfucacolourdata data especi german research comput color constanc also aim make data gener possibl anticip wide rang benefit research comput color scienc comput vision data use context provid detail collect process includ camera character data use determin character signific part data imag scene taken care chosen set illumin data set also sever standard set spectra synthet data experi includ data fluoresc surfac wiley period inc col re appl publish onlin wiley intersci wwwintersciencewileycom doi col
57d791eb2cd5fe8ed9cfe8a7167f7a4439e3b11e,Data Management Challenges of Data-Intensive Scientific Workflows,"Scientific workflows play an important role in today's science. Many disciplines rely on workflow technologies to orchestrate the execution of thousands of computational tasks. Much research to-date focuses on efficient, scalable, and robust workflow execution, especially in distributed environments. However, many challenges remain in the area of data management related to workflow creation, execution, and result management. In this paper we examine some of these issues in the context of the entire workflow lifecycle.",scientif workflow play import role today scienc mani disciplin reli workflow technolog orchestr execut thousand comput task much research todat focus effici scalabl robust workflow execut especi distribut environ howev mani challeng remain area data manag relat workflow creation execut result manag paper examin issu context entir workflow lifecycl
8743ad5d9ce5e08b8d81a52ac0820c92c4f65afe,"Stories as data, data as stories: making sense of narrative inquiry in clinical education *","Background  Narrative inquiry is a form of qualitative research that takes story as either its raw data or its product. Science and narrative can be seen as two kinds of knowing, reflected in the distinction between evidence‐based medicine derived from population studies and narrative‐based medicine focused upon the single case. A similar tension exists in the field of narrative inquiry between cognitive‐orientated analytical methods and affective‐orientated methods of synthesis.",background narr inquiri form qualit research take stori either raw data product scienc narr seen two kind know reflect distinct evidencebas medicin deriv popul studi narrativebas medicin focus upon singl case similar tension exist field narr inquiri cognitiveorient analyt method affectiveorient method synthesi
3a15b30f1276aaf8f6f211c52f241295ce0bbe3e,"Mobility, Data Mining and Privacy - Geographic Knowledge Discovery",,nan
173e0355f87b33f3829f80e4c852dbcefe6a7974,Combinatorial Materials Science and Catalysis.,"After forever changing the drug discovery process in the pharmaceutical industry, combinatorial chemistry methodologies are increasingly being applied to the discovery and optimization of more efficient catalysts and materials (see picture). With the advent of new combinatorial synthesis and screening technologies, coupled with integrated data management systems, the application of these technologies to materials science and catalyst research holds tremendous potential and brings high expectations to this new and exciting field.",forev chang drug discoveri process pharmaceut industri combinatori chemistri methodolog increasingli appli discoveri optim effici catalyst materi see pictur advent new combinatori synthesi screen technolog coupl integr data manag system applic technolog materi scienc catalyst research hold tremend potenti bring high expect new excit field
370bfc7952aec403957eae9d9ce62f38f0ef4fb4,Spatially integrated social science,"Spatial analysis assists theoretical understanding and empirical testing in the social sciences, and rapidly expanding applications of geographic information technologies have advanced the spatial data-gathering needed for spatial analysis and model making. This much-needed volume covers outstanding examples of spatial thinking in the social sciences, with each chapter showing some aspect of how certain social processes can be understood by analyzing their spatial context. The audience for this work is as trans-disciplinary as its authorship because it contains approaches and methodologies useful to geography, anthropology, history, political science, economics, criminology, sociology, and statistics.",spatial analysi assist theoret understand empir test social scienc rapidli expand applic geograph inform technolog advanc spatial datagath need spatial analysi model make muchneed volum cover outstand exampl spatial think social scienc chapter show aspect certain social process understood analyz spatial context audienc work transdisciplinari authorship contain approach methodolog use geographi anthropolog histori polit scienc econom criminolog sociolog statist
293da404614d89f0eb9621d26d3b23afd6c9d0ff,"Scientific Data Management - Challenges, Technology, and Deployment","We introduce and describe scientific workflows, i.e., executable descriptions of automatable scientific processes such as computational science simulations and data analyses. Scientific workflows are often expressed in terms of tasks and their (data ow) dependencies. This chapter first provides an overview of the characteristic features of scientific workflows and outlines their life cycle. A detailed case study highlights workflow challenges and solutions in simulation management. We then provide a brief overview of how some concrete systems support the various phases of the workflow life cycle, i.e., design, resource management, execution, and provenance management. We conclude with a discussion on community-based workflow sharing.",introduc describ scientif workflow ie execut descript automat scientif process comput scienc simul data analys scientif workflow often express term task data ow depend chapter first provid overview characterist featur scientif workflow outlin life cycl detail case studi highlight workflow challeng solut simul manag provid brief overview concret system support variou phase workflow life cycl ie design resourc manag execut proven manag conclud discuss communitybas workflow share
35150893834d1b260e9a83c7823e40b1de24ca41,UNDERGRADUATE SCIENCE STUDENTS' IMAGES OF SCIENCE,"This article describes views about the nature of science held by a small sample of science students in their final year at the university. In a longitudinal interview study, 11 students were asked questions about the nature of science during the time they were involved in project work. Statements about the nature of science were characterized and coded using a framework drawing on aspects of the epistemology and sociology of science. The framework in this study has three distinct areas: the relationship between data and knowledge claims, the nature of lines of scientific enquiry, and science as a social activity. The students in our sample tended to see knowledge claims as resting solely on empirical grounds, although some students mentioned social factors as also being important. Many of the students showed significant development in their understanding of how lines of scientific enquiry are influenced by theoretical developments within a discipline, over the 5–8 month period of their project work. Issues relating to scientists working as a community were underrepresented in the students' discussions about science. Individual students drew upon a range of views about the nature of science, depending on the scientific context being discussed. © 1999 John Wiley & Sons, Inc. J Res Sci Teach 36: 201–219, 1999",articl describ view natur scienc held small sampl scienc student final year univers longitudin interview studi student ask question natur scienc time involv project work statement natur scienc character code use framework draw aspect epistemolog sociolog scienc framework studi three distinct area relationship data knowledg claim natur line scientif enquiri scienc social activ student sampl tend see knowledg claim rest sole empir ground although student mention social factor also import mani student show signific develop understand line scientif enquiri influenc theoret develop within disciplin month period project work issu relat scientist work commun underrepres student discuss scienc individu student drew upon rang view natur scienc depend scientif context discuss john wiley son inc j re sci teach
58661dccf9c996e8ab0bb0afd1a5455e14ed1a99,"Promoting Access to Public Research Data for Scientific, Economic, and Social Development","Access to and sharing of data are essential for the conduct and advancement of science. This article argues that publicly funded research data should be openly available to the maximum extent possible. To seize upon advancements of cyberinfrastructure and the explosion of data in a range of scientific disciplines, this access to and sharing of publicly funded data must be advanced within an international framework, beyond technological solutions. The authors, members of an OECD Follow-up Group, present their research findings, based closely on their report to OECD, on key issues in data access, as well as operating principles and management aspects necessary to successful data access regimes.",access share data essenti conduct advanc scienc articl argu publicli fund research data openli avail maximum extent possibl seiz upon advanc cyberinfrastructur explos data rang scientif disciplin access share publicli fund data must advanc within intern framework beyond technolog solut author member oecd followup group present research find base close report oecd key issu data access well oper principl manag aspect necessari success data access regim
95c977f2f4d5db61bdab5a31ecbadd959cadb47e,Studying research collaboration using co-authorships,,nan
4e6aa0488ddd0b99ca8d51e4872db53d74e452cd,Science and the Precautionary Principle,"The Precautionary Principle has become enshrined in international law, and is the basis for European environmental legislation. However, ""precautionary"" decisions have been controversial, and the principle itself lacks clear definition. A recent commentary by the European Commission offers guidelines for politically transparent application of the principle, while emphasizing the need for careful review of relevant scientific data. Recent precautionary policies for limiting public exposure to radio-frequency energy shows that the principle can be applied in a way that does not conflict with traditional exposure guidelines. Major uncertainties still remain in the standard of proof needed to invoke the principle.",precautionari principl becom enshrin intern law basi european environment legisl howev precautionari decis controversi principl lack clear definit recent commentari european commiss offer guidelin polit transpar applic principl emphas need care review relev scientif data recent precautionari polici limit public exposur radiofrequ energi show principl appli way conflict tradit exposur guidelin major uncertainti still remain standard proof need invok principl
5040d7244bd5c25477d790cfb6e6f53292513585,Handbook of categorization in cognitive science,"Categorization in Cognitive Science. Semantic Categories. Syntactic Categories. Acquisition of Categories. Neuroscience of Categorization and Category Learning. Categories in Perception and Inference. Grounding, Recognition, and Reasoning in Categorization. Machine Category Learning. Data Mining for Categories and Ontologies. The Naturalization of Categories.",categor cognit scienc semant categori syntact categori acquisit categori neurosci categor categori learn categori percept infer ground recognit reason categor machin categori learn data mine categori ontolog natur categori
b09be6368f117f876246af58062247c18ac9ccce,"Mobility, Data Mining and Privacy: Geographic Knowledge Discovery",,nan
110cd53ef4b63aa6951a4897c4a53e04c465883c,A Primer for Panel Data Analysis,"Panel data analysis is a method of studying a particular subject within multiple sites, periodically observed over a defined time frame. Within the social sciences, panel analysis has enabled researchers to undertake longitudinal analyses in a wide variety of fields. In economics, panel data analysis is used to study the behavior of firms and wages of people over time. In political science, it is used to study political behavior of parties and organizations over time. It is used in psychology, sociology, and health research to study characteristics of groups of people followed over time. In educational research, researchers study classes of students or graduates over time.",panel data analysi method studi particular subject within multipl site period observ defin time frame within social scienc panel analysi enabl research undertak longitudin analys wide varieti field econom panel data analysi use studi behavior firm wage peopl time polit scienc use studi polit behavior parti organ time use psycholog sociolog health research studi characterist group peopl follow time educ research research studi class student graduat time
a5fa73ec0bb416c7a345bbeedc512085623ba847,Data mining,"Abstract A student's ability to complete a study according to a designated time is an important factor in assessing university accreditation. A good accreditation shows the image of a university. The problem that arises is that many students miss the completion of their studies, which hinders the certification of their learning programs. The purpose of this study is to design an application program that can support student graduation-related decisions. This study applies the Nave Bayesian method, which can predict future opportunities based on past experience at the University of Al- Ashalia Mander, School of Computer Science, and Information Systems Research Program. This study is a data mining application program for student graduation classification using the Nave Bayes method, which is expected to help educators complete their studies on time and develop their ability to increase accreditation in their research programs. The design was successful.",abstract student abil complet studi accord design time import factor assess univers accredit good accredit show imag univers problem aris mani student miss complet studi hinder certif learn program purpos studi design applic program support student graduationrel decis studi appli nave bayesian method predict futur opportun base past experi univers al ashalia mander school comput scienc inform system research program studi data mine applic program student graduat classif use nave bay method expect help educ complet studi time develop abil increas accredit research program design success
3e6e98b35872d2011c296e3b64cafc55e18d16f6,A Proposed Standard for the Scholarly Citation of Quantitative Data,"An essential aspect of science is a community of scholars cooperating and competing in the pursuit of common goals. A critical component of this community is the common language of and the universal standards for scholarly citation, credit attribution, and the location and retrieval of articles and books. We propose a similar universal standard for citing quantitative data that retains the advantages of print citations, adds other components made possible by, and needed due to, the digital form and systematic nature of quantitative data sets, and is consistent with most existing subfield-specific approaches. Although the digital library field includes numerous creative ideas, we limit ourselves to only those elements that appear ready for easy practical use by scientists, journal editors, publishers, librarians, and archivists.",essenti aspect scienc commun scholar cooper compet pursuit common goal critic compon commun common languag univers standard scholarli citat credit attribut locat retriev articl book propos similar univers standard cite quantit data retain advantag print citat add compon made possibl need due digit form systemat natur quantit data set consist exist subfieldspecif approach although digit librari field includ numer creativ idea limit element appear readi easi practic use scientist journal editor publish librarian archivist
9d076765e9b46eee7aee32a6013e4ee809df73a4,Data Mining and Knowledge Discovery: Making Sense Out of Data,"Find loads of the data mining and knowledge discovery making sense out of data book catalogues in this site as the choice of you visiting this page. You can also join to the website book library that will show you numerous books from any types. Literature, science, politics, and many more catalogues are presented to offer you the best book to find. The book that really makes you feels satisfied. Or that's the book that will save you from your job deadline.",find load data mine knowledg discoveri make sens data book catalogu site choic visit page also join websit book librari show numer book type literatur scienc polit mani catalogu present offer best book find book realli make feel satisfi that book save job deadlin
8440f7d0811ada6c3f0a0025b27a8fc3e6675faa,The knowledge pyramid: a critique of the DIKW hierarchy,"The paper evaluates the data—information—knowledge—wisdom (DIKW) hierarchy. This hierarchy, also known as the `knowledge hierarchy', is part of the canon of information science and management. Arguments are offered that the hierarchy is unsound and methodologically undesirable. The paper identifies a central logical error that DIKW makes. The paper also identifies the dated and unsatisfactory philosophical positions of operationalism and inductivism as the philosophical backdrop to the hierarchy. The paper concludes with a sketch of some positive theories, of value to information science, on the nature of the components of the hierarchy: that data is anything recordable in a semantically and pragmatically sound way, that information is what is known in other literature as `weak knowledge', that knowledge also is `weak knowledge' and that wisdom is the possession and use, if required, of wide practical knowledge, by an agent who appreciates the fallible nature of that knowledge.",paper evalu datainformationknowledgewisdom dikw hierarchi hierarchi also known knowledg hierarchi part canon inform scienc manag argument offer hierarchi unsound methodolog undesir paper identifi central logic error dikw make paper also identifi date unsatisfactori philosoph posit operation inductiv philosoph backdrop hierarchi paper conclud sketch posit theori valu inform scienc natur compon hierarchi data anyth record semant pragmat sound way inform known literatur weak knowledg knowledg also weak knowledg wisdom possess use requir wide practic knowledg agent appreci fallibl natur knowledg
15270a976b83c49ae02587f54481dcc3db50eb1b,Helping English Learners Increase Achievement Through Inquiry-Based Science Instruction,"Abstract This study summarizes the results of a four-year project in science education conducted in a rural setting with English learners in grades K–6 in the El Centro Elementary School District in southern California. Data were collected to measure student achievement in science, writing, reading, and mathematics for participating students. These data were analyzed relative to the number of years that students participated in kit- and inquiry-based science instruction that included the use of science notebooks. Results indicated that the achievement of English learners increased in relation to the number of years they participated in the project. The longer they were in the program, the higher their scores were in science, writing, reading, and mathematics.",abstract studi summar result fouryear project scienc educ conduct rural set english learner grade k el centro elementari school district southern california data collect measur student achiev scienc write read mathemat particip student data analyz rel number year student particip kit inquirybas scienc instruct includ use scienc notebook result indic achiev english learner increas relat number year particip project longer program higher score scienc write read mathemat
c2b35ecb8998226da8f6e51e949bc0a1057aa814,Big data: Distilling meaning from data,,nan
5fafc89d30ab130905e769a953c09e69352af588,Explaining Science*,"Following the revolutionary book by Thomas Kuhn [1962], philosophical accounts of the development of science have attended more or less closely to actual episodes of scientific inquiry. Lakatos and his students launched their historiographic research programme as a means of testing his scientific methodology, and both Laudan [1977] and Hull [1988] likewise appeal to data from past or contemporary scientific practice. In his new book Explaining Science [1988] Ronald Giere would take us beyond this limited test-bed for the philosophy of science by directly applying results from the cognitive sciences. The main features of this new approach are perhaps best expressed in the preface:",follow revolutionari book thoma kuhn philosoph account develop scienc attend less close actual episod scientif inquiri lakato student launch historiograph research programm mean test scientif methodolog laudan hull likewis appeal data past contemporari scientif practic new book explain scienc ronald gier would take us beyond limit testb philosophi scienc directli appli result cognit scienc main featur new approach perhap best express prefac
3fa51d53df3e1049cebfec5734927521efbb6dd9,"How hard is hard science, how soft is soft science? The empirical cumulativeness of research.",""" Research results in the social and behavioral sciences are often conceded to be less replicable than research results in the physical sciences. However, direct empirical comparisons of the cumulativeness of research in the social and physical sciences have not been made to date. This article notes the parallels between methods used in the quantitative synthesis of research in the social and in the physical sciences. Essentially identical methods are used to test the consistency of research results in physics and in psychology. These methods can be used to compare the consistency of replicated research results in physics and in the social sciences. The methodology is illustrated with 13 exemplary reviews from each domain. The exemplary comparison suggests that the results of physical experiments may not be strikingly more consistent than those of social or behavioral experiments. The data suggest that even the results of physical experiments may not be cumulative in the absolute sense by statistical criteria. It is argued that the study of the actual cumulativeness found in physical data could inform social scientists about what to expect from replicated experiments under good conditions. Psychologists and other social scientists have often compared their fields to the natural (the ""hard"") sciences with a tinge of dismay. Those of us in the social and behavioral sciences know intuitively that there is something ""softer"" and less cumulative about our research results than about those of the physical sciences. It is easy to chronicle the differences between soft and hard sciences that might lead to less cumulative research results in the soft sciences. One such chronicle is provided by Meehl (1978), who listed 20 such differences and went on to argue that reliance on tests of statistical significance also contributes to the poorer cumulativeness of research results in the social sciences. Other distinguished researchers have cited the pervasive presence of interactions (Cronbach, 1975) or historical influences (Gergen, 1973, 1982) as reasons not to expect a cumulative social science. Still others (Kruskal, 1978, 1981) have cited the low quality of data in the social sciences as a barrier to truly cumulative social inquiry. These pessimistic views have been accompanied by a tendency to reconceptualize the philosophy of inquiry into a format that implies less ambitious aspirations for social knowledge (e.g., Cronbach, 1975; Gergen, 1982). Cumulativeness in the scientific enterprise can mean at least two things. In the broadest sense scientific results are cumulative if empirical laws and theoretical structures build on one another so that later developments extend and unify earlier work. This idea might be called conceptual or theoretical cumulativeness. The assessment of theoretical cumulativeness must be rather subjective. A narrower and less subjective indicator of cumulativeness is the degree of agreement among replicated experiments or the degree to which related experimental results fit into a simple pattern that makes conceptual sense. This idea might be called empirical cumulativeness. The purpose of this article is to suggest that it may be possible to compare at least the empirical cumulativeness of psychological research with that of research in the physical sciences. An exemplary comparison suggests that the differences may be less striking than previously imagined. The mechanism for this comparison is derived from recent developments in methods for the quantitative synthesis of research in the social sciences. Some of the methods used in meta-analysis are analogous to methods used in the quantitative synthesis of research in the physical sciences. In particular, physicists and psychologists use analogous methods for assessing the consistency of research results, a fact that makes possible comparisons among quantitative reviews in physics and in psychology. One such comparison is reported in this article. This comparison was not chosen in a way that guarantees it to be representative of either social science research or physical science research. However, some effort was exerted to prevent the comparison from obviously favoring one domain or the other, and additional examples are provided to suggest that the case for the empirical cumulativeness of physical science could have been made to look far worse. More data would obviously be needed to support strong conclusions. It seems, however, that the ""obvious"" conclusion that the results of physical science experiments are more cumulative than those of social science experiments does not have much empirical sup-",research result social behavior scienc often conced less replic research result physic scienc howev direct empir comparison cumul research social physic scienc made date articl note parallel method use quantit synthesi research social physic scienc essenti ident method use test consist research result physic psycholog method use compar consist replic research result physic social scienc methodolog illustr exemplari review domain exemplari comparison suggest result physic experi may strikingli consist social behavior experi data suggest even result physic experi may cumul absolut sens statist criteria argu studi actual cumul found physic data could inform social scientist expect replic experi good condit psychologist social scientist often compar field natur hard scienc ting dismay us social behavior scienc know intuit someth softer less cumul research result physic scienc easi chronicl differ soft hard scienc might lead less cumul research result soft scienc one chronicl provid meehl list differ went argu relianc test statist signific also contribut poorer cumul research result social scienc distinguish research cite pervas presenc interact cronbach histor influenc gergen reason expect cumul social scienc still other kruskal cite low qualiti data social scienc barrier truli cumul social inquiri pessimist view accompani tendenc reconceptu philosophi inquiri format impli less ambiti aspir social knowledg eg cronbach gergen cumul scientif enterpris mean least two thing broadest sens scientif result cumul empir law theoret structur build one anoth later develop extend unifi earlier work idea might call conceptu theoret cumul assess theoret cumul must rather subject narrow less subject indic cumul degre agreement among replic experi degre relat experiment result fit simpl pattern make conceptu sens idea might call empir cumul purpos articl suggest may possibl compar least empir cumul psycholog research research physic scienc exemplari comparison suggest differ may less strike previous imagin mechan comparison deriv recent develop method quantit synthesi research social scienc method use metaanalysi analog method use quantit synthesi research physic scienc particular physicist psychologist use analog method assess consist research result fact make possibl comparison among quantit review physic psycholog one comparison report articl comparison chosen way guarante repres either social scienc research physic scienc research howev effort exert prevent comparison obvious favor one domain addit exampl provid suggest case empir cumul physic scienc could made look far wors data would obvious need support strong conclus seem howev obviou conclus result physic scienc experi cumul social scienc experi much empir sup
90a98883117f1c6ca3a1fd2ac42f2bb320a25979,Future trends in data mining,,nan
5aeeec05d45626155a057ba9eb02114dde39cd0c,Planetary science: A lunar perspective,"An interpretative synthesis of current knowledge on the moon and the terrestrial planets is presented, emphasizing the impact of recent lunar research (using Apollo data and samples) on theories of planetary morphology and evolution. Chapters are included on the exploration of the solar system; geology and stratigraphy; meteorite impacts, craters, and multiring basins; planetary surfaces; planetary crusts; basaltic volcanism; planetary interiors; the chemical composition of the planets; the origin and evolution of the moon and planets; and the significance of lunar and planetary exploration. Photographs, drawings, graphs, tables of quantitative data, and a glossary are provided.",interpret synthesi current knowledg moon terrestri planet present emphas impact recent lunar research use apollo data sampl theori planetari morpholog evolut chapter includ explor solar system geolog stratigraphi meteorit impact crater multir basin planetari surfac planetari crust basalt volcan planetari interior chemic composit planet origin evolut moon planet signific lunar planetari explor photograph draw graph tabl quantit data glossari provid
d57f9d5b641a86ac2ea235bbe1cb4d5a3432d182,Keynote address - data abstraction and hierarchy,"Data abstraction is a valuable method for organizing programs to make them easier to modify and maintain. Inheritance allows one implementation of a data abstraction to be related to another hierarchically. This paper investigates the usefulness of hierarchy in program development, and concludes that although data abstraction is the more important idea, hierarchy does extend its usefulness in some situations. This research was supported by the NEC Professorship of Software Science and Engineering October 1987 OOPSLA ‘87 Addendum to the Proceedings 17",data abstract valuabl method organ program make easier modifi maintain inherit allow one implement data abstract relat anoth hierarch paper investig use hierarchi program develop conclud although data abstract import idea hierarchi extend use situat research support nec professorship softwar scienc engin octob oopsla addendum proceed
6041496b16718fcbc471c079c33bae57c7af8ad5,A Qualitative Study of Factors Influencing Science Teaching Self-Efficacy of Elementary Level Teachers.,"Science teaching self-efficacy may be one area of importance which has been over-looked in implementing change to improve science teaching in elementary schools. This qualitative study was designed to examine factors which influence personal science teaching efficacy and science teaching outcome expectancy in elementary teachers. Based on Bandura's psychological construct of self-efficacy, science teaching self-efficacy has been related to teachers' belief in their ability to teach science, called personal science teaching efficacy (PSTE), and their belief in students' ability to learn, called science teaching outcome expectancy (STOE). Data were collected from 23 elementary teachers involved in a project to enhance science, mathematics, and technology education. Initially, data on variables identified as related to science teaching self-efficacy were collected and triangulated from several self-reporting instruments, including the Science Teaching Efficacy Beliefs Instrument, In-service version (STEBI-A) Teachers' scores on personal science teaching efficacy (PSTE) and science teaching outcome expectancy (STOE), two subscales of the STEBI-A, along with other data were used to develop in depth interview questions. Ten of the teachers, with varying PSTE and STOE levels (high, moderate, and low), were purposefully selected for interviews regarding their teacher preparation, professional development, and science-related antecedent experiences. The qualitative data analysis methods of constant-comparison and clustering were used to identify patterns and themes within the interview data. Qualitative analysis of triangulated data provided insights as to development of PSTE and STOE. Results of the interview analysis revealed more definitive findings for the dimension of personal science teaching efficacy than for science teaching outcome expectancy. Theme in the data indicated that antecedent experiences influenced interest in science teaching. Preservice and in-service experiences such as success in high quality science courses and workshops, access to a lesser degree STOE. Findings on experiences which influenced STOE were limited. Implications for early science experiences, teacher preparation and teacher professional development are presented. Recommendations for further research are made for PSTE and STOE. © 1996 John Wiley & Sons, Inc.",scienc teach selfefficaci may one area import overlook implement chang improv scienc teach elementari school qualit studi design examin factor influenc person scienc teach efficaci scienc teach outcom expect elementari teacher base bandura psycholog construct selfefficaci scienc teach selfefficaci relat teacher belief abil teach scienc call person scienc teach efficaci pste belief student abil learn call scienc teach outcom expect stoe data collect elementari teacher involv project enhanc scienc mathemat technolog educ initi data variabl identifi relat scienc teach selfefficaci collect triangul sever selfreport instrument includ scienc teach efficaci belief instrument inservic version stebia teacher score person scienc teach efficaci pste scienc teach outcom expect stoe two subscal stebia along data use develop depth interview question ten teacher vari pste stoe level high moder low purpos select interview regard teacher prepar profession develop sciencerel anteced experi qualit data analysi method constantcomparison cluster use identifi pattern theme within interview data qualit analysi triangul data provid insight develop pste stoe result interview analysi reveal definit find dimens person scienc teach efficaci scienc teach outcom expect theme data indic anteced experi influenc interest scienc teach preservic inservic experi success high qualiti scienc cours workshop access lesser degre stoe find experi influenc stoe limit implic earli scienc experi teacher prepar teacher profession develop present recommend research made pste stoe john wiley son inc
7d6571232e2006ca2301439d5c9ad858e2d35735,Measurement in the Social Sciences: The Link Between Theory and Data,1. Introduction to measurement 2. Factor analysis 3. Reliability 4. Validity 5. Evaluating systematic error 6. Integrating reliability and validity Appendix: multiple indicators Bibliography Index.,introduct measur factor analysi reliabl valid evalu systemat error integr reliabl valid appendix multipl indic bibliographi index
bdece7df1e2808ccb947f3cc2d16e9ad6d1fcd4b,What Are Data? The Many Kinds of Data and Their Implications for Data Re-Use,"One key feature of e-science is to encourage archiving and release of data so that they are available in digitally-processable forms for re-use almost from the point of collection. This assumes particular processes of translation by which data can be made visible in transportable and intelligible forms. It also requires mechanisms by which data quality and provenance can be trusted once ""disconnected"" from their producers. By analyzing the ""life stages"" of data in four academic projects, we show that these requirements create difficulties for disciplines where tacit knowledge and craft-like methods are deeply embedded in researchers, as well as for disciplines producing non-digital heterogeneous data or data derived from people rather than from material phenomena. While craft practices and tacit knowledges are a feature of most scientific endeavors, some disciplines currently appear more inclined to attempt to formalize or at least record these knowledges. We discuss the implications this has for the e-science objective of widespread data re-use.",one key featur escienc encourag archiv releas data avail digitallyprocess form reus almost point collect assum particular process translat data made visibl transport intellig form also requir mechan data qualiti proven trust disconnect produc analyz life stage data four academ project show requir creat difficulti disciplin tacit knowledg craftlik method deepli embed research well disciplin produc nondigit heterogen data data deriv peopl rather materi phenomena craft practic tacit knowledg featur scientif endeavor disciplin current appear inclin attempt formal least record knowledg discuss implic escienc object widespread data reus
a025360e9b43f45b8a0446af275f9a654cbbe692,Voyager Radio Science Observations of Neptune and Triton,"The Voyager 2 encounter with the Neptune system included radio science investigations of the masses and densities of Neptune and Triton, the low-order gravitational harmonics of Neptune, the vertical structures of the atmospheres and ionospheres of Neptune and Triton, the composition of the atmosphere of Neptune, and characteristics of ring material. Demanding experimental requirements were met successfully, and study of the large store of collected data has begun. The initial search of the data revealed no detectable effects of ring material with optical depth τ [unknown] 0.01. Preliminary representative results include the following: 1.0243 x 1026 and 2.141 x 1022 kilograms for the masses of Neptune and Triton; 1640 and 2054 kilograms per cubic meter for their respective densities; 1355 � 7 kilometers, provisionally, for the radius of Triton; and J2 = 3411 � 10(x 10-6) and J4 = -26+12-20(x10-6) for Neptune's gravity field (J>2 and J4 are harmonic coefficients of the gravity field). The equatorial and polar radii of Neptune are 24,764 � 20 and 24,340 � 30 kllometers, respectively, at the 105-pascal (1 bar) pressure level. Neptune's atmosphere was probed to a pressure level of about 5 x 105 pascals, and effects of a methane cloud region and probable ammonia absorption below the cloud are evident in the data. Results for the mixing ratios of helium and ammonia are still being investigated; the methane abundance below the clouds is at least 1 percent by volume. Derived temperature-pressure profiles to 1.2 x 105 pascals and 78 kelvins (K) show a lapse rate corresponding to ""frozen"" equilibrium of the para- and ortho-hydrogen states. Neptune's ionosphere exhibits an extended topside at a temperature of 950 � 160 K if H+ is the dominant ion, and narrow ionization layers of the type previously seen at the other three giant planets. Triton has a dense ionosphere with a peak electron concentration of 46 x 109 per cubic meter at an altitude of 340 kilometers measured during occultation egress. Its topside plasma temperature is about 80 � 16 K if N2+ is the principal ion. The tenuous neutral atmosphere of Triton produced distinct signatures in the occultation data; however, the accuracy of the measurements is limited by uncertainties in the frequency of the spacecraft reference oscillator. Preliminary values for the surface pressure of 1.6 � 0.3 pascals and an equivalent isothermal temperature of 48 � 5 K are suggested, on the assumption that molecular nitrogen dominates the atmosphere. The radio data may be showing the effects of a thermal inversion near the surface; this and other evidence imply that the Triton atmosphere is controlled by vapor-pressure equilibrium with surface ices, at a temperature of 38 K and a methane mixing ratio of about 10-4.",voyag encount neptun system includ radio scienc investig mass densiti neptun triton loword gravit harmon neptun vertic structur atmospher ionospher neptun triton composit atmospher neptun characterist ring materi demand experiment requir met success studi larg store collect data begun initi search data reveal detect effect ring materi optic depth τ unknown preliminari repres result includ follow x x kilogram mass neptun triton kilogram per cubic meter respect densiti kilomet provision radiu triton j x j x neptun graviti field j j harmon coeffici graviti field equatori polar radii neptun kllomet respect pascal bar pressur level neptun atmospher probe pressur level x pascal effect methan cloud region probabl ammonia absorpt cloud evid data result mix ratio helium ammonia still investig methan abund cloud least percent volum deriv temperaturepressur profil x pascal kelvin k show laps rate correspond frozen equilibrium para orthohydrogen state neptun ionospher exhibit extend topsid temperatur k h domin ion narrow ioniz layer type previous seen three giant planet triton dens ionospher peak electron concentr x per cubic meter altitud kilomet measur occult egress topsid plasma temperatur k n princip ion tenuou neutral atmospher triton produc distinct signatur occult data howev accuraci measur limit uncertainti frequenc spacecraft refer oscil preliminari valu surfac pressur pascal equival isotherm temperatur k suggest assumpt molecular nitrogen domin atmospher radio data may show effect thermal invers near surfac evid impli triton atmospher control vaporpressur equilibrium surfac ice temperatur k methan mix ratio
992c22c3ddcc142c63be1edbd7584bf2d983546a,"""Science Citation Index""--A New Dimension in Indexing.","ing Services Recently Bennett (47) has reiterated my earlier recommendation that an index to the abstracts in specialty journals and to abstracts prepared by the smaller abstracting services be compiled (21). Frequently these are abstracts which include criticism. As such, they constitute original publications. Every author should know of such critical abstracts of his papers. In literature searches, abstracts may serve in lieu of the original articles, particularly when the original article is in a foreign language, or when it is not readily available. Citation indexes can be used to locate these abstracts quickly and to identify unabstracted articles (31). Author Citation Index A random-access computer memory does not require special ordering for data storage. In such memories the arbitrarily assigned data-addresses need not be known to the user. By contrast, a printed citation index must have a",ing servic recent bennett reiter earlier recommend index abstract specialti journal abstract prepar smaller abstract servic compil frequent abstract includ critic constitut origin public everi author know critic abstract paper literatur search abstract may serv lieu origin articl particularli origin articl foreign languag readili avail citat index use locat abstract quickli identifi unabstract articl author citat index randomaccess comput memori requir special order data storag memori arbitrarili assign dataaddress need known user contrast print citat index must
61ae2c7cdc4df8241b7aac187b6202373a83861a,An Ontology-Driven Framework for Data Transformation in Scientific Workflows,,nan
a08e42db0257e5a25458253ebb4491b7e6c1afd0,"OPeNDAP: Accessing data in a distributed, heterogeneous environment","In the process of implementing a protocol for the transport of science data, the Open Source Project for a Network Data Access Protocol (OPeNDAP) group has learned a considerable amount about the internal anatomy of what are commonly considered monolithic concepts. In order to communicate among our group, we have adopted a collection of deinitions and observations about data and the metadata that make them useful: differentiating between ""semantic"" and ""syntactic"" metadata, and deining categories such as ""translational"" and ""use"" metadata. We share the deinitions and categorizations here in the hope that others will ind them as useful as we do.",process implement protocol transport scienc data open sourc project network data access protocol opendap group learn consider amount intern anatomi commonli consid monolith concept order commun among group adopt collect deinit observ data metadata make use differenti semant syntact metadata dein categori translat use metadata share deinit categor hope other ind use
a0a3ed290942aaad5dbb0ac87b61d05ff2aa8dd4,A structural model of parent and teacher influences on science attitudes of eighth graders: Evidence from NELS: 88,"Research on science attitudes has focused mostly on teacher variables and learning environment variables. Furthermore, in the parent involvement literature, the outcome variable of interest has been mostly science achievement rather than science attitudes. Limited research is available on the joint influence of teacher and parent variables on science attitudes. This article proposes a model of parent and teacher influences on the science attitudes of eighth graders using data from the base year survey of the National Educational Longitudinal Study of 1988. The data were analyzed using structural equation modeling methodology for categorical data. The results show that the availability of science facilities has a significant direct effect on science experiments. Parental involvement has significant direct as well as indirect effects on science attitudes mediated through science activities and library/museum visits. Science activities have a significant direct effect on science attitudes. This study suggests that improving the quality of science instruction and science activities in schools will have implications for science education in schools and this will, in turn, indirectly affect the science attitudes of students. More importantly, the findings of this study provide concrete empirical evidence that parents play a very important role in the development of science attitudes of students. © 1998 John Wiley & Sons, Inc. Sci Ed82:93–109, 1998.",research scienc attitud focus mostli teacher variabl learn environ variabl furthermor parent involv literatur outcom variabl interest mostli scienc achiev rather scienc attitud limit research avail joint influenc teacher parent variabl scienc attitud articl propos model parent teacher influenc scienc attitud eighth grader use data base year survey nation educ longitudin studi data analyz use structur equat model methodolog categor data result show avail scienc facil signific direct effect scienc experi parent involv signific direct well indirect effect scienc attitud mediat scienc activ librarymuseum visit scienc activ signific direct effect scienc attitud studi suggest improv qualiti scienc instruct scienc activ school implic scienc educ school turn indirectli affect scienc attitud student importantli find studi provid concret empir evid parent play import role develop scienc attitud student john wiley son inc sci ed
4db958de7c1d28d3ea807f45083bb034509bb3be,GIS and spatial data analysis: Converging perspectives,,nan
e95a50a367aa3aec6674c87793c7f2ea2fd9a4a1,Political Science Research Methods,"Table of Contents (Each chapter ends with Conclusion, Terms Introduced, and Suggested Readings.)1. Introduction 2. Studying Politics Scientifically3. Research Design4. The Building Blocks of Social Scientific Research: Hypotheses, Concepts, and Variables5. Conducting a Literature Review 6. The Building Blocks of Social Scientific Research: Measurement7. Making Empirical Observations: Direct and Indirect Observation 8. Document Analysis: Using the Written Record9. Sampling10. Elite Interviewing and Survey Research11. Univariate Data Analysis and Descriptive Statistics12. Measuring Relationships and Testing Hypotheses: Bivariate Data Analysis 13. Searching for Complete Explanations and Causal Knowledge: Multivariate Analysis14. The Research Report: An Annotated Example",tabl content chapter end conclus term introduc suggest read introduct studi polit scientif research design build block social scientif research hypothes concept variabl conduct literatur review build block social scientif research measur make empir observ direct indirect observ document analysi use written record sampl elit interview survey research univari data analysi descript statist measur relationship test hypothes bivari data analysi search complet explan causal knowledg multivari analysi research report annot exampl
b4e273b8bdf2385f0445e7780ec4eac02fbc281e,An introduction to the WEKA data mining system,"This is a proposal for a half day tutorial on Weka, an open source Data Mining software package written in Java and available from www.cs.waikato.ac.nz/~ml/weka/index.html. The goal of the tutorial is to introduce faculty to the package and to the pedagogical possibilities for its use in the undergraduate computer science and engineering curricula. The Weka system provides a rich set of powerful Machine Learning algorithms for Data Mining tasks, some not found in commercial data mining systems. These include basic statistics and visualization tools, as well as tools for pre-processing, classification, and clustering, all available through an easy to use graphical user interface.",propos half day tutori weka open sourc data mine softwar packag written java avail wwwcswaikatoacnzmlwekaindexhtml goal tutori introduc faculti packag pedagog possibl use undergradu comput scienc engin curricula weka system provid rich set power machin learn algorithm data mine task found commerci data mine system includ basic statist visual tool well tool preprocess classif cluster avail easi use graphic user interfac
7b8536a97d0a053623fdba024fd572893cb95fc5,Culture of Science: Strange History of the Methodological Thinking in Psychology,,nan
f8e8e2db5145a1df1271879907f8bd33c6dbf37f,Data envelopment analysis,,nan
ca84d0bc7791d027d63c663d61cf95be41cecdb0,"Dimensions of evidence, the public understanding of science and science education","This paper explores the nature and type of evidence employed by participants in an issue of public concern. By examining documents and interviewing members of the public involved in the debate, the way in which evidence was used in the arguments for and against the issue was determined. Three dimensions of evidence emerged from the data: formal scientific evidence based on the data; informal evidence (e.g. common sense, personal experience) and wider issues which impinge on the evidence (e.g. environmental or legal concerns). In this particular controversy, it was the questioning of the formal evidence by local scientists which became the 'magic bullet' but pertinent questioning by local nonscientists also framed the debate. The authors suggest that school science curricula should include practice in questioning and manipulating different sorts of real data in a variety of ways so that pupils are equipped and empowered to tackle contemporary issues of this kind.",paper explor natur type evid employ particip issu public concern examin document interview member public involv debat way evid use argument issu determin three dimens evid emerg data formal scientif evid base data inform evid eg common sens person experi wider issu imping evid eg environment legal concern particular controversi question formal evid local scientist becam magic bullet pertin question local nonscientist also frame debat author suggest school scienc curricula includ practic question manipul differ sort real data varieti way pupil equip empow tackl contemporari issu kind
48e719eddbc0d5e0c9d39bdfc2e6d0bf287797b2,Statistical Themes and Lessons for Data Mining,,nan
ce8876858c14560afd6d8bd3e8bcae8425d33cab,Data Access in a Cyber World: Making Use of Cyberinfrastructure,The vast amount of data now collected on human beings and organizations as a result of cyberinfrastructure advances has created similarly vast opportunities for social scientists to study and understand human behavior. It has also made traditional ways of protecting social science data obsolete. The challenge to social scientists is to exploit advances in cyberinfrastructure to develop new access modalities that not only provide access but preserve data and create scientific communities. This paper outlines an approach that draws on both advances in the social science and the computer science literatures.,vast amount data collect human be organ result cyberinfrastructur advanc creat similarli vast opportun social scientist studi understand human behavior also made tradit way protect social scienc data obsolet challeng social scientist exploit advanc cyberinfrastructur develop new access modal provid access preserv data creat scientif commun paper outlin approach draw advanc social scienc comput scienc literatur
5c779f032e8d1a7595d32ef16f3f9b8b70246125,Data Analysis and Decision Making with Microsoft Excel,"From the Publisher: 
In response to the growing market trend in quantitative education, Albright, Winston, and Zappe's integrated business-statistics and management-science text presents core statistics and management-science methods in a modern, unified spreadsheet-oriented approach. 
With a focus on applications, not on mathematical techniques, the book covers business statistics with some essential management-science topics included. The example-based, Excel spreadsheet approach is useful in courses that combine traditional statistics and management-science topics, though it can be easily used for a one-term business statistics only course. The modeling and application focus, together with the Excel spreadsheet add-ins, provides a complete learning source for both students and practicing managers.",publish respons grow market trend quantit educ albright winston zapp integr businessstatist managementsci text present core statist managementsci method modern unifi spreadsheetori approach focu applic mathemat techniqu book cover busi statist essenti managementsci topic includ examplebas excel spreadsheet approach use cours combin tradit statist managementsci topic though easili use oneterm busi statist cours model applic focu togeth excel spreadsheet addin provid complet learn sourc student practic manag
8f306edfaf6ebc326604f99d3116f4dfd25c6b06,Gender Differences in Patenting in the Academic Life Sciences,We analyzed longitudinal data on academic careers and conducted interviews with faculty members to determine the scope and causes of the gender gap in patenting among life scientists. Our regressions on a random sample of 4227 life scientists over a 30-year period show that women faculty members patent at about 40% of the rate of men. We found that the gender gap has improved over time but remains large.,analyz longitudin data academ career conduct interview faculti member determin scope caus gender gap patent among life scientist regress random sampl life scientist year period show women faculti member patent rate men found gender gap improv time remain larg
dec9042be40c5842c97352caa820a869f35b516a,Advances in Intelligent Data Analysis,,nan
c6313afd8fa7468a741757f4faf0fd06694165ef,Data and phenomena,,nan
28ee52385ce6998008132a824dfc1d97893b91a5,Some Frontiers in Social Science,"The fundamental challenge in the social sciences is moving from complicated correlations to useful prediction. Progress usually reflects an interplay between theory, data, and tools. Six areas of innovation, principally data and tools, are now pushing at the frontiers of these sciences: longitudinal data, laboratory experimentation, improved statistical methods, geographic information tools, biosocial science, and international replication. These innovations are gaining power as they cross disciplinary boundaries, helping to attribute causality to observed relationships, to understand their nature, and thereby to improve the accuracy and usefulness of predictions.",fundament challeng social scienc move complic correl use predict progress usual reflect interplay theori data tool six area innov princip data tool push frontier scienc longitudin data laboratori experiment improv statist method geograph inform tool biosoci scienc intern replic innov gain power cross disciplinari boundari help attribut causal observ relationship understand natur therebi improv accuraci use predict
ff8c339a5b24e47246cd30ea399b44f0946cb25f,The data analysis handbook,"Analyzing observed or measured data is an important step in applied sciences. The recent increase in computer capacity has resulted in a revolution both in data collection and data analysis. An increasing number of scientists, researchers and students are venturing into statistical data analysis; hence the need for more guidance in this field, which was previously dominated mainly by statisticians. This handbook fills the gap in the range of textbooks on data analysis. Written in a dictionary format, it will serve as a comprehensive reference book in a rapidly growing field. However, this book is more structured than an ordinary dictionary, where each entry is a separate, self-contained entity. The authors provide not only definitions and short descriptions, but also offer an overview of the different topics. Therefore, the handbook can also be used as a companion to textbooks for undergraduate or graduate courses. 1700 entries are given in alphabetical order grouped into 20 topics and each topic is organized in a hierarchical fashion. Additional specific entries on a topic can be easily found by following the cross-references in a top-down manner. Several figures and tables are provided to enhance the comprehension of the topics and a list of acronyms helps to locate the full terminologies. The bibliography offers suggestions for further reading.",analyz observ measur data import step appli scienc recent increas comput capac result revolut data collect data analysi increas number scientist research student ventur statist data analysi henc need guidanc field previous domin mainli statistician handbook fill gap rang textbook data analysi written dictionari format serv comprehens refer book rapidli grow field howev book structur ordinari dictionari entri separ selfcontain entiti author provid definit short descript also offer overview differ topic therefor handbook also use companion textbook undergradu graduat cours entri given alphabet order group topic topic organ hierarch fashion addit specif entri topic easili found follow crossrefer topdown manner sever figur tabl provid enhanc comprehens topic list acronym help locat full terminolog bibliographi offer suggest read
d9c73428e9bda201985d84374b7d0d80e004393b,"Social Sciences and Modern States: Policy research: data, ideas, or arguments?","We have delayed examination of the effects of social science on public policy long enough. This, and the succeeding chapter by Wittrock, now address ways in which the social sciences influence the development of policies in the modern state. Where Majone (chapter 13) drew ideas from the philosophy of science, I adopt an idea from the legal system, the idea of argumentation. In the first half of the chapter, I examine the influence on policy of three types of research products: data and findings, ideas and criticism, and arguments or briefs for policy action. Whereas the traditional output of a policy study is a report of the first kind, heavy on data, conclusions, statistics, and findings, a review of the sketchy evidence available suggests that in some settings research has greater impact when it becomes part of advocacy for a preferred position. The second part of the chapter then wrestles with the normative question: what stance should researchers adopt? It confronts the question of whether advocacy has a place in the policy researcher's kit. Policy research is a close relative of social science, and even though it has put on its working clothes and gone out to labour in the offices and chambers of government, it has not relinquished the ‘science’ label: thus, policy sciences. There is something uncomfortable in the thought of abandoning the norms of objectivity that characterize a science and embracing a notion of advocacy more suitable to an interest group or lobbyist.",delay examin effect social scienc public polici long enough succeed chapter wittrock address way social scienc influenc develop polici modern state majon chapter drew idea philosophi scienc adopt idea legal system idea argument first half chapter examin influenc polici three type research product data find idea critic argument brief polici action wherea tradit output polici studi report first kind heavi data conclus statist find review sketchi evid avail suggest set research greater impact becom part advocaci prefer posit second part chapter wrestl norm question stanc research adopt confront question whether advocaci place polici research kit polici research close rel social scienc even though put work cloth gone labour offic chamber govern relinquish scienc label thu polici scienc someth uncomfort thought abandon norm object character scienc embrac notion advocaci suitabl interest group lobbyist
1502f80367837e0580c9fae07f73a2ad1643cafd,"Science and Ethics in Conducting, Analyzing, and Reporting Psychological Research","The relationship between scientific quality and ethical quality is considered for three aspects of the research process: conduct of the research, data analysis, and reporting of results. In the area of conducting research, issues discussed involve design, recruitment, causism, scientific quality, and costs and utilities. The discussion of data analysis considers data dropping, data exploitation, and meta-analysis. Issues regarding reporting of results include misrepresentation of findings, misrepresentation of credit, and failure to report results as a result of self-censoring or external censoring.",relationship scientif qualiti ethic qualiti consid three aspect research process conduct research data analysi report result area conduct research issu discuss involv design recruit causism scientif qualiti cost util discuss data analysi consid data drop data exploit metaanalysi issu regard report result includ misrepresent find misrepresent credit failur report result result selfcensor extern censor
3dc9912896bd260b3ae08d48aa9daf1b1ff901ee,Crime and Victimization Data,"Introduction Uniform Crime Reports Official Data National Crime Surveys Victim Reports Self Report Surveys Offender Reports Crime Rates Based on UCR, NCS, and SR Data Convergence and Divergence Conclusions Social Science and Social Policy Implications",introduct uniform crime report offici data nation crime survey victim report self report survey offend report crime rate base ucr nc sr data converg diverg conclus social scienc social polici implic
78062c10c42efd649f8d7ac7620eb2636e329f92,Data Mining,,nan
a3b72fec32c5c8fe09efe0aa09323d011f277c33,Causal Models in the Social Sciences.,"Causal models are formal theories stating the relationships between precisely defined variables, and have become an indispensable tool of the social scientist. This collection of articles is a course book on the causal modeling approach to theory construction and data analysis. H. M. Blalock, Jr. summarizes the then-current developments in causal model utilization in sociology, political science, economics, and other disciplines. This book provides a comprehensive multidisciplinary picture of the work on causal models. It seeks to address the problem of measurement in the social sciences and to link theory and research through the development of causal models.Organized into five sections (Simple Recursive Models, Path Analysis, Simultaneous Equations Techniques, The Causal Approach to Measurement Error, and Other Complications), this volume contains twenty-seven articles (eight of which were specially commissioned). Each section begins with an introduction explaining the concepts to be covered in the section and links them to the larger subject. It provides a general overview of the theory and application of causal modeling.Blalock argues for the development of theoretical models that can be operationalized and provide verifiable predictions. Many of the discussions of this subject that occur in other literature are too technical for most social scientists and other scholars who lack a strong background in mathematics. This book attempts to integrate a few of the less technical papers written by econometricians such as Koopmans, Wold, Strotz, and Fisher with discussions of causal approaches in the social and biological sciences. This classic text by Blalock is a valuable source of material for those interested in the issue of measurement in the social sciences and the construction of mathematical models.",causal model formal theori state relationship precis defin variabl becom indispens tool social scientist collect articl cours book causal model approach theori construct data analysi h blalock jr summar thencurr develop causal model util sociolog polit scienc econom disciplin book provid comprehens multidisciplinari pictur work causal model seek address problem measur social scienc link theori research develop causal modelsorgan five section simpl recurs model path analysi simultan equat techniqu causal approach measur error complic volum contain twentyseven articl eight special commiss section begin introduct explain concept cover section link larger subject provid gener overview theori applic causal modelingblalock argu develop theoret model operation provid verifi predict mani discuss subject occur literatur technic social scientist scholar lack strong background mathemat book attempt integr less technic paper written econometrician koopman wold strotz fisher discuss causal approach social biolog scienc classic text blalock valuabl sourc materi interest issu measur social scienc construct mathemat model
79020730b41ec3b29a204c4c9be756276b6e3086,LETTING THE DATA SPEAK FOR THEMSELVES,"ABSTRACT In Science, great difficulty is sometimes experienced in giving up hypothesized structures. The inadequacies of Freudian hypotheses are highlighted, and attention is directed to Dasein-analysis, which stays close to the data. This perspective focuses attention upon the phenomenological tradition, and suggests that certain mathematical frameworks in human geography are inappropriate. The adequacy of a priori models is also questioned from a Heideggerian perspective, and more general qualitative algebras are suggested to replace the distorted functional thinking inherited from the physical sciences.",abstract scienc great difficulti sometim experienc give hypothes structur inadequaci freudian hypothes highlight attent direct daseinanalysi stay close data perspect focus attent upon phenomenolog tradit suggest certain mathemat framework human geographi inappropri adequaci priori model also question heideggerian perspect gener qualit algebra suggest replac distort function think inherit physic scienc
eadeb224797c2184367970f363dbdb49a60ffcd7,Remote Sensing in Geology,"Describes the theory, techniques, and applications of remote sensing in the geological sciences. Prepared by 20 leading experts in the field and written within an integrated context, the text has been organized into 4 sections; the science of the interaction of light with surfaces and the acquisition of data; optical and digital processing of data in preparation for analysis; interpretive techniques; and the application of remotely sensed data to different disciplines within geology.",describ theori techniqu applic remot sens geolog scienc prepar lead expert field written within integr context text organ section scienc interact light surfac acquisit data optic digit process data prepar analysi interpret techniqu applic remot sens data differ disciplin within geolog
b59b81c3d26f9f119faae83b64daea629f737237,NONGEOSPATIAL METADATA FOR THE ECOLOGICAL SCIENCES,"Issues related to data preservation and sharing are receiving increased at- tention from scientific societies, funding agencies, and the broad scientific community. Ecologists, for example, are increasingly using data collected by other scientists to address questions at broader spatial, temporal, and thematic scales (e.g., global change, biodiversity, sustainability). No data set is perfect and self-explanatory. Ecologists must, therefore, rely upon a set of instructions or documentation to acquire a specific data set, determine its suitability for meeting specific research objectives, and accurately interpret results from subsequent processing, analysis, and modeling. ""Metadata"" represent the set of instructions or documentation that describe the content, context, quality, structure, and accessibility of a data set. Although geospatial metadata standards have been developed and widely endorsed by the geographical science community, such standards do not yet exist for the ecological sciences. In this paper, we examine potential benefits and costs associated with developing and implementing metadata for nongeospatial ecological data. We present a set of generic metadata descriptors that could serve as the basis for a ""metadata standard"" for nongeospatial ecological data. Alternative strategies for metadata implementation that meet differing organizational or investigator- specific objectives are presented. Finally, we conclude with several recommendations related to future development and implementation of ecological metadata.",issu relat data preserv share receiv increas tention scientif societi fund agenc broad scientif commun ecologist exampl increasingli use data collect scientist address question broader spatial tempor themat scale eg global chang biodivers sustain data set perfect selfexplanatori ecologist must therefor reli upon set instruct document acquir specif data set determin suitabl meet specif research object accur interpret result subsequ process analysi model metadata repres set instruct document describ content context qualiti structur access data set although geospati metadata standard develop wide endors geograph scienc commun standard yet exist ecolog scienc paper examin potenti benefit cost associ develop implement metadata nongeospati ecolog data present set gener metadata descriptor could serv basi metadata standard nongeospati ecolog data altern strategi metadata implement meet differ organiz investig specif object present final conclud sever recommend relat futur develop implement ecolog metadata
a17ae7090e12106e12aafeb1c3fd79458f321cb8,Remote sensing for the earth sciences,"SPECTRAL CHARACTERISTICS. Spectroscopy of Rocks and Minerals and Principles of Spectroscopy (R. Clark). Multispectral Thermal Infrared Data in Geological Studies (S. Hook, et al.). Soil Reflectance (E. Ben-Dor, et al.). Geobotany: Vegetation Mapping in Earth Science (S. Ustin, et al.). ANALYSIS. Spectral Analysis for Earth Science Investigation (J. Mustard & J. Sunshine). Integration and Visualization of Geoscience Data (J. Harris, et al.). APPLICATIONS. Stratigraphy (H. Lang). Strategies for Mineral Exploration (C. Sabine). Hydrocarbon Exploration (J. Berry & G. Prost). Planetary Geology (J. Bell, et al.). SENSORS/CASE STUDIES. Visible and Infrared: Sensors and Case Studies (F. Kruse). Radar: Sensors and Case Studies (J. Plaut, et al.). Geophysical Methods (J. Broome). Index.",spectral characterist spectroscopi rock miner principl spectroscopi r clark multispectr thermal infrar data geolog studi hook et al soil reflect e bendor et al geobotani veget map earth scienc ustin et al analysi spectral analysi earth scienc investig j mustard j sunshin integr visual geoscienc data j harri et al applic stratigraphi h lang strategi miner explor c sabin hydrocarbon explor j berri g prost planetari geolog j bell et al sensorscas studi visibl infrar sensor case studi f kruse radar sensor case studi j plaut et al geophys method j broom index
867e112fbf0851641f723ea5b17e134d14043bb8,Learning to Interview in the Social Sciences,"A large proportion of social science investigations rely on interview data, yet few researchers received formal training in interviewing. The authors investigated how novice researchers developed their interview skills, reporting on postgraduate students' experiences and reflections during an intensive 15-day interview course. Data analyzed for the article include audiotapes and transcripts of in-depth interviews and students' written critiques and journal reflections. Challenges faced by novice interviewers conducting in-depth interviews included unexpected participant behaviors, dealing with the consequences of the interviewers' own actions and subjectivities, constructing and delivering questions, and handling sensitive research topics. The authors also discuss the transcription of audio-recorded talk and include their own and students' reflections concerning the learning and teaching of interviewing. Finally, the authors provide recommendations for teaching interview skills for the purpose of doing social science research. This study informs teachers of qualitative research and researchers who seek to develop their interview skills.",larg proport social scienc investig reli interview data yet research receiv formal train interview author investig novic research develop interview skill report postgradu student experi reflect intens day interview cours data analyz articl includ audiotap transcript indepth interview student written critiqu journal reflect challeng face novic interview conduct indepth interview includ unexpect particip behavior deal consequ interview action subject construct deliv question handl sensit research topic author also discuss transcript audiorecord talk includ student reflect concern learn teach interview final author provid recommend teach interview skill purpos social scienc research studi inform teacher qualit research research seek develop interview skill
6073a19e0f80dff147abba0b16a0d1f854538444,On Issues of Instance Selection,,nan
1a20c6e39eba4e874f221eaf385519ab8a025483,States of consciousness and state-specific sciences.,"Charles T. Tart not in tenrns of any particular wn'tent of consciousness, or ,specific lbeh,avior or physiological chan,ge, ,but in terms of ' the overall patterning of psychological functioning. An analogy with computer funotioning can clarify this definition. A c m puter has a com'plex program of many subroutines. If we repro,Dam it quite differently, the same sorts of input data may be han,dled in qui,te different ways; we will be able to prediot very little from our knowledge of the old program about the effects of varying the input, even though old anld new programs have some su,brout.ines in common. The new program with its input-output in(teractions mlust be stjudied Blackburn ( I ) recently noted' that and have his antiscientific attitude furin and of itself. AX is many of our most talented young people ther reinforced. It is clear to him that to =hanging temporarily *he program of are ''turned off"" to science: as a salnthe scientist has no real understanding a computer. tion, he proposed that we recognize the 'of what marijuana intoxication is all ~ h , A ~ c ' ~ experienced by al,most validity of a more sensuous-intui,tive apabout (3). ordinary people are drealming states proach to nature, treating it as WmMore formally, an increasin'gly and the hypnogogic and hypnopompic plamentary to the classical in.tellect.ua1 significant num~ber of people are experistates, the transi,tional states (&tween approach. menting with ASC's in themselves, and sleeping and waking. M~~~ other I have seen the same rejection of finding the experiences thus gained of experience another A x , alcohol science by many of the brightest extreme i,mportance in their philosophy intoxication. students in California, and the problem and style of life. The conflict between he relatively new (to our cul:ture) is indeed serious. Blaoklburn's analysis experiences in these ASC's and the atASS that are now h,aving rnch an is valid, but not deep enough. A more titudes and intellectual-emotional sysimpact are those produced by mari6",charl tart tenrn particular wntent conscious specif lbehavior physiolog chang term overal pattern psycholog function analog comput funot clarifi definit c puter complex program mani subroutin reprodam quit differ sort input data may handl quit differ way abl prediot littl knowledg old program effect vari input even though old anld new program subroutin common new program inputoutput interact mlust stjudi blackburn recent note antiscientif attitud furin ax mani talent young peopl ther reinforc clear hang temporarili program turn scienc salnth scientist real understand comput tion propos recogn marijuana intox h c experienc almost valid sensuousintuit apabout ordinari peopl drealm state proach natur treat wmmore formal increasingli hypnogog hypnopomp plamentari classic intellectua signific number peopl experist transit state tween approach ment asc sleep wake seen reject find experi thu gain experi anoth x alcohol scienc mani brightest extrem import philosophi intox student california problem style life conflict rel new cultur inde seriou blaoklburn analysi experi asc atass rnch valid deep enough titud intellectualemot sysimpact produc mari
4d91d032d1961eee08aba75e6466457e2ca74198,Life Sciences,"The radiobiological properties of the heavy ions of cosmic radiation were investigated on Spacelab 1 by use of biostacks, monolayers of biological test organisms sandwiched between thin foils of different types of nuclear track detectors. Biostacks were exposed to cosmic radiation at several locations with different shielding environments in the module and on the pallet. Evaluations of the physical and biological components of the experiment to date indicate that in general they survived the spaceflight in good condition. Dosimetric data are presented for the different shielding environments.",radiobiolog properti heavi ion cosmic radiat investig spacelab use biostack monolay biolog test organ sandwich thin foil differ type nuclear track detector biostack expos cosmic radiat sever locat differ shield environ modul pallet evalu physic biolog compon experi date indic gener surviv spaceflight good condit dosimetr data present differ shield environ
c78475b9450c42764c94bf28abfbace01893ef6a,Introduction to Data Mining,,nan
155391192091a99f44b377db1e0e7819f2317498,Estimating the reproducibility of psychological science,"Empirically analyzing empirical evidence One of the central goals in any scientific endeavor is to understand causality. Experiments that seek to demonstrate a cause/effect relation most often manipulate the postulated causal factor. Aarts et al. describe the replication of 100 experiments reported in papers published in 2008 in three high-ranking psychology journals. Assessing whether the replication and the original experiment yielded the same result according to several criteria, they find that about one-third to one-half of the original findings were also observed in the replication study. Science, this issue 10.1126/science.aac4716 A large-scale assessment suggests that experimental reproducibility in psychology leaves a lot to be desired. INTRODUCTION Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error. RATIONALE There is concern about the rate and predictors of reproducibility, but limited evidence. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a previously observed finding and is the means of establishing reproducibility of a finding with new data. We conducted a large-scale, collaborative effort to obtain an initial estimate of the reproducibility of psychological science. RESULTS We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. There is no single standard for evaluating replication success. Here, we evaluated reproducibility using significance and P values, effect sizes, subjective assessments of replication teams, and meta-analysis of effect sizes. The mean effect size (r) of the replication effects (Mr = 0.197, SD = 0.257) was half the magnitude of the mean effect size of the original effects (Mr = 0.403, SD = 0.188), representing a substantial decline. Ninety-seven percent of original studies had significant results (P < .05). Thirty-six percent of replications had significant results; 47% of original effect sizes were in the 95% confidence interval of the replication effect size; 39% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams. CONCLUSION No single indicator sufficiently describes replication success, and the five indicators examined here are not the only ways to evaluate reproducibility. Nonetheless, collectively these results offer a clear conclusion: A large portion of replications produced weaker evidence for the original findings despite using materials provided by the original authors, review in advance for methodological fidelity, and high statistical power to detect the original effect sizes. Moreover, correlational evidence is consistent with the conclusion that variation in the strength of initial evidence (such as original P value) was more predictive of replication success than variation in the characteristics of the teams conducting the research (such as experience and expertise). The latter factors certainly can influence replication success, but they did not appear to do so here. Reproducibility is not well understood because the incentives for individual scientists prioritize novelty over replication. Innovation is the engine of discovery and is vital for a productive, effective scientific enterprise. However, innovative ideas become old news fast. Journal reviewers and editors may dismiss a new test of a published idea as unoriginal. The claim that “we already know this” belies the uncertainty of scientific evidence. Innovation points out paths that are possible; replication points out paths that are likely; progress relies on both. Replication can increase certainty when findings are reproduced and promote innovation when they are not. This project provides accumulating evidence for many findings in psychological research and suggests that there is still more work to do to verify whether we know what we think we know. Original study effect size versus replication effect size (correlation coefficients). Diagonal line represents replication effect size equal to original effect size. Dotted line represents replication effect size of 0. Points below the dotted line were effects in the opposite direction of the original. Density plots are separated by significant (blue) and nonsignificant (red) effects. Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47% of original effect sizes were in the 95% confidence interval of the replication effect size; 39% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.",empir analyz empir evid one central goal scientif endeavor understand causal experi seek demonstr causeeffect relat often manipul postul causal factor aart et al describ replic experi report paper publish three highrank psycholog journal assess whether replic origin experi yield result accord sever criteria find onethird onehalf origin find also observ replic studi scienc issu scienceaac largescal assess suggest experiment reproduc psycholog leav lot desir introduct reproduc defin featur scienc extent character current research unknown scientif claim gain credenc statu author origin replic support evid even research exemplari qualiti may irreproduc empir find random systemat error rational concern rate predictor reproduc limit evid potenti problemat practic includ select report select analysi insuffici specif condit necessari suffici obtain result direct replic attempt recreat condit believ suffici obtain previous observ find mean establish reproduc find new data conduct largescal collabor effort obtain initi estim reproduc psycholog scienc result conduct replic experiment correl studi publish three psycholog journal use highpow design origin materi avail singl standard evalu replic success evalu reproduc use signific p valu effect size subject assess replic team metaanalysi effect size mean effect size r replic effect mr sd half magnitud mean effect size origin effect mr sd repres substanti declin ninetyseven percent origin studi signific result p thirtysix percent replic signific result origin effect size confid interv replic effect size effect subject rate replic origin result bia origin result assum combin origin replic result left statist signific effect correl test suggest replic success better predict strength origin evid characterist origin replic team conclus singl indic suffici describ replic success five indic examin way evalu reproduc nonetheless collect result offer clear conclus larg portion replic produc weaker evid origin find despit use materi provid origin author review advanc methodolog fidel high statist power detect origin effect size moreov correl evid consist conclus variat strength initi evid origin p valu predict replic success variat characterist team conduct research experi expertis latter factor certainli influenc replic success appear reproduc well understood incent individu scientist priorit novelti replic innov engin discoveri vital product effect scientif enterpris howev innov idea becom old news fast journal review editor may dismiss new test publish idea unorigin claim alreadi know beli uncertainti scientif evid innov point path possibl replic point path like progress reli replic increas certainti find reproduc promot innov project provid accumul evid mani find psycholog research suggest still work verifi whether know think know origin studi effect size versu replic effect size correl coeffici diagon line repres replic effect size equal origin effect size dot line repres replic effect size point dot line effect opposit direct origin densiti plot separ signific blue nonsignific red effect reproduc defin featur scienc extent character current research unknown conduct replic experiment correl studi publish three psycholog journal use highpow design origin materi avail replic effect half magnitud origin effect repres substanti declin ninetyseven percent origin studi statist signific result thirtysix percent replic statist signific result origin effect size confid interv replic effect size effect subject rate replic origin result bia origin result assum combin origin replic result left statist signific effect correl test suggest replic success better predict strength origin evid characterist origin replic team
0e779fd59353a7f1f5b559b9d65fa4bfe367890c,Geometric Deep Learning: Going beyond Euclidean data,"Many scientific fields study data with an underlying structure that is non-Euclidean. Some examples include social networks in computational social sciences, sensor networks in communications, functional networks in brain imaging, regulatory networks in genetics, and meshed surfaces in computer graphics. In many applications, such geometric data are large and complex (in the case of social networks, on the scale of billions) and are natural targets for machine-learning techniques. In particular, we would like to use deep neural networks, which have recently proven to be powerful tools for a broad range of problems from computer vision, natural-language processing, and audio analysis. However, these tools have been most successful on data with an underlying Euclidean or grid-like structure and in cases where the invariances of these structures are built into networks used to model them.",mani scientif field studi data underli structur noneuclidean exampl includ social network comput social scienc sensor network commun function network brain imag regulatori network genet mesh surfac comput graphic mani applic geometr data larg complex case social network scale billion natur target machinelearn techniqu particular would like use deep neural network recent proven power tool broad rang problem comput vision naturallanguag process audio analysi howev tool success data underli euclidean gridlik structur case invari structur built network use model
5d150cec2775f9bc863760448f14104cc8f42368,Discovering governing equations from data by sparse identification of nonlinear dynamical systems,"Significance Understanding dynamic constraints and balances in nature has facilitated rapid development of knowledge and enabled technology, including aircraft, combustion engines, satellites, and electrical power. This work develops a novel framework to discover governing equations underlying a dynamical system simply from data measurements, leveraging advances in sparsity techniques and machine learning. The resulting models are parsimonious, balancing model complexity with descriptive ability while avoiding overfitting. There are many critical data-driven problems, such as understanding cognition from neural recordings, inferring climate patterns, determining stability of financial markets, predicting and suppressing the spread of disease, and controlling turbulence for greener transportation and energy. With abundant data and elusive laws, data-driven discovery of dynamics will continue to play an important role in these efforts. Extracting governing equations from data is a central challenge in many diverse areas of science and engineering. Data are abundant whereas models often remain elusive, as in climate science, neuroscience, ecology, finance, and epidemiology, to name only a few examples. In this work, we combine sparsity-promoting techniques and machine learning with nonlinear dynamical systems to discover governing equations from noisy measurement data. The only assumption about the structure of the model is that there are only a few important terms that govern the dynamics, so that the equations are sparse in the space of possible functions; this assumption holds for many physical systems in an appropriate basis. In particular, we use sparse regression to determine the fewest terms in the dynamic governing equations required to accurately represent the data. This results in parsimonious models that balance accuracy with model complexity to avoid overfitting. We demonstrate the algorithm on a wide range of problems, from simple canonical systems, including linear and nonlinear oscillators and the chaotic Lorenz system, to the fluid vortex shedding behind an obstacle. The fluid example illustrates the ability of this method to discover the underlying dynamics of a system that took experts in the community nearly 30 years to resolve. We also show that this method generalizes to parameterized systems and systems that are time-varying or have external forcing.",signific understand dynam constraint balanc natur facilit rapid develop knowledg enabl technolog includ aircraft combust engin satellit electr power work develop novel framework discov govern equat underli dynam system simpli data measur leverag advanc sparsiti techniqu machin learn result model parsimoni balanc model complex descript abil avoid overfit mani critic datadriven problem understand cognit neural record infer climat pattern determin stabil financi market predict suppress spread diseas control turbul greener transport energi abund data elus law datadriven discoveri dynam continu play import role effort extract govern equat data central challeng mani divers area scienc engin data abund wherea model often remain elus climat scienc neurosci ecolog financ epidemiolog name exampl work combin sparsitypromot techniqu machin learn nonlinear dynam system discov govern equat noisi measur data assumpt structur model import term govern dynam equat spars space possibl function assumpt hold mani physic system appropri basi particular use spars regress determin fewest term dynam govern equat requir accur repres data result parsimoni model balanc accuraci model complex avoid overfit demonstr algorithm wide rang problem simpl canon system includ linear nonlinear oscil chaotic lorenz system fluid vortex shed behind obstacl fluid exampl illustr abil method discov underli dynam system took expert commun nearli year resolv also show method gener parameter system system timevari extern forc
6a8f0593165afacae9e1bce383810e8da4af820e,THE ELEVENTH AND TWELFTH DATA RELEASES OF THE SLOAN DIGITAL SKY SURVEY: FINAL DATA FROM SDSS-III,"The third generation of the Sloan Digital Sky Survey (SDSS-III) took data from 2008 to 2014 using the original SDSS wide-field imager, the original and an upgraded multi-object fiber-fed optical spectrograph, a new near-infrared high-resolution spectrograph, and a novel optical interferometer. All of the data from SDSS-III are now made public. In particular, this paper describes Data Release 11 (DR11) including all data acquired through 2013 July, and Data Release 12 (DR12) adding data acquired through 2014 July (including all data included in previous data releases), marking the end of SDSS-III observing. Relative to our previous public release (DR10), DR12 adds one million new spectra of galaxies and quasars from the Baryon Oscillation Spectroscopic Survey (BOSS) over an additional 3000 deg2 of sky, more than triples the number of H-band spectra of stars as part of the Apache Point Observatory (APO) Galactic Evolution Experiment (APOGEE), and includes repeated accurate radial velocity measurements of 5500 stars from the Multi-object APO Radial Velocity Exoplanet Large-area Survey (MARVELS). The APOGEE outputs now include the measured abundances of 15 different elements for each star. In total, SDSS-III added 5200 deg2 of ugriz imaging; 155,520 spectra of 138,099 stars as part of the Sloan Exploration of Galactic Understanding and Evolution 2 (SEGUE-2) survey; 2,497,484 BOSS spectra of 1,372,737 galaxies, 294,512 quasars, and 247,216 stars over 9376 deg2; 618,080 APOGEE spectra of 156,593 stars; and 197,040 MARVELS spectra of 5513 stars. Since its first light in 1998, SDSS has imaged over 1/3 of the Celestial sphere in five bands and obtained over five million astronomical spectra.",third gener sloan digit sky survey sdssiii took data use origin sdss widefield imag origin upgrad multiobject fiberf optic spectrograph new nearinfrar highresolut spectrograph novel optic interferomet data sdssiii made public particular paper describ data releas dr includ data acquir juli data releas dr ad data acquir juli includ data includ previou data releas mark end sdssiii observ rel previou public releas dr dr add one million new spectra galaxi quasar baryon oscil spectroscop survey boss addit deg sky tripl number hband spectra star part apach point observatori apo galact evolut experi apoge includ repeat accur radial veloc measur star multiobject apo radial veloc exoplanet largearea survey marvel apoge output includ measur abund differ element star total sdssiii ad deg ugriz imag spectra star part sloan explor galact understand evolut segu survey boss spectra galaxi quasar star deg apoge spectra star marvel spectra star sinc first light sdss imag celesti sphere five band obtain five million astronom spectra
b1b825efc9f4c4a577d9bd7909e19c8758c06bb1,Data Reduction And Error Analysis For The Physical Sciences, ,
5cca605ccbda79502210edd94a227d897389de4c,Grand challenges in the science of wind energy,"A multifaceted future for wind power Modern wind turbines already represent a tightly optimized confluence of materials science and aerodynamic engineering. Veers et al. review the challenges and opportunities for further expanding this technology, with an emphasis on the need for interdisciplinary collaboration. They highlight the need to better understand atmospheric physics in the regions where taller turbines will operate as well as the materials constraints associated with the scale-up. The mutual interaction of turbine sites with one another and with the evolving features of the overall electricity grid will furthermore necessitate a systems approach to future development. Science, this issue p. eaau2027 BACKGROUND A growing global population and an increasing demand for energy services are expected to result in substantially greater deployment of clean energy sources. Wind energy is already playing a role as a mainstream source of electricity, driven by decades of scientific discovery and technology development. Additional research and exploration of design options are needed to drive innovation to meet future demand and functionality. The growing scale and deployment expansion will, however, push the technology into areas of both scientific and engineering uncertainty. This Review explores grand challenges in wind energy research that must be addressed to enable wind energy to supply one-third to one-half, or even more, of the world’s electricity needs. ADVANCES Drawing from a recent international workshop, we identify three grand challenges in wind energy research that require further progress from the scientific community: (i) improved understanding of the physics of atmospheric flow in the critical zone of wind power plant operation, (ii) materials and system dynamics of individual wind turbines, and (iii) optimization and control of fleets of wind plants comprising hundreds of individual generators working synergistically within the larger electric grid system. These grand challenges are interrelated, so progress in each domain must build on concurrent advances in the other two. Characterizing the wind power plant operating zone in the atmosphere will be essential to designing the next generation of even-larger wind turbines and achieving dynamic control of the machines. Enhanced forecasting of the nature of the atmospheric inflow will subsequently enable control of the plant in the manner necessary for grid support. These wind energy science challenges bridge previously separable geospatial and temporal scales that extend from the physics of the atmosphere to flexible aeroelastic and mechanical systems more than 200 m in diameter and, ultimately, to the electrical integration with and support for a continent-sized grid system. OUTLOOK Meeting the grand research challenges in wind energy science will enable the wind power plant of the future to supply many of the anticipated electricity system needs at a low cost. The interdependence of the grand challenges requires expansion of integrated and cross-disciplinary research efforts. Methods for handling and streamlining exchange of vast quantities of information across many disciplines (both experimental and computational) will also be crucial to enabling successful integrated research. Moreover, research in fields related to computational and data science will support the research community in seeking to further integrate models and data across scales and disciplines. The cascade of scales underlying wind energy scientific grand challenges. Length scales from weather systems at a global level down the boundary layer of a wind turbine airfoil and time scales from seasonal fluctuations in weather to subsecond dynamic control and balancing of electrical generation and demand must be understood and managed. ILLUSTRATION: JOSH BAUER AND BESIKI KAZAISHVILI, NREL Harvested by advanced technical systems honed over decades of research and development, wind energy has become a mainstream energy resource. However, continued innovation is needed to realize the potential of wind to serve the global demand for clean energy. Here, we outline three interdependent, cross-disciplinary grand challenges underpinning this research endeavor. The first is the need for a deeper understanding of the physics of atmospheric flow in the critical zone of plant operation. The second involves science and engineering of the largest dynamic, rotating machines in the world. The third encompasses optimization and control of fleets of wind plants working synergistically within the electricity grid. Addressing these challenges could enable wind power to provide as much as half of our global electricity needs and perhaps beyond.",multifacet futur wind power modern wind turbin alreadi repres tightli optim confluenc materi scienc aerodynam engin veer et al review challeng opportun expand technolog emphasi need interdisciplinari collabor highlight need better understand atmospher physic region taller turbin oper well materi constraint associ scaleup mutual interact turbin site one anoth evolv featur overal electr grid furthermor necessit system approach futur develop scienc issu p eaau background grow global popul increas demand energi servic expect result substanti greater deploy clean energi sourc wind energi alreadi play role mainstream sourc electr driven decad scientif discoveri technolog develop addit research explor design option need drive innov meet futur demand function grow scale deploy expans howev push technolog area scientif engin uncertainti review explor grand challeng wind energi research must address enabl wind energi suppli onethird onehalf even world electr need advanc draw recent intern workshop identifi three grand challeng wind energi research requir progress scientif commun improv understand physic atmospher flow critic zone wind power plant oper ii materi system dynam individu wind turbin iii optim control fleet wind plant compris hundr individu gener work synergist within larger electr grid system grand challeng interrel progress domain must build concurr advanc two character wind power plant oper zone atmospher essenti design next gener evenlarg wind turbin achiev dynam control machin enhanc forecast natur atmospher inflow subsequ enabl control plant manner necessari grid support wind energi scienc challeng bridg previous separ geospati tempor scale extend physic atmospher flexibl aeroelast mechan system diamet ultim electr integr support continents grid system outlook meet grand research challeng wind energi scienc enabl wind power plant futur suppli mani anticip electr system need low cost interdepend grand challeng requir expans integr crossdisciplinari research effort method handl streamlin exchang vast quantiti inform across mani disciplin experiment comput also crucial enabl success integr research moreov research field relat comput data scienc support research commun seek integr model data across scale disciplin cascad scale underli wind energi scientif grand challeng length scale weather system global level boundari layer wind turbin airfoil time scale season fluctuat weather subsecond dynam control balanc electr gener demand must understood manag illustr josh bauer besiki kazaishvili nrel harvest advanc technic system hone decad research develop wind energi becom mainstream energi resourc howev continu innov need realiz potenti wind serv global demand clean energi outlin three interdepend crossdisciplinari grand challeng underpin research endeavor first need deeper understand physic atmospher flow critic zone plant oper second involv scienc engin largest dynam rotat machin world third encompass optim control fleet wind plant work synergist within electr grid address challeng could enabl wind power provid much half global electr need perhap beyond
656fc9ee80901678859bbf310b92118bb4a21a07,Coding qualitative data: a synthesis guiding the novice,"Qualitative research has gained in importance in the social sciences. General knowledge about qualitative data analysis, how to code qualitative data and decisions concerning related research design in the analytical process are all important for novice researchers. This article offers researchers who are new to qualitative research a thorough yet practical introduction to the vocabulary and craft of coding.",qualit research gain import social scienc gener knowledg qualit data analysi code qualit data decis concern relat research design analyt process import novic research articl offer research new qualit research thorough yet practic introduct vocabulari craft code
3f1c2a64e76ebea6474ea936f88a757e72e42040,Applied Spatial Data Analysis with R,,nan
2711117464ccbb23a310b9de727c9bcfec86ba2e,Geneious Basic: An integrated and extendable desktop software platform for the organization and analysis of sequence data,"Summary: The two main functions of bioinformatics are the organization and analysis of biological data using computational resources. Geneious Basic has been designed to be an easy-to-use and flexible desktop software application framework for the organization and analysis of biological data, with a focus on molecular sequences and related data types. It integrates numerous industry-standard discovery analysis tools, with interactive visualizations to generate publication-ready images. One key contribution to researchers in the life sciences is the Geneious public application programming interface (API) that affords the ability to leverage the existing framework of the Geneious Basic software platform for virtually unlimited extension and customization. The result is an increase in the speed and quality of development of computation tools for the life sciences, due to the functionality and graphical user interface available to the developer through the public API. Geneious Basic represents an ideal platform for the bioinformatics community to leverage existing components and to integrate their own specific requirements for the discovery, analysis and visualization of biological data. Availability and implementation: Binaries and public API freely available for download at http://www.geneious.com/basic, implemented in Java and supported on Linux, Apple OSX and MS Windows. The software is also available from the Bio-Linux package repository at http://nebc.nerc.ac.uk/news/geneiousonbl. Contact: peter@biomatters.com",summari two main function bioinformat organ analysi biolog data use comput resourc geneiou basic design easytous flexibl desktop softwar applic framework organ analysi biolog data focu molecular sequenc relat data type integr numer industrystandard discoveri analysi tool interact visual gener publicationreadi imag one key contribut research life scienc geneiou public applic program interfac api afford abil leverag exist framework geneiou basic softwar platform virtual unlimit extens custom result increas speed qualiti develop comput tool life scienc due function graphic user interfac avail develop public api geneiou basic repres ideal platform bioinformat commun leverag exist compon integr specif requir discoveri analysi visual biolog data avail implement binari public api freeli avail download httpwwwgeneiouscombas implement java support linux appl osx ms window softwar also avail biolinux packag repositori httpnebcnercacuknewsgeneiousonbl contact peterbiomatterscom
f72d3f58ff73353978e224af348448b34d27cf7b,Dynamic Mode Decomposition: Data-Driven Modeling of Complex Systems,"Data-driven dynamical systems is a burgeoning field-it connects how measurements of nonlinear dynamical systems and/or complex systems can be used with well-established methods in dynamical systems theory. This is a critically important new direction because the governing equations of many problems under consideration by practitioners in various scientific fields are not typically known. Thus, using data alone to help derive, in an optimal sense, the best dynamical system representation of a given application allows for important new insights. The recently developed dynamic mode decomposition (DMD) is an innovative tool for integrating data with dynamical systems theory. The DMD has deep connections with traditional dynamical systems theory and many recent innovations in compressed sensing and machine learning. Dynamic Mode Decomposition: Data-Driven Modeling of Complex Systems, the first book to address the DMD algorithm, presents a pedagogical and comprehensive approach to all aspects of DMD currently developed or under development; blends theoretical development, example codes, and applications to showcase the theory and its many innovations and uses; highlights the numerous innovations around the DMD algorithm and demonstrates its efficacy using example problems from engineering and the physical and biological sciences; and provides extensive MATLAB code, data for intuitive examples of key methods, and graphical presentations. Audience: The core audience for this book is engineers and applied mathematicians working in the physical and biological sciences. It can be used in courses that integrate data analysis with dynamical systems.",datadriven dynam system burgeon fieldit connect measur nonlinear dynam system andor complex system use wellestablish method dynam system theori critic import new direct govern equat mani problem consider practition variou scientif field typic known thu use data alon help deriv optim sens best dynam system represent given applic allow import new insight recent develop dynam mode decomposit dmd innov tool integr data dynam system theori dmd deep connect tradit dynam system theori mani recent innov compress sens machin learn dynam mode decomposit datadriven model complex system first book address dmd algorithm present pedagog comprehens approach aspect dmd current develop develop blend theoret develop exampl code applic showcas theori mani innov use highlight numer innov around dmd algorithm demonstr efficaci use exampl problem engin physic biolog scienc provid extens matlab code data intuit exampl key method graphic present audienc core audienc book engin appli mathematician work physic biolog scienc use cours integr data analysi dynam system
35aab48e1045740b1a8b3992e541f51f624130bc,Solving inverse problems using data-driven models,"Recent research in inverse problems seeks to develop a mathematically coherent foundation for combining data-driven models, and in particular those based on deep learning, with domain-specific knowledge contained in physical–analytical models. The focus is on solving ill-posed inverse problems that are at the core of many challenging applications in the natural sciences, medicine and life sciences, as well as in engineering and industrial applications. This survey paper aims to give an account of some of the main contributions in data-driven inverse problems.",recent research invers problem seek develop mathemat coher foundat combin datadriven model particular base deep learn domainspecif knowledg contain physicalanalyt model focu solv illpos invers problem core mani challeng applic natur scienc medicin life scienc well engin industri applic survey paper aim give account main contribut datadriven invers problem
efa13986a1a4df6fcc379e3b40701da07b057576,Data Mining: The Textbook,"This textbook explores the different aspects of data mining from the fundamentals to the complex data types and their applications, capturing the wide diversity of problem domains for data mining issues. It goes beyond the traditional focus on data mining problems to introduce advanced data types such as text, time series, discrete sequences, spatial data, graph data, and social networks. Until now, no single book has addressed all these topics in a comprehensive and integrated way. The chapters of this book fall into one of three categories: Fundamental chapters: Data mining has four main problems, which correspond to clustering, classification, association pattern mining, and outlier analysis. These chapters comprehensively discuss a wide variety of methods for these problems. Domain chapters: These chapters discuss the specific methods used for different domains of data such as text data, time-series data, sequence data, graph data, and spatial data. Application chapters: These chapters study important applications such as stream mining, Web mining, ranking, recommendations, social networks, and privacy preservation. The domain chapters also have an applied flavor. Appropriate for both introductory and advanced data mining courses, Data Mining: The Textbook balances mathematical details and intuition. It contains the necessary mathematical details for professors and researchers, but it is presented in a simple and intuitive style to improve accessibility for students and industrial practitioners (including those with a limited mathematical background). Numerous illustrations, examples, and exercises are included, with an emphasis on semantically interpretable examples. Praise for Data Mining: The Textbook - As I read through this book, I have already decided to use it in my classes. This is a book written by an outstanding researcher who has made fundamental contributions to data mining, in a way that is both accessible and up to date. The book is complete with theory and practical use cases. Its a must-have for students and professors alike!"" -- Qiang Yang, Chair of Computer Science and Engineering at Hong Kong University of Science and Technology""This is the most amazing and comprehensive text book on data mining. It covers not only the fundamental problems, such as clustering, classification, outliers and frequent patterns, and different data types, including text, time series, sequences, spatial data and graphs, but also various applications, such as recommenders, Web, social network and privacy. It is a great book for graduate students and researchers as well as practitioners."" -- Philip S. Yu, UIC Distinguished Professor and Wexler Chair in Information Technology at University of Illinois at Chicago",textbook explor differ aspect data mine fundament complex data type applic captur wide divers problem domain data mine issu goe beyond tradit focu data mine problem introduc advanc data type text time seri discret sequenc spatial data graph data social network singl book address topic comprehens integr way chapter book fall one three categori fundament chapter data mine four main problem correspond cluster classif associ pattern mine outlier analysi chapter comprehens discuss wide varieti method problem domain chapter chapter discuss specif method use differ domain data text data timeseri data sequenc data graph data spatial data applic chapter chapter studi import applic stream mine web mine rank recommend social network privaci preserv domain chapter also appli flavor appropri introductori advanc data mine cours data mine textbook balanc mathemat detail intuit contain necessari mathemat detail professor research present simpl intuit style improv access student industri practition includ limit mathemat background numer illustr exampl exercis includ emphasi semant interpret exampl prais data mine textbook read book alreadi decid use class book written outstand research made fundament contribut data mine way access date book complet theori practic use case musthav student professor alik qiang yang chair comput scienc engin hong kong univers scienc technologythi amaz comprehens text book data mine cover fundament problem cluster classif outlier frequent pattern differ data type includ text time seri sequenc spatial data graph also variou applic recommend web social network privaci great book graduat student research well practition philip yu uic distinguish professor wexler chair inform technolog univers illinoi chicago
d5424a5f93f9d410cf17c5393eb5e6a1821dc135,Observational Health Data Sciences and Informatics (OHDSI): Opportunities for Observational Researchers,"The vision of creating accessible, reliable clinical evidence by accessing the clincial experience of hundreds of millions of patients across the globe is a reality. Observational Health Data Sciences and Informatics (OHDSI) has built on learnings from the Observational Medical Outcomes Partnership to turn methods research and insights into a suite of applications and exploration tools that move the field closer to the ultimate goal of generating evidence about all aspects of healthcare to serve the needs of patients, clinicians and all other decision-makers around the world.",vision creat access reliabl clinic evid access clincial experi hundr million patient across globe realiti observ health data scienc informat ohdsi built learn observ medic outcom partnership turn method research insight suit applic explor tool move field closer ultim goal gener evid aspect healthcar serv need patient clinician decisionmak around world
0f07c5ce71d2e4d8940821ce16642e599fa789d3,CNSA: a data repository for archiving omics data,"With the application and development of high-throughput sequencing technology in life and health sciences, massive multi-dimensional biological data brings the problem of efficient management and utilization. Database development and biocuration are the prerequisites for the reuse of these big data. Here, relying on China National GeneBank (CNGB), we present CNGB Sequence Archive (CNSA) for archiving omics data, including raw sequencing data and its analytical data and related metadata which are organized into six objects, namely Project, Sample, Experiment, Run, Assembly, and Variation at present. Moreover, CNSA has created the correlation model of living samples, sample information, and analytical data on some projects, so that all data can be traced throughout the life cycle from the living sample to the sample information to the analytical data. Complying with the data standards commonly used in the life sciences, CNSA is committed to building a comprehensive and curated data repository for the storage, management and sharing of omics data, improving the data standards, and providing free access to open data resources for worldwide scientific communities to support academic research and the bio-industry. Database URL: https://db.cngb.org/cnsa/",applic develop highthroughput sequenc technolog life health scienc massiv multidimension biolog data bring problem effici manag util databas develop biocur prerequisit reus big data reli china nation genebank cngb present cngb sequenc archiv cnsa archiv omic data includ raw sequenc data analyt data relat metadata organ six object name project sampl experi run assembl variat present moreov cnsa creat correl model live sampl sampl inform analyt data project data trace throughout life cycl live sampl sampl inform analyt data compli data standard commonli use life scienc cnsa commit build comprehens curat data repositori storag manag share omic data improv data standard provid free access open data resourc worldwid scientif commun support academ research bioindustri databas url httpsdbcngborgcnsa
b14c291d99f32580fe987c20e52a248c62838e68,"The data revolution : big data, open data, data infrastructures & their consequences","Chapter 1: Conceptualising Data What are data? Kinds of data Data, information, knowledge, wisdom Framing data Thinking critically about databases and data infrastructures Data assemblages and the data revolution Chapter 2: Small Data, Data Infrastructures and Data Brokers Data holdings, data archives and data infrastructures Rationale for research data infrastructures The challenges of building data infrastructures The challenges of building data infrastructuresData brokers and markets Chapter 3: Open and Linked Data Open data Linked data The case for open data The economics of open data Concerns with respect to opening data Chapter 4: Big Data Volume Exhaustive Resolution and indexicality Relationality Velocity Variety Flexibility Chapter 5: Enablers and Sources of Big Data The enablers of big data Sources of big data Directed Data Automated data Volunteered data Chapter 6: Data Analytics Pre-analytics Machine learning Data mining and pattern recognition Data visualisation and visual analytics Statistical analysis Prediction, simulation and optimization Chapter 7: The Governmental and Business Rationale for Big Data Governing people Managing organisations Leveraging value and producing capital Creating better places Chapter 8: The Reframing of Science, Social Science and Humanities Research The fourth paradigm in science? The re-emergence of empiricism The fallacies of empiricism Data-driven science Computational social sciences and digital humanities Chapter 9: Technical and Organisational Issues Deserts and deluges Access Data quality, veracity and lineage Data integration and interoperability Poor analysis and ecological fallacies Skills and human resourcing Chapter 10: Ethical, Political, Social and Legal Concerns Data shadows and dataveillance Privacy Data security Profiling, social sorting and redlining Secondary uses, control creep and anticipatory governance Modes of governance and technological lock-ins Chapter 11: Making Sense of the Data Revolution Understanding data and the data revolution Researching data assemblages Final thoughts",chapter conceptualis data data kind data data inform knowledg wisdom frame data think critic databas data infrastructur data assemblag data revolut chapter small data data infrastructur data broker data hold data archiv data infrastructur rational research data infrastructur challeng build data infrastructur challeng build data infrastructuresdata broker market chapter open link data open data link data case open data econom open data concern respect open data chapter big data volum exhaust resolut index relation veloc varieti flexibl chapter enabl sourc big data enabl big data sourc big data direct data autom data volunt data chapter data analyt preanalyt machin learn data mine pattern recognit data visualis visual analyt statist analysi predict simul optim chapter government busi rational big data govern peopl manag organis leverag valu produc capit creat better place chapter refram scienc social scienc human research fourth paradigm scienc reemerg empiric fallaci empiric datadriven scienc comput social scienc digit human chapter technic organis issu desert delug access data qualiti verac lineag data integr interoper poor analysi ecolog fallaci skill human resourc chapter ethic polit social legal concern data shadow dataveil privaci data secur profil social sort redlin secondari use control creep anticipatori govern mode govern technolog lockin chapter make sens data revolut understand data data revolut research data assemblag final thought
0a66086a2f23ef968f65395f88cdb2f4d458923a,Progressive statistics for studies in sports medicine and exercise science.,"Statistical guidelines and expert statements are now available to assist in the analysis and reporting of studies in some biomedical disciplines. We present here a more progressive resource for sample-based studies, meta-analyses, and case studies in sports medicine and exercise science. We offer forthright advice on the following controversial or novel issues: using precision of estimation for inferences about population effects in preference to null-hypothesis testing, which is inadequate for assessing clinical or practical importance; justifying sample size via acceptable precision or confidence for clinical decisions rather than via adequate power for statistical significance; showing SD rather than SEM, to better communicate the magnitude of differences in means and nonuniformity of error; avoiding purely nonparametric analyses, which cannot provide inferences about magnitude and are unnecessary; using regression statistics in validity studies, in preference to the impractical and biased limits of agreement; making greater use of qualitative methods to enrich sample-based quantitative projects; and seeking ethics approval for public access to the depersonalized raw data of a study, to address the need for more scrutiny of research and better meta-analyses. Advice on less contentious issues includes the following: using covariates in linear models to adjust for confounders, to account for individual differences, and to identify potential mechanisms of an effect; using log transformation to deal with nonuniformity of effects and error; identifying and deleting outliers; presenting descriptive, effect, and inferential statistics in appropriate formats; and contending with bias arising from problems with sampling, assignment, blinding, measurement error, and researchers' prejudices. This article should advance the field by stimulating debate, promoting innovative approaches, and serving as a useful checklist for authors, reviewers, and editors.",statist guidelin expert statement avail assist analysi report studi biomed disciplin present progress resourc samplebas studi metaanalys case studi sport medicin exercis scienc offer forthright advic follow controversi novel issu use precis estim infer popul effect prefer nullhypothesi test inadequ assess clinic practic import justifi sampl size via accept precis confid clinic decis rather via adequ power statist signific show sd rather sem better commun magnitud differ mean nonuniform error avoid pure nonparametr analys cannot provid infer magnitud unnecessari use regress statist valid studi prefer impract bias limit agreement make greater use qualit method enrich samplebas quantit project seek ethic approv public access deperson raw data studi address need scrutini research better metaanalys advic less contenti issu includ follow use covari linear model adjust confound account individu differ identifi potenti mechan effect use log transform deal nonuniform effect error identifi delet outlier present descript effect inferenti statist appropri format contend bia aris problem sampl assign blind measur error research prejudic articl advanc field stimul debat promot innov approach serv use checklist author review editor
2309a3231cd2622e2d815f1811bdcea24de06d1f,Qualitative and descriptive research: Data type versus data analysis,"Qualitative and descriptive research methods have been very common procedures for conducting research in many disciplines, including education, psychology, and social sciences. These types of research have also begun to be increasingly used in the field of second language teaching and learning. The interest in such methods, particularly in qualitative research, is motivated in part by the recognition that L2 teaching and learning is complex. To uncover this complexity, we need to not only examine how learning takes place in general or what factors affect it, but also provide more in-depth examination and understanding of individual learners and their behaviors and experiences. Qualitative and descriptive research is well suited to the study of L2 classroom teaching, where conducting tightly controlled experimental research is hardly possible, and even if controlled experimental research is conducted in such settings, the generalizability of its findings to real classroom contexts are questionable. Therefore, Language Teaching Research receives many manuscripts that report qualitative or descriptive research. The terms qualitative research and descriptive research are sometimes used interchangeably. However, a distinction can be made between the two. One fundamental characteristic of both types of research is that they involve naturalistic data. That is, they attempt to study language learning and teaching in their naturally occurring settings without any intervention or manipulation of variables. Nonetheless, these two types of research may differ in terms of their goal, degree of control, and the way the data are analyzed. The goal of descriptive research is to describe a phenomenon and its characteristics. This research is more concerned with what rather than how or why something has happened. Therefore, observation and survey tools are often used to gather data (Gall, Gall, & Borg, 2007). In such research, the data may be collected qualitatively, but it is often analyzed quantitatively, using frequencies, percentages, averages, or other statistical analyses to determine relationships. Qualitative research, however, is more holistic and often involves a rich collection of data from various sources to gain a deeper understanding of individual participants, including their opinions, perspectives, and attitudes. Qualitative research collects data qualitatively, and the method of analysis is 572747 LTR0010.1177/1362168815572747Language Teaching ResearchEditorial editorial2015",qualit descript research method common procedur conduct research mani disciplin includ educ psycholog social scienc type research also begun increasingli use field second languag teach learn interest method particularli qualit research motiv part recognit l teach learn complex uncov complex need examin learn take place gener factor affect also provid indepth examin understand individu learner behavior experi qualit descript research well suit studi l classroom teach conduct tightli control experiment research hardli possibl even control experiment research conduct set generaliz find real classroom context question therefor languag teach research receiv mani manuscript report qualit descript research term qualit research descript research sometim use interchang howev distinct made two one fundament characterist type research involv naturalist data attempt studi languag learn teach natur occur set without intervent manipul variabl nonetheless two type research may differ term goal degre control way data analyz goal descript research describ phenomenon characterist research concern rather someth happen therefor observ survey tool often use gather data gall gall borg research data may collect qualit often analyz quantit use frequenc percentag averag statist analys determin relationship qualit research howev holist often involv rich collect data variou sourc gain deeper understand individu particip includ opinion perspect attitud qualit research collect data qualit method analysi ltrlanguag teach researcheditori editori
b941e0d4ba87bcd2612b7063e9952db6a0c86520,"Using Data Sciences in Digital Marketing: Framework, methods, and performance metrics",,nan
43e2159db4d0e66c0f07e78bac1dc0c4c69558ac,Science with the Cherenkov Telescope Array,"The Cherenkov Telescope Array, CTA, will be the major global observatory for very high energy gamma-ray astronomy over the next decade and beyond. The scientific potential of CTA is extremely broad: from understanding the role of relativistic cosmic particles to the search for dark matter. CTA is an explorer of the extreme universe, probing environments from the immediate neighbourhood of black holes to cosmic voids on the largest scales. Covering a huge range in photon energy from 20 GeV to 300 TeV, CTA will improve on all aspects of performance with respect to current instruments. The observatory will operate arrays on sites in both hemispheres to provide full sky coverage and will hence maximize the potential for the rarest phenomena such as very nearby supernovae, gamma-ray bursts or gravitational wave transients. With 99 telescopes on the southern site and 19 telescopes on the northern site, flexible operation will be possible, with sub-arrays available for specific tasks. CTA will have important synergies with many of the new generation of major astronomical and astroparticle observatories. Multi-wavelength and multi-messenger approaches combining CTA data with those from other instruments will lead to a deeper understanding of the broad-band non-thermal properties of target sources. The CTA Observatory will be operated as an open, proposal-driven observatory, with all data available on a public archive after a pre-defined proprietary period. Scientists from institutions worldwide have combined together to form the CTA Consortium. This Consortium has prepared a proposal for a Core Programme of highly motivated observations. The programme, encompassing approximately 40% of the available observing time over the first ten years of CTA operation, is made up of individual Key Science Projects (KSPs), which are presented in this document.",cherenkov telescop array cta major global observatori high energi gammaray astronomi next decad beyond scientif potenti cta extrem broad understand role relativist cosmic particl search dark matter cta explor extrem univers probe environ immedi neighbourhood black hole cosmic void largest scale cover huge rang photon energi gev tev cta improv aspect perform respect current instrument observatori oper array site hemispher provid full sky coverag henc maxim potenti rarest phenomena nearbi supernova gammaray burst gravit wave transient telescop southern site telescop northern site flexibl oper possibl subarray avail specif task cta import synergi mani new gener major astronom astroparticl observatori multiwavelength multimesseng approach combin cta data instrument lead deeper understand broadband nontherm properti target sourc cta observatori oper open proposaldriven observatori data avail public archiv predefin proprietari period scientist institut worldwid combin togeth form cta consortium consortium prepar propos core programm highli motiv observ programm encompass approxim avail observ time first ten year cta oper made individu key scienc project ksp present document
65d61afd9c35b0a75d9de77c2a4a2428af0f7f7b,Big Data Analysis with Signal Processing on Graphs: Representation and processing of massive data sets with irregular structure,"Analysis and processing of very large data sets, or big data, poses a significant challenge. Massive data sets are collected and studied in numerous domains, from engineering sciences to social networks, biomolecular research, commerce, and security. Extracting valuable information from big data requires innovative approaches that efficiently process large amounts of data as well as handle and, moreover, utilize their structure. This article discusses a paradigm for large-scale data analysis based on the discrete signal processing (DSP) on graphs (DSPG). DSPG extends signal processing concepts and methodologies from the classical signal processing theory to data indexed by general graphs. Big data analysis presents several challenges to DSPG, in particular, in filtering and frequency analysis of very large data sets. We review fundamental concepts of DSPG, including graph signals and graph filters, graph Fourier transform, graph frequency, and spectrum ordering, and compare them with their counterparts from the classical signal processing theory. We then consider product graphs as a graph model that helps extend the application of DSPG methods to large data sets through efficient implementation based on parallelization and vectorization. We relate the presented framework to existing methods for large-scale data processing and illustrate it with an application to data compression.",analysi process larg data set big data pose signific challeng massiv data set collect studi numer domain engin scienc social network biomolecular research commerc secur extract valuabl inform big data requir innov approach effici process larg amount data well handl moreov util structur articl discuss paradigm largescal data analysi base discret signal process dsp graph dspg dspg extend signal process concept methodolog classic signal process theori data index gener graph big data analysi present sever challeng dspg particular filter frequenc analysi larg data set review fundament concept dspg includ graph signal graph filter graph fourier transform graph frequenc spectrum order compar counterpart classic signal process theori consid product graph graph model help extend applic dspg method larg data set effici implement base parallel vector relat present framework exist method largescal data process illustr applic data compress
c115d436572afbe2a1f528a581bb3d7b0aa031dc,Handbook of photovoltaic science and engineering,"About the Editors. List of Contributors. Preface to the 2nd Edition. 1 Achievements and Challenges of Solar Electricity from Photovoltaics (Steven Hegedus and Antonio Luque). 1.1 The Big Picture. 1.2 What is Photovoltaics? 1.3 Photovoltaics Today. 1.4 The Great Challenge. 1.5 Trends in Technology. 1.6 Conclusions. 2 The Role of Policy in PV Industry Growth: Past, Present and Future (John Byrne and Lado Kurdgelashvili). 2.1 Introduction. 2.2 Policy Review of Selected Countries. 2.3 Policy Impact on PV Market Development. 2.4 Future PV Market Growth Scenarios. 2.5 Toward a Sustainable Future. 3 The Physics of the Solar Cell (Jeffery L. Gray). 3.1 Introduction. 3.2 Fundamental Properties of Semiconductors. 3.3 Solar Cell Fundamentals. 3.4 Additional Topics. 3.5 Summary. 4 Theoretical Limits of Photovoltaic Conversion and New-generation Solar Cells (Antonio Luque and Antonio Marti). 4.1 Introduction. 4.2 Thermodynamic Background. 4.3 Photovoltaic Converters. 4.4 The Technical Efficiency Limit for Solar Converters. 4.5 Very-high-efficiency Concepts. 4.6 Conclusions. 5 Solar Grade Silicon Feedstock (Bruno Ceccaroli and Otto Lohne). 5.1 Introduction. 5.2 Silicon. 5.3 Production of Silicon Metal/Metallurgical Grade Silicon. 5.4 Production of Polysilicon/Silicon of Electronic and Photovoltaic Grade. 5.5 Current Silicon Feedstock to Solar Cells. 5.6 Requirements of Silicon for Crystalline Solar Cells. 5.7 Routes to Solar Grade Silicon. 5.8 Conclusions. 6 Bulk Crystal Growth and Wafering for PV (Hugo Rodriguez, Ismael Guerrero, Wolfgang Koch, Arthur L. Endros, Dieter Franke, Christian Hassler, Juris P. Kalejs and H. J. Moller). 6.1 Introduction. 6.2 Bulk Monocrystalline Material. 6.3 Bulk Multicrystalline Silicon. 6.4 Wafering. 6.5 Silicon Ribbon and Foil Production. 6.6 Numerical Simulations of Crystal Growth Techniques. 6.7 Conclusions. 7 Crystalline Silicon Solar Cells and Modules (Ignacio Tobias, Carlos del Ca""nizo and Jesus Alonso). 7.1 Introduction. 7.2 Crystalline Silicon as a Photovoltaic Material. 7.3 Crystalline Silicon Solar Cells. 7.4 Manufacturing Process. 7.5 Variations to the Basic Process. 7.6 Other Industrial Approaches. 7.7 Crystalline Silicon Photovoltaic Modules. 7.8 Electrical and Optical Performance of Modules. 7.9 Field Performance of Modules. 7.10 Conclusions. 8 High-efficiency III-V Multijunction Solar Cells (D. J. Friedman, J. M. Olson and Sarah Kurtz). 8.1 Introduction. 8.2 Applications. 8.3 Physics of III-V Multijunction and Single-junction Solar Cells. 8.4 Cell Configuration. 8.5 Computation of Series-connected Device Performance. 8.6 Materials Issues Related to GaInP/GaAs/Ge Solar Cells. 8.7 Epilayer Characterization and Other Diagnostic Techniques. 8.8 Reliability and Degradation. 8.9 Future-generation Solar Cells. 8.10 Summary. 9 Space Solar Cells and Arrays (Sheila Bailey and Ryne Raffaelle). 9.1 The History of Space Solar Cells. 9.2 The Challenge for Space Solar Cells. 9.3 Silicon Solar Cells. 9.4 III-V Solar Cells. 9.5 Space Solar Arrays. 9.6 Future Cell and Array Possibilities. 9.7 Power System Figures of Merit. 9.8 Summary. 10 Photovoltaic Concentrators (Gabriel Sala and Ignacio Anton). 10.1 What is the Aim of Photovoltaic Concentration and What Does it Do? 10.2 Objectives, Limitations and Opportunities. 10.3 Typical Concentrators: an Attempt at Classification. 10.4 Concentration Optics: Thermodynamic Limits. 10.5 Factors of Merit for Concentrators in Relation to the Optics. 10.6 Photovoltaic Concentration Modules and Assemblies. 10.7 Tracking for Concentrator Systems. 10.8 Measurements of Cells, Modules and Photovoltaic Systems in Concentration. 10.9 Summary. 11 Crystalline Silicon Thin-Film Solar Cells via High-temperature and Intermediate-temperature Approaches (Armin G. Aberle and Per I. Widenborg). 11.1 Introduction. 11.2 Modelling. 11.4 Crystalline Silicon Thin-Film Solar Cells on Intermediate-T Foreign Supporting Materials. 11.5 Conclusions. 12 Amorphous Silicon-based Solar Cells (Eric A. Schiff, Steven Hegedus and Xunming Deng). 12.1 Overview. 12.2 Atomic and Electronic Structure of Hydrogenated Amorphous Silicon. 12.3 Depositing Amorphous Silicon. 12.4 Understanding a-Si pin Cells. 12.5 Multijunction Solar Cells. 12.6 Module Manufacturing. 12.7 Conclusions and Future Projections. 13 Cu(InGa)Se2 Solar Cells (William N. Shafarman, Susanne Siebentritt and Lars Stolt). 13.1 Introduction. 13.2 Material Properties. 13.3 Deposition Methods. 13.4 Junction and Device Formation. 13.5 Device Operation. 13.6 Manufacturing Issues. 13.7 The Cu(InGa)Se2 Outlook. 14 Cadmium Telluride Solar Cells (Brian E. McCandless and James R. Sites). 14.1 Introduction. 14.2 Historical Development. 14.3 CdTe Properties. 14.4 CdTe Film Deposition. 14.5 CdTe Thin Film Solar Cells. 14.6 CdTe Modules. 14.7 Future of CdTe-based Solar Cells. 15 Dye-sensitized Solar Cells (Kohjiro Hara and Shogo Mori). 15.1 Introduction. 15.2 Operating Mechanism of DSSC. 15.3 Materials. 15.4 Performance of Highly Efficient DSSCs. 15.5 Electron-transfer Processes. 15.6 New Materials. 15.7 Stability. 15.8 Approach to Commercialization. 15.9 Summary and Prospects. 16 Sunlight Energy Conversion Via Organics (Sam-Shajing Sun and Hugh O'Neill). 16.1 Principles of Organic and Polymeric Photovoltaics. 16.2 Evolution and Types of Organic and Polymeric Solar Cells. 16.3 Organic and Polymeric Solar Cell Fabrication and Characterization. 16.4 Natural Photosynthetic Sunlight Energy Conversion Systems. 16.5 Artificial Photosynthetic Systems. 16.6 Artificial Reaction Centers. 16.7 Towards Device Architectures. 16.8 Summary and Future Perspectives. 17 Transparent Conducting Oxides for Photovoltaics (Alan E. Delahoy and Sheyu Guo). 17.1 Introduction. 17.2 Survey of Materials. 17.3 Deposition Methods. 17.4 TCO Theory and Modeling: Electrical and Optical Properties and their Impact on Module Performance. 17.5 Principal Materials and Issues for Thin Film and Wafer-based PV. 17.6 Textured Films. 17.7 Measurements and Characterization Methods. 17.8 TCO Stability. 17.9 Recent Developments and Prospects. 18 Measurement and Characterization of Solar Cells and Modules (Keith Emery). 18.1 Introduction. 18.2 Rating PV Performance. 18.3 Current-Voltage Measurements. 18.4 Spectral Responsivity Measurements. 18.5 Module Qualification and Certification. 18.6 Summary. 19 PV Systems (Charles M. Whitaker, Timothy U. Townsend, Anat Razon, Raymond M. Hudson and Xavier Vallve). 19.1 Introduction: There is gold at the end of the rainbow. 19.2 System Types. 19.3 Exemplary PV Systems. 19.4 Ratings. 19.5 Key System Components. 19.6 System Design Considerations. 19.7 System Design. 19.8 Installation. 19.9 Operation and Maintenance/Monitoring. 19.10 Removal, Recycling and Remediation. 19.11 Examples. 20 Electrochemical Storage for Photovoltaics (Dirk Uwe Sauer). 20.1 Introduction. 20.2 General Concept of Electrochemical Batteries. 20.3 Typical Operation Conditions of Batteries in PV Applications. 20.4 Secondary Electrochemical Accumulators with Internal Storage. 20.5 Secondary Electrochemical Battery Systems with External Storage. 20.6 Investment and Lifetime Cost Considerations. 20.7 Conclusion. 21 Power Conditioning for Photovoltaic Power Systems (Heribert Schmidt, Bruno Burger and Jurgen Schmid). 21.1 Charge Controllers and Monitoring Systems for Batteries in PV Power Systems. 21.2 Inverters. 22 Energy Collected and Delivered by PV Modules (Eduardo Lorenzo). 22.1 Introduction. 22.2 Movement between Sun and Earth. 22.3 Solar Radiation Components. 22.4 Solar Radiation Data and Uncertainty. 22.5 Radiation on Inclined Surfaces. 22.6 Diurnal Variations of the Ambient Temperature. 22.7 Effects of the Angle of Incidence and of Dirt. 22.8 Some Calculation Tools. 22.9 Irradiation on Most Widely Studied Surfaces. 22.10 PV Generator Behaviour Under Real Operation Conditions. 22.11 Reliability and Sizing of Stand-alone PV Systems. 22.12 The Case of Solar Home Systems. 22.13 Energy Yield of Grid-connected PV Systems. 22.14 Conclusions. 23 PV in Architecture (Tjerk H. Reijenga and Henk F. Kaan). 23.1 Introduction. 23.2 PV in Architecture. 23.3 BIPV Basics. 23.4 Steps in the Design Process with PV. 23.5 Concluding Remarks. 24 Photovoltaics and Development (Jorge M. Huacuz, Jaime Agredano and Lalith Gunaratne). 24.1 Electricity and Development. 24.2 Breaking the Chains of Underdevelopment. 24.3 The PV Alternative. 24.4 Examples of PV Rural Electrification. 24.5 Toward a New Paradigm for Rural Electrification. References. Index.",editor list contributor prefac nd edit achiev challeng solar electr photovolta steven hegedu antonio luqu big pictur photovolta photovolta today great challeng trend technolog conclus role polici pv industri growth past present futur john byrn lado kurdgelashvili introduct polici review select countri polici impact pv market develop futur pv market growth scenario toward sustain futur physic solar cell jefferi l gray introduct fundament properti semiconductor solar cell fundament addit topic summari theoret limit photovolta convers newgener solar cell antonio luqu antonio marti introduct thermodynam background photovolta convert technic effici limit solar convert veryhigheffici concept conclus solar grade silicon feedstock bruno ceccaroli otto lohn introduct silicon product silicon metalmetallurg grade silicon product polysiliconsilicon electron photovolta grade current silicon feedstock solar cell requir silicon crystallin solar cell rout solar grade silicon conclus bulk crystal growth wafer pv hugo rodriguez ismael guerrero wolfgang koch arthur l endro dieter frank christian hassler juri p kalej h j moller introduct bulk monocrystallin materi bulk multicrystallin silicon wafer silicon ribbon foil product numer simul crystal growth techniqu conclus crystallin silicon solar cell modul ignacio tobia carlo del canizo jesu alonso introduct crystallin silicon photovolta materi crystallin silicon solar cell manufactur process variat basic process industri approach crystallin silicon photovolta modul electr optic perform modul field perform modul conclus higheffici iiiv multijunct solar cell j friedman j olson sarah kurtz introduct applic physic iiiv multijunct singlejunct solar cell cell configur comput seriesconnect devic perform materi issu relat gainpgaasg solar cell epilay character diagnost techniqu reliabl degrad futuregener solar cell summari space solar cell array sheila bailey ryne raffael histori space solar cell challeng space solar cell silicon solar cell iiiv solar cell space solar array futur cell array possibl power system figur merit summari photovolta concentr gabriel sala ignacio anton aim photovolta concentr object limit opportun typic concentr attempt classif concentr optic thermodynam limit factor merit concentr relat optic photovolta concentr modul assembl track concentr system measur cell modul photovolta system concentr summari crystallin silicon thinfilm solar cell via hightemperatur intermediatetemperatur approach armin g aberl per widenborg introduct model crystallin silicon thinfilm solar cell intermediatet foreign support materi conclus amorph siliconbas solar cell eric schiff steven hegedu xunm deng overview atom electron structur hydrogen amorph silicon deposit amorph silicon understand asi pin cell multijunct solar cell modul manufactur conclus futur project cuingas solar cell william n shafarman susann siebentritt lar stolt introduct materi properti deposit method junction devic format devic oper manufactur issu cuingas outlook cadmium tellurid solar cell brian e mccandless jame r site introduct histor develop cdte properti cdte film deposit cdte thin film solar cell cdte modul futur cdtebas solar cell dyesensit solar cell kohjiro hara shogo mori introduct oper mechan dssc materi perform highli effici dssc electrontransf process new materi stabil approach commerci summari prospect sunlight energi convers via organ samshaj sun hugh oneil principl organ polymer photovolta evolut type organ polymer solar cell organ polymer solar cell fabric character natur photosynthet sunlight energi convers system artifici photosynthet system artifici reaction center toward devic architectur summari futur perspect transpar conduct oxid photovolta alan e delahoy sheyu guo introduct survey materi deposit method tco theori model electr optic properti impact modul perform princip materi issu thin film waferbas pv textur film measur character method tco stabil recent develop prospect measur character solar cell modul keith emeri introduct rate pv perform currentvoltag measur spectral respons measur modul qualif certif summari pv system charl whitak timothi u townsend anat razon raymond hudson xavier vallv introduct gold end rainbow system type exemplari pv system rate key system compon system design consider system design instal oper maintenancemonitor remov recycl remedi exampl electrochem storag photovolta dirk uwe sauer introduct gener concept electrochem batteri typic oper condit batteri pv applic secondari electrochem accumul intern storag secondari electrochem batteri system extern storag invest lifetim cost consider conclus power condit photovolta power system heribert schmidt bruno burger jurgen schmid charg control monitor system batteri pv power system invert energi collect deliv pv modul eduardo lorenzo introduct movement sun earth solar radiat compon solar radiat data uncertainti radiat inclin surfac diurnal variat ambient temperatur effect angl incid dirt calcul tool irradi wide studi surfac pv gener behaviour real oper condit reliabl size standalon pv system case solar home system energi yield gridconnect pv system conclus pv architectur tjerk h reijenga henk f kaan introduct pv architectur bipv basic step design process pv conclud remark photovolta develop jorg huacuz jaim agredano lalith gunaratn electr develop break chain underdevelop pv altern exampl pv rural electrif toward new paradigm rural electrif refer index
0e8a5df8824feef18d44d7d3b009ef9df800e097,"Genome, transcriptome and proteome: the rise of omics data and their integration in biomedical sciences","Abstract Advances in the technologies and informatics used to generate and process large biological data sets (omics data) are promoting a critical shift in the study of biomedical sciences. While genomics, transcriptomics and proteinomics, coupled with bioinformatics and biostatistics, are gaining momentum, they are still, for the most part, assessed individually with distinct approaches generating monothematic rather than integrated knowledge. As other areas of biomedical sciences, including metabolomics, epigenomics and pharmacogenomics, are moving towards the omics scale, we are witnessing the rise of inter-disciplinary data integration strategies to support a better understanding of biological systems and eventually the development of successful precision medicine. This review cuts across the boundaries between genomics, transcriptomics and proteomics, summarizing how omics data are generated, analysed and shared, and provides an overview of the current strengths and weaknesses of this global approach. This work intends to target students and researchers seeking knowledge outside of their field of expertise and fosters a leap from the reductionist to the global-integrative analytical approach in research.",abstract advanc technolog informat use gener process larg biolog data set omic data promot critic shift studi biomed scienc genom transcriptom proteinom coupl bioinformat biostatist gain momentum still part assess individu distinct approach gener monothemat rather integr knowledg area biomed scienc includ metabolom epigenom pharmacogenom move toward omic scale wit rise interdisciplinari data integr strategi support better understand biolog system eventu develop success precis medicin review cut across boundari genom transcriptom proteom summar omic data gener analys share provid overview current strength weak global approach work intend target student research seek knowledg outsid field expertis foster leap reductionist globalintegr analyt approach research
85e7d96dfd5efcbb0711bcc89039ba0d1dbda64e,Toward discovery science of human brain function,"Although it is being successfully implemented for exploration of the genome, discovery science has eluded the functional neuroimaging community. The core challenge remains the development of common paradigms for interrogating the myriad functional systems in the brain without the constraints of a priori hypotheses. Resting-state functional MRI (R-fMRI) constitutes a candidate approach capable of addressing this challenge. Imaging the brain during rest reveals large-amplitude spontaneous low-frequency (<0.1 Hz) fluctuations in the fMRI signal that are temporally correlated across functionally related areas. Referred to as functional connectivity, these correlations yield detailed maps of complex neural systems, collectively constituting an individual's “functional connectome.” Reproducibility across datasets and individuals suggests the functional connectome has a common architecture, yet each individual's functional connectome exhibits unique features, with stable, meaningful interindividual differences in connectivity patterns and strengths. Comprehensive mapping of the functional connectome, and its subsequent exploitation to discern genetic influences and brain–behavior relationships, will require multicenter collaborative datasets. Here we initiate this endeavor by gathering R-fMRI data from 1,414 volunteers collected independently at 35 international centers. We demonstrate a universal architecture of positive and negative functional connections, as well as consistent loci of inter-individual variability. Age and sex emerged as significant determinants. These results demonstrate that independent R-fMRI datasets can be aggregated and shared. High-throughput R-fMRI can provide quantitative phenotypes for molecular genetic studies and biomarkers of developmental and pathological processes in the brain. To initiate discovery science of brain function, the 1000 Functional Connectomes Project dataset is freely accessible at www.nitrc.org/projects/fcon_1000/.",although success implement explor genom discoveri scienc elud function neuroimag commun core challeng remain develop common paradigm interrog myriad function system brain without constraint priori hypothes restingst function mri rfmri constitut candid approach capabl address challeng imag brain rest reveal largeamplitud spontan lowfrequ hz fluctuat fmri signal tempor correl across function relat area refer function connect correl yield detail map complex neural system collect constitut individu function connectom reproduc across dataset individu suggest function connectom common architectur yet individu function connectom exhibit uniqu featur stabl meaning interindividu differ connect pattern strength comprehens map function connectom subsequ exploit discern genet influenc brainbehavior relationship requir multicent collabor dataset initi endeavor gather rfmri data volunt collect independ intern center demonstr univers architectur posit neg function connect well consist loci interindividu variabl age sex emerg signific determin result demonstr independ rfmri dataset aggreg share highthroughput rfmri provid quantit phenotyp molecular genet studi biomark development patholog process brain initi discoveri scienc brain function function connectom project dataset freeli access wwwnitrcorgprojectsfcon_
ee09b6f83d9b169f534e2acb5a0ab19face6b33e,Data Reduction and Error Analysis for the Physical Sciences,Uncertainties in measurements probability distributions error analysis estimates of means and errors Monte Carlo techniques dependent and independent variables least-squares fit to a polynomial least-squares fit to an arbitrary function fitting composite peaks direct application of the maximum likelihood. Appendices: numerical methods matrices graphs and tables histograms and graphs computer routines in Pascal.,uncertainti measur probabl distribut error analysi estim mean error mont carlo techniqu depend independ variabl leastsquar fit polynomi leastsquar fit arbitrari function fit composit peak direct applic maximum likelihood appendic numer method matric graph tabl histogram graph comput routin pascal
76b0d691be19c0796990685f31cbcde46f864858,Qualitative Data Analysis with NVivo,"This straightforward, jargon-free book provides an invaluable introduction to planning and conducting qualitative data analysis with NVivo. Written by leading authorities, with over 40 years combined experience in computer-assisted analysis of qualitative and mixed-mode data, the new edition of this best selling textbook is an ideal mix of practical instruction, methodology and real world examples. Practical, clear and focused the book effectively shows how NVivo software can accommodate and assist analysis across a wide range of research questions, data types, perspectives and methodologies. It sets out: - The power and flexibility of the NVivo software - How best to use NVivo at each stage in your research project - Examples from the authors' own research and the sample data that accompanies the software, supplemented with vignettes drawn from across the social sciences - Annotated screen shots - A website with links to data, sample projects, supplementary/updated instructions, and SAGE journal content This second edition contains new chapters on handling a literature review, visualizing data, working in mixed methods and social media datasets, and approaching NVivo as a team. An insightful step-by-step guide to the messy reality of doing computer-assisted analysis, this successful book is essential reading for anyone considering using NVivo software.",straightforward jargonfre book provid invalu introduct plan conduct qualit data analysi nvivo written lead author year combin experi computerassist analysi qualit mixedmod data new edit best sell textbook ideal mix practic instruct methodolog real world exampl practic clear focus book effect show nvivo softwar accommod assist analysi across wide rang research question data type perspect methodolog set power flexibl nvivo softwar best use nvivo stage research project exampl author research sampl data accompani softwar supplement vignett drawn across social scienc annot screen shot websit link data sampl project supplementaryupd instruct sage journal content second edit contain new chapter handl literatur review visual data work mix method social media dataset approach nvivo team insight stepbystep guid messi realiti computerassist analysi success book essenti read anyon consid use nvivo softwar
1d4c7199e5165011175ff1e83aa2a51188834795,Analysing Qualitative Data in Psychology,"Analysing Qualitative Data in Psychology equips students and researchers in psychology and the social sciences to carry out qualitative data analysis, focusing on four major methods (grounded theory, interpretative phenomenological analysis, discourse analysis and narrative analysis). Assuming no prior knowledge of qualitative research, chapters on the nature, assumptions and practicalities of each method are written by acknowledged experts. To help students and researchers make informed methodological choices about their own research the book addresses data collection and the writing up of research using each method, while providing a sustained comparison of the four methods, backed up with authoritative analyses using the different methods.",analys qualit data psycholog equip student research psycholog social scienc carri qualit data analysi focus four major method ground theori interpret phenomenolog analysi discours analysi narr analysi assum prior knowledg qualit research chapter natur assumpt practic method written acknowledg expert help student research make inform methodolog choic research book address data collect write research use method provid sustain comparison four method back authorit analys use differ method
a04ce672e8838e3c73a10559b2068b93810c3f24,Regression Analysis of Count Data,"Students in both social and natural sciences often seek regression methods to explain the frequency of events, such as visits to a doctor, auto accidents, or new patents awarded. This book, now in its second edition, provides the most comprehensive and up-to-date account of models and methods to interpret such data. The authors combine theory and practice to make sophisticated methods of analysis accessible to researchers and practitioners working with widely different types of data and software in areas such as applied statistics, econometrics, marketing, operations research, actuarial studies, demography, biostatistics and quantitative social sciences. The new material includes new theoretical topics, an updated and expanded treatment of cross-section models, coverage of bootstrap-based and simulation-based inference, expanded treatment of time series, multivariate and panel data, expanded treatment of endogenous regressors, coverage of quantile count regression, and a new chapter on Bayesian methods.",student social natur scienc often seek regress method explain frequenc event visit doctor auto accid new patent award book second edit provid comprehens uptod account model method interpret data author combin theori practic make sophist method analysi access research practition work wide differ type data softwar area appli statist econometr market oper research actuari studi demographi biostatist quantit social scienc new materi includ new theoret topic updat expand treatment crosssect model coverag bootstrapbas simulationbas infer expand treatment time seri multivari panel data expand treatment endogen regressor coverag quantil count regress new chapter bayesian method
a89d59f39e805e71b554a962d07449c5d39b7df3,Combining labeled and unlabeled data with co-training,"We consider the problem of using a large unlabeled sample to boost performance of a learning algorit,hrn when only a small set of labeled examples is available. In particular, we consider a problem setting motivated by the task of learning to classify web pages, in which the description of each example can be partitioned into two distinct views. For example, the description of a web page can be partitioned into the words occurring on that page, and the words occurring in hyperlinks t,hat point to that page. We assume that either view of the example would be sufficient for learning if we had enough labeled data, but our goal is to use both views together to allow inexpensive unlabeled data to augment, a much smaller set of labeled examples. Specifically, the presence of two distinct views of each example suggests strategies in which two learning algorithms are trained separately on each view, and then each algorithm’s predictions on new unlabeled examples are used to enlarge the training set of the other. Our goal in this paper is to provide a PAC-style analysis for this setting, and, more broadly, a PAC-style framework for the general problem of learning from both labeled and unlabeled data. We also provide empirical results on real web-page data indicating that this use of unlabeled examples can lead to significant improvement of hypotheses in practice. *This research was supported in part by the DARPA HPKB program under contract F30602-97-1-0215 and by NSF National Young investigator grant CCR-9357793. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. TO copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. COLT 98 Madison WI USA Copyright ACM 1998 l-58113-057--0/98/ 7...%5.00 92 Tom Mitchell School of Computer Science Carnegie Mellon University Pittsburgh, PA 15213-3891 mitchell+@cs.cmu.edu",consid problem use larg unlabel sampl boost perform learn algorithrn small set label exampl avail particular consid problem set motiv task learn classifi web page descript exampl partit two distinct view exampl descript web page partit word occur page word occur hyperlink point page assum either view exampl would suffici learn enough label data goal use view togeth allow inexpens unlabel data augment much smaller set label exampl specif presenc two distinct view exampl suggest strategi two learn algorithm train separ view algorithm predict new unlabel exampl use enlarg train set goal paper provid pacstyl analysi set broadli pacstyl framework gener problem learn label unlabel data also provid empir result real webpag data indic use unlabel exampl lead signific improv hypothes practic research support part darpa hpkb program contract f nsf nation young investig grant ccr permiss make digit hard copi part work person classroom use grant without fee provid copi made distribut profit commerci advantag copi bear notic full citat first page copi otherwis republish post server redistribut list requir prior specif permiss andor fee colt madison wi usa copyright acm l tom mitchel school comput scienc carnegi mellon univers pittsburgh pa mitchellcscmuedu
216b5d37a8d3115bb52049b2c2544cd222670839,Analysis of Longitudinal Data,"chemists. Commenting on the new material in the second edition (2E), which was published in 1991, Blackwood (1994) noted the predominance of citations from the chemometrics literature and commented that “references from other statistical sources are sparse.” Chemometrics had certainly arrived in a big way by 1991, and there had not been much impact from the statistical community. If the methodology has not developed greatly through the 1990s, then the applications certainly have blossomed. (See the Journal of Chemometrics or Chemometrics and Intelligent Laboratory Systems, which have a lot of papers that would work perfectly well in the pages of Technometrics.) Blackwood (1994) noted in his review of the 2E that “The mathematical and statistical theory behind factor analysis is generally well presented, but it is in the practice and application areas that the book does best” (p. 115). In the Preface, the author notes that “the introductory chapters, 1 through 5, remain unchanged” (p. ix). Why mess with a proven product? Blackwood (1994) did comment that “the book is not an easy read,” and “it requires a good deal of mathematical understanding to get through.” See the review for a complete summary of the 2E. The remainder of the book has been revised considerably. Chapter 6, formerly “Spectral Methods of Factor Analysis,” has been reorganized and retitled as “Evolutionary Methods.” It focuses on self-modeling methods and rank-annihilation factor analysis. This chapter is followed by additional material from the former Chapter 6 that has been expanded into two new chapters, “Multimode Analysis” and “Partial Least-Squares Regression.” All statisticians are quite familiar with the latter methodology, if not with some of the advanced realizations in chemistry, such as multiblock PLS, serial PLS, and multilinear PLS, that are described in this chapter. The chapter on multimode analysis carries the factor analysis tools into the arena of multiway arrays. This chapter deals with three-dimensional rank-annihilation factor analysis, simultaneous analysis, three-mode factor analysis, and PARAFAC (parallel factor analysis). The four application chapters that conclude the book continue to bear the same titles as before, but they have all been updated to incorporate the latest advances in a wide variety of disciplines where various factor analysis methodologies have been applied. Three of the chapters are focused strictly within the realm of chemistry, whereas the  nal chapter broadens the spectrum to incorporate examples from related sciences, speci cally biomedical, fuels, environmental, and food science applications. Despite the vast computational complexity of many of the methods in the book, the author continues to make no attempt to integrate statistical software into the text. There is an appendix that discusses the Toolbox for Chemical Factor Analysis, a suite of Matlab which the author apparently wrote. However, no CD-ROM is included. These programs need to be purchased. Another appendix provides the actual Matlab code for three of the programs, which are like subroutines in FORTRAN in that they need to be strung together to create a factor analysis program. There is no reference to software packages from Umetrics or other companies whose software can carry out many of the analyses in the book.",chemist comment new materi second edit e publish blackwood note predomin citat chemometr literatur comment refer statist sourc spars chemometr certainli arriv big way much impact statist commun methodolog develop greatli applic certainli blossom see journal chemometr chemometr intellig laboratori system lot paper would work perfectli well page technometr blackwood note review e mathemat statist theori behind factor analysi gener well present practic applic area book best p prefac author note introductori chapter remain unchang p ix mess proven product blackwood comment book easi read requir good deal mathemat understand get see review complet summari e remaind book revis consider chapter formerli spectral method factor analysi reorgan retitl evolutionari method focus selfmodel method rankannihil factor analysi chapter follow addit materi former chapter expand two new chapter multimod analysi partial leastsquar regress statistician quit familiar latter methodolog advanc realiz chemistri multiblock pl serial pl multilinear pl describ chapter chapter multimod analysi carri factor analysi tool arena multiway array chapter deal threedimension rankannihil factor analysi simultan analysi threemod factor analysi parafac parallel factor analysi four applic chapter conclud book continu bear titl updat incorpor latest advanc wide varieti disciplin variou factor analysi methodolog appli three chapter focus strictli within realm chemistri wherea nal chapter broaden spectrum incorpor exampl relat scienc speci calli biomed fuel environment food scienc applic despit vast comput complex mani method book author continu make attempt integr statist softwar text appendix discuss toolbox chemic factor analysi suit matlab author appar wrote howev cdrom includ program need purchas anoth appendix provid actual matlab code three program like subroutin fortran need strung togeth creat factor analysi program refer softwar packag umetr compani whose softwar carri mani analys book
75ffcc4d8fde3834b3433f0e67d5916ebfead74c,Statistical Methods for Survival Data Analysis,"Praise for the Third Edition. . . an easy-to read introduction to survival analysis which covers the major concepts and techniques of the subject. Statistics in Medical ResearchUpdated and expanded to reflect the latest developments, Statistical Methods for Survival Data Analysis, Fourth Edition continues to deliver a comprehensive introduction to the most commonly-used methods for analyzing survival data. Authored by a uniquely well-qualified author team, the Fourth Edition is a critically acclaimed guide to statistical methods with applications in clinical trials, epidemiology, areas of business, and the social sciences. The book features many real-world examples to illustrate applications within these various fields, although special consideration is given to the study of survival data in biomedical sciences.Emphasizing the latest research and providing the most up-to-date information regarding software applications in the field, Statistical Methods for Survival Data Analysis, Fourth Edition also includes:Marginal and random effect models for analyzing correlated censored or uncensored dataMultiple types of two-sample and K-sample comparison analysisUpdated treatment of parametric methods for regression model fitting with a new focus on accelerated failure time modelsExpanded coverage of the Cox proportional hazards modelExercises at the end of each chapter to deepen knowledge of the presented materialStatistical Methods for Survival Data Analysis is an ideal text for upper-undergraduate and graduate-level courses on survival data analysis. The book is also an excellent resource for biomedical investigators, statisticians, and epidemiologists, as well as researchers in every field in which the analysis of survival data plays a role.",prais third edit easyto read introduct surviv analysi cover major concept techniqu subject statist medic researchupd expand reflect latest develop statist method surviv data analysi fourth edit continu deliv comprehens introduct commonlyus method analyz surviv data author uniqu wellqualifi author team fourth edit critic acclaim guid statist method applic clinic trial epidemiolog area busi social scienc book featur mani realworld exampl illustr applic within variou field although special consider given studi surviv data biomed sciencesemphas latest research provid uptod inform regard softwar applic field statist method surviv data analysi fourth edit also includesmargin random effect model analyz correl censor uncensor datamultipl type twosampl ksampl comparison analysisupd treatment parametr method regress model fit new focu acceler failur time modelsexpand coverag cox proport hazard modelexercis end chapter deepen knowledg present materialstatist method surviv data analysi ideal text upperundergradu graduatelevel cours surviv data analysi book also excel resourc biomed investig statistician epidemiologist well research everi field analysi surviv data play role
d8f16b07147e2cbedd8227ea5a8ef2cd7f8ae413,GeoDa: An Introduction to Spatial Data Analysis,"The development of specialized software for spatial data analysis has seen rapid growth since the lack of such tools was lamented in the late 1980s by Haining (1989) and cited as a major impediment to the adoption and use of spatial statistics by GIS researchers. Initially, attention tended to focus on conceptual issues, such as how to integrate spatial statistical methods and a GIS environment (loosely vs. tightly coupled, embedded vs. modular, etc.), and which techniques would be most fruitfully included in such a framework. Familiar reviews of these issues are represented in, among others, Anselin and Getis (1992), Goodchild et al. (1992), Fischer and Nijkamp (1993), Fotheringham and Rogerson (1993, 1994), Fischer et al. (1996), and Fischer and Getis (1997). Today, the situation is quite different, and a fairly substantial collection of spatial data analysis software is readily available, ranging from niche programs, customized scripts and extensions for commercial statistical and GIS packages, to a burgeoning open source effort using software environments such as R, Java and Python. This is exemplified by the growing contents of the software tools clearing house maintained by the U.S.- based Center for Spatially Integrated Social Science [CSISS] (see http://www.csiss.org/clearinghouse/).",develop special softwar spatial data analysi seen rapid growth sinc lack tool lament late hain cite major impedi adopt use spatial statist gi research initi attent tend focu conceptu issu integr spatial statist method gi environ loos vs tightli coupl embed vs modular etc techniqu would fruit includ framework familiar review issu repres among other anselin geti goodchild et al fischer nijkamp fotheringham rogerson fischer et al fischer geti today situat quit differ fairli substanti collect spatial data analysi softwar readili avail rang nich program custom script extens commerci statist gi packag burgeon open sourc effort use softwar environ r java python exemplifi grow content softwar tool clear hous maintain us base center spatial integr social scienc csiss see httpwwwcsissorgclearinghous
6b5206e860f258dc3d228eb498005371c19e809c,Advancing the Science of Collaborative Problem Solving,"Collaborative problem solving (CPS) has been receiving increasing international attention because much of the complex work in the modern world is performed by teams. However, systematic education and training on CPS is lacking for those entering and participating in the workforce. In 2015, the Programme for International Student Assessment (PISA), a global test of educational progress, documented the low levels of proficiency in CPS. This result not only underscores a significant societal need but also presents an important opportunity for psychological scientists to develop, adopt, and implement theory and empirical research on CPS and to work with educators and policy experts to improve training in CPS. This article offers some directions for psychological science to participate in the growing attention to CPS throughout the world. First, it identifies the existing theoretical frameworks and empirical research that focus on CPS. Second, it provides examples of how recent technologies can automate analyses of CPS processes and assessments so that substantially larger data sets can be analyzed and so students can receive immediate feedback on their CPS performance. Third, it identifies some challenges, debates, and uncertainties in creating an infrastructure for research, education, and training in CPS. CPS education and assessment are expected to improve when supported by larger data sets and theoretical frameworks that are informed by psychological science. This will require interdisciplinary efforts that include expertise in psychological science, education, assessment, intelligent digital technologies, and policy.",collabor problem solv cp receiv increas intern attent much complex work modern world perform team howev systemat educ train cp lack enter particip workforc programm intern student assess pisa global test educ progress document low level profici cp result underscor signific societ need also present import opportun psycholog scientist develop adopt implement theori empir research cp work educ polici expert improv train cp articl offer direct psycholog scienc particip grow attent cp throughout world first identifi exist theoret framework empir research focu cp second provid exampl recent technolog autom analys cp process assess substanti larger data set analyz student receiv immedi feedback cp perform third identifi challeng debat uncertainti creat infrastructur research educ train cp cp educ assess expect improv support larger data set theoret framework inform psycholog scienc requir interdisciplinari effort includ expertis psycholog scienc educ assess intellig digit technolog polici
0140a0f2bc07b3768b2cdee91c455f9680cd45a2,Longitudinal And Panel Data Analysis And Applications In The Social Sciences,"longitudinal and panel data: analysis and applications for longitudinal and panel data library of congress longitudinal and panel data analysis and applications in longitudinal and panel data analysis and applications in longitudinal and panel data analysis and applications in longitudinal and panel data analysis and applications in longitudinal analysis michael l. berbaum institute for ps2701 advanced methodology: longitudinal analysis course august, 2003 longitudinal and panel data: analysis and an overview of methods for the analysis of panel pol 574: quantitative analysis iv q-apsinceton longitudinal data analysis icpsr data analysis an introduction quantitative applications in home syllabus university of iowa department of 22s:162 applied generalized regression, spring 2010 poli 803: longitudinal data analysis multivariate longitudinal data analysis for actuarial growth mixture models in longitudinal research statmodel browse the table of contents, or select an option from by robert a. yaffee september 2003 portland state university biostatistics 537: longitudinal data analysis econometrics institute of information theory and automation sociology 7140—longitudinal data analysis (fall semester data analysis an introduction quantitative applications in by robert a. yaffee september 2003 sites.google analyzing panel data quantitative applications in the time series 10 panel data [read-only] thus spake vm mixture models for longitudinal analysis: applications of quantitative approaches to longitudinal research vijayamohanan pillai n thusspakevmles.wordpress an experience rating approach to insurer projected loss ratios g93.2314 longitudinal statistics course description/syllabus using panel data techniques for social science unirioja missing data quantitative applications in the social sciences download applied longitudinal data analysis: modeling sociology 7140—longitudinal data analysis (spring semester quantitative longitudinal research: references / resources",longitudin panel data analysi applic longitudin panel data librari congress longitudin panel data analysi applic longitudin panel data analysi applic longitudin panel data analysi applic longitudin panel data analysi applic longitudin analysi michael l berbaum institut ps advanc methodolog longitudin analysi cours august longitudin panel data analysi overview method analysi panel pol quantit analysi iv qapsinceton longitudin data analysi icpsr data analysi introduct quantit applic home syllabu univers iowa depart appli gener regress spring poli longitudin data analysi multivari longitudin data analysi actuari growth mixtur model longitudin research statmodel brows tabl content select option robert yaffe septemb portland state univers biostatist longitudin data analysi econometr institut inform theori autom sociolog longitudin data analysi fall semest data analysi introduct quantit applic robert yaffe septemb sitesgoogl analyz panel data quantit applic time seri panel data readonli thu spake vm mixtur model longitudin analysi applic quantit approach longitudin research vijayamohanan pillai n thusspakevmleswordpress experi rate approach insur project loss ratio g longitudin statist cours descriptionsyllabu use panel data techniqu social scienc unirioja miss data quantit applic social scienc download appli longitudin data analysi model sociolog longitudin data analysi spring semest quantit longitudin research refer resourc
d8d139a250b7d30ac917dda842096b65819f1a8e,Regression Models for Count Data in R,"The classical Poisson, geometric and negative binomial regression models for count data belong to the family of generalized linear models and are available at the core of the statistics toolbox in the R system for statistical computing. After reviewing the conceptual and computational features of these methods, a new implementation of zero-inflated and hurdle regression models in the functions zeroinfl() and hurdle() from the package pscl is introduced. It re-uses design and functionality of the basic R functions just as the underlying conceptual tools extend the classical models. Both model classes are able to incorporate over-dispersion and excess zeros - two problems that typically occur in count data sets in economics and the social and political sciences - better than their classical counterparts. Using cross-section data on the demand for medical care, it is illustrated how the classical as well as the zero-augmented models can be fitted, inspected and tested in practice.",classic poisson geometr neg binomi regress model count data belong famili gener linear model avail core statist toolbox r system statist comput review conceptu comput featur method new implement zeroinfl hurdl regress model function zeroinfl hurdl packag pscl introduc reus design function basic r function underli conceptu tool extend classic model model class abl incorpor overdispers excess zero two problem typic occur count data set econom social polit scienc better classic counterpart use crosssect data demand medic care illustr classic well zeroaug model fit inspect test practic
c107e55f9c02b24c38b6e92827ace6512fa73074,Mathematical Analysis and Numerical Methods for Science and Technology,"These six volumes - the result of a ten year collaboration between the authors, two of France's leading scientists and both distinguished international figures - compile the mathematical knowledge required by researchers in mechanics, physics, engineering, chemistry and other branches of application of mathematics for the theoretical and numerical resolution of physical models on computers. Since the publication in 1924 of the Methoden der mathematischen Physik by Courant and Hilbert, there has been no other comprehensive and up-to-date publication presenting the mathematical tools needed in applications of mathematics in directly implementable form. The advent of large computers has in the meantime revolutionised methods of computation and made this gap in the literature intolerable: the objective of the present work is to fill just this gap. Many phenomena in physical mathematics may be modeled by a system of partial differential equations in distributed systems: a model here means a set of equations, which together with given boundary data and, if the phenomenon is evolving in time, initial data, defines the system. The advent of high-speed computers has made it possible for the first time to caluclate values from models accurately and rapidly. Researchers and engineers thus have a crucial means of using numerical results to modify and adapt arguments and experiments along the way. Every fact of technical and industrial activity has been affected by these developments. Modeling by distributed systems now also supports work in many areas of physics (plasmas, new materials, astrophysics, geophysics), chemistry and mechanics and is finding increasing use in the life sciences. Volumes 5 and 6 cover problems of Transport and Evolution.",six volum result ten year collabor author two franc lead scientist distinguish intern figur compil mathemat knowledg requir research mechan physic engin chemistri branch applic mathemat theoret numer resolut physic model comput sinc public methoden der mathematischen physik courant hilbert comprehens uptod public present mathemat tool need applic mathemat directli implement form advent larg comput meantim revolutionis method comput made gap literatur intoler object present work fill gap mani phenomena physic mathemat may model system partial differenti equat distribut system model mean set equat togeth given boundari data phenomenon evolv time initi data defin system advent highspe comput made possibl first time calucl valu model accur rapidli research engin thu crucial mean use numer result modifi adapt argument experi along way everi fact technic industri activ affect develop model distribut system also support work mani area physic plasma new materi astrophys geophys chemistri mechan find increas use life scienc volum cover problem transport evolut
ef1a0e88c2474162222a68f9eb13c996925d31ba,The Danish National Hospital Register. A valuable source of data for modern health sciences.,"The Danish National Hospital Register (LPR) has collected nationwide data on all somatic hospital admissions since 1977, and since 1995 data on outpatients and emergency patients have been included as well. Numerous research projects have been undertaken in the national Danish context as well as in collaboration with international teams, and the LPR is truly a valuable source of data for health sciences, especially in epidemiology, health services research and clinical research. Nearly complete registration of somatic hospital events in Denmark is combined with ideal conditions for longterm follow-up due to the existence of a national system of unique person identification in a population of relative demographic stability. Examples of studies are provided for illustration within three main areas: I: Using LPR for surveillance of the occurrence of diseases and of surgical procedures, II: Using the Register as a sampling frame for longitudinal population based and clinical research, and III: Using the Register as a data source for monitoring outcomes. Data available from the Register as well as studies of the validity of the data are mentioned, and it is described how researchers may get access to the Register. The Danish National Hospital Register is well suited to contribute to international comparative studies with relevance for evidence-based medicine.",danish nation hospit regist lpr collect nationwid data somat hospit admiss sinc sinc data outpati emerg patient includ well numer research project undertaken nation danish context well collabor intern team lpr truli valuabl sourc data health scienc especi epidemiolog health servic research clinic research nearli complet registr somat hospit event denmark combin ideal condit longterm followup due exist nation system uniqu person identif popul rel demograph stabil exampl studi provid illustr within three main area use lpr surveil occurr diseas surgic procedur ii use regist sampl frame longitudin popul base clinic research iii use regist data sourc monitor outcom data avail regist well studi valid data mention describ research may get access regist danish nation hospit regist well suit contribut intern compar studi relev evidencebas medicin
f5430dab07cb7d8ae3f257ec0d41190e7093570d,"Open Source Software and the ""Private-Collective"" Innovation Model: Issues for Organization Science","Currently, two models of innovation are prevalent in organization science. The ""private investment"" model assumes returns to the innovator result from private goods and efficient regimes of intellectual property protection. The ""collective action"" model assumes that under conditions of market failure, innovators collaborate in order to produce a public good. The phenomenon of open source software development shows that users program to solve their own as well as shared technical problems, and freely reveal their innovations without appropriating private returns from selling the software. In this paper, we propose that open source software development is an exemplar of a compound ""private-collective"" model of innovation that contains elements of both the private investment and the collective action models and can offer society the ""best of both worlds"" under many conditions. We describe a new set of research questions this model raises for scholars in organization science. We offer some details regarding the types of data available for open source projects in order to ease access for researchers who are unfamiliar with these, and also offer some advice on conducting empirical studies on open source software development processes.",current two model innov preval organ scienc privat invest model assum return innov result privat good effici regim intellectu properti protect collect action model assum condit market failur innov collabor order produc public good phenomenon open sourc softwar develop show user program solv well share technic problem freeli reveal innov without appropri privat return sell softwar paper propos open sourc softwar develop exemplar compound privatecollect model innov contain element privat invest collect action model offer societi best world mani condit describ new set research question model rais scholar organ scienc offer detail regard type data avail open sourc project order eas access research unfamiliar also offer advic conduct empir studi open sourc softwar develop process
0efa2632f2e1edc5c0383f7b4dc257e2806032a0,Mining Text Data,,nan
5289463e90a350b57a5f84190c456d8c38d86368,MassBank: a public repository for sharing mass spectral data for life sciences.,"MassBank is the first public repository of mass spectra of small chemical compounds for life sciences (<3000 Da). The database contains 605 electron-ionization mass spectrometry (EI-MS), 137 fast atom bombardment MS and 9276 electrospray ionization (ESI)-MS(n) data of 2337 authentic compounds of metabolites, 11 545 EI-MS and 834 other-MS data of 10,286 volatile natural and synthetic compounds, and 3045 ESI-MS(2) data of 679 synthetic drugs contributed by 16 research groups (January 2010). ESI-MS(2) data were analyzed under nonstandardized, independent experimental conditions. MassBank is a distributed database. Each research group provides data from its own MassBank data servers distributed on the Internet. MassBank users can access either all of the MassBank data or a subset of the data by specifying one or more experimental conditions. In a spectral search to retrieve mass spectra similar to a query mass spectrum, the similarity score is calculated by a weighted cosine correlation in which weighting exponents on peak intensity and the mass-to-charge ratio are optimized to the ESI-MS(2) data. MassBank also provides a merged spectrum for each compound prepared by merging the analyzed ESI-MS(2) data on an identical compound under different collision-induced dissociation conditions. Data merging has significantly improved the precision of the identification of a chemical compound by 21-23% at a similarity score of 0.6. Thus, MassBank is useful for the identification of chemical compounds and the publication of experimental data.",massbank first public repositori mass spectra small chemic compound life scienc da databas contain electronion mass spectrometri eim fast atom bombard ms electrospray ioniz esimsn data authent compound metabolit eim otherm data volatil natur synthet compound esim data synthet drug contribut research group januari esim data analyz nonstandard independ experiment condit massbank distribut databas research group provid data massbank data server distribut internet massbank user access either massbank data subset data specifi one experiment condit spectral search retriev mass spectra similar queri mass spectrum similar score calcul weight cosin correl weight expon peak intens masstocharg ratio optim esim data massbank also provid merg spectrum compound prepar merg analyz esim data ident compound differ collisioninduc dissoci condit data merg significantli improv precis identif chemic compound similar score thu massbank use identif chemic compound public experiment data
f7d3f3a23c1b284a17adc93a922c56be38d221df,"On the Safety of Machine Learning: Cyber-Physical Systems, Decision Sciences, and Data Products","Machine learning algorithms increasingly influence our decisions and interact with us in all parts of our daily lives. Therefore, just as we consider the safety of power plants, highways, and a variety of other engineered socio-technical systems, we must also take into account the safety of systems involving machine learning. Heretofore, the definition of safety has not been formalized in a machine learning context. In this article, we do so by defining machine learning safety in terms of risk, epistemic uncertainty, and the harm incurred by unwanted outcomes. We then use this definition to examine safety in all sorts of applications in cyber-physical systems, decision sciences, and data products. We find that the foundational principle of modern statistical machine learning, empirical risk minimization, is not always a sufficient objective. We discuss how four different categories of strategies for achieving safety in engineering, including inherently safe design, safety reserves, safe fail, and procedural safeguards can be mapped to a machine learning context. We then discuss example techniques that can be adopted in each category, such as considering interpretability and causality of predictive models, objective functions beyond expected prediction accuracy, human involvement for labeling difficult or rare examples, and user experience design of software and open data.",machin learn algorithm increasingli influenc decis interact us part daili live therefor consid safeti power plant highway varieti engin sociotechn system must also take account safeti system involv machin learn heretofor definit safeti formal machin learn context articl defin machin learn safeti term risk epistem uncertainti harm incur unwant outcom use definit examin safeti sort applic cyberphys system decis scienc data product find foundat principl modern statist machin learn empir risk minim alway suffici object discuss four differ categori strategi achiev safeti engin includ inher safe design safeti reserv safe fail procedur safeguard map machin learn context discuss exampl techniqu adopt categori consid interpret causal predict model object function beyond expect predict accuraci human involv label difficult rare exampl user experi design softwar open data
1a62eb61b2663f8135347171e30cb9dc0a8931b5,pandas: a Foundational Python Library for Data Analysis and Statistics,"In this paper we will discuss pandas, a Python library of rich data structures and tools for working with structured data sets common to statistics, finance, social sciences, and many other fields. The library provides integrated, intuitive routines for performing common data manipulations and analysis on such data sets. It aims to be the foundational layer for the future of statistical computing in Python. It serves as a strong complement to the existing scientific Python stack while implementing and improving upon the kinds of data manipulation tools found in other statistical programming languages such as R. In addition to detailing its design and features of pandas, we will discuss future avenues of work and growth opportunities for statistics and data analysis applications in the Python language.",paper discuss panda python librari rich data structur tool work structur data set common statist financ social scienc mani field librari provid integr intuit routin perform common data manipul analysi data set aim foundat layer futur statist comput python serv strong complement exist scientif python stack implement improv upon kind data manipul tool found statist program languag r addit detail design featur panda discuss futur avenu work growth opportun statist data analysi applic python languag
f018f775d72bd86200cba2e623ae84449147f49f,Data integration in the era of omics: current and future challenges,,nan
69497049c77d8c49b1bf0a704d332fcc4a9b7a01,PLANETARY CANDIDATES OBSERVED BY KEPLER. III. ANALYSIS OF THE FIRST 16 MONTHS OF DATA,"New transiting planet candidates are identified in 16 months (2009 May–2010 September) of data from the Kepler spacecraft. Nearly 5000 periodic transit-like signals are vetted against astrophysical and instrumental false positives yielding 1108 viable new planet candidates, bringing the total count up to over 2300. Improved vetting metrics are employed, contributing to higher catalog reliability. Most notable is the noise-weighted robust averaging of multi-quarter photo-center offsets derived from difference image analysis that identifies likely background eclipsing binaries. Twenty-two months of photometry are used for the purpose of characterizing each of the candidates. Ephemerides (transit epoch, T0, and orbital period, P) are tabulated as well as the products of light curve modeling: reduced radius (RP/R⋆), reduced semimajor axis (d/R⋆), and impact parameter (b). The largest fractional increases are seen for the smallest planet candidates (201% for candidates smaller than 2 R⊕ compared to 53% for candidates larger than 2 R⊕) and those at longer orbital periods (124% for candidates outside of 50 day orbits versus 86% for candidates inside of 50 day orbits). The gains are larger than expected from increasing the observing window from 13 months (Quarters 1–5) to 16 months (Quarters 1–6) even in regions of parameter space where one would have expected the previous catalogs to be complete. Analyses of planet frequencies based on previous catalogs will be affected by such incompleteness. The fraction of all planet candidate host stars with multiple candidates has grown from 17% to 20%, and the paucity of short-period giant planets in multiple systems is still evident. The progression toward smaller planets at longer orbital periods with each new catalog release suggests that Earth-size planets in the habitable zone are forthcoming if, indeed, such planets are abundant.",new transit planet candid identifi month may septemb data kepler spacecraft nearli period transitlik signal vet astrophys instrument fals posit yield viabl new planet candid bring total count improv vet metric employ contribut higher catalog reliabl notabl noiseweight robust averag multiquart photocent offset deriv differ imag analysi identifi like background eclips binari twentytwo month photometri use purpos character candid ephemerid transit epoch orbit period p tabul well product light curv model reduc radiu rpr reduc semimajor axi dr impact paramet b largest fraction increas seen smallest planet candid candid smaller r compar candid larger r longer orbit period candid outsid day orbit versu candid insid day orbit gain larger expect increas observ window month quarter month quarter even region paramet space one would expect previou catalog complet analys planet frequenc base previou catalog affect incomplet fraction planet candid host star multipl candid grown pauciti shortperiod giant planet multipl system still evid progress toward smaller planet longer orbit period new catalog releas suggest earthsiz planet habit zone forthcom inde planet abund
a3b3a4d32c731522e36f6dc8307b6a48bee2fb51,Social media and the social sciences: How researchers employ Big Data analytics,"Social media posts are full of potential for data mining and analysis. Recognizing this potential, platform providers increasingly restrict free access to such data. This shift provides new challenges for social scientists and other non-profit researchers who seek to analyze public posts with a purpose of better understanding human interaction and improving the human condition. This paper seeks to outline some of the recent changes in social media data analysis, with a focus on Twitter, specifically. Using Twitter data from a 24-hour period following The Sisters in Spirit Candlelight Vigil, sponsored by the Native Women’s Association of Canada, this article compares three free-use Twitter application programming interfaces for capturing tweets and enabling analysis. Although recent Twitter data restrictions limit free access to tweets, there are many dynamic options for social scientists to choose from in the capture and analysis of Twitter and other social media platform data. This paper calls for critical social media data analytics combined with traditional, qualitative methods to address the developing ‘data gold rush.’",social media post full potenti data mine analysi recogn potenti platform provid increasingli restrict free access data shift provid new challeng social scientist nonprofit research seek analyz public post purpos better understand human interact improv human condit paper seek outlin recent chang social media data analysi focu twitter specif use twitter data hour period follow sister spirit candlelight vigil sponsor nativ women associ canada articl compar three freeus twitter applic program interfac captur tweet enabl analysi although recent twitter data restrict limit free access tweet mani dynam option social scientist choos captur analysi twitter social media platform data paper call critic social media data analyt combin tradit qualit method address develop data gold rush
e50bf4ae589d0afd8ed54ad357c0ace3acb668a6,Promises and Challenges of Big Data Computing in Health Sciences,,nan
71f0cee4a4d848be2561ec3808d0bea28c536494,Mars Science Laboratory Mission and Science Investigation,,nan
dc32cfebb82aaab6ac5c6b3407d0a3233d80aa0e,Statistical and Econometric Methods for Transportation Data Analysis,"In each chapter the authors present an example (from the health sciences), followed by a discussion on how to summarize the data. The assumptions of the models are stated, and useful information is given on how to check whether these assumptions are met or not and what to do when they are not satisfied. I noticed from the beginning that this text has examples only from the health sciences, making it more useful for students and researchers from that field. I am surprised that the title of this text did not reflect this fact. A more fitting title would have been something like Analysis of Variance and Regression for the Health Sciences: A Consulting Approach. It should be mentioned that no statistical software packages are discussed in the text and no software outputs are explained. I wish that the authors had illustrated some of the in-depth methods used with some software output and explanations. I was positively impressed by the authors’ repeated coverage of what to do when data do not fit the model. I found most of the material covered in this text accurate, but I am not happy with the multiple regression part of the text. The methods presented on variable selection are either outdated (e.g., forward selection, backward elimination, or stepwise) or are presented in a very condensed way. The authors do not present material on multicollinearity, except for a few lines. I would revisit the subsection on the equality of population variances within the section on checking whether the data fit the one-way ANOVA model. The authors briefly mention Levene’s test (and its modified Brown and Forsythe version) but do not mention Bartlett’s test or Hartley’s test, both of which are usually far more powerful tests than Levene’s test for normal data. The equality of variances is very important for the ANOVA model, and more material is needed here. My overall impression of this text is that it contains a wealth of useful upto-date information and examples from the health sciences. However, I find the presentation of material in this text difficult to follow for students. There are no summary “boxes” given to present important results or formulas. You have to fish for information throughout the text. The material is being presented as if you were sitting with a statistical consultant who is going over your research project and providing you with the necessary information to analyze your dataset. Maybe this approach is refreshing in the eyes of some users, but some may view it as a “cookbook” approach. I am not confident that this text would be suitable for second courses in statistics for the health sciences (or other fields). It is most likely very useful for applied researchers who need to review their statistical information as they work on projects that require statistical analysis. I know that I will be using examples from this text to support some of my future statistics courses, but I am unsure whether my students would be happy with this text.",chapter author present exampl health scienc follow discuss summar data assumpt model state use inform given check whether assumpt met satisfi notic begin text exampl health scienc make use student research field surpris titl text reflect fact fit titl would someth like analysi varianc regress health scienc consult approach mention statist softwar packag discuss text softwar output explain wish author illustr indepth method use softwar output explan posit impress author repeat coverag data fit model found materi cover text accur happi multipl regress part text method present variabl select either outdat eg forward select backward elimin stepwis present condens way author present materi multicollinear except line would revisit subsect equal popul varianc within section check whether data fit oneway anova model author briefli mention leven test modifi brown forsyth version mention bartlett test hartley test usual far power test leven test normal data equal varianc import anova model materi need overal impress text contain wealth use uptod inform exampl health scienc howev find present materi text difficult follow student summari box given present import result formula fish inform throughout text materi present sit statist consult go research project provid necessari inform analyz dataset mayb approach refresh eye user may view cookbook approach confid text would suitabl second cours statist health scienc field like use appli research need review statist inform work project requir statist analysi know use exampl text support futur statist cours unsur whether student would happi text
6bd7a682d2ab15d3479d01cddaa921a0ae569bf8,Measurements of Energetic Particle Radiation in Transit to Mars on the Mars Science Laboratory,"Going to Mars The Mars Science Laboratory spacecraft containing the Curiosity rover, was launched from Earth in November 2011 and arrived at Gale crater on Mars in August 2012. Zeitlin et al. (p. 1080) report measurements of the energetic particle radiation environment inside the spacecraft during its cruise to Mars, confirming the hazard likely to be posed by this radiation to astronauts on a future potential trip to Mars. Williams et al. (p. 1068, see the Perspective by Jerolmack) report the detection of sedimentary conglomerates (pebbles mixed with sand and turned to rock) at Gale crater. The rounding of the rocks suggests abrasion of the pebbles as they were transported by flowing water several kilometers or more from their source. The radiation dose on a round-trip to Mars could represent a large fraction of the accepted lifetime limit for astronauts. The Mars Science Laboratory spacecraft, containing the Curiosity rover, was launched to Mars on 26 November 2011, and for most of the 253-day, 560-million-kilometer cruise to Mars, the Radiation Assessment Detector made detailed measurements of the energetic particle radiation environment inside the spacecraft. These data provide insights into the radiation hazards that would be associated with a human mission to Mars. We report measurements of the radiation dose, dose equivalent, and linear energy transfer spectra. The dose equivalent for even the shortest round-trip with current propulsion systems and comparable shielding is found to be 0.66 ± 0.12 sievert.",go mar mar scienc laboratori spacecraft contain curios rover launch earth novemb arriv gale crater mar august zeitlin et al p report measur energet particl radiat environ insid spacecraft cruis mar confirm hazard like pose radiat astronaut futur potenti trip mar william et al p see perspect jerolmack report detect sedimentari conglomer pebbl mix sand turn rock gale crater round rock suggest abras pebbl transport flow water sever kilomet sourc radiat dose roundtrip mar could repres larg fraction accept lifetim limit astronaut mar scienc laboratori spacecraft contain curios rover launch mar novemb day millionkilomet cruis mar radiat assess detector made detail measur energet particl radiat environ insid spacecraft data provid insight radiat hazard would associ human mission mar report measur radiat dose dose equival linear energi transfer spectra dose equival even shortest roundtrip current propuls system compar shield found sievert
3bdbcbfba7ab3e40265580da8c5701bef8fb5f70,Electron Backscatter Diffraction in Materials Science,,nan
d29132482931f3dca1976e5b9c468647302deb6e,Interpreting qualitative data : a guide to the principles of qualitative research,PART ONE: THEORY AND METHOD IN QUALITATIVE RESEARCH What Is Qualitative Research? In Search of a Working Definition Loaded Evaluations of Research Methods Methods Should Fit Your Research Question The Good Sense of Quantitative Research The Nonsense of Quantitative Research The Good Sense of Qualitative Research The Nonsense of Qualitative Research Varieties of Qualitative Research Designing a Research Project Selecting a Topic Formulating a Researchable Question Fitting your Research Question into an Appropriate Theory Choosing an Effective Research Design An Effective Literature Review Basic Terms in Research Design Conclusions Data Analysis Some Rules for Data Analysis Content Analysis Grounded Theory Narrative Analysis Conclusion Research Ethics Ethical Pitfalls Ethical Safeguards Some Ethical Complications PART TWO: METHODS Ethnography and Observation The Ethnographic Focus Methodological Issues The Theoretical Character of Ethnographic Observations Conclusion: The Unity of the Ethnographic Project Interviews What Is an 'Open-Ended' Interview? Why Interview? Implications: Three Versions of Interview Data Positivism Emotionalism Constructionism Adolescent Cultures: Combining 'What' and 'How' Questions Moral Tales of Parenthood The Three Models: A Summary Summary: Basic Issues Three Practical Questions - and Answers Conclusion Focus Groups What Are Focus Groups? Analysing Focus Group Data in Social Science Form or Substance? Concluding Comments Texts Structure of This Chapter Comparative Keyword Analysis (CKA) Ethnography Ethnomethodology: Membership Categorisation Analysis Conclusion Naturally-Occurring Talk Why Work with Tapes? Transcribing Audiotapes Why Talk Matters Conversation Analysis Discourse Analysis Conversation Analysis and Discourse Analysis Compared Conclusion Visual Images Kinds of Visual Data Research Strategies Content Analysis Semiotics Workplace Studies Conclusion PART THREE: RESEARCH PRACTICE Credible Qualitative Research Does Credibility Matter? Reliability Validity Generalisability Conclusions Writing Your Report Beginnings Your Literature Review Your Methodology Section Writing Up Your Data Your Final Section A Short Note on Plagiarism Self-Expression or Argument? PART FOUR: IMPLICATIONS The Relevance of Qualitative Research Three Roles for the Social Scientist The Audiences for Qualitative Research The Contribution of Qualitative Social Science Summary Conclusion The Potential of Qualitative Research: Eight Reminders Take Advantage of Naturally Occurring Data Avoid Treating the Actor's Point of View as an Explanation Study the Interrelationships Between Elements Attempt Theoretically Fertile Research Address Wider Audiences Begin With 'How' Questions Then Ask 'Why?' Study 'Hyphenated' Phenomena Treat Qualitative Research as Different from Journalism Concluding Remarks,part one theori method qualit research qualit research search work definit load evalu research method method fit research question good sens quantit research nonsens quantit research good sens qualit research nonsens qualit research varieti qualit research design research project select topic formul research question fit research question appropri theori choos effect research design effect literatur review basic term research design conclus data analysi rule data analysi content analysi ground theori narr analysi conclus research ethic ethic pitfal ethic safeguard ethic complic part two method ethnographi observ ethnograph focu methodolog issu theoret charact ethnograph observ conclus uniti ethnograph project interview openend interview interview implic three version interview data positiv emotion construction adolesc cultur combin question moral tale parenthood three model summari summari basic issu three practic question answer conclus focu group focu group analys focu group data social scienc form substanc conclud comment text structur chapter compar keyword analysi cka ethnographi ethnomethodolog membership categoris analysi conclus naturallyoccur talk work tape transcrib audiotap talk matter convers analysi discours analysi convers analysi discours analysi compar conclus visual imag kind visual data research strategi content analysi semiot workplac studi conclus part three research practic credibl qualit research credibl matter reliabl valid generalis conclus write report begin literatur review methodolog section write data final section short note plagiar selfexpress argument part four implic relev qualit research three role social scientist audienc qualit research contribut qualit social scienc summari conclus potenti qualit research eight remind take advantag natur occur data avoid treat actor point view explan studi interrelationship element attempt theoret fertil research address wider audienc begin question ask studi hyphen phenomena treat qualit research differ journal conclud remark
cd4a32103ed6560b34df75bd34ab1ca23062cdb0,Metadata matters: access to image data in the real world,"Data sharing is important in the biological sciences to prevent duplication of effort, to promote scientific integrity, and to facilitate and disseminate scientific discovery. Sharing requires centralized repositories, and submission to and utility of these resources require common data formats. This is particularly challenging for multidimensional microscopy image data, which are acquired from a variety of platforms with a myriad of proprietary file formats (PFFs). In this paper, we describe an open standard format that we have developed for microscopy image data. We call on the community to use open image data standards and to insist that all imaging platforms support these file formats. This will build the foundation for an open image data repository.",data share import biolog scienc prevent duplic effort promot scientif integr facilit dissemin scientif discoveri share requir central repositori submiss util resourc requir common data format particularli challeng multidimension microscopi imag data acquir varieti platform myriad proprietari file format pff paper describ open standard format develop microscopi imag data call commun use open imag data standard insist imag platform support file format build foundat open imag data repositori
74efcb15d3ab7d36afad656beed88c8e940596e0,What “ideas‐about‐science” should be taught in school science? A Delphi study of the expert community,"Recent arguments in science education have proposed that school science should pay more attention to teaching the nature of science and its social practices. However, unlike the content of science, for which there is well-established consensus, there would appear to be much less unanimity within the academic community about which ideas-about-science are essential elements that should be included in the contemporary school science curriculum. Hence, this study sought to determine empirically the extent of any consensus using a three stage Delphi questionnaire with 23 participants drawn from the communities of leading and acknowledged international experts of science educators; scientists; historians, philosophers, and sociologists of science; experts engaged in work to improve the public understanding of science; and expert science teachers. The outcome of the research was a set of nine themes encapsulating key ideas about the nature of science for which there was consensus and which were considered to be an essential component of school science curriculum. Together with extensive comments provided by the participants, these data give some measure of the existing level of agreement in the community engaged in science education and science communication about the salient features of a vulgarized account of the nature of science. Although some of the themes are already a feature of existing school science curricula, many others are not. The findings of this research, therefore, challenge (a) whether the picture of science represented in the school science curriculum is sufficiently comprehensive, and (b) whether there balance in the curriculum between teaching about the content of science and the nature of science is appropriate.",recent argument scienc educ propos school scienc pay attent teach natur scienc social practic howev unlik content scienc wellestablish consensu would appear much less unanim within academ commun ideasaboutsci essenti element includ contemporari school scienc curriculum henc studi sought determin empir extent consensu use three stage delphi questionnair particip drawn commun lead acknowledg intern expert scienc educ scientist historian philosoph sociologist scienc expert engag work improv public understand scienc expert scienc teacher outcom research set nine theme encapsul key idea natur scienc consensu consid essenti compon school scienc curriculum togeth extens comment provid particip data give measur exist level agreement commun engag scienc educ scienc commun salient featur vulgar account natur scienc although theme alreadi featur exist school scienc curricula mani other find research therefor challeng whether pictur scienc repres school scienc curriculum suffici comprehens b whether balanc curriculum teach content scienc natur scienc appropri
78a0cc5df515048d75ffe35203eab2ead1b5f678,Statistics for Censored Environmental Data Using Minitab and R,"Praise for the First Edition"" . . . an excellent addition to an upper-level undergraduate course on environmental statistics, and . . . a 'must-have' desk reference for environmental practitioners dealing with censored datasets."" Vadose Zone JournalStatistical Methods for Censored Environmental Data Using Minitab and R, Second Edition introduces and explains methods for analyzing and interpreting censored data in the environmental sciences. Adapting survival analysis techniques from other fields, the book translates well-established methods from other disciplines into new solutions for environmental studies. This new edition applies methods of survival analysis, including methods for interval-censored data to the interpretation of low-level contaminants in environmental sciences and occupational health. Now incorporating the freely available R software as well as Minitab into the discussed analyses, the book features newly developed and updated material including: A new chapter on multivariate methods for censored data Use of interval-censored methods for treating true nondetects as lower than and separate from values between the detection and quantitation limits (""remarked data"") A section on summing data with nondetects A newly written introduction that discusses invasive data, showing why substitution methods fail Expanded coverage of graphical methods for censored data The author writes in a style that focuses on applications rather than derivations, with chapters organized by key objectives such as computing intervals, comparing groups, and correlation. Examples accompany each procedure, utilizing real-world data that can be analyzed using the Minitab and R software macros available on the book's related website, and extensive references direct readers to authoritative literature from the environmental sciences.Statistics for Censored Environmental Data Using Minitab and R, Second Edition is an excellent book for courses on environmental statistics at the upper-undergraduate and graduate levels. The book also serves as a valuable reference for?environmental professionals, biologists, and ecologists who focus on the water sciences, air quality, and soil science.",prais first edit excel addit upperlevel undergradu cours environment statist musthav desk refer environment practition deal censor dataset vados zone journalstatist method censor environment data use minitab r second edit introduc explain method analyz interpret censor data environment scienc adapt surviv analysi techniqu field book translat wellestablish method disciplin new solut environment studi new edit appli method surviv analysi includ method intervalcensor data interpret lowlevel contamin environment scienc occup health incorpor freeli avail r softwar well minitab discuss analys book featur newli develop updat materi includ new chapter multivari method censor data use intervalcensor method treat true nondetect lower separ valu detect quantit limit remark data section sum data nondetect newli written introduct discuss invas data show substitut method fail expand coverag graphic method censor data author write style focus applic rather deriv chapter organ key object comput interv compar group correl exampl accompani procedur util realworld data analyz use minitab r softwar macro avail book relat websit extens refer direct reader authorit literatur environment sciencesstatist censor environment data use minitab r second edit excel book cours environment statist upperundergradu graduat level book also serv valuabl refer forenvironment profession biologist ecologist focu water scienc air qualiti soil scienc
ed88ab30162e3fb43fb0c7cec598202b1cb4516d,Data Sciences,"Machine learning is a highly influential field that has made major contributions to the increased effectiveness of artificial intelligence. Machine learning utilizes different methods, four of which have been particularly effective. The Analogizers classify patterns based on their similarity to other patterns. Multidimensional scaling provides support. The Bayesians revise the probability of hypotheses based on new evidence. The Connectionists adjust the strength between layers of “neurons.” Deep leaning based on many layers of connections has proven particularly successful. The Symbolists use rules that combine pieces of pre-existing knowledge. Hybrid systems combine these methods to create systems that are more effective than individual methods.",machin learn highli influenti field made major contribut increas effect artifici intellig machin learn util differ method four particularli effect analog classifi pattern base similar pattern multidimension scale provid support bayesian revis probabl hypothes base new evid connectionist adjust strength layer neuron deep lean base mani layer connect proven particularli success symbolist use rule combin piec preexist knowledg hybrid system combin method creat system effect individu method
8047db76d3244204520d2e809a5a7787e62e9c24,The Wiley/NBS registry of mass spectral data,"Mass spectrometry is used extensively to identify unkown chemicals in almost all areas of chemistry, biochemistry, medical chemistry, and the environmental sciences. This massive work has been compiled and written by two acknowledged leaders in their field. McLafferty and Stauffer are the authors of two previous books on mass spectral data, and of various database versions of the data--but the present 7-volume work, Registry of Mass Spectral Data, 2nd Edition is, by far, the most complete and up-to-date collection of mass spectra available in book form. In it are presented the registry spectra for 108,173 compounds.",mass spectrometri use extens identifi unkown chemic almost area chemistri biochemistri medic chemistri environment scienc massiv work compil written two acknowledg leader field mclafferti stauffer author two previou book mass spectral data variou databas version databut present volum work registri mass spectral data nd edit far complet uptod collect mass spectra avail book form present registri spectra compound
41be484549d47db42bf3baea98b7997eab6e7125,Statistical Analysis of Spherical Data.,"This is the first comprehensive, yet clearly presented, account of statistical methods for analysing spherical data. The analysis of data, in the form of directions in space or of positions of points on a spherical surface, is required in many contexts in the earth sciences, astrophysics and other fields, yet the methodology required is disseminated throughout the literature. Statistical Analysis of Spherical Data aims to present a unified and up-to-date account of these methods for practical use. The emphasis is on applications rather than theory, with the statistical methods being illustrated throughout the book by data examples.",first comprehens yet clearli present account statist method analys spheric data analysi data form direct space posit point spheric surfac requir mani context earth scienc astrophys field yet methodolog requir dissemin throughout literatur statist analysi spheric data aim present unifi uptod account method practic use emphasi applic rather theori statist method illustr throughout book data exampl
d24878e31ec57d701385a386a2812e92e081e765,Qualitative research methods: a data collectors field guide.,Qualitative research methods are gaining in popularity outside the traditional academic social sciences particularly in public health and international development research. Whereas quantitative research methods once dominated these fields researchers have now begun drawing from a more diverse repertoire of methodologies as they tackle international public health problems. Qualitative methods have become important tools within this broader approach to applied research in large part because they provide valuable insights into the local perspectives of study populations. The great contribution of qualitative research is the culturally specific and contextually rich data it produces. Such data are proving critical in the design of comprehensive solutions to public health problems in developing countries as scientists medical doctors pharmaceutical companies and humanitarian organizations have come to recognize that biomedical solutions are only partial remedies. Rather the success of a health intervention -- that is whether it actually reaches the people it is intended to help -- rests also on how well it addresses sociobehavioral factors such as cultural norms ethnic identities gender norms stigma and socioeconomic status. Success measured on this basis has a bearing in turn on the cost-effectiveness efficiency and efficacy of interventions concerns not insignificant in the eyes of project managers and funding agencies. (excerpt),qualit research method gain popular outsid tradit academ social scienc particularli public health intern develop research wherea quantit research method domin field research begun draw divers repertoir methodolog tackl intern public health problem qualit method becom import tool within broader approach appli research larg part provid valuabl insight local perspect studi popul great contribut qualit research cultur specif contextu rich data produc data prove critic design comprehens solut public health problem develop countri scientist medic doctor pharmaceut compani humanitarian organ come recogn biomed solut partial remedi rather success health intervent whether actual reach peopl intend help rest also well address sociobehavior factor cultur norm ethnic ident gender norm stigma socioeconom statu success measur basi bear turn costeffect effici efficaci intervent concern insignific eye project manag fund agenc excerpt
f5a059e8f50ae137e0146fbf32e199d8c6dcb83a,Social Network Data Analytics,,nan
e81194700e924dc0899281040f5c8de59d1c7222,Discourse as Data: A Guide for Analysis,"This workbook will be invaluable for students across the social sciences who need to learn how to analyze discourse. Using a step-by-step approach, students are introduced to the principal range of methods for analyzing different types of text, taken through key analytic concepts, offered specimen analyses and given the opportunity to try out analytic concepts on new data. 
 
 
Discourse as Data is organized around eight chapters, six of which are related to the domains covered in the Reader, and top and tailed by two chapters which set up common methodological issues in discourse research relevant to all approaches (such as transcription and the application and the critical evaluation of discourse research). 
 
 
Though the text will be a perfect companion to the simultaneously published Reader, its broad coverage, combined with didactic, practical guidance should make this important reading for any student or researcher wishing to learn more about discourse analysis. 
 
 
This book will be ideal as a teaching tool, and an invaluable aid on discourse analysis courses, which have a practical content, most notably within the fields of psychology, cultural and media studies, sociology and linguistics.",workbook invalu student across social scienc need learn analyz discours use stepbystep approach student introduc princip rang method analyz differ type text taken key analyt concept offer specimen analys given opportun tri analyt concept new data discours data organ around eight chapter six relat domain cover reader top tail two chapter set common methodolog issu discours research relev approach transcript applic critic evalu discours research though text perfect companion simultan publish reader broad coverag combin didact practic guidanc make import read student research wish learn discours analysi book ideal teach tool invalu aid discours analysi cours practic content notabl within field psycholog cultur media studi sociolog linguist
847daf424eac68d822542e91dfe995c6fa257065,Undergraduate research experiences support science career decisions and active learning.,"The present study examined the reliability of student evaluations of summer undergraduate research experiences using the SURE (Survey of Undergraduate Research Experiences) and a follow-up survey disseminated 9 mo later. The survey further examines the hypothesis that undergraduate research enhances the educational experience of science undergraduates, attracts and retains talented students to careers in science, and acts as a pathway for minority students into science careers. Undergraduates participated in an online survey on the benefits of undergraduate research experiences. Participants indicated gains on 20 potential benefits and reported on career plans. Most of the participants began or continued to plan for postgraduate education in the sciences. A small group of students who discontinued their plans for postgraduate science education reported significantly lower gains than continuing students. Women and men reported similar levels of benefits and similar patterns of career plans. Undergraduate researchers from underrepresented groups reported higher learning gains than comparison students. The results replicated previously reported data from this survey. The follow-up survey indicated that students reported gains in independence, intrinsic motivation to learn, and active participation in courses taken after the summer undergraduate research experience.",present studi examin reliabl student evalu summer undergradu research experi use sure survey undergradu research experi followup survey dissemin mo later survey examin hypothesi undergradu research enhanc educ experi scienc undergradu attract retain talent student career scienc act pathway minor student scienc career undergradu particip onlin survey benefit undergradu research experi particip indic gain potenti benefit report career plan particip began continu plan postgradu educ scienc small group student discontinu plan postgradu scienc educ report significantli lower gain continu student women men report similar level benefit similar pattern career plan undergradu research underrepres group report higher learn gain comparison student result replic previous report data survey followup survey indic student report gain independ intrins motiv learn activ particip cours taken summer undergradu research experi
